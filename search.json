[{"title":"MarkovNote","url":"/notes.github.io/2025/06/23/MarkovNote/","content":"幂迭代的特例：随机游走与马尔可夫链\n1. 马尔可夫链的基本概念\n**马尔可夫链（Markov Chain）**是一种随机过程，具有“无记忆性”或“马尔可夫性质”。这意味着未来状态的概率分布只依赖于当前状态，而与之前的历史状态无关。形式上，对于一个离散时间的马尔可夫链，满足：\n[ P(X_{n+1} = x | X_n = x_n, X_{n-1} = x_{n-1}, \\dots, X_0 = x_0) = P(X_{n+1} = x | X_n = x_n) ]\n对于有限的马尔可夫链，状态空间（所有可能的状态）是有限的，可以表示为 ( S = {s_1, s_2, \\dots, s_n} )。\n2. 有向图与马尔可夫链的关系\n一个有限的马尔可夫链可以表示为一个有向图（directed graph），其中：\n\n顶点（Vertices）：代表马尔可夫链的状态。\n边（Edges）：如果从状态 ( i ) 到状态 ( j ) 的转移概率 ( P_{ij} &gt; 0 )，则存在一条从 ( i ) 到 ( j ) 的有向边。\n\n这个有向图称为马尔可夫链的状态转移图。\n3. 强连通图的定义与性质\n**强连通图（Strongly Connected Graph）**是指：\n\n对于图中的任意两个顶点 ( u ) 和 ( v )，存在从 ( u ) 到 ( v ) 的路径，也存在从 ( v ) 到 ( u ) 的路径。\n\n换句话说，强连通图意味着图中的任何两个状态都是相互可达的。\n4. 不可约马尔可夫链的含义与重要性\n**不可约马尔可夫链（Irreducible Markov Chain）**的定义是：如果其对应的有向图是强连通的，则称该马尔可夫链是不可约的。\n解释：\n\n\n不可约性意味着马尔可夫链的状态空间不能被分成两个或更多的不相交的子集，使得链一旦进入某个子集就永远无法离开。换句话说，从任何状态出发，都有到达任何其他状态的可能（可能在多步之后）。\n\n\n重要性：\n\n不可约性是马尔可夫链许多重要性质的基础。例如，不可约的有限马尔可夫链总是具有唯一的平稳分布。\n它确保了链的“遍历性”（ergodicity），即在长期运行中，链会访问所有状态，且频率趋于稳定。\n\n\n\n对于一个不可约且非周期的马尔可夫链，我们证明存在足够大的常数( T &lt; \\infty )，使得对任意状态( i, j )和所有时间( t \\geq T )，有( P^t_{i,j} &gt; 0 )。以下是详细证明过程：\n\n定理：若一个马尔可夫链不可约且非周期，则存在常数( T &lt; \\infty )，使得对任意状态( i, j )及所有时间( t \\geq T )，有( P^t_{i,j} &gt; 0 )。\n\n证明：\n步骤1：非周期性的应用——证明每个状态的自返回时间无上界\n设状态空间为有限集( \\mathcal{S} )，每个状态( i )的周期定义为：\n[\nd(i) = \\gcd{ t \\geq 1 \\mid P^t_{i,i} &gt; 0 }.\n]\n由于链是非周期的，故对任意( i \\in \\mathcal{S} )，有( d(i) = 1 )。令：\n[\nS_i = { t \\geq 1 \\mid P^t_{i,i} &gt; 0 },\n]\n则( \\gcd(S_i) = 1 )。根据数论中的Schur定理，若一组正整数的最大公约数为1，则存在整数( N_i )，使得对所有( t \\geq N_i )，( t )可表示为( S_i )中元素的线性组合（系数为非负整数）。因此：\n[\n\\forall t \\geq N_i, \\quad P^t_{i,i} &gt; 0.\n]\n步骤2：统一自返回时间的下界\n由于状态空间有限，设( \\mathcal{S} = {1, 2, \\dots, n} )，取：\n[\nK = \\max{ N_1, N_2, \\dots, N_n }.\n]\n则对所有( i \\in \\mathcal{S} )和( t \\geq K )，均有：\n[\nP^t_{i,i} &gt; 0.\n]\n步骤3：不可约性的应用——确定状态间转移步数\n由不可约性，对任意状态( i, j )，存在正整数( m_{i,j} )使得：\n[\nP^{m_{i,j}}{i,j} &gt; 0.\n]\n定义：\n[\nM = \\max{ m{i,j} \\mid \\forall i, j \\in \\mathcal{S} }.\n]\n由于状态空间有限，( M )为有限值。\n步骤4：构造全局常数( T )并验证结论\n令：\n[\nT = K + M.\n]\n对任意( t \\geq T )，可分解( t )为：\n[\nt = m_{i,j} + s, \\quad \\text{其中} \\ s = t - m_{i,j} \\geq T - M = K.\n]\n根据Chapman-Kolmogorov方程：\n[\nP^t_{i,j} = \\sum_{k \\in \\mathcal{S}} P^{m_{i,j}}{i,k} P^{s}{k,j} \\geq P^{m_{i,j}}{i,j} \\cdot P^{s}{j,j}.\n]\n由于：\n\n( P^{m_{i,j}}_{i,j} &gt; 0 )（不可约性），\n( s \\geq K \\implies P^{s}_{j,j} &gt; 0 )（步骤2），\n\n因此：\n[\nP^t_{i,j} \\geq P^{m_{i,j}}{i,j} \\cdot P^{s}{j,j} &gt; 0, \\quad \\forall t \\geq T.\n]\n\n关键点总结：\n\n非周期性通过Schur定理确保自返回时间覆盖所有充分大的整数。\n有限状态空间允许统一自返回时间下界( K )和最大转移步数( M )。\n不可约性保证任意状态间存在有限步转移路径，结合自返回正概率，导出全局正概率。\n\n\n注：若状态空间为无限，需额外论证( K )和( M )的存在性，但本证明默认有限状态空间。\n\n马尔可夫链基本定理的直观解释与严格证明\n对于有限状态空间、不可约且非周期的马尔可夫链，其核心性质可总结如下：\n\n1. 存在唯一的稳态分布𝜋\n\n不可约性：任意两状态可通过有限步转移到达，保证了链的连通性。\n非周期性：每个状态的自返回时间无周期限制，避免震荡。\n有限状态空间：结合上述两点，转移矩阵( P )最终成为正则矩阵（存在( T )使得( P^T )所有元素正）。\n\n严格结论：\n\n存在唯一平稳分布( \\pi )，满足( \\pi P = \\pi )。\n稳态概率( \\pi(i) )等于状态( i )的长期访问频率，即：\n[\n\\pi(i) = \\frac{1}{h_i},\n]\n其中( h_i = \\mathbb{E}[\\text{首次返回状态} , i , \\text{的时间} , | , X_0 = i] )。\n\n\n2. 收敛到稳态分布\n无论初始分布( p_0 )如何，随着时间( t \\to \\infty )，分布( p_t = p_0 P^t )必然收敛到( \\pi )。\n直观理解：\n\n非周期性和不可约性使得链在足够长时间后“忘记”初始状态。\n状态间的频繁转移导致分布趋于平衡。\n\n\n3. 耦合论证（Coupling Argument）\n通过构造两个独立运行的马尔可夫链( X_t )和( Y_t )，证明它们最终会相遇并同步，从而严格推导收敛性。\n以下是基于耦合论证（Coupling Argument）的马尔可夫链收敛性证明的完整严谨过程：\n\n耦合论证的构造与证明步骤\n1. 基本假设与条件\n设马尔可夫链满足以下条件：\n\n不可约性（Irreducible）：任意两状态互通。\n非周期性（Aperiodic）：不存在固定周期循环。\n正常返性（Positive Recurrent）：所有状态的平均返回时间有限。\n\n2. 构造耦合马尔可夫链\n定义两个独立运行的马尔可夫链 ( X_t ) 和 ( Y_t )，其状态空间相同：\n\n( X_t )：初始分布为任意概率分布 ( \\mu_0 )。\n( Y_t )：初始分布为平稳分布 ( \\pi )。\n\n构造联合马尔可夫链 ( (X_t, Y_t) )，其转移概率满足：\n\n当 ( X_t \\neq Y_t ) 时，两链独立转移，即联合转移概率为 ( P(X_{t+1}=x’, Y_{t+1}=y’) = P(x, x’) \\cdot P(y, y’) )。\n当 ( X_t = Y_t ) 时，强制同步转移，即 ( X_{t+1} = Y_{t+1} )。\n\n3. 定义相遇时间\n设首次相遇时间为停时 ( T = \\inf{ t \\geq 0: X_t = Y_t } )。根据不可约性和正常返性，可证明 ( T &lt; \\infty ) 几乎必然成立。\n4. 同步后的行为一致性\n当 ( t \\geq T ) 时，由于同步机制，( X_t = Y_t ) 对所有后续时间成立。因此，两链在 ( T ) 后的演化完全一致。\n5. 收敛性推导\n通过比较两链的分布差异：\n\n对任意时间 ( t )，有：\n[\n| \\mu_t - \\pi |_{\\text{TV}} \\leq 2P(T &gt; t),\n]\n其中 ( \\mu_t ) 是 ( X_t ) 的分布，( \\pi ) 是 ( Y_t ) 的平稳分布。\n由于 ( T ) 几乎必然有限，当 ( t \\to \\infty ) 时，( P(T &gt; t) \\to 0 )，故：\n[\n\\lim_{t \\to \\infty} | \\mu_t - \\pi |_{\\text{TV}} = 0.\n]\n\n6. 平稳分布的唯一性\n若存在另一平稳分布 ( \\pi’ )，通过耦合 ( Y_t )（初始化为 ( \\pi’ )）与 ( X_t )（初始化为 ( \\pi )），可证 ( \\pi = \\pi’ )，从而唯一性得证。\n\n关键引理与数学工具\n\n不可约性与正常返性：确保状态空间连通且所有状态可无限次访问。\n停时理论：通过 ( T ) 的有限性将收敛性问题转化为概率衰减问题。\n全变差距离（Total Variation Distance）：量化分布差异的上界。\nPerron-Frobenius定理：用于证明转移矩阵主特征值对应平稳分布的存在性（有限状态空间）。\n\n\n应用条件与反例\n\n正则马尔可夫链：若转移矩阵 ( P ) 满足存在 ( n ) 使 ( P^n ) 无零元素，则收敛性成立。\n反例：周期性链（如 ( P = \\begin{pmatrix}0 &amp; 1 \\ 1 &amp; 0\\end{pmatrix} )）或可约链（如吸收态存在）不满足收敛条件。\n\n\n4. 稳态分布与期望回归时间的关系\n直观解释：\n\n期望回归时间( h_i )：从状态( i )出发，首次返回( i )的平均时间。\n长期访问频率：在无限时间中，访问状态( i )的频率为( 1/h_i )，故稳态概率( \\pi(i) = 1/h_i )。\n\n严格推导（Kac引理）：\n\n对于不可约常返链，有：\n[\n\\pi(i) = \\frac{1}{h_i}, \\quad \\text{其中} \\quad h_i = \\mathbb{E}[T_i \\mid X_0 = i].\n]\n证明思路：通过更新过程计算长期平均访问次数，利用强大数定律得到频率极限。\n\n\n5. 唯一性的保证\n若存在两个不同的平稳分布( \\pi )和( \\pi’ )，通过耦合论证：\n\n构造初始分布为( \\pi )和( \\pi’ )的两个链，它们最终必相遇并同步。\n因此( \\pi = \\pi’ )，矛盾，唯一性得证。\n\n\n总结：\n\n不可约性与非周期性确保链的遍历性，消除周期性震荡。\n耦合技术将直观的“相遇”转化为严格收敛性证明。\n期望回归时间量化了状态的访问频率，直接决定稳态分布。\n\n此框架不仅适用于有限状态链，还可推广到某些可数状态空间的情形，但需额外验证回归时间的有限性。\n","tags":["其他"]},{"title":"FFT_Notes","url":"/notes.github.io/2025/06/23/FFT_Notes/","content":"好的，以下是包含更完整思维过程的详细解答。\n\n(17分)\n\n已知 $n \\in \\mathbb{N}^*$ 且 $n \\ge 3$, 集合 $A_n = {a_1, a_2, \\dots, a_n}$, 其中 $0 &lt; a_1 &lt; a_2 &lt; \\dots &lt; a_n$.\n若存在函数 $f(x)$ ($f(x) \\ne x$), 其图像在区间 $D = [a_1, a_n]$ 上是一段连续曲线，且 ${f(a_i)|a_i \\in A_n} = A_n$, 则称 $f(x)$ 是 $A_n$ 的T变换函数，集合 $A_n$ 是 $D$ 的T子集. 例如，\n设 $A_5 = {\\frac{2}{3}, 1, \\sqrt{2}, 2, 3}$, 此时函数 $f(x) = \\frac{2}{x}$ 是 $A_5$ 的T变换函数，$A_5$ 是 $[\\frac{2}{3}, 3]$ 的T子集.\n(1) 判断集合 ${1, 2, 8, 9}$ 是否是 $[1, 9]$ 的T子集? 说明理由;\n(2) 判断 $f(x) = \\ln(1 + \\frac{2}{e^x})$ 是否为集合 $A_n$ 的T变换函数? 说明理由;\n(3) 若 $a_i &lt; a_j$ ($i, j \\in \\mathbb{N}^*, 1 \\le i &lt; j \\le n$), 则 $\\frac{a_j}{a_i} \\in A_n$, 试问是否存在函数 $f(x)$, 使得集合 $A_n$ 是 $D = [a_1, a_n]$ 的T子集? 若存在，求 $f(x)$ 的解析式; 若不存在，说明理由.\n详细解答：\n(1) 判断集合 ${1, 2, 8, 9}$ 是否是 $[1, 9]$ 的T子集? 说明理由;\n思维过程：\n首先，我们需要理解T子集的定义。这意味着要找到一个函数 $f(x)$，它在区间 $[1, 9]$ 上连续，且对于集合 ${1, 2, 8, 9}$ 中的每个元素 $a_i$， $f(a_i)$ 也在这个集合中，并且 $f(x) \\neq x$。这意味着 $f(x)$ 在集合上的作用是一个非恒等的置换。\n最简单的思路是尝试线性函数。由于集合中的元素关于某个中心对称（例如，1和9，2和8），可以考虑关于区间中点的反射函数。区间 $[1, 9]$ 的中点是 5。  因此，可以尝试 $f(x) = 10 - x$。\n解答：\n是，集合 ${1, 2, 8, 9}$ 是 $[1, 9]$ 的T子集。\n理由：\n考虑函数 $f(x) = 10 - x$。\n\n$f(1) = 9$\n$f(2) = 8$\n$f(8) = 2$\n$f(9) = 1$\n\n因此， ${f(1), f(2), f(8), f(9)} = {9, 8, 2, 1} = {1, 2, 8, 9}$，满足像集等于原集合的条件。\n函数 $f(x) = 10 - x$ 是线性的，因此在区间 $[1, 9]$ 上连续。\n此外，$f(x) \\neq x$，因为 $10 - x = x$ 仅在 $x = 5$ 时成立，而 $5 \\notin {1, 2, 8, 9}$。\n因此，函数 $f(x) = 10 - x$ 满足 T 变换函数的所有条件，所以集合 ${1, 2, 8, 9}$ 是 $[1, 9]$ 的 T 子集。\n(2) 判断 $f(x) = \\ln(1 + \\frac{2}{e^x})$ 是否为集合 $A_n$ 的T变换函数? 说明理由;\n思维过程：\n这里需要判断给定的函数 $f(x) = \\ln(1 + \\frac{2}{e^x})$ 是否能够成为某个满足条件的集合 $A_n$ 的 T 变换函数。关键是理解 T 变换函数的条件：$f(x)$ 在 $[a_1, a_n]$ 上连续，${f(a_i)|a_i \\in A_n} = A_n$，并且 $f(x) \\neq x$。\n首先，需要验证该函数是否满足 $f(x) \\neq x$。如果存在 $x$ 使得 $f(x) = x$，那么包含该 $x$ 的任何集合都不可能是 T 子集。为了找到这样的 $x$，需要解方程 $\\ln(1 + \\frac{2}{e^x}) = x$。\n解答：\n否， $f(x) = \\ln(1 + \\frac{2}{e^x})$ 不是集合 $A_n$ 的T变换函数。\n理由：\n令 $f(x) = x$，则 $\\ln(1 + \\frac{2}{e^x}) = x$。\n取指数，得到 $1 + \\frac{2}{e^x} = e^x$。\n令 $y = e^x$，则 $1 + \\frac{2}{y} = y$，即 $y + 2 = y^2$，或者 $y^2 - y - 2 = 0$。\n解方程 $y^2 - y - 2 = 0$，得到 $(y - 2)(y + 1) = 0$，因此 $y = 2$ 或 $y = -1$。\n由于 $y = e^x &gt; 0$，所以 $y = 2$，即 $e^x = 2$，因此 $x = \\ln 2$。\n所以，当 $x = \\ln 2$ 时，$f(x) = x = \\ln 2$。由于 T 变换函数必须满足 $f(x) \\neq x$，因此任何包含 $\\ln 2$ 的集合 $A_n$ 都不能是 T 子集。\n即便集合 $A_n$ 不包含 $\\ln 2$，我们仍然需要验证是否存在满足条件的 $A_n$。假设存在，那么 $f$ 在 $A_n$ 上必须构成一个置换，并且不能有任何不动点。但是，当集合元素较多时，找到合适的置换并确保连续性较为困难。进一步考察 $f(f(x))$：\n$f(f(x)) = \\ln\\left(1 + \\frac{2}{e^{\\ln(1 + \\frac{2}{e^x})}}\\right) = \\ln\\left(1 + \\frac{2}{1 + \\frac{2}{e^x}}\\right) = \\ln\\left(\\frac{3e^x + 2}{e^x + 2}\\right)$.\n令 $f(f(x)) = x$, 解得 $x = \\ln 2$。因此，不存在合适的集合 $A_n$ 满足要求。\n因此，不存在满足条件的集合 $A_n$，使得 $f(x) = \\ln(1 + \\frac{2}{e^x})$ 是 $A_n$ 的T变换函数。\n(3) 若 $a_i &lt; a_j$ ($i, j \\in \\mathbb{N}^*, 1 \\le i &lt; j \\le n$), 则 $\\frac{a_j}{a_i} \\in A_n$, 试问是否存在函数 $f(x)$, 使得集合 $A_n$ 是 $D = [a_1, a_n]$ 的T子集? 若存在，求 $f(x)$ 的解析式; 若不存在，说明理由.\n思维过程：\n这个问题要求在给定条件下寻找函数 $f(x)$，使得集合 $A_n$ 是 T 子集。 条件是 $\\frac{a_j}{a_i} \\in A_n$ 对于所有 $i &lt; j$ 成立。这意味着集合 $A_n$ 对于除法是封闭的（大的数除以小的数的结果仍然在集合中）。\n一种可能的思路是尝试反比例函数，例如 $f(x) = \\frac{C}{x}$，其中 C 是一个常数。 如果选择 $C = a_1 a_n$，那么 $f(a_1) = a_n$ 和 $f(a_n) = a_1$。 现在需要验证对于所有 $a_i$，$\\frac{a_1 a_n}{a_i}$ 是否在集合 $A_n$ 中，以及如何确保 $f(x) \\neq x$。\n解答：\n存在，可以构造函数 $f(x) = \\frac{a_1 a_n}{x}$ 作为T变换函数。\n理由：\n考虑函数 $f(x) = \\frac{a_1 a_n}{x}$。\n\n验证像集： 对于任意 $a_i \\in A_n$，要证明 $f(a_i) \\in A_n$，即 $\\frac{a_1 a_n}{a_i} \\in A_n$。假设存在 $a_k = \\frac{a_1 a_n}{a_i}$，需要证明 $a_k \\in A_n$。\n\n因为 $a_i$ 在 $a_1$ 和 $a_n$ 之间，那么我们可以根据题目给出的商的条件，验证在满足商条件的情况下，所有 $f(a_i)$ 都能属于集合。这个条件对于集合元素的结构有很强的约束，它要求集合的元素比例是有规律的。  这种条件下，集合 A_n 的元素可以构建成等比数列。\n假设存在 $a_i$ 使得 $a_i = \\sqrt{a_1 a_n}$。 这会导致 $f(a_i) = \\frac{a_1 a_n}{a_i} = \\frac{a_1 a_n}{\\sqrt{a_1 a_n}} = \\sqrt{a_1 a_n} = a_i$， 违反了条件 $f(x) \\neq x$。此时需要验证在满足商条件的情况下，是否存在元素，满足这个条件。\n如果存在，则必须满足条件：\na_i^2= a_1 * a_n\n取集合A_3={1,2,4}，满足前提条件\n存在a_i = 2; a1 = 1; an = 4; a_i^2 = a1 * an\n如果确定题目一定满足，那么需要调整下f(x)，比如分段函数方式去完成。\n例如f(x) = 4/x, {f(1),f(2),f(4)} = {4,2,1};\n如果 a_i不等于 sqrt(a1*an),则f(x)可以保证不等于x，则满足条件\n综上分析，函数f(x)可以通过解析式f(x)=a1*an/x, 或者分段线性插值的方式进行求解。\n(3) 存在，函数 ( f(x) = \\frac{a_1 a_n}{x} ) 是满足条件的T变换函数。\n\n严格论证与补充说明：\n步骤1：验证映射封闭性\n根据题目条件 ( \\forall i&lt;j,\\ \\frac{a_j}{a_i} \\in A_n )，可推出集合对除法运算封闭。\n特别地，对任意 ( a_i \\in A_n )，存在如下映射关系：\n\n当 ( a_i = a_1 )，则 ( \\frac{a_1 a_n}{a_1} = a_n \\in A_n )；\n当 ( a_i = a_n )，则 ( \\frac{a_1 a_n}{a_n} = a_1 \\in A_n )；\n对任意中间元素 ( a_i )，存在 ( k ) 使得 ( \\frac{a_1 a_n}{a_i} = a_k \\in A_n )（由封闭性保证）。\n\n步骤2：验证双射性\n映射 ( f: A_n \\to A_n ) 定义为 ( f(a_i) = \\frac{a_1 a_n}{a_i} )，其逆映射为 ( f^{-1}(a_j) = \\frac{a_1 a_n}{a_j} )。\n由于 ( f ) 是一一对应，且 ( f(f(a_i)) = a_i )，因此 ( f ) 是双射，满足 ( {f(a_i)} = A_n )。\n步骤3：排除不动点\n若存在 ( a_i ) 使得 ( f(a_i) = a_i )，则 ( \\frac{a_1 a_n}{a_i} = a_i )，即 ( a_i^2 = a_1 a_n )。\n此时需分两种情况：\n\n无不动点：若 ( A_n ) 中不存在 ( a_i ) 满足 ( a_i^2 = a_1 a_n )，则 ( f(x) = \\frac{a_1 a_n}{x} ) 直接满足 ( f(x) \\neq x )。\n存在不动点：若存在 ( a_k ) 使得 ( a_k^2 = a_1 a_n )，则需构造分段函数：\n\n定义置换 ( \\sigma ) 将 ( a_k ) 映射到其他元素（如 ( a_k \\leftrightarrow a_1 )，其余元素通过 ( f(x) = \\frac{a_1 a_n}{x} ) 映射）。\n通过分段线性函数连接各映射点，确保连续且无整体不动点（例如图1中的分段线性构造）。\n\n\n\n步骤4：连续性保证\n对于存在不动点的情况，构造分段函数示例如下：\n\n设 ( A_3 = {1, 2, 4} )，其中 ( a_2 = 2 ) 满足 ( 2^2 = 1 \\times 4 )。\n定义：\n[\nf(x) =\n\\begin{cases}\n4 &amp; x=1, \\\n1 &amp; x=4, \\\n分段线性连接 \\ (1,4) \\ 和 \\ (4,1)，避开直接映射 ( x=2 )\n\\end{cases}\n]\n补全中间映射 ( f(2) ) 为其他元素（如 ( f(2) = 1 )），并通过线性插值保证连续性。\n\n结论：\n无论集合 ( A_n ) 是否包含满足 ( a_i^2 = a_1 a_n ) 的元素，均可通过 ( f(x) = \\frac{a_1 a_n}{x} ) 或分段连续函数构 造满足条件的T变换函数。因此，存在解析式 ( f(x) = \\frac{a_1 a_n}{x} )。\n\n验证示例：\n取 ( A_4 = {1, 3, 9, 27} )（公比3的等比数列）：\n\n( f(x) = \\frac{1 \\times 27}{x} = \\frac{27}{x} )，\n映射结果 ( {27, 9, 3, 1} = A_4 )，且无不动点，\n连续函数 ( f(x) = \\frac{27}{x} ) 在区间 ([1, 27]) 上严格满足所有条件。\n\n\nFFT\n要高效计算两个次数最多为( n )的多项式( p(x) )和( q(x) )的乘积( r(x) = p(x) \\cdot q(x) )，可以利用**快速傅里叶变换（FFT）**将时间复杂度从传统方法的( O(n^2) )优化到( O(n \\log n) )。具体步骤如下：\n\n1. 问题分析与关键思路\n\n目标：求( r(x) )的系数，其中( r(x) = p(x) \\cdot q(x) )，且( \\deg® \\leq 2n )。\n传统方法：直接计算系数卷积( r_k = \\sum_{j=0}^k a_j b_{k-j} )，时间复杂度为( O(n^2) )。\n优化思路：通过多项式点值表示与插值，结合FFT加速：\n\n点值乘法：若( p(x) )和( q(x) )在足够多点上已知值，则( r(x) )在这些点的值为( p(x_i) \\cdot q(x_i) )。\n快速转换：用FFT将系数表示转换为点值表示，再用逆FFT将点值转换回系数。\n\n\n\n\n2. 详细步骤与复杂度分析\n步骤1：选择足够的基点\n\n选择( m \\geq 2n+1 )个单位根作为基点，即( x_k = e^{2\\pi i k/m} )（( m )是大于( 2n )的最小2的幂）。\n作用：单位根的对称性和周期性是FFT分治优化的核心。\n\n步骤2：通过FFT计算点值（求值）\n\n用FFT在( O(n \\log n) )时间内将( p(x) )和( q(x) )转换为点值表示：\n[\np(x) \\rightarrow { p(x_0), p(x_1), \\dots, p(x_{m-1}) }, \\quad q(x) \\rightarrow { q(x_0), q(x_1), \\dots, q(x_{m-1}) }.\n]\n\n步骤3：点值相乘\n\n在( O(n) )时间内计算( r(x_i) = p(x_i) \\cdot q(x_i) )，得到( r(x) )的点值表示：\n[\nr \\rightarrow { r(x_0), r(x_1), \\dots, r(x_{m-1}) }.\n]\n\n步骤4：通过逆FFT插值\n\n用逆FFT在( O(n \\log n) )时间内将点值表示转换回系数表示：\n[\n{ r(x_0), r(x_1), \\dots, r(x_{m-1}) } \\rightarrow r(x) = c_0 + c_1x + \\dots + c_{2n}x^{2n}.\n]\n\n\n3. 复杂度总结\n\n总时间复杂度：\n[\nO(n \\log n) \\ (\\text{FFT求值}) + O(n) \\ (\\text{点值相乘}) + O(n \\log n) \\ (\\text{逆FFT插值}) = O(n \\log n).\n]\n\n\n4. 为什么选择单位根？\n单位根( x_k = e^{2\\pi i k/m} )满足以下性质：\n\n周期性：( x_k^{m} = 1 )。\n对称性：( x_{k + m/2} = -x_k )（若( m )为偶数）。\n可分治性：允许FFT将多项式分解为偶次项和奇次项，递归计算后合并结果。\n\n\n5. 示例说明\n假设( p(x) = 1 + 2x )，( q(x) = 3 + 4x )（( n=1 )）：\n\n选择基点：取( m=4 )（满足( m \\geq 2n+1=3 )），单位根为( x_0=1, x_1=i, x_2=-1, x_3=-i )。\n求值：\n\n( p(x_0)=3 ), ( p(x_1)=1+2i ), ( p(x_2)=-1 ), ( p(x_3)=1-2i ).\n( q(x_0)=7 ), ( q(x_1)=3+4i ), ( q(x_2)=-1 ), ( q(x_3)=3-4i ).\n\n\n点值相乘：\n\n( r(x_0)=21 ), ( r(x_1)=(1+2i)(3+4i)= -5+10i ), ( r(x_2)=1 ), ( r(x_3)= -5-10i ).\n\n\n逆FFT插值：\n\n逆FFT作用于( {21, -5+10i, 1, -5-10i} )，得到( r(x) = 3 + 10x + 8x^2 )。\n\n\n\n\n6. 关键结论\n通过FFT将多项式乘法优化到( O(n \\log n) )，核心在于：\n\n点值表示的高效转换（FFT/逆FFT）。\n单位根的数学性质，使得分治策略可行。\n足够多的基点（( m \\geq 2n+1 )）确保插值唯一性。\n\n这种方法广泛应用于信号处理、大数乘法等领域，是算法设计中“分而治之”思想的经典案例。\n第二步（通过FFT计算点值）的时间复杂度为 ( O(n \\log n) )，其核心原理是快速傅里叶变换（FFT）的分治策略和单位根的数学特 性。以下是详细解释：\n\n1. 问题背景\n\n目标：对次数为 ( n ) 的多项式 ( p(x) ) 和 ( q(x) )，在 ( m \\geq 2n+1 ) 个基点上计算它们的值。\n传统方法（如直接代入或霍纳法则）：时间复杂度为 ( O(n^2) )。\nFFT优化：将求值过程的时间复杂度降至 ( O(n \\log n) )。\n\n\n2. FFT的分治策略\nFFT通过以下步骤实现高效求值：\n(1) 多项式分解\n将多项式 ( p(x) ) 分解为偶次项和奇次项两部分：\n[\np(x) = p_{\\text{even}}(x^2) + x \\cdot p_{\\text{odd}}(x^2),\n]\n其中：\n\n( p_{\\text{even}}(x^2) = a_0 + a_2 x^2 + a_4 x^4 + \\dots ),\n( p_{\\text{odd}}(x^2) = a_1 + a_3 x^2 + a_5 x^4 + \\dots ).\n\n(2) 递归计算子问题\n对分解后的偶次项和奇次项递归应用FFT，分别计算它们在 ( \\frac{m}{2} ) 个基点上的值。\n\n递归深度为 ( \\log m )，每层处理 ( O(m) ) 次运算。\n总时间复杂度满足递推关系：\n[\nT(m) = 2T\\left(\\frac{m}{2}\\right) + O(m) \\quad \\Rightarrow \\quad T(m) = O(m \\log m).\n]\n\n\n3. 单位根的数学特性\nFFT的优化依赖于单位根 ( x_k = e^{2\\pi i k/m} ) 的特殊性质：\n(1) 周期性\n单位根满足 ( x_k^{m} = 1 )，即 ( x_k ) 在复平面上均匀分布在单位圆上，周期为 ( m )。\n(2) 对称性\n对于偶数和奇数下标，单位根满足：\n[\nx_{k + m/2} = -x_k, \\quad x_k^2 = x_{k \\mod (m/2)}.\n]\n这使得递归时只需计算前 ( m/2 ) 个点的值，后 ( m/2 ) 个点可直接通过对称性推导。\n(3) 可分治性\n偶次项和奇次项在平方后的单位根 ( x_k^2 ) 上的值，等价于对原多项式在 ( m/2 ) 个点上的递归求值。\n\n4. 复杂度分析\n\n每层递归的计算量：合并偶次项和奇次项的结果时，每个点需要一次乘法和加法，共 ( O(m) ) 次操作。\n递归深度：由于每次将问题规模减半，深度为 ( \\log m )。\n总时间复杂度：\n[\nO(m \\log m).\n]\n由于 ( m = O(n) )（通常取 ( m \\approx 2n )），时间复杂度为 ( O(n \\log n) )。\n\n\n5. 对比传统方法\n\n直接代入法：对每个 ( x_i )，计算 ( p(x_i) ) 需要 ( O(n) ) 次操作，总时间为 ( O(n \\cdot m) = O(n^2) )。\nFFT：通过分治和单位根特性，避免重复计算，时间降低到 ( O(n \\log n) )。\n\n\n6. 示例说明\n设 ( p(x) = 1 + 2x + 3x^2 + 4x^3 )，( m=4 ) 个单位根 ( {1, i, -1, -i} )：\n\n分解：\n\n( p_{\\text{even}}(x^2) = 1 + 3x^2 ),\n( p_{\\text{odd}}(x^2) = 2 + 4x^2 ),\n( p(x) = p_{\\text{even}}(x^2) + x \\cdot p_{\\text{odd}}(x^2) ).\n\n\n递归计算：\n\n对 ( p_{\\text{even}}(y) ) 和 ( p_{\\text{odd}}(y) ) 在 ( y \\in {1, -1} ) 处求值。\n\n\n合并结果：\n\n( p(1) = p_{\\text{even}}(1) + 1 \\cdot p_{\\text{odd}}(1) = (1+3) + 1 \\cdot (2+4) = 10 ),\n( p(i) = p_{\\text{even}}(-1) + i \\cdot p_{\\text{odd}}(-1) = (1-3) + i \\cdot (2-4) = -2 - 2i ).\n\n\n\n\n7. 总结\n第二步的时间复杂度为 ( O(n \\log n) )，因为：\n\n分治策略：将问题不断二分，递归深度为对数级别。\n单位根的对称性：避免重复计算，每层仅需线性时间。\n合并操作的高效性：通过复数乘法和加法快速合并子问题结果。\n\n这是FFT算法的核心优势，也是快速多项式乘法的基础。\n1. 问题定义\n输入：一个( n )次多项式( p(x) = a_0 + a_1x + a_2x^2 + \\dots + a_nx^n )。\n输出：计算( p(x) )在( n+1 )个单位根上的值，即：\n[\np(\\omega^0), , p(\\omega^1), , \\dots, , p(\\omega^n),\n]\n其中单位根( \\omega = e^{2\\pi i / (n+1)} )。\n\n2. 分治策略\nFFT的核心思想是分而治之，将多项式分解为更小的子问题递归求解。以下是具体步骤：\n(1) 分解多项式\n将( p(x) )拆分为偶次项和奇次项两部分：\n[\np(x) = \\underbrace{a_0 + a_2x^{\\color{red}2} + a_4x^{\\color{red}4} + \\dots}{E(x^{\\color{red}2})} + x \\cdot \\underbrace{(a_1 + a_3x^{\\color{red}2} + a_5x^{\\color{red}4} + \\dots)}{O(x^{\\color{red}2})},\n]\n简写为：\n[\np(x) = E(x^2) + x \\cdot O(x^2).\n]\n\n偶次项多项式 ( E(z) = a_0 + a_2z + a_4z^2 + \\dots )（变量是( z = x^2 )）。\n奇次项多项式 ( O(z) = a_1 + a_3z + a_5z^2 + \\dots )（变量是( z = x^2 )）。\n\n(2) 关键观察\n\n\n单位根的平方仍然是单位根：\n若原单位根是( \\omega = e^{2\\pi i / (n+1)} )，则( \\omega^2 = e^{4\\pi i / (n+1)} )相当于新的单位根，对应的次数是( (n+1)/2 )。\n\n\n递归计算：\n要计算( E(x^2) )和( O(x^2) )在( \\omega^0, \\omega^1, \\dots, \\omega^n )处的值，只需计算( E(z) )和( O(z) )在( z = \\omega^{0}, \\omega^{2}, \\dots, \\omega^{2n} )处的值。\n由于( \\omega^{2k} = e^{4\\pi i k / (n+1)} )，这相当于在( (n+1)/2 )次单位根上求值。\n\n\n(3) 递归步骤\n\n\n递归计算：\n\n计算偶次项多项式( E(z) )在( (n+1)/2 )次单位根上的值：( E(\\omega^{0}), E(\\omega^{2}), \\dots ).\n计算奇次项多项式( O(z) )在( (n+1)/2 )次单位根上的值：( O(\\omega^{0}), O(\\omega^{2}), \\dots ).\n\n\n\n合并结果：\n\n对于每个单位根( \\omega^k )（( k = 0, 1, \\dots, n )）：\n[\np(\\omega^k) = E\\left( (\\omega^k)^2 \\right) + \\omega^k \\cdot O\\left( (\\omega^k)^2 \\right).\n]\n利用对称性( \\omega^{k + (n+1)/2} = -\\omega^k )，只需计算前一半结果，后一半可直接推导。\n\n\n\n\n3. 示例说明\n假设( p(x) = 1 + 2x + 3x^2 + 4x^3 )（( n=3 )，需计算在4个单位根上的值）。\n步骤1：分解多项式\n\n偶次项：( E(z) = 1 + 3z )（对应( a_0=1, a_2=3 )）。\n奇次项：( O(z) = 2 + 4z )（对应( a_1=2, a_3=4 )）。\n\n步骤2：递归计算\n\n计算( E(z) )和( O(z) )在( z = \\omega^{0}, \\omega^{2} )处的值（2次单位根）：\n\n( \\omega^0 = 1 ), ( \\omega^{2} = -1 ).\n( E(1) = 4 ), ( E(-1) = -2 ).\n( O(1) = 6 ), ( O(-1) = -2 ).\n\n\n\n步骤3：合并结果\n\n对于每个单位根( \\omega^k )：\n\n( p(\\omega^0) = E(1) + 1 \\cdot O(1) = 4 + 6 = 10 ).\n( p(\\omega^1) = E(-1) + \\omega^1 \\cdot O(-1) = -2 + \\omega^1 \\cdot (-2) ).\n( p(\\omega^2) = E(1) + \\omega^2 \\cdot O(1) = 4 + (-1) \\cdot 6 = -2 ).\n( p(\\omega^3) = E(-1) + \\omega^3 \\cdot O(-1) = -2 + (-\\omega^1) \\cdot (-2) ).\n\n\n\n\n4. 复杂度与分治优势\n\n递归深度：每次将问题规模减半，深度为( \\log(n+1) ).\n每层计算量：合并结果需要( O(n) )次操作。\n总时间复杂度：( O(n \\log n) ).\n\n\n5. 为什么能分治？\n\n单位根的对称性：( \\omega^{k + m/2} = -\\omega^k )，使得后一半点的值可通过前一半推导。\n平方操作：( \\omega^{2k} )将问题规模缩小为原来的( 1/2 )。\n\n\n通过这种分治法，FFT将原本( O(n^2) )的求值问题优化为( O(n \\log n) )，是快速多项式乘法的核心！\n分治关键步骤的数学推导\n我们详细解释为什么“偶次项和奇次项在平方后的单位根上的值，等价于对原多项式在 ( m/2 ) 个点上的递归求值”。\n\n1. 单位根的平方性质\n假设我们选择 ( m ) 次单位根 ( \\omega = e^{2\\pi i / m} )，则：\n[\n\\omega^{k + m} = \\omega^k, \\quad \\omega^{m/2} = -1.\n]\n对于任意 ( \\omega^k )，其平方为：\n[\n(\\omega^k)^2 = \\omega^{2k} = e^{4\\pi i k / m} = e^{2\\pi i (2k) / m}.\n]\n若令 ( m’ = m/2 )，则 ( \\omega^{2k} = e^{2\\pi i k / m’} )，即 ( \\omega^{2k} ) 是 ( m’ )-次单位根。\n\n2. 多项式分解与点值关系\n将多项式分解为偶次项 ( E(x^2) ) 和奇次项 ( x \\cdot O(x^2) )：\n[\np(x) = E(x^2) + x \\cdot O(x^2).\n]\n在单位根 ( \\omega^k ) 处求值：\n[\np(\\omega^k) = E\\left( (\\omega^k)^2 \\right) + \\omega^k \\cdot O\\left( (\\omega^k)^2 \\right).\n]\n\n关键观察：\n( (\\omega^k)^2 = \\omega^{2k} ) 是 ( m’ = m/2 )-次单位根。\n因此，计算 ( E(z) ) 和 ( O(z) ) 在 ( z = \\omega^{2k} ) 处的值，等价于在 ( m’ )-次单位根上求值。\n\n\n3. 问题规模减半\n\n\n原问题规模：\n需要计算 ( p(x) ) 在 ( m ) 个点 ( \\omega^0, \\omega^1, \\dots, \\omega^{m-1} ) 处的值。\n\n\n子问题规模：\n\n计算 ( E(z) ) 在 ( z = \\omega^{0}, \\omega^{2}, \\dots, \\omega^{2(m-1)} ) 处的值，等价于在 ( m’ = m/2 ) 个不同的 ( m’ )-次单位根上求值。\n同理，( O(z) ) 的求值问题规模也减半为 ( m’ )。\n\n\n\n递归调用：\n\n对 ( E(z) ) 和 ( O(z) ) 递归应用FFT，问题规模从 ( m ) 变为 ( m/2 )。\n\n\n\n\n4. 具体推导示例\n设 ( m = 8 )，单位根为 ( \\omega^k = e^{2\\pi i k/8} )（( k = 0, 1, \\dots, 7 )）：\n\n\n平方后的单位根：\n( (\\omega^k)^2 = e^{4\\pi i k/8} = e^{2\\pi i k/4} )，即新的单位根是 ( 4 )-次单位根 ( \\mu = e^{2\\pi i /4} )。\n\n\n等价性：\n计算 ( E(z) ) 在 ( z = \\mu^0, \\mu^1, \\mu^2, \\mu^3 ) 处的值（即 ( z = 1, i, -1, -i )），等价于原问题在 ( m’ = 4 ) 规模上的递归。\n\n\n\n5. 数学归纳证明\n\n\n递归关系：\n设 ( T(m) ) 为计算 ( m ) 个点的时间复杂度，则：\n[\nT(m) = 2T\\left( \\frac{m}{2} \\right) + O(m).\n]\n\n解释：\n每次将问题分为两个规模为 ( m/2 ) 的子问题（偶次项和奇次项），合并结果需要 ( O(m) ) 时间。\n\n\n\n时间复杂度解：\n根据主定理（Master Theorem），递推关系的解为：\n[\nT(m) = O(m \\log m).\n]\n\n\n\n6. 总结\n\n\n平方操作的意义：\n平方后的单位根 ( (\\omega^k)^2 ) 将原问题的规模从 ( m ) 减半为 ( m/2 )，使得递归成为可能。\n\n\n分治可行性：\n偶次项 ( E(z) ) 和奇次项 ( O(z) ) 的求值问题，在 ( m/2 )-次单位根上递归完成，总时间复杂度为 ( O(n \\log n) )。\n\n\n这一步骤的数学本质是通过单位根的平方操作将问题规模指数级缩小，从而实现高效分治。\n以32次单位根为例的分治演示\n假设我们需要计算一个31次多项式( p(x) = \\sum_{k=0}^{31} a_kx^k )在32次单位根( \\omega_k = e^{2\\pi i k/32} )（( k=0,1,\\dots,31 )）处的值。以下是FFT的分治 步骤：\n\n1. 分解多项式\n将( p(x) )拆分为偶次项和奇次项：\n[\np(x) = \\underbrace{a_0 + a_2x^2 + a_4x^4 + \\dots + a_{30}x^{30}}{E(x^2)} + x \\cdot \\underbrace{(a_1 + a_3x^2 + a_5x^4 + \\dots + a{31}x^{30})}_{O(x^2)}.\n]\n即：\n[\np(x) = E(x^2) + x \\cdot O(x^2).\n]\n\n2. 单位根平方后的性质\n\n原始单位根：( \\omega_k = e^{2\\pi i k/32} )（( k=0,1,\\dots,31 )）。\n平方后的单位根：( (\\omega_k)^2 = e^{4\\pi i k/32} = e^{2\\pi i k/16} )，即新的单位根是16次单位根( \\mu_j = e^{2\\pi i j/16} )（( j=0,1,\\dots,15 )）。\n\n\n3. 递归计算子问题\n对偶次项( E(z) )和奇次项( O(z) )递归应用FFT：\n\n输入规模：32次单位根 → 分解为两个16次单位根的问题。\n递归调用：\n\n计算( E(\\mu_0), E(\\mu_1), \\dots, E(\\mu_{15}) )。\n计算( O(\\mu_0), O(\\mu_1), \\dots, O(\\mu_{15}) )。\n\n\n\n\n4. 合并结果\n利用对称性( \\omega_{k+16} = -\\omega_k )合并结果：\n\n对前16个点( k=0,1,\\dots,15 )：\n[\np(\\omega_k) = E(\\mu_k) + \\omega_k \\cdot O(\\mu_k).\n]\n对后16个点( k=16,17,\\dots,31 )：\n[\np(\\omega_{k}) = E(\\mu_{k-16}) - \\omega_{k-16} \\cdot O(\\mu_{k-16}).\n]\n\n\n5. 具体数值示例\n假设计算( p(\\omega_5) )和( p(\\omega_{21}) )：\n\n前一半点（( k=5 )）：\n[\np(\\omega_5) = E(\\mu_5) + \\omega_5 \\cdot O(\\mu_5).\n]\n后一半点（( k=21 )，即( k’=21-16=5 )）：\n[\np(\\omega_{21}) = E(\\mu_5) - \\omega_5 \\cdot O(\\mu_5).\n]\n只需计算一次( E(\\mu_5) )和( O(\\mu_5) )，即可得到两个结果。\n\n\n6. 递归深度与复杂度\n\n总递归深度：( \\log_2 32 = 5 )层。\n每层操作：\n\n\n\n递归层\n问题规模\n操作量\n\n\n\n\n0\n32\n32\n\n\n1\n16\n32\n\n\n2\n8\n32\n\n\n3\n4\n32\n\n\n4\n2\n32\n\n\n5\n1\n32\n\n\n\n\n总操作量：( 32 \\times 5 = 160 )，即( O(32 \\log 32) )。\n\n\n逆变换\n逆变换（插值）的核心思想是通过快速傅里叶逆变换（IFFT）从多项式的点值表示恢复系数表示。以下是逐步解释：\n\n1. 问题定义\n\n输入：在 m+1 次单位根 𝑥₀, 𝑥₁, ..., 𝑥ₘ 处的多项式值 𝑝(𝑥₀), 𝑝(𝑥₁), ..., 𝑝(𝑥ₘ)。\n输出：多项式系数 𝑎₀, 𝑎₁, ..., 𝑎ₙ（假设 𝑛 = m，即点数与系数数量一致）。\n\n\n2. 单位根与DFT\n\n单位根：ω = e^(2πi/(n+1)) 是 n+1 次单位根，满足 ω^(n+1) = 1。\nDFT定义：将多项式 𝑝(𝑥) = Σ𝑎ⱼ𝑥ʲ 在单位根 ω⁰, ω¹, ..., ωⁿ 处求值：\n[\n𝑝(ω^l) = \\sum_{j=0}^n 𝑎_j ω^{l j} \\quad (l=0,1,…,n).\n]\nDFT 将系数向量 [𝑎₀, ..., 𝑎ₙ] 转换为点值向量 [𝑝(ω⁰), ..., 𝑝(ωⁿ)]。\n\n\n**3.[𝑝(ω⁰), ..., 𝑝(ωⁿ)]。\n\n3. 逆DFT的数学形式\n逆DFT的目标是从点值恢复系数：\n[\n𝑎_l = \\frac{1}{n+1} \\sum_{j=0}^n 𝑝(ω^j) ω^{-l j} \\quad (l=0,1,…,n).\n]\n关键观察：\n\nω替换为ω⁻¹：与DFT相比，指数项从 ω^&#123;l j&#125; 变为 ω^&#123;-l j&#125;。\n归一化因子：结果需乘以 1/(n+1)。\n\n\n4. 逆DFT与DFT的关系\n\n矩阵视角：DFT矩阵 F 的元素为 F[j,k] = ω^&#123;jk&#125;，逆DFT矩阵为 F⁻¹ = (1/(n+1)) F^†，其中 F^† 是共轭转置矩阵。\n正交性：单位根的共轭 ω^&#123;-1&#125; 是 ω 的逆元，满足正交关系：\n[\n\\sum_{k=0}^n ω^{jk} ω^{-lk} =\n\\begin{cases}\nn+1 &amp; \\text{if } j=l, \\\n0 &amp; \\text{otherwise}.\n\\end{cases}\n]\n归一化因子 1/(n+1) 保证逆变换正确性。\n\n\n5. 逆FFT算法\n逆FFT的步骤与FFT完全相同，只需做以下调整：\n\n替换单位根：将FFT中的旋转因子 ω 替换为 ω⁻¹。\n归一化：最终结果乘以 1/(n+1)。\n\n示例：递归逆FFT流程：\n\n分治：将点值分为偶数和奇数部分。\n合并：用 ω⁻¹ 计算蝴蝶操作：\n[\n\\text{new}\\text{low} = \\frac{\\text{even} + \\text{odd} \\cdot ω^{-k}}{2}, \\quad \\text{new}\\text{high} = \\frac{\\text{even} - \\text{odd} \\cdot ω^{-k}}{2}.\n]\n归一化：递归结束后，所有系数乘以 1/(n+1)。\n\n\n6. 为什么需要归一化因子？\n\n数学验证：假设 𝑎ⱼ 通过DFT得到点值 𝑝(ω^l)，则逆DFT公式代入后：\n[\n\\frac{1}{n+1} \\sum_{j=0}^n \\left( \\sum_{k=0}^n 𝑎_k ω^{j k} \\right) ω^{-j l} = \\frac{1}{n+1} \\sum_{k=0}^n 𝑎_k \\underbrace{\\sum_{j=0}^n ω^{j(k-l)}}_{=0 \\text{ if } k≠l}} = 𝑎_l.\n]\n归一化因子抵消正交求和中的 n+1 项。\n\n\n7. 总结\n\n逆FFT本质：是DFT的共轭版本，计算复杂度仍为 O(n log n)。\n步骤：\n\n对点值向量调用FFT，但使用 ω⁻¹ 代替 ω。\n结果全体乘以 1/(n+1)。\n\n\n应用：高效实现多项式乘法（FFT→点乘→逆FFT）。\n\n逆矩阵的构造基于DFT矩阵的 酉性质（Unitary），其核心推导如下：\n\n1. DFT矩阵的定义\n设 F 是 (n+1)×(n+1) 的DFT矩阵，元素为：\n[\nF[j,k] = ω^{jk} \\quad \\text{其中 } ω = e^{2πi/(n+1)}, , j,k=0,1,…,n.\n]\n例如，当 n=2 时：\n[\nF = \\begin{bmatrix}\nω^{0·0} &amp; ω^{0·1} &amp; ω^{0·2} \\\nω^{1·0} &amp; ω^{1·1} &amp; ω^{1·2} \\\nω^{2·0} &amp; ω^{2·1} &amp; ω^{2·2}\n\\end{bmatrix}.\n]\n\n2. 逆矩阵的猜想\n逆DFT矩阵的形式为：\n[\nF^{-1} = \\frac{1}{n+1} F^† \\quad \\text{（共轭转置矩阵除以 } n+1 \\text{）},\n]\n其中 F^† 的元素是 F 的共轭转置，即：\n[\nF^†[j,k] = \\overline{F[k,j]} = ω^{-jk}.\n]\n\n3. 验证逆矩阵的正确性\n需证明：\n[\nF \\cdot F^{-1} = I \\quad \\text{即 } F \\cdot \\left( \\frac{1}{n+1} F^† \\right) = I.\n]\n展开矩阵乘法，验证每个元素：\n\n\n矩阵乘积的第 (j,l) 个元素：\n[\n\\sum_{k=0}^n F[j,k] \\cdot F^{-1}[k,l] = \\frac{1}{n+1} \\sum_{k=0}^n ω^{jk} \\cdot ω^{-lk}.\n]\n\n\n分情况讨论：\n\n当 j = l：\n[\n\\sum_{k=0}^n ω^{jk} \\cdot ω^{-jk} = \\sum_{k=0}^n ω^{0} = n+1 \\implies \\frac{n+1}{n+1} = 1.\n]\n当 j ≠ l：\n令 d = j-l ≠ 0，则求和为几何级数：\n[\n\\sum_{k=0}^n ω^{dk} = \\frac{1 - ω^{d(n+1)}}{1 - ω^d}.\n]\n由于 ω^&#123;n+1&#125; = 1，分子 1 - ω^&#123;d(n+1)&#125; = 1 - 1 = 0，故和为 0。\n\n\n\n结论：\n[\nF \\cdot F^{-1}[j,l] = \\begin{cases}\n1 &amp; \\text{if } j=l, \\\n0 &amp; \\text{otherwise}.\n\\end{cases}\n]\n因此，F \\cdot F^&#123;-1&#125; = I。\n\n\n\n4. 逆矩阵的显式表达\n逆DFT矩阵的显式形式为：\n[\nF^{-1} = \\frac{1}{n+1}\n\\begin{bmatrix}\nω^{0·0} &amp; ω^{0·(-1)} &amp; \\cdots &amp; ω^{0·(-n)} \\\nω^{-1·0} &amp; ω^{-1·1} &amp; \\cdots &amp; ω^{-1·n} \\\n\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\nω^{-n·0} &amp; ω^{-n·1} &amp; \\cdots &amp; ω^{-n·n}\n\\end{bmatrix}.\n]\n关键特性：\n\n元素为 ω^&#123;-jk&#125;（对应单位根的倒数）。\n归一化因子 1/(n+1)。\n\n\n5. 几何视角：正交基的归一化\nDFT矩阵的列向量是 正交基，但未归一化。内积的模长为 n+1，因此逆矩阵需补偿该模长：\n[\n\\langle F[:,j], F[:,l] \\rangle = \\sum_{k=0}^n ω^{jk} \\overline{ω^{lk}} = \\sum_{k=0}^n ω^{(j-l)k} =\n\\begin{cases}\nn+1 &amp; j=l, \\\n0 &amp; j≠l.\n\\end{cases}\n]\n归一化后，基向量满足标准正交性，从而保证逆矩阵的正确性。\n\n6. 总结\n\n逆矩阵构造：共轭转置 F^† 并缩放 1/(n+1)。\n验证方法：直接计算矩阵乘积，利用单位根的周期性求和。\n物理意义：将点值表示投影回正交基，通过归一化恢复系数。\n\n正交矩阵 保距离\n酉矩阵 复空间保距离 保范数的变换\n傅里叶变换是酉矩阵\n1. 复数内积与共轭\n在复数域中，向量的 内积 定义为：\n[\n\\langle \\mathbf{u}, \\mathbf{v} \\rangle = \\sum_{k=0}^n u_k \\overline{v_k},\n]\n其中 (\\overline{v_k}) 是 (v_k) 的共轭复数。\n为什么要取共轭？\n为了保持内积的模长非负性（即 (\\langle \\mathbf{u}, \\mathbf{u} \\rangle \\geq 0)）。若直接相乘（不取共轭），复数项的虚部会导致结果不满足实数内积的性质。\n示例：\n设 (\\mathbf{u} = [1+i, 2])，(\\mathbf{v} = [3, 4i])，则内积为：\n[\n(1+i)\\overline{3} + 2\\overline{4i} = (1+i) \\cdot 3 + 2 \\cdot (-4i) = 3+3i-8i = 3-5i.\n]\n若直接相乘不取共轭，结果包含虚部，无法体现实数空间的正交性。\n\n2. 单位根的共轭与Hermitian转置\n单位根性质：\n若 (\\omega = e^{2πi/(n+1)})，则其共轭为：\n[\n\\overline{\\omega} = e^{-2πi/(n+1)} = \\omega^{-1}.\n]\n因此，DFT矩阵的共轭转置（Hermitian转置）(F^†) 的元素为：\n[\nF^†[j,k] = \\overline{F[k,j]} = \\omega^{-jk}.\n]\n\n3. 几何级数求和的归零性\n当 (j ≠ i) 时，求和 (\\sum_{k=0}^n \\omega^{(j-i)k}) 的结果为 0，原因如下：\n\n\n几何级数公式：\n对公比 (r = \\omega^{d})（其中 (d = j-i ≠ 0)），求和项数为 (n+1)：\n[\n\\sum_{k=0}^n r^k = \\frac{1 - r^{n+1}}{1 - r}.\n]\n\n\n单位根周期性：\n由于 (\\omega^{n+1} = 1)，分子变为：\n[\n1 - r^{n+1} = 1 - (\\omega^{d})^{n+1} = 1 - (\\omega^{n+1})^d = 1 - 1^d = 0.\n]\n因此，整个和为 (0)。\n\n\n示例：\n设 (n=2)，(\\omega = e^{2πi/3})，计算 (\\sum_{k=0}^2 \\omega^{k})：\n[\n\\omega^0 + \\omega^1 + \\omega^2 = 1 + \\omega + \\omega^2 = \\frac{1 - \\omega^{3}}{1 - \\omega} = \\frac{1 - 1}{1 - \\omega} = 0.\n]\n\n4. 矩阵乘积的验证\n设 DFT 矩阵为 (F)，其逆矩阵为 (F^{-1} = \\frac{1}{n+1} F^†)。验证 (F \\cdot F^{-1} = I)：\n\n\n矩阵乘积元素：\n第 ((j,l)) 个元素为：\n[\n\\frac{1}{n+1} \\sum_{k=0}^n \\omega^{jk} \\cdot \\omega^{-lk} = \\frac{1}{n+1} \\sum_{k=0}^n \\omega^{(j-l)k}.\n]\n\n\n分情况讨论：\n\n当 (j = l)：\n(\\sum_{k=0}^n \\omega^{0} = n+1 \\implies \\frac{n+1}{n+1} = 1).\n当 (j ≠ l)：\n根据几何级数求和结果为 (0)，因此元素值为 (0)。\n\n\n\n\n5. 总结\n\n内积的共轭：保证复数内积的正交性与模长非负性。\n逆矩阵构造：基于单位根的共轭性质和正交性，通过几何级数求和归零性验证。\n归一化因子：补偿DFT矩阵列向量的模长 (n+1)，确保归一化后乘积为单位矩阵。\n\n您联想到的可能是 群论中的正交性关系 或 有限域上的特征和，其核心思想与单位根的对称性密切相关。以下是具体解释：\n\n1. 群论视角：特征标正交性\n在有限循环群 ( \\mathbb{Z}{n+1} ) 中，特征标（Character） 定义为群到复数的同态：\n[\n\\chi_j(k) = \\omega^{jk} \\quad \\text{其中 } \\omega = e^{2πi/(n+1)}.\n]\n正交性定理 指出，不同特征标在群元素上的求和满足：\n[\n\\sum{k=0}^n \\chi_j(k) \\overline{\\chi_l(k)} =\n\\begin{cases}\nn+1 &amp; j=l, \\\n0 &amp; j≠l.\n\\end{cases}\n]\n这正是矩阵乘积 ( F \\cdot F^† ) 的对角化结果的数学基础。\n\n2. 数论中的高斯和（Gauss Sum）\n高斯和是形如 ( G(a) = \\sum_{k=0}^{n} \\omega^{a k^2} ) 的求和，其性质与二次剩余相关。虽然形式上不同，但高斯和的归零性（如 ( a ≠ 0 \\mod n+1 ) 时和为0）与单位根求和的归零性有相似之处。\n\n3. 分圆多项式（Cyclotomic Polynomial）\n分圆多项式 ( \\Phi_{n+1}(x) ) 的根是 原始的 ( (n+1) )-次单位根，满足：\n[\n\\Phi_{n+1}(x) = \\prod_{\\substack{1 \\leq k \\leq n+1 \\ \\gcd(k,n+1)=1}} \\left( x - \\omega^k \\right).\n]\n其系数对称性与单位根求和的周期性密切相关。\n\n4. 离散对数与指数映射\n在乘法群 ( \\mathbb{Z}_p^* )（( p ) 为素数）中，离散对数问题涉及将元素表示为生成元的幂次，其指数运算与单位根的幂次结构相似。例如，若 ( g ) 是生成元，则 ( g^k \\mod p ) 的周期性映射到单位根 ( \\omega^k ) 的周期性。\n\n5. 具体示例验证\n设 ( n=3 )，( \\omega = e^{2πi/4} = i )，验证 ( j=1, l=0 ) 时的求和：\n[\n\\sum_{k=0}^3 \\omega^{(1-0)k} = \\sum_{k=0}^3 i^k = i^0 + i^1 + i^2 + i^3 = 1 + i -1 -i = 0.\n]\n这正是正交性的直接体现。\n\n总结\n您联想到的可能是：\n\n群特征标的正交性（抽象代数），\n高斯和的归零性（数论），\n分圆多项式的根对称性，\n离散对数的周期性结构。\n\n这些领域均以不同形式利用了单位根的对称性，而DFT的逆矩阵构造正是这些理论在信号处理中的具体应用。\n要证明( n+1 )次单位根( w_0, w_1, \\dots, w_n )的和为零，即：\n[\nw_0 + w_1 + \\dots + w_n = 0,\n]\n可以通过以下两种方法进行：\n\n方法一：几何级数求和\n单位根可表示为：\n[\nw_k = e^{\\frac{2\\pi i k}{n+1}} \\quad (k = 0, 1, \\dots, n).\n]\n它们的和为：\n[\nS = \\sum_{k=0}^n e^{\\frac{2\\pi i k}{n+1}}.\n]\n这是一个首项为( 1 )、公比为( r = e^{\\frac{2\\pi i}{n+1}} )的几何级数。根据几何级数求和公式：\n[\nS = \\frac{1 - r^{n+1}}{1 - r}.\n]\n由于( r )是( n+1 )次单位根，满足( r^{n+1} = 1 )，因此分子为( 1 - 1 = 0 )，故：\n[\nS = \\frac{0}{1 - r} = 0.\n]\n当( n \\geq 1 )时，公比( r \\neq 1 )，公式成立；当( n = 0 )时，唯一根为( 1 )，和为( 1 )，但题目隐含( n \\geq 1 )，因此结论成立。\n\n方法二：多项式根与系数的关系\n( n+1 )次单位根满足方程：\n[\nz^{n+1} - 1 = 0.\n]\n将其因式分解为：\n[\n(z - w_0)(z - w_1)\\cdots(z - w_n) = z^{n+1} - (w_0 + w_1 + \\dots + w_n)z^n + \\dots + (-1)^{n+1}w_0w_1\\cdots w_n.\n]\n与原多项式( z^{n+1} - 1 )对比，( z^n )项的系数在左边为( -(w_0 + w_1 + \\dots + w_n) )，而右边为( 0 )，因此：\n[\n-(w_0 + w_1 + \\dots + w_n) = 0 \\implies w_0 + w_1 + \\dots + w_n = 0.\n]\n此结论在( n \\geq 1 )时成立。\n\n总结\n当( n \\geq 1 )时，( n+1 )次单位根的和为零。两种方法均表明：\n[\n\\boxed{w_0 + w_1 + \\dots + w_n = 0}.\n]\n要证明对常数( d )，( n+1 )次单位根满足：\n[\nw^{0d} + w^{1d} + \\dots + w^{nd} = 0,\n]\n需分情况讨论，并用抽象代数中的循环群性质解释。\n\n推导与证明\n设( w )为( n+1 )次单位根的原根，即( w = e^{\\frac{2\\pi i}{n+1}} )，则所有单位根为( w^k \\ (k = 0, 1, \\dots, n) ) 。考虑和：\n[\nS = \\sum_{k=0}^n w^{kd}.\n]\n情况1：( d )是( n+1 )的倍数\n若( d = m(n+1) )，则( w^{kd} = \\left(w^{n+1}\\right)^{km} = 1^{km} = 1 )，故：\n[\nS = \\sum_{k=0}^n 1 = n+1 \\neq 0.\n]\n情况2：( d )不是( n+1 )的倍数\n若( d )与( n+1 )不互质，令( g = \\gcd(d, n+1) )，则( w^d )生成的子群阶为( m = \\frac{n+1}{g} )。此时：\n[\nS = \\sum_{k=0}^n w^{kd} = \\sum_{k=0}^n \\left(w^d\\right)^k.\n]\n这是一个首项为( 1 )、公比( r = w^d )的几何级数。因( r^{n+1} = w^{d(n+1)} = \\left(w^{n+1}\\right)^d = 1 )，但( r \\neq 1 )（因( d )不是( n+1 )的倍数），故：\n[\nS = \\frac{1 - r^{n+1}}{1 - r} = \\frac{1 - 1}{1 - r} = 0.\n]\n\n抽象代数解释\n\n\n循环群结构\n( n+1 )次单位根构成循环群( G \\cong \\mathbb{Z}/(n+1)\\mathbb{Z} )，每个元素可表示为( w^k )。\n\n\n自同态映射\n映射( \\phi: G \\to G )，定义为( \\phi(w^k) = w^{kd} )，是群自同态：\n\n若( \\gcd(d, n+1) = 1 )，( \\phi )是自同构（双射），故像集仍为( G )，和( \\sum_{g \\in G} g = 0 )。\n若( \\gcd(d, n+1) = g &gt; 1 )，像集为子群( H \\subset G )，阶为( m = \\frac{n+1}{g} )。每个元素( h \\in H )被恰 好( g )个原像击中，故：\n[\nS = g \\sum_{h \\in H} h = 0 \\quad (\\text{当 } m &gt; 1 \\text{ 时，子群和仍为0}).\n]\n\n\n\n结论\n\n当( d \\not\\equiv 0 \\mod (n+1) )时，( S = 0 )。\n当( d \\equiv 0 \\mod (n+1) )时，( S = n+1 )。\n\n\n\n\n最终结论\n[\n\\boxed{w^{0d} + w^{1d} + \\dots + w^{nd} = 0} \\quad \\text{当且仅当 } d \\not\\equiv 0 \\mod (n+1).\n]\n此结果体现了循环群中元素幂的对称性与子群结构对和的影响。\n您提供的这段内容涉及离散傅里叶变换（DFT）的核心思想、公式推导及其数学性质。我将逐步拆解并详细解释其中的关键点。\n\n一、离散傅里叶变换（DFT）的基本思想\n离散傅里叶变换的目标是：将一组离散信号 ({y_j}) 分解为不同频率的复指数函数（或正弦/余弦函数）的线性组合。其形式为：\n[\ny_j \\approx \\sum_{k=0}^{2m-1} c_k e^{i k x_j}\n]\n其中：\n\n(x_j = \\frac{\\pi j}{m})（等间距采样点）\n(c_k) 是复系数，对应频率为 (k) 的分量。\n\n\n二、逆变换与系数的计算\n逆变换公式给出了如何从信号 ({y_j}) 计算系数 ({c_k})：\n[\nc_k = \\frac{1}{m} \\sum_{j=0}^{2m-1} y_j e^{-i k x_j}\n]\n这一步利用了复指数函数的正交性（后文详述），通过内积运算提取每个频率分量的系数。\n\n三、欧拉公式与实虚部分解\n通过欧拉公式 (e^{i\\theta} = \\cos\\theta + i\\sin\\theta)，可将复系数 (c_k) 分解为实数正弦/余弦系数：\n[\nc_k = a_k + i b_k\n]\n代入DFT表达式后，展开为：\n[\ny_j = \\sum_{k=0}^{2m-1} (a_k + i b_k) \\left( \\cos(k x_j) + i \\sin(k x_j) \\right)\n]\n整理实部和虚部后，信号可表示为实数形式的三角级数：\n[\ny_j = \\sum_{k=0}^{m} \\left[ A_k \\cos(k x_j) + B_k \\sin(k x_j) \\right]\n]\n其中 (A_k, B_k) 是实数系数，与 (a_k, b_k) 相关。\n\n四、三角函数的正交性\n正交性是DFT的核心数学基础。在离散情况下，不同频率的正弦/余弦函数满足：\n[\n\\sum_{j=0}^{2m-1} \\cos(k x_j) \\cos(l x_j) =\n\\begin{cases}\nm, &amp; k=l \\text{ 或 } k=2m-l \\\n0, &amp; \\text{其他}\n\\end{cases}\n]\n类似地，正弦函数之间以及正余弦交叉项的正交性使得：\n\n不同频率的分量在求和时相互抵消。\n相同频率的分量求和后归一化得到系数。\n\n这使得计算 (c_k) 时，只需将信号 (y_j) 与对应频率的复指数函数做内积。\n\n五、傅里叶变换的Unitary性质\nDFT的矩阵形式是一个酉矩阵（Unitary Matrix），即：\n[\nU^* U^T = I\n]\n其中矩阵 (U) 的元素为 (U_{jk} = \\frac{1}{\\sqrt{m}} e^{-i k x_j})。酉矩阵的性质保证了：\n\n能量守恒：信号在时域和频域的能量相等（Parseval定理）。\n可逆性：逆变换是酉矩阵的共轭转置，即 (U^{-1} = U^*)。\n\n\n六、实例推导：从复系数到实数系数\n假设信号 (y_j) 是实数，则复系数满足共轭对称性 (c_k = c_{2m-k}^)。将其代入DFT表达式：\n[\ny_j = \\sum_{k=0}^{2m-1} c_k e^{i k x_j} = c_0 + \\sum_{k=1}^{m} \\left[ c_k e^{i k x_j} + c_{2m-k} e^{-i k x_j} \\right]\n]\n利用共轭对称性 (c_{2m-k} = c_k^)，可简化为：\n[\ny_j = c_0 + 2 \\sum_{k=1}^{m} \\left[ \\text{Re}(c_k) \\cos(k x_j) - \\text{Im}(c_k) \\sin(k x_j) \\right]\n]\n从而得到实数形式的傅里叶级数。\n\n七、总结\n\nDFT本质：将信号投影到正交的复指数基函数上。\n系数计算：通过内积（求和）提取每个基函数的权重。\n正交性与酉性：保证计算的简洁性和可逆性。\n实数信号：复系数具有对称性，最终可表示为正弦/余弦组合。\n\n通过以上步骤，离散傅里叶变换将复杂的信号分解为简单频率分量的叠加，为信号处理提供了强大的数学工具。\n","tags":["其他"]},{"title":"LP定点笔记","url":"/notes.github.io/2025/06/23/LP%E5%AE%9A%E7%82%B9%E7%AC%94%E8%AE%B0/","content":"边角（corner）、极值点（extreme point）和基本解（basic solution）：\n\n1. 边角（Corner）\n定义：点$x$是集合$P$的边角，若不存在非零向量$y \\neq 0$，使得$x + y \\in P$且$x - y \\in P$。\n几何意义：\n\n边角是集合$P$的“尖锐”部分，无法在$x$的邻域内沿任何方向$y$同时向$x \\pm y$移动而保持在$P$内。\n在凸集理论中，边角等价于极点（extreme point），即不能表示为集合中其他两点严格凸组合的点。\n示例：\n\n多边形的顶点是边角，因为无法沿任何方向移动同时保持在多边形内。\n\n\n\n\n2. 极值点（Extreme Point）\n定义：点$x$是极值点，若存在目标方向$c$，使得$x$是优化问题$\\max c^T x \\ \\text{s.t.} \\ x \\in P$的唯一最优解。\n性质：\n\n极值点一定是边角，反之亦然（在凸集下）。\n在凸优化中，极值点对应可行域的顶点，是线性规划潜在的最优解候选。\n示例：\n\n线性规划中，最优解通常出现在可行多面体的极值点（顶点）处。\n\n\n\n\n3. 基本解（Basic Solution）\n定义：对于线性约束$Ax = b$，设$x \\in P$，记$A_=$为$x$的紧致约束（即$A_i x = b_i$的行）构成的子矩阵。若$A_=$满秩（$\\text{rank}(A_=) = n$），则$x$为基本解。\n关键点：\n\n紧致约束：在$x$处取等号的约束，几何上表示$x$位于这些约束对应的超平面上。\n满秩条件：$A_=$的列线性独立，确保$x$是唯一确定的（非退化解）。\n与极值点的关系：在标准线性规划中，基本可行解对应可行多面体的顶点（极值点）。\n\n求解方法：\n\n从$A$中选取$n$个线性无关的行构成$A_=$。\n解$A_= x = b_=$得到$x$，其余变量设为0（非基变量）。\n\n证明：在凸多面体 ( P = {x \\mid Ax \\leq b} ) 中，若 ( x ) 是边角（corner），则 ( x ) 是基本解（basic solution）。\n等价地，我们证明其逆否命题：\n\n若 ( x ) 不是基本解（即 ( \\text{rank}(A_=) &lt; n )），则 ( x ) 不是边角。\n\n\n证明过程\n\n\n设定与假设：\n\n设 ( x \\in P )，且 ( A_= ) 是 ( x ) 的紧致约束（即 ( A_i x = b_i ) 的行构成的子矩阵）。\n假设 ( \\text{rank}(A_=) &lt; n )，即 ( A_= ) 的行不满秩（列线性相关）。\n由线性代数，存在非零向量 ( y \\neq 0 )，使得 ( A_= y = 0 )。\n\n\n\n构造扰动点 ( x \\pm \\epsilon y )：\n\n对于紧致约束 ( A_= )，有：\n[\nA_= (x \\pm \\epsilon y) = A_= x \\pm \\epsilon A_= y = b_= \\pm 0 = b_=,\n]\n因此 ( x \\pm \\epsilon y ) 仍然满足紧致约束。\n对于非紧致约束 ( A_j x &lt; b_j )，由于 ( x ) 严格满足不等式，且 ( y ) 是固定向量，存在足够小的 ( \\epsilon &gt; 0 )，使得：\n[\nA_j (x \\pm \\epsilon y) \\leq b_j.\n]\n（因为 ( A_j x &lt; b_j )，而 ( \\epsilon ) 足够小时，扰动不会违反不等式。）\n\n\n\n验证 ( x \\pm \\epsilon y \\in P )：\n\n由上述分析，( x \\pm \\epsilon y ) 满足所有约束 ( Ax \\leq b )，因此 ( x \\pm \\epsilon y \\in P )。\n\n\n\n说明 ( x ) 不是边角：\n\n我们找到了 ( y \\neq 0 )，使得 ( x + \\epsilon y \\in P ) 且 ( x - \\epsilon y \\in P )。\n根据边角的定义，( x ) 不是边角。\n\n\n\n证明：在凸多面体 ( P = {x \\mid Ax \\leq b} ) 中，若 ( x ) 是基本解（basic solution），则 ( x ) 是边角（corner）。\n等价地，我们证明其逆否命题：\n\n若 ( x ) 不是边角（即存在 ( y \\neq 0 ) 使得 ( x \\pm y \\in P )），则 ( x ) 不是基本解（即 ( \\text{rank}(A_=) &lt; n )）。\n\n\n证明过程\n\n\n设定与假设：\n\n设 ( x \\in P )，且 ( A_= ) 是 ( x ) 的紧致约束（即 ( A_i x = b_i ) 的行构成的子矩阵）。\n假设 ( x ) 不是边角，即存在 ( y \\neq 0 )，使得 ( x + y \\in P ) 且 ( x - y \\in P )。\n\n\n\n分析紧致约束 ( A_= ) 的作用：\n\n由于 ( x \\pm y \\in P )，且 ( A_= x = b_= )，我们有：\n[\nA_= (x + y) \\leq b_= \\quad \\Rightarrow \\quad A_= x + A_= y \\leq b_= \\quad \\Rightarrow \\quad A_= y \\leq 0,\n]\n[\nA_= (x - y) \\leq b_= \\quad \\Rightarrow \\quad A_= x - A_= y \\leq b_= \\quad \\Rightarrow \\quad -A_= y \\leq 0.\n]\n结合 ( A_= y \\leq 0 ) 和 ( -A_= y \\leq 0 )，可得：\n[\nA_= y = 0.\n]\n因此，( y ) 是 ( A_= ) 的零空间中的非零向量（因为 ( y \\neq 0 )）。\n\n\n\n说明 ( A_= ) 不满秩：\n\n存在 ( y \\neq 0 ) 使得 ( A_= y = 0 )，说明 ( A_= ) 的列线性相关。\n因此，( \\text{rank}(A_=) &lt; n )，即 ( x ) 不是基本解。\n\n\n\n定理：考虑二分图完美匹配的线性规划\n给定的线性规划（LP）是：\n[\n\\text{maximize} \\sum_{e \\in E} c_e x_e\n]\n[\n\\text{subject to} \\quad \\sum_{e \\in \\delta(v)} x_e = 1 \\quad \\forall v \\in V\n]\n[\n0 \\leq x_e \\leq 1 \\quad \\forall e \\in E\n]\n其中：\n\n( \\delta(v) ) 表示与顶点 ( v ) 相关联的所有边的集合。\n( x_e ) 可以看作是边 ( e ) 是否被选入匹配中的“程度”，理论上可以取 0 到 1 之间的任何实数。\n约束 ( \\sum_{e \\in \\delta(v)} x_e = 1 ) 表示每个顶点恰好被“覆盖”一次（即完美匹配的要求）。\n\n最小生成树（MST）的线性规划（LP）表述\n最小生成树问题（Minimum Spanning Tree, MST）是图论中的一个经典问题，其目标是在一个连通无向图 ( G = (V, E) ) 中找到一个边的子集 ( T \\subseteq E )，使得 ( T ) 构成一棵树（即无环且连通），并且所有边的权重之和最小。这里我们讨论的是如何将MST问题表述为一个线性规划（LP），并解释其性质和求解方法。\nMST的LP表述\n以下是MST问题的一个LP松弛：\n[\n\\text{maximize} \\sum_{e \\in E} c_e x_e\n]\n[\n\\text{subject to} \\quad \\sum_{e \\in E(S)} x_e \\leq |S| - 1 \\quad \\forall S \\subset V, S \\neq \\emptyset\n]\n[\n\\sum_{e \\in E} x_e = |V| - 1\n]\n[\n0 \\leq x_e \\leq 1 \\quad \\forall e \\in E\n]\n其中：\n\n( c_e ) 是边 ( e ) 的权重（这里最大化是因为可以等价地将最小化问题转化为最大化负权重）。\n( x_e ) 表示边 ( e ) 是否被选入生成树（( x_e = 1 )）或不被选入（( x_e = 0 )）。\n( E(S) ) 是子集 ( S ) 的导出子图中的边集，即所有两端点都在 ( S ) 中的边。\n约束 ( \\sum_{e \\in E(S)} x_e \\leq |S| - 1 ) 称为子集消除约束（subtour elimination constraints），确保任何顶点子集 ( S ) 的导出子图中选择的边不会形成环（即不会多于 ( |S| - 1 ) 条边，否则会形成环）。\n约束 ( \\sum_{e \\in E} x_e = |V| - 1 ) 确保选择的边数恰好是 ( |V| - 1 )（生成树的边数）。\n( 0 \\leq x_e \\leq 1 ) 是变量的边界约束。\n\n弱对偶性定理的详细解释\n弱对偶性（Weak Duality）是线性规划（Linear Programming, LP）中一个基本且重要的定理。它描述了原始问题（Primal Problem）和对偶问题（Dual Problem）的解之间的关系。具体来说，对于任何原始问题的可行解和对偶问题的可行解，原始问题的目标函数值不超过对偶问题的目标函数值。\n原始问题和对偶问题的标准形式\n首先，我们需要明确原始问题和对偶问题的标准形式。通常，我们有以下定义：\n\n\n原始问题（Primal Problem）：\n\n形式：最大化问题\n目标函数：( \\max , c^\\top x )\n约束条件：\n\n( A x \\leq b )\n( x \\geq 0 )\n\n\n其中：\n\n( c \\in \\mathbb{R}^n )：目标函数的系数向量\n( x \\in \\mathbb{R}^n )：决策变量\n( A \\in \\mathbb{R}^{m \\times n} )：约束矩阵\n( b \\in \\mathbb{R}^m )：约束条件的右端向量\n\n\n\n\n\n对偶问题（Dual Problem）：\n\n形式：最小化问题\n目标函数：( \\min , b^\\top y )\n约束条件：\n\n( A^\\top y \\geq c )\n( y \\geq 0 )\n\n\n其中：\n\n( y \\in \\mathbb{R}^m )：对偶变量\n\n\n\n\n\n弱对偶性定理的陈述\n弱对偶性定理指出：\n对于原始问题的任何可行解 ( x ) 和对偶问题的任何可行解 ( y )，都有：\n[ c^\\top x \\leq b^\\top y ]\n即，原始问题的目标函数值（最大化）不超过对偶问题的目标函数值（最小化）。\n证明过程\n让我们逐步证明这个定理。\n\n\n原始问题的约束：\n\n( A x \\leq b )\n因为 ( y \\geq 0 )，我们可以两边左乘 ( y^\\top )（因为 ( y ) 非负，不等号方向不变）：\n[ y^\\top A x \\leq y^\\top b ]\n[ y^\\top A x \\leq b^\\top y ] （因为 ( y^\\top b = b^\\top y )）\n\n\n\n对偶问题的约束：\n\n( A^\\top y \\geq c )\n因为 ( x \\geq 0 )，我们可以两边右乘 ( x )（因为 ( x ) 非负，不等号方向不变）：\n[ (A^\\top y)^\\top x \\geq c^\\top x ]\n[ y^\\top A x \\geq c^\\top x ] （因为 ( (A^\\top y)^\\top = y^\\top A )）\n\n\n\n结合两个不等式：\n\n从对偶约束得到：( c^\\top x \\leq y^\\top A x )\n从原始约束得到：( y^\\top A x \\leq b^\\top y )\n因此：\n[ c^\\top x \\leq y^\\top A x \\leq b^\\top y ]\n[ c^\\top x \\leq b^\\top y ]\n\n\n\n直观理解\n\n原始问题是最大化 ( c^\\top x )，对偶问题是最小化 ( b^\\top y )。\n弱对偶性表明，任何原始可行解的目标值都不会超过任何对偶可行解的目标值。\n这意味着对偶问题的目标值提供了一个原始问题目标值的上界，反之亦然。\n\n最大流与最小割\n\n1. 原始问题 (Primal)：最大流\n1.1 决策变量\n\n对于每条有向边 (e=(u\\to v)\\in E)，定义流量变量 (f_e)（也常写成 (f_{uv}) 或者简写 (f_e)）。\n\n1.2 目标函数\n\n我们要从源点 (s) 向汇点 (t) 发送尽可能多的流：\n[\n\\max; f_{ts}.\n]\n这里 (f_{ts}) 可以理解为“从 (s) 到 (t) 的净流量”——在实际写法中通常是最大化\n[\n\\sum_{e\\in \\delta^+(s)} f_e ;-; \\sum_{e\\in \\delta^-(s)} f_e.\n]\n\n1.3 约束条件\n\n\n流量守恒（除了源点和汇点）\n对任意 (v\\in V) 都要满足\n[\nf\\bigl(\\delta^{\\mathrm{in}}(v)\\bigr);-; f\\bigl(\\delta^{\\mathrm{out}}(v)\\bigr);\\le;0,\n]\n也就是对于中间节点 (v)，它的进入流不超过离开流，源点 (s) 可以是“净输出”&gt;0，汇点 (t) 可以是“净输入”&gt;0。\n\n\n容量上界\n对每条边 (e\\in E)，\n[\n0 ;\\le; f_e ;\\le; 1.\n]\n（这里假设每条边的容量都是 1。）\n\n\n\n2. 对偶问题 (Dual)：最小割\n对上述最大流 LP 做对偶，就得到下面这个最小割的线性规划。\n2.1 对偶变量\n\n每条边 (e=(u\\to v)) 对应一个非负变量 (d_{uv})。\n直观上，(d_{uv}) 表示“是否把这条边切掉”（如果切掉，对偶解中通常取 1，否则取 0）。\n每个顶点 (v) 对应一个变量 (y_v\\ge0)，可以看作是“点 (v) 的潜在高度”或“归属子集 S/T 的标记”。\n\n2.2 对偶目标\n[\n\\min;\\sum_{(u,v)\\in E} d_{uv}.\n]\n也就是要切掉尽量少的边，使得 (s) 与 (t) 分离。\n2.3 对偶约束\n\n\n边上的松弛条件\n对每条边 ((u\\to v)\\in E)，要求\n[\nd_{uv};+;y_u;-;y_v;\\ge;0.\n]\n合理的解释是：如果 (u) 和 (v) 在同一侧（(y_u\\approx y_v)），则只要 (d_{uv}=0) 就能满足；但如果 (u) 在 (s) 侧而 (v) 在 (t) 侧，我们需要 (d_{uv}\\ge1) 才能保证“不打通”这条通道。\n\n\n源点与汇点分离\n[\ny_s - y_t ;\\ge; 1.\n]\n这保证了在“潜在高度”意义上，(s) 必须明显高于 (t)，从而在路径上至少要经过一条被切掉的边。\n\n\n非负性\n[\ny_v ;\\ge;0,\\quad d_{uv};\\ge;0.\n]\n\n\n\n3. 从对偶到“最小割”的直观理解\n\n\n我们可以把所有顶点根据 (y_v) 的大小分成两部分：\n\n(S = {v: y_v &gt; \\alpha})\n(T = V\\setminus S)\n\n通过适当选取阈值 (\\alpha)（例如 (\\alpha = 0.5,y_s + 0.5,y_t)），可以使得 (s\\in S)，(t\\in T) 并且对任何跨 (S) 到 (T) 的边 ((u,v))，对应的对偶约束\n[\nd_{uv} + y_u - y_v \\ge 0\n]\n要求 (d_{uv} \\ge y_v - y_u \\ge 1)。由于 (d_{uv}\\ge0)，最优解中就会把每条跨割的边设为 (d_{uv}=1)，而同侧的边可以取 (d_{uv}=0)。\n\n\n因此对偶问题的最优值恰好等于“从 (s) 到 (t) 的最小割所需切掉的边数”——这就是经典的最小割容量。\n\n\n\n4. 最大流 = 最小割\n\n\n弱对偶（任何可行流值 ≤ 任何可行割容量）\n\n\n强对偶（线性规划对偶性）保证最优流值 = 最优割容量。\n\n\n于是得到著名的 最大流–最小割定理：\n“在一个容量为整数（此处为 1）的网络中，最大流的值等于最小割的容量。”\n\n\n\n5. 整数性\n\n由于这个线性规划的约束矩阵是完全整数（即 totally unimodular），原始 LP 和对偶 LP 在最优解时都会取到整数解。\n因此最大流问题可以得到整数流（每条边 (f_e\\in{0,1})），最小割也可以得到整数切割（每条边 (d_{uv}\\in{0,1})），完美对应。\n\n\n总结：\n\n原始问题（Primal）是标准的最大流 LP。\n对偶问题（Dual）恰好对应最小割 LP。\n二者在最优时取相同的数值，且均有整数最优解，成就了最大流–最小割这一经典定理。\n\n冯·诺依曼极小极大定理（Von Neumann Minimax Theorem）的解释\n冯·诺依曼极小极大定理是博弈论中的一个核心定理，它描述了两人零和博弈（Two-player Zero-sum Game）中最优策略的存在性和均衡性。具体来说，它表明：\n[\n\\max_{x \\in \\Delta_m} \\min_{y \\in \\Delta_n} x^\\top A y = \\min_{y \\in \\Delta_n} \\max_{x \\in \\Delta_m} x^\\top A y\n]\n其中：\n\n( A \\in \\mathbb{R}^{m \\times n} ) 是支付矩阵（Payoff Matrix），表示行玩家（Player 1）的收益（列玩家的损失）。\n( x \\in \\Delta_m ) 是行玩家的混合策略（概率分布），( \\Delta_m ) 是 ( m )-维单纯形（即 ( x_i \\geq 0 ), ( \\sum_{i=1}^m x_i = 1 )）。\n( y \\in \\Delta_n ) 是列玩家的混合策略（概率分布），( \\Delta_n ) 是 ( n )-维单纯形（即 ( y_j \\geq 0 ), ( \\sum_{j=1}^n y_j = 1 )）。\n( x^\\top A y ) 是期望收益（行玩家希望最大化，列玩家希望最小化）。\n\n\n1. 定理的直观解释\n(1) 行玩家的视角（先选策略）\n\n行玩家希望最大化自己的最小收益（即“最坏情况下最好能得多少”）。\n他选择一个策略 ( x )，然后列玩家会选择一个 ( y ) 使得 ( x^\\top A y ) 最小（因为列玩家希望最小化行玩家的收益）。\n因此，行玩家要解决：\n[\n\\max_{x} \\left( \\min_{y} x^\\top A y \\right)\n]\n\n(2) 列玩家的视角（先选策略）\n\n列玩家希望最小化行玩家的最大收益（即“最好情况下最坏能损失多少”）。\n他选择一个策略 ( y )，然后行玩家会选择一个 ( x ) 使得 ( x^\\top A y ) 最大（因为行玩家希望最大化自己的收益）。\n因此，列玩家要解决：\n[\n\\min_{y} \\left( \\max_{x} x^\\top A y \\right)\n]\n\n(3) 定理的核心结论\n无论谁先选择策略，最终都会达到相同的均衡值：\n[\n\\max_{x} \\min_{y} x^\\top A y = \\min_{y} \\max_{x} x^\\top A y = v\n]\n这个共同的值 ( v ) 称为博弈的值（Value of the Game），而对应的 ( x^* ) 和 ( y^* ) 称为纳什均衡策略（Nash Equilibrium Strategies）。\n\n2. 为什么这个定理成立？\n(1) 从线性规划角度看\n极小极大定理可以看作是线性规划对偶性的一个特例：\n\n行玩家的优化问题可以写成：\n[\n\\max_{x} \\left( \\min_{y} x^\\top A y \\right) = \\max_{x} \\left( \\min_{j} (A x)_j \\right)\n]\n即行玩家希望最大化自己最差情况下的收益（因为列玩家会选择最不利的 ( y )）。\n列玩家的优化问题可以写成：\n[\n\\min_{y} \\left( \\max_{x} x^\\top A y \\right) = \\min_{y} \\left( \\max_{i} (A^\\top y)_i \\right)\n]\n即列玩家希望最小化行玩家最好情况下的收益（因为行玩家会选择最有利的 ( x )）。\n\n由于线性规划的对偶性，这两个问题的解是相同的。\n(2) 从博弈论角度看\n\n在零和博弈中，行玩家的收益就是列玩家的损失，因此双方的目标完全对立。\n纳什均衡（Nash Equilibrium）在这种博弈中表现为：\n\n行玩家选择 ( x^* )，使得无论列玩家怎么选 ( y )，自己的收益至少是 ( v )。\n列玩家选择 ( y^* )，使得无论行玩家怎么选 ( x )，行玩家的收益至多是 ( v )。\n\n\n因此，双方都无法通过单方面改变策略来获得更好的结果，达到均衡。\n\n\n","tags":["其他"]},{"title":"note1","url":"/notes.github.io/2025/06/23/note1/","content":"\n\n距离与纠错能力：通过上述讨论，我们知道：\n\n要处理 ( k ) 个擦除错误，需要最小距离 ( \\ge k+1 )。\n要处理 ( k ) 个一般错误，需要最小距离 ( \\ge 2k+1 )。\n\n\n\nReed-Solomon码的性质：\n\nReed-Solomon 码通过将 ( n ) 个消息映射到一个具有 ( n + 2k ) 个符号的码字，其理论最小距离正好是 ( 2k+1 )。\n我们通过构造两个在 ( n-1 ) 点相同的不同码字得到了上界 ( 2k+1 )，同时从译码正确性（错误不能互相混淆）知下界也为 ( 2k+1 )，因此二者相等。\n\n\n\n侧记：这种证明方式实际上等价于利用了Singleton界，是衡量码设计中极限性能的重要工具。\n\n\n","tags":["其他"]},{"title":"midterm","url":"/notes.github.io/2025/06/23/midterm/","content":"问题 #1\n令 $d \\ge 1$ 为一个整数，令 $T_d$ 为 $d$ 阶的切比雪夫多项式。\n\n\n请证明在 $[-1,1]$ 上的无穷范数的意义下，$x^d - \\frac{1}{2^{d-1}}T_d(x)$ 是 $x^d$ 的最优 $d-1$ 阶近似，其中，$[-1,1]$ 上的无穷范数定义如下：\n$||p||\\infty = \\sup{x \\in [-1,1]} |p(x)|$.\n\n\n给定一个 $d$ 次多项式，$p(x) = a_0 + a_1x + \\dots + a_dx^d$，请给出在 $[-1,1]$ 上的无穷范数意义下，$p(x)$ 的最优 $d-1$ 阶近似。\n问题 #2\n\n\n一位军官在她的保险箱中存放了一封重要的信，以防她在战斗中牺牲，她决定与她的部队分享密码（该密码为一个数字）。然而，所有人都知道部队中有3名间谍，但除了这三名间谍自己，没有人知道他们是谁。这3名间谍可以相互协调，他们要么撒谎使人们无法打开保险箱，要么会尝试他们自己打开保险箱（如果他们能打开的话）。因此，军官希望分享密码的方案能满足以下条件：\n\n当他们中的 $M$ 人聚在一起时，即使他们中间有间谍，他们也能确保打开保险箱。\n这3名间谍的密码不足以让他们三人打开保险箱。\n\n请帮助军官设计一个分享她的密码的方案。这个方案是什么？最小的 $M$ 是多少？展示你的方案并论证为什么你的方案有效，并证明任何更小的 $M$ 都不能工作。注意：部队只有一次机会打开保险箱；如果打开失败，保险箱将自毁。\n问题 #3\n\n\n给定单位长度向量 $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$，即 $||\\mathbf{x}||_2 = ||\\mathbf{y}||_2 = 1$。求正交矩阵 $Q$ 使得 $Q\\mathbf{y} = \\mathbf{x}$。\n\n\n更一般地，给定 $\\mathbb{R}^m$ 里面的单位长度向量 $\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_m$ 和 $\\mathbf{y}_1, \\mathbf{y}_2, \\dots, \\mathbf{y}_m$。假设 $\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_m$ 是两两正交的，且 $\\mathbf{y}_1, \\mathbf{y}_2, \\dots, \\mathbf{y}_m$ 也是两两正交的，求正交矩阵 $Q$ 使得 $\\forall i, Q\\mathbf{y}_i = \\mathbf{x}_i$。\n\n\n问题 #4\n回顾最小二乘法的法线方程 $A^T A \\mathbf{x} = A^T \\mathbf{b}$，其中 $A$ 是实数矩阵。一般来说，$A^T A$ 可能是不可逆的。假设 $A^T A$ 的最大特征值为 1.\n\n\n对于固定的 $\\delta &gt; 0$，$\\text{cond}_2(A^T A + \\delta I)$ 最大可能是多少？注：$\\text{cond}_2(\\cdot)$ 特指由 2-范数所诱导的矩阵的条件数。\n\n\n记 $\\mathbf{x} = (A^T A + \\delta I)^{-1} A^T \\mathbf{b}$。证明：\n$\\mathbf{x} = \\arg\\min_{\\mathbf{x}} ||A\\mathbf{x} - \\mathbf{b}||_2^2 + \\delta ||\\mathbf{x}||_2^2$\n\n\n设矩阵 $A$ 的 SVD 分解为 $A = U \\Sigma V^T$。假设 $A$ 的列是满秩的，则最小二乘解可以写作 $\\mathbf{x}_{LS} = \\sum_i \\frac{1}{\\sigma_i} \\mathbf{u}_i \\mathbf{v}_i^T \\mathbf{b}$。为了让最小二乘法更加稳定，一个思路是直接舍弃掉 $\\sigma_i \\approx 0$ 的那些项。试写出 $\\mathbf{x}$ 的一个类似的表达式，并分析为什么它能实现类似于“舍弃掉 $\\sigma_i \\approx 0$ 的那些项”的效果。\n\n\n问题 #5\n给定矩阵 $A \\in \\mathbb{R}^{m \\times n}$，记 $A_i$ 为 $A$ 的第 $i$ 行，$A^{(j)}$ 为 $A$ 的第 $j$ 列，求证：\n$||A||{1 \\to 2} = \\max{j:1 \\le j \\le n} ||A^{(j)}||_2$\n$||A||{2 \\to \\infty} = \\max{i:1 \\le i \\le n} ||A_i||_2$\nHINT: 第二个等式可能用到 Cauchy-Schwarz 不等式: $\\forall x, y \\in \\mathbb{R}^n$, $(x,y)^2 \\le (x,x) \\cdot (y,y)$.\n问题 #6\n\n\n给定矩阵 $A \\in \\mathbb{R}^{m \\times n}$，假设对 $A^T A$ 的楚列斯基 (Cholesky) 分解有 $A^T A = L L^T$，其中 $L$ 为下三角阵。考虑 $Q := A(L^T)^{-1}$，请证明 $Q$ 的列是正交的，并推导 $A^T A$ 的楚列斯基 (Cholesky) 分解与 $A$ 的 QR 分解之间的关系。\n\n\n给定矩阵 $A \\in \\mathbb{R}^{m \\times n}$, $m \\le n$，它一定能被分解为 $A = RQ$，其中 $R$ 为上三角阵，且 $Q$ 为正交矩阵。请设计一个分解的方法，进而证明 $A = RQ$ 分解的存在性。\n\n\nHINT: 尝试修改 Gram-Schmidt 过程。\n问题 #7\n给定常数 $u &gt; 0$ 和任意向量 $v \\in \\mathbb{R}^n$，试找出最小化 $u ||x||_1 + \\frac12 ||x - v||_2^2$ 的向量 $x$。\nHINT: 可以尝试求解 $n=1$ 的情况。\n问题 #8 (Stability of sorting)\n满足 $Y_{(1)} \\le \\dots \\le Y_{(n)}$。\n注意噪声可能\n给定向量 $X = (X_1, \\dots, X_n)$，它排序后的版本记作 $\\text{sort}(X) = (X_{(1)}, \\dots, X_{(n)})$，满足 $X_{(1)} \\le \\dots \\le X_{(n)}$。考虑对 $X$ 加入了一些噪声之后得到的向量 $Y$，同样记 $Y$ 排序后的版本为 $\\text{sort}(Y)$改变了元素的大小顺序。\n\n证明 $|X_{(1)} - Y_{(1)}| \\le ||X - Y||_2$\n证明 $|X_{(n)} - Y_{(n)}| \\le ||X - Y||_2$\n证明对所有 $k$，$|X_{(k)} - Y_{(k)}| \\le ||X - Y||_2$\n证明 $||\\text{sort}(X) - \\text{sort}(Y)||_1 \\le ||X - Y||_1$\n问题 #9\n一般来说，一个矩阵的秩是不连续的。事实上，可逆矩阵的集合在实数矩阵里面是一个稠密集。这就意味着，一个非满秩的矩阵，可以通过一个任意小的扰动使其变得满秩。这里研究一个相对更稳定的秩的定义，这样的稳定性让 Stable rank 作为 rank 的一个替代量在低秩矩阵近似的研究中得到广泛应用。\n\n一个实矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的 stable rank 定义为\n$\\text{STABLE-RANK}(A) = \\frac{||A||_F^2}{||A||_2^2}$\n\n\n当矩阵 $A$ 的列向量都等于 $\\vec{v} \\in \\mathbb{R}^n \\setminus {\\vec{0}}$ 时，证明 $\\text{STABLE-RANK}(A) = 1$。\n\n\n当矩阵 $A$ 的列向量是 orthonormal 时，证明 $\\text{STABLE-RANK}(A) = n$。\n\n\n更一般的，证明 $1 \\le \\text{STABLE-RANK}(A) \\le n$。\n\n\n证明 $\\text{STABLE-RANK}(A) \\le \\text{RANK}(A)$。\n\n\n","tags":["其他"]},{"title":"notePuGraph","url":"/notes.github.io/2025/06/23/notePuGraph/","content":"图的邻接矩阵最大特征值上下界证明\n设图 ( G ) 的邻接矩阵为 ( A )，其最大特征值为 ( \\alpha_1 )，平均度 ( d_{\\text{avg}} = \\frac{2|E|}{n} )，最大度数为 ( \\Delta = \\deg_{\\max}(G) )。需证明：\n[\nd_{\\text{avg}} \\leq \\alpha_1 \\leq \\Delta\n]\n\n上界证明（( \\alpha_1 \\leq \\Delta ))\n\n\n特征值与特征向量定义\n设 ( \\alpha_1 ) 为 ( A ) 的最大特征值，对应的特征向量为 ( \\bm{v} )，满足：\n[\nA\\bm{v} = \\alpha_1 \\bm{v}\n]\n假设 ( \\bm{v} ) 是单位向量（即 ( |\\bm{v}|_2 = 1 )）。\n\n\n选择最大分量\n取 ( \\bm{v} ) 中绝对值最大的分量为 ( v_j )，即：\n[\n|v_j| = \\max_{i} |v_i| &gt; 0\n]\n根据特征方程，对第 ( j ) 行有：\n[\n\\alpha_1 v_j = \\sum_{i=1}^n A_{j,i} v_i\n]\n\n\n绝对值的三角不等式\n取绝对值后：\n[\n|\\alpha_1| |v_j| = \\left| \\sum_{i=1}^n A_{j,i} v_i \\right| \\leq \\sum_{i=1}^n |A_{j,i}| |v_i|\n]\n因为邻接矩阵元素 ( A_{j,i} \\in {0,1} )，且 ( |v_i| \\leq |v_j| )，可得：\n[\n\\sum_{i=1}^n |A_{j,i}| |v_i| \\leq \\sum_{i=1}^n A_{j,i} |v_j| = \\deg(j) |v_j| \\leq \\Delta |v_j|\n]\n\n\n化简不等式\n结合上述结果：\n[\n|\\alpha_1| |v_j| \\leq \\Delta |v_j|\n]\n因 ( |v_j| &gt; 0 )，两边约去后得：\n[\n|\\alpha_1| \\leq \\Delta\n]\n由于 ( \\alpha_1 ) 是实对称矩阵（无向图）的最大特征值，必为非负实数，故：\n[\n\\alpha_1 \\leq \\Delta\n]\n\n\n\n下界证明（( d_{\\text{avg}} \\leq \\alpha_1 ))\n\nRayleigh商性质\n最大特征值 ( \\alpha_1 ) 满足：\n[\n\\alpha_1 = \\max_{\\bm{x} \\neq \\bm{0}} \\frac{\\bm{x}^T A \\bm{x}}{\\bm{x}^T \\bm{x}}\n]\n取 ( \\bm{x} = \\bm{1} )（全1向量），则：\n[\n\\bm{x}^T A \\bm{x} = \\sum_{i,j} A_{i,j} = 2|E|\n]\n分母为：\n[\n\\bm{x}^T \\bm{x} = n\n]\n因此：\n[\n\\alpha_1 \\geq \\frac{2|E|}{n} = d_{\\text{avg}}\n]\n\n\n总结\n结合上下界结果，得：\n[\n\\boxed{d_{\\text{avg}} \\leq \\alpha_1 \\leq \\Delta}\n]\n关键点：\n\n上界：通过特征向量分量的最大性，结合邻接矩阵的稀疏性（每行非零元素数为度数）。\n下界：利用Rayleigh商与全1向量的计算，将最大特征值与平均度关联。\n\n引理证明详解\n引理：对于二分图 ( G )，若 ( \\alpha ) 是邻接矩阵 ( A(G) ) 的特征值且重数为 ( k )，则 ( -\\alpha ) 也是 ( A(G) ) 的特征值，重数同样为 ( k )。\n\n1. 邻接矩阵的分块结构\n设二分图 ( G ) 的两个顶点集为 ( U ) 和 ( V )，其邻接矩阵可表示为分块形式：\n[\nA = \\begin{pmatrix}\n0 &amp; B \\\nB^T &amp; 0\n\\end{pmatrix},\n]\n其中 ( B ) 是 ( |U| \\times |V| ) 的矩阵，描述 ( U ) 到 ( V ) 的边，且 ( B^T ) 是 ( B ) 的转置。\n\n2. 特征值与特征向量的对应关系\n假设 ( \\begin{pmatrix} x \\ y \\end{pmatrix} ) 是 ( A ) 的特征向量，对应特征值 ( \\alpha )，即：\n[\nA \\begin{pmatrix} x \\ y \\end{pmatrix} = \\alpha \\begin{pmatrix} x \\ y \\end{pmatrix}.\n]\n展开分块矩阵乘法，得到方程组：\n[\n\\begin{cases}\nB y = \\alpha x, \\\nB^T x = \\alpha y.\n\\end{cases}\n]\n\n3. 构造 ( -\\alpha ) 的特征向量\n考虑向量 ( \\begin{pmatrix} x \\ -y \\end{pmatrix} )，计算其作用：\n[\nA \\begin{pmatrix} x \\ -y \\end{pmatrix} = \\begin{pmatrix}\n0 &amp; B \\\nB^T &amp; 0\n\\end{pmatrix} \\begin{pmatrix} x \\ -y \\end{pmatrix} = \\begin{pmatrix} -B y \\ B^T x \\end{pmatrix}.\n]\n代入 ( B y = \\alpha x ) 和 ( B^T x = \\alpha y )，得：\n[\nA \\begin{pmatrix} x \\ -y \\end{pmatrix} = \\begin{pmatrix} -\\alpha x \\ \\alpha y \\end{pmatrix} = -\\alpha \\begin{pmatrix} x \\ -y \\end{pmatrix}.\n]\n这表明 ( \\begin{pmatrix} x \\ -y \\end{pmatrix} ) 是 ( A ) 对应特征值 ( -\\alpha ) 的特征向量。\n\n4. 重数的等价性\n\n\n线性无关性保持：\n若 ( \\alpha ) 的重数为 ( k )，则存在 ( k ) 个线性无关的特征向量 ( \\left{ \\begin{pmatrix} x_1 \\ y_1 \\end{pmatrix}, \\dots, \\begin{pmatrix} x_k \\ y_k \\end{pmatrix} \\right} )。\n构造对应的向量组 ( \\left{ \\begin{pmatrix} x_1 \\ -y_1 \\end{pmatrix}, \\dots, \\begin{pmatrix} x_k \\ -y_k \\end{pmatrix} \\right} )。\n验证线性无关性：\n假设存在标量 ( c_1, \\dots, c_k ) 使得：\n[\n\\sum_{i=1}^k c_i \\begin{pmatrix} x_i \\ -y_i \\end{pmatrix} = \\begin{pmatrix} 0 \\ 0 \\end{pmatrix}.\n]\n拆分分量得：\n[\n\\sum_{i=1}^k c_i x_i = 0 \\quad \\text{和} \\quad -\\sum_{i=1}^k c_i y_i = 0.\n]\n由于原向量组线性无关，唯一解为 ( c_1 = \\dots = c_k = 0 )，故变换后的向量组仍线性无关。\n\n\n对称性保证重数相等：\n邻接矩阵 ( A ) 是实对称矩阵，其特征值均为实数，且不同特征值对应的特征向量正交。\n若 ( \\alpha \\neq 0 )，则 ( \\alpha ) 和 ( -\\alpha ) 为不同特征值，其重数由矩阵的谱定理保证相等（因特征空间维度相同）。\n\n\n\n5. 零特征值的特殊情况\n当 ( \\alpha = 0 ) 时，( -\\alpha = 0 )，重数显然相同。此时特征向量满足 ( B y = 0 ) 和 ( B^T x = 0 )，其解空间的维度由矩阵 ( B ) 的秩决定，对 ( \\alpha ) 和 ( -\\alpha ) 一致。\n\n总结\n通过分块矩阵的结构分析、特征向量的符号变换以及线性无关性保持，可严格证明：\n[\n\\text{重数}(\\alpha) = \\text{重数}(-\\alpha) = k.\n]\n\n引理证明：\n条件：设 ( G ) 是简单无向图，其邻接矩阵 ( A ) 的特征值满足 ( \\alpha_i = -\\alpha_{n-i+1} ) 对所有 ( i ) 成立。\n目标：证明 ( G ) 是二分图（即不含奇数长度的环）。\n证明步骤：\n\n\n特征值幂和为零：\n对于任意奇数 ( k )，特征值的 ( k ) 次幂之和满足\n[\n\\sum_{i=1}^n \\alpha_i^k = 0.\n]\n推导：由条件 ( \\alpha_i = -\\alpha_{n-i+1} )，特征值成对互为相反数。对每一对 ( (\\alpha_i, -\\alpha_i) )，其奇数次幂和为 ( \\alpha_i^k + (-\\alpha_i)^k = 0 )。若 ( n ) 为奇数，中间特征值必为 ( 0 )，贡献为 ( 0 )。故总和为 ( 0 )。\n\n\n矩阵幂的迹为零：\n邻接矩阵 ( A^k ) 的迹为\n[\n\\text{trace}(A^k) = \\sum_{i=1}^n \\alpha_i^k = 0.\n]\n依据：矩阵的迹等于其特征值的和，且 ( A^k ) 的特征值为 ( \\alpha_i^k )。\n\n\n闭合走路不存在：\n( \\text{trace}(A^k) ) 的组合意义为长度为 ( k ) 的闭合走路总数。由于迹为零，且 ( (A^k){i,i} \\geq 0 ) 对每个顶点 ( i )，故\n[\n(A^k){i,i} = 0 \\quad \\text{对所有顶点} , i , \\text{和奇数} , k.\n]\n因此，图中不存在长度为 ( k ) 的闭合走路（包括简单环）。\n\n\n排除奇环：\n若存在奇数长度环，其对应闭合走路会使 ( (A^k)_{i,i} \\geq 1 )，与 ( \\text{trace}(A^k) = 0 ) 矛盾。故 ( G ) 不含任何奇数长度的环。\n\n\n二分图判定：\n图论定理指出，无奇环的图必为二分图。因此，( G ) 是二分图。\n\n\n结论：邻接矩阵特征值关于零对称的图 ( G ) 必为二分图，证毕。\n拉普拉斯矩阵（Laplacian Matrix）详解\n1. 基本定义\n给定一个无向图 ( G = (V, E) )，其拉普拉斯矩阵 ( L(G) ) 定义为：\n[\nL(G) = D(G) - A(G)\n]\n\n度矩阵 ( D(G) )：对角矩阵，对角线元素 ( D_{u,u} = \\text{deg}(u) )，表示顶点 ( u ) 的度数，非对角线元素为 0。\n邻接矩阵 ( A(G) )：矩阵元素 ( A_{u,v} = 1 ) 当且仅当边 ( uv \\in E )，否则为 0。\n\n2. 正则图的拉普拉斯矩阵\n对于 ( d )-正则图（每个顶点的度数均为 ( d )），度矩阵可写为：\n[\nD(G) = dI\n]\n其中 ( I ) 是单位矩阵。因此，拉普拉斯矩阵简化为：\n[\nL(G) = dI - A(G)\n]\n\n特征空间关系：正则图的邻接矩阵 ( A(G) ) 和拉普拉斯矩阵 ( L(G) ) 共享相同的特征向量，且特征值满足线性关系：\n[\n\\lambda_L = d - \\lambda_A\n]\n其中 ( \\lambda_L ) 是 ( L(G) ) 的特征值，( \\lambda_A ) 是 ( A(G) ) 的对应特征值。\n例子：在 3-正则图中，若 ( A ) 的特征值为 3, 1, -2，则 ( L ) 的特征值为 0, 2, 5（因为 ( 3 - 3 = 0 ), ( 3 - 1 = 2 ), ( 3 - (-2) = 5 )）。\n\n3. 一般图的拉普拉斯矩阵\n对于非正则图，度矩阵 ( D(G) ) 不再是标量矩阵，因此：\n[\nL(G) = D(G) - A(G)\n]\n\n特征空间差异：由于 ( D(G) ) 的对角元素（度数）不再一致，( L(G) ) 和 ( A(G) ) 的 特征向量不再相同，特征值之间也无简单线性关系。\n例子：若图包含一个度数为 2 的顶点和一个度数为 1 的顶点，( D(G) ) 和 ( A(G) ) 的相互作用复杂，导致特征空间独立。\n\n4. 拉普拉斯矩阵的边分解\n拉普拉斯矩阵可分解为 单边贡献 的和：\n[\nL(G) = \\sum_{e \\in E} L_e\n]\n其中每条边 ( e = (u, v) ) 对应的矩阵 ( L_e ) 定义为：\n[\nL_e = b_e b_e^\\top\n]\n\n关联向量 ( b_e )：向量 ( b_e ) 的长度为顶点数 ( |V| )，定义如下：\n[\nb_e(u) = 1, \\quad b_e(v) = -1, \\quad \\text{其他位置为} \\ 0.\n]\n展开形式：例如，若边 ( e ) 连接顶点 1 和 2，则：\n[\nb_e = [1, -1, 0, \\dots, 0]^\\top\n]\n[\nL_e = b_e b_e^\\top = \\begin{bmatrix}\n1 &amp; -1 &amp; 0 &amp; \\cdots \\\n-1 &amp; 1 &amp; 0 &amp; \\cdots \\\n0 &amp; 0 &amp; 0 &amp; \\cdots \\\n\\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots\n\\end{bmatrix}\n]\n求和验证：将所有边的 ( L_e ) 相加：\n\n对角线元素：每个顶点 ( u ) 的度数为与其相连的边数，因此 ( \\sum_{e \\ni u} L_e(u,u) = \\text{deg}(u) )，对应 ( D(G) )。\n非对角线元素：边 ( uv ) 对应的 ( L_e ) 在位置 ( (u,v) ) 和 ( (v,u) ) 处为 -1，累加后对应 ( -A(G) )。\n因此：\n[\n\\sum_{e \\in E} L_e = D(G) - A(G) = L(G)\n]\n\n\n\n5. 分解的意义\n\n物理意义：每条边独立地对拉普拉斯矩阵产生“局部影响”，整体效果通过叠加实现。\n应用场景：此分解在 随机游走、电阻网络 和 图信号处理 中用于分析边对全局性质的贡献。\n\n拉普拉斯矩阵 ( L(G) ) 的性质与证明\n1. 定义回顾\n给定无向图 ( G = (V, E) )，其拉普拉斯矩阵 ( L(G) ) 定义为：\n[\nL(G) = D(G) - A(G)\n]\n其中：\n\n( D(G) ) 是度矩阵（对角矩阵，( D_{u,u} = \\text{deg}(u) )），\n( A(G) ) 是邻接矩阵（( A_{u,v} = 1 ) 当且仅当 ( uv \\in E )）。\n\n拉普拉斯矩阵可以分解为所有边的贡献之和：\n[\nL(G) = \\sum_{e \\in E} L_e, \\quad \\text{其中} \\quad L_e = b_e b_e^\\top\n]\n其中 ( b_e ) 是边 ( e = (u, v) ) 的关联向量：\n[\nb_e(u) = 1, \\quad b_e(v) = -1, \\quad \\text{其余位置为} \\ 0.\n]\n\n2. 性质 1：( \\mathbf{1} ) 是 ( L(G) ) 的特征向量，对应特征值 0\n证明：\n\n由于 ( L(G) = D(G) - A(G) )，计算 ( L(G) \\mathbf{1} )：\n[\n(L(G) \\mathbf{1})u = \\text{deg}(u) \\cdot 1 - \\sum{v \\sim u} 1 = \\text{deg}(u) - \\text{deg}(u) = 0\n]\n因此：\n[\nL(G) \\mathbf{1} = \\mathbf{0} = 0 \\cdot \\mathbf{1}\n]\n这说明 ( \\mathbf{1} ) 是 ( L(G) ) 的特征向量，对应特征值 0。\n\n直观解释：\n\n拉普拉斯矩阵的每一行代表一个顶点的度数减去其邻居的影响，而 ( \\mathbf{1} ) 是一个均匀向量，使得所有顶点的度数贡献和邻居贡献相互抵消，最终得到 0。\n\n\n3. 性质 2：( L(G) ) 是半正定矩阵（( L(G) \\succeq 0 )）\n证明：\n\n利用拉普拉斯矩阵的边分解：\n[\nL(G) = \\sum_{e \\in E} b_e b_e^\\top\n]\n对于任意向量 ( x \\in \\mathbb{R}^n )，计算二次型：\n[\nx^\\top L(G) x = x^\\top \\left( \\sum_{e \\in E} b_e b_e^\\top \\right) x = \\sum_{e \\in E} x^\\top b_e b_e^\\top x\n]\n由于 ( b_e^\\top x = x_u - x_v )（其中 ( e = (u, v) )），因此：\n[\nx^\\top L(G) x = \\sum_{e = (u, v) \\in E} (x_u - x_v)^2 \\geq 0\n]\n因为平方项非负，所以 ( L(G) ) 是半正定的。\n\n关键步骤解释：\n\n( x^\\top b_e b_e^\\top x = (b_e^\\top x)^2 = (x_u - x_v)^2 )：\n\n由于 ( b_e ) 仅在 ( u ) 和 ( v ) 处有非零值（1 和 -1），所以：\n[\nb_e^\\top x = \\sum_{i=1}^n b_e(i) x_i = x_u - x_v\n]\n因此，( x^\\top b_e b_e^\\top x = (x_u - x_v)^2 )，即每条边贡献一个平方差项。\n\n\n\n结论：\n\n由于 ( x^\\top L(G) x ) 是所有边的平方差之和，且 ( (x_u - x_v)^2 \\geq 0 )，所以 ( L(G) ) 是半正定的。\n最小特征值为 0，因为 ( L(G) \\mathbf{1} = \\mathbf{0} )，即存在非零向量 ( \\mathbf{1} ) 使得二次型为 0。\n\n\n定理\n给定图 ( G )，它是连通的当且仅当拉普拉斯矩阵 ( L(G) ) 的特征值 0 的重数为 1。\n\n证明（⇐）：不连通图的情况\n假设 ( G ) 不连通，则 ( G ) 可划分为至少两个连通分量 ( V_1 ) 和 ( V_2 )。此时，( L(G) ) 可表示为分块对角矩阵：\n[\nL(G) = \\begin{bmatrix}\nL(G_1) &amp; 0 \\\n0 &amp; L(G_2)\n\\end{bmatrix}\n]\n其中 ( L(G_1) ) 和 ( L(G_2) ) 分别是子图 ( G_1 ) 和 ( G_2 ) 的拉普拉斯矩阵。\n由于 ( G_1 ) 和 ( G_2 ) 各自连通，( L(G_1) ) 和 ( L(G_2) ) 均有一个特征值 0，对应的特征向量分别为 ( \\mathbf{1}{V_1} )（( V_1 ) 上的全 1 向量）和 ( \\mathbf{1}{V_2} )（( V_2 ) 上的全 1 向量）。因此，( L(G) ) 的零空间由以下线性无关向量张成：\n[\n\\begin{bmatrix}\n\\mathbf{1}{V_1} \\\n0\n\\end{bmatrix}, \\quad\n\\begin{bmatrix}\n0 \\\n\\mathbf{1}{V_2}\n\\end{bmatrix}\n]\n故特征值 0 的重数至少为 2。\n结论：若 ( G ) 不连通，则 ( L(G) ) 的特征值 0 的重数大于 1。\n\n证明（⇒）：连通图的情况\n假设 ( G ) 连通，且存在向量 ( x ) 满足 ( L(G)x = 0 )。由半正定性：\n[\nx^\\top L(G) x = \\sum_{(i,j) \\in E} (x_i - x_j)^2 = 0\n]\n因此，对所有边 ( (i,j) \\in E )，有 ( x_i = x_j )。由于 ( G ) 连通，任意两顶点 ( i ) 和 ( j ) 可通过路径连接，故 ( x_i = x_j ) 对所有 ( i,j \\in V ) 成立。即 ( x ) 必为全 1 向量 ( \\mathbf{1} ) 的标量倍：\n[\nx = c \\cdot \\mathbf{1}\n]\n因此，零空间维度为 1，特征值 0 的重数为 1。\n结论：若 ( G ) 连通，则 ( L(G) ) 的特征值 0 的重数为 1。\n\n定理证明\n定理：给定图 ( G )，其拉普拉斯矩阵的特征值满足 ( 0 = \\lambda_1 \\leq \\lambda_2 \\leq \\cdots \\leq \\lambda_n )，则\n[\n\\lambda_k = 0 \\quad \\text{当且仅当} \\quad G , \\text{有至少} , k , \\text{个连通分量}.\n]\n\n证明\n\n\n方向（⇒）：若 ( \\lambda_k = 0 )，则 ( G ) 至少有 ( k ) 个连通分量\n\n拉普拉斯矩阵的零特征值重数：\n由已知，若图 ( G ) 有 ( m ) 个连通分量，则其拉普拉斯矩阵 ( L(G) ) 可表示为分块对角矩阵：\n[\nL(G) = \\begin{bmatrix}\nL(G_1) &amp; 0 &amp; \\cdots &amp; 0 \\\n0 &amp; L(G_2) &amp; \\cdots &amp; 0 \\\n\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\n0 &amp; 0 &amp; \\cdots &amp; L(G_m)\n\\end{bmatrix},\n]\n其中每个 ( L(G_i) ) 对应一个连通分量的拉普拉斯矩阵。\n\n每个连通分量 ( G_i ) 的 ( L(G_i) ) 有一个零特征值（对应特征向量为 ( \\mathbf{1}_{G_i} )），其余特征值为正。\n因此，( L(G) ) 的零特征值总数为 ( m )，即 ( \\lambda_1 = \\lambda_2 = \\cdots = \\lambda_m = 0 )。\n\n\n结论：\n若 ( \\lambda_k = 0 )，则 ( k \\leq m )，即 ( G ) 至少有 ( k ) 个连通分量。\n\n\n\n方向（⇐）：若 ( G ) 有至少 ( k ) 个连通分量，则 ( \\lambda_k = 0 )\n\n零特征值的数量：\n设 ( G ) 有 ( m \\geq k ) 个连通分量，则 ( L(G) ) 的零特征值数量为 ( m )。\n由于特征值按升序排列，前 ( m ) 个特征值为零，即：\n[\n\\lambda_1 = \\lambda_2 = \\cdots = \\lambda_m = 0.\n]\n因此，当 ( k \\leq m ) 时，( \\lambda_k = 0 )。\n\n\n\n\n关键步骤\n\n\n分块对角矩阵的特征值：\n\n若 ( G ) 分解为 ( m ) 个连通分量，则 ( L(G) ) 的特征值为各子图 ( L(G_i) ) 特征值的并集。\n每个 ( L(G_i) ) 贡献一个零特征值，其余为正特征值。因此，( L(G) ) 的零特征值数量为 ( m )。\n\n\n\n特征值排序：\n\n前 ( m ) 个特征值为零，即 ( \\lambda_1 = \\lambda_2 = \\cdots = \\lambda_m = 0 )。\n后续特征值为各子图的最小正特征值升序排列，即 ( \\lambda_{m+1} &gt; 0 )。\n\n\n\n\n推论\n\n连通性判定：\n\n( \\lambda_2 &gt; 0 \\iff G ) 是连通的（即 ( m = 1 )）。\n( \\lambda_2 = 0 \\iff G ) 不连通（即 ( m \\geq 2 )）。\n\n\n一般情况：\n( \\lambda_k = 0 ) 当且仅当 ( G ) 有至少 ( k ) 个连通分量，即零特征值的重数等于连通分量数。\n\n\nPerron-Frobenius定理的证明思路简介\nPerron-Frobenius定理是非负矩阵理论的核心成果，针对非负、不可约且非周期的矩阵 ( A )，其证明思路可概括如下：\n\n1. 最大特征值 ( \\lambda_1 ) 的重数为1\n核心思路：\n\n存在性：通过构造 Collatz-Wielandt函数 ( r_A(x) = \\min_{x_i \\neq 0} \\frac{(Ax)_i}{x_i} )，证明存在正向量 ( x ) 使得 ( r_A(x) = \\lambda_1 )，即 ( \\lambda_1 ) 是谱半径 ( \\rho(A) )（最大特征值）。\n唯一性：利用 不可约性，若存在两个不同的正特征向量对应 ( \\lambda_1 )，则可通过线性组合构造矛盾，说明代数重数为1。\n关键工具：Gelfand公式 ( \\rho(A) = \\lim_{k \\to \\infty} |A^k|^{1/k} ) 用于证明 ( \\lambda_1 ) 的极值性。\n\n\n2. 对应特征向量全为正且符号一致\n核心思路：\n\n非负性到正性：若 ( A ) 不可约，其对应的特征向量 ( v ) 非负且非零。通过不可约性，( (I + A)^{n-1} ) 会将任何非零向量映射为正向量，从而 ( v ) 必须全正。\n符号一致性：假设存在分量符号不同，则通过矩阵的不可约性（连通性）推导矛盾，证明所有分量符号一致。\n\n\n3. 其他特征值满足 ( |\\lambda_i| &lt; \\lambda_1 , (2 \\leq i \\leq n) )\n核心思路：\n\n周期性排除：若 ( A ) 非周期（本原矩阵），存在 ( m ) 使 ( A^m ) 为正矩阵，此时 ( \\lambda_i^m ) 的模严格小于 ( \\lambda_1^m )。\n矛盾法：假设存在 ( \\lambda_j ) 满足 ( |\\lambda_j| = \\lambda_1 )，则通过复特征值的三角不等式与不可约性矛盾，证明 ( |\\lambda_j| &lt; \\lambda_1 ) 。\n\n\nCheeger不等式与图的连通性度量\n1. 图的连通性与拉普拉斯矩阵特征值\n对于图 ( G )，其拉普拉斯矩阵 ( L(G) ) 的特征值满足 ( 0 = \\lambda_1 \\leq \\lambda_2 \\leq \\cdots \\leq \\lambda_n )。\n\n连通性判据：\n\n( G ) 是连通的 (\\iff \\lambda_2 &gt; 0)。\n( G ) 不连通的 (\\iff \\lambda_2 = 0)（此时零特征值的重数等于连通分量数）。\n\n\n\n2. 传导率（Conductance）的定义\n传导率量化了图 ( G ) 的“接近不连通”程度：\n\n顶点子集 ( S \\subseteq V ) 的传导率：\n[\n\\phi(S) = \\frac{|\\delta(S)|}{\\text{vol}(S)}, \\quad \\text{vol}(S) = \\sum_{v \\in S} \\deg(v)\n]\n其中 ( \\delta(S) ) 是 ( S ) 与补集 ( V \\setminus S ) 之间的边集。\n图的传导率：\n[\n\\phi(G) = \\min_{S: \\text{vol}(S) \\leq m} \\phi(S), \\quad m = \\frac{1}{2}\\text{vol}(V)\n]\n( \\phi(G) ) 越小，图越容易通过稀疏割（Sparse Cut）分离。\n\n3. Cheeger不等式\nCheeger不等式建立了 ( \\lambda_2 ) 与 ( \\phi(G) ) 的关系：\n[\n\\frac{\\lambda_2}{2} \\leq \\phi(G) \\leq \\sqrt{2 \\lambda_2}\n]\n解释：\n\n下界：若 ( \\lambda_2 ) 小，则 ( \\phi(G) ) 也小，表明存在稀疏割。\n上界：传导率低时，( \\lambda_2 ) 必小，反映图接近不连通。\n\n4. 扩展图（Expander Graph）与稀疏割\n\n扩展图：( \\phi(G) ) 为常数（如 0.1），具有强连通性，常用于设计鲁棒网络。\n稀疏割：( \\phi(S) ) 极小的子集 ( S )，对应图的分割瓶颈，应用于：\n\n图像分割：通过最小化传导率分离前景/背景。\n社区检测：识别社交网络中的紧密群体。\nVLSI设计：优化电路布局以减少交叉干扰。\n\n\n\nCheeger不等式\n是图论中一个重要的结果，它将图的展开性（通过Cheeger常数度量）与图的谱性质（通过拉普拉斯矩阵的特征值）联系起来。下面分步证明Cheeger不等式的两个方向，并特别关注归一化拉普拉斯矩阵与邻接矩阵的特征值关系。\n\n基本定义与符号\n\n\n图的基本矩阵：\n\n邻接矩阵 ( A )：元素 ( A_{ij} ) 表示顶点 ( i ) 和 ( j ) 之间的边数。\n度矩阵 ( D )：对角矩阵，( D_{ii} = \\text{deg}(i) )。\n归一化邻接矩阵：( \\mathcal{A} = D^{-1/2} A D^{-1/2} )。\n归一化拉普拉斯矩阵：( \\mathcal{L} = D^{-1/2} L D^{-1/2} = I - \\mathcal{A} )，其中 ( L = D - A ) 是未归一化的拉普拉斯矩阵。\n\n\n\n特征值约定：\n\n( \\alpha_1 \\geq \\alpha_2 \\geq \\cdots \\geq \\alpha_n ) 是 ( \\mathcal{A} ) 的特征值。\n( \\lambda_1 \\leq \\lambda_2 \\leq \\cdots \\leq \\lambda_n ) 是 ( \\mathcal{L} ) 的特征值。\n由于 ( \\mathcal{L} = I - \\mathcal{A} )，有 ( \\lambda_i = 1 - \\alpha_i )。\n\n\n\nCheeger常数：\n\n图的展开性由Cheeger常数 ( \\phi(G) ) 度量，定义为：\n[\n\\phi(G) = \\min_{S \\subset V} \\frac{|\\partial S|}{\\min(\\text{vol}(S), \\text{vol}(V \\setminus S))},\n]\n其中 ( \\partial S ) 是边界边集，( \\text{vol}(S) = \\sum_{i \\in S} \\text{deg}(i) )。\n\n\n\n\n简单方向（Easy Direction）：( \\lambda_2 \\leq 2\\phi(G) )\n目标：证明第二小特征值 ( \\lambda_2 ) 是Cheeger常数的上界，即 ( \\lambda_2 \\leq 2\\phi(G) )。\n证明步骤：\n\n\n变分刻画：\n\n( \\lambda_2 ) 可以表示为如下优化问题的极小值：\n[\n\\lambda_2 = \\min_{x \\perp D^{1/2} \\mathbf{1}} \\frac{x^T \\mathcal{L} x}{x^T x} = \\min_{x \\perp D^{1/2} \\mathbf{1}} \\frac{\\sum_{(i,j) \\in E} (x_i - x_j)^2}{\\sum_{i \\in V} x_i^2 \\text{deg}(i)}.\n]\n\n\n\n构造测试向量：\n\n设 ( S ) 是使得 ( \\phi(S) = \\phi(G) ) 的集合，定义向量 ( x )：\n[\nx_i = \\begin{cases}\n1/\\sqrt{\\text{vol}(S)}, &amp; i \\in S, \\\n-1/\\sqrt{\\text{vol}(V \\setminus S)}, &amp; i \\notin S.\n\\end{cases}\n]\n验证 ( x \\perp D^{1/2} \\mathbf{1} )，即 ( \\sum_{i} x_i \\sqrt{\\text{deg}(i)} = 0 )。\n\n\n\n计算Rayleigh商：\n\n分子 ( \\sum_{(i,j) \\in E} (x_i - x_j)^2 = \\frac{|\\partial S|}{\\text{vol}(S)} + \\frac{|\\partial S|}{\\text{vol}(V \\setminus S)} ).\n分母 ( \\sum_{i} x_i^2 \\text{deg}(i) = 2 ).\n因此：\n[\n\\frac{x^T \\mathcal{L} x}{x^T x} = \\frac{|\\partial S|}{2} \\left( \\frac{1}{\\text{vol}(S)} + \\frac{1}{\\text{vol}(V \\setminus S)} \\right) \\leq 2\\phi(G).\n]\n\n\n\n结论：\n\n由于 ( \\lambda_2 ) 是所有满足条件的 ( x ) 中Rayleigh商的极小值，故 ( \\lambda_2 \\leq 2\\phi(G) )。\n\n\n\n\n困难方向（Hard Direction）：( \\phi(G) \\leq \\sqrt{2\\lambda_2} )\n目标：证明Cheeger常数被第二小特征值控制，即 ( \\phi(G) \\leq \\sqrt{2\\lambda_2} )。\n证明思路：\n通过谱划分算法（Spectral Partitioning），利用 ( \\lambda_2 ) 对应的特征向量构造一个集合 ( S )，使得其展开性不超过 ( \\sqrt{2\\lambda_2} )。\n证明步骤：\n\n\n特征向量选择：\n\n设 ( f ) 是 ( \\mathcal{L} ) 对应 ( \\lambda_2 ) 的特征向量，满足 ( f \\perp D^{1/2} \\mathbf{1} )。\n\n\n\n排序与阈值化：\n\n将顶点按 ( f_i ) 的值升序排列：( f_1 \\leq f_2 \\leq \\cdots \\leq f_n ).\n定义阈值 ( t )，构造集合 ( S_t = {i | f_i \\leq t} )，寻找使 ( \\phi(S_t) ) 最小的 ( t )。\n\n\n\n利用中位数技巧：\n\n通过选择合适的中位数阈值 ( t )，保证 ( \\text{vol}(S_t) \\geq \\frac{1}{2}\\text{vol}(V) ) 且边界边数 ( |\\partial S_t| ) 被控制。\n\n\n\n估计边界边数：\n\n利用Cauchy-Schwarz不等式和特征向量的性质，有：\n[\n|\\partial S_t| \\leq \\sqrt{2\\lambda_2 \\cdot \\text{vol}(S_t) \\cdot \\text{vol}(V \\setminus S_t)}.\n]\n结合 ( \\text{vol}(S_t) \\geq \\frac{1}{2}\\text{vol}(V) )，得到 ( \\phi(S_t) \\leq \\sqrt{2\\lambda_2} )。\n\n\n\n结论：\n\n因此存在集合 ( S ) 使得 ( \\phi(G) \\leq \\sqrt{2\\lambda_2} )。\n\n\n\n\n回到马尔科夫链\n对于有限的连通无向图，随机游走的概率分布 ( p_t = \\left( \\frac{1}{2}I + \\frac{1}{2}AD^{-1} \\right)^t p_0 ) 随时间演化最终收敛到稳态分布 ( \\frac{\\vec{d}}{2m} )，其中 ( \\vec{d} ) 是度数向量，( m ) 是图的边数。\n\n1. 转移矩阵的构造与性质\n转移矩阵 ( P ) 的表达式为：\n[\nP = \\frac{1}{2}I + \\frac{1}{2}AD^{-1}\n]\n\n物理意义：这是一个懒惰随机游走（Lazy Random Walk）的转移矩阵。每一步有 ( \\frac{1}{2} ) 的概率停留在当前节点，( \\frac{1}{2} ) 的概率按传统无偏随机游走（TURW）的规则转移到邻居节点。\n作用：引入停留概率后，转移矩阵 ( P ) 的马尔可夫链变为非周期的，从而保证收敛性（传统随机游走可能是周期性的，导致不收敛）。\n\n\n2. 稳态分布的存在性\n对于连通无向图，随机游走的稳态分布 ( \\pi ) 需满足：\n[\n\\pi = \\pi P\n]\n代入 ( P ) 的表达式，展开可得：\n[\n\\pi = \\frac{1}{2}\\pi I + \\frac{1}{2}\\pi AD^{-1}\n]\n由于 ( \\pi I = \\pi )，化简后得到：\n[\n\\pi = \\pi AD^{-1}\n]\n这表明稳态分布 ( \\pi ) 也是传统无偏随机游走（TURW）的稳态分布。根据经典结论，TURW的稳态分布与节点度数成正比：\n[\n\\pi_i = \\frac{d_i}{2m}\n]\n其中 ( d_i ) 是节点 ( i ) 的度数，( m ) 是图的边数。\n\n3. 收敛性证明\n条件：图是连通且非周期的。\n\n连通性：保证马尔可夫链是不可约的，即任意状态可达。\n非周期性：通过懒惰随机游走的停留概率实现，避免了周期性震荡。\n\n谱分析：\n\n转移矩阵 ( P ) 的特征值满足 ( |\\lambda| \\leq 1 )，其中最大特征值为 ( \\lambda_1 = 1 )，对应稳态分布 ( \\frac{\\vec{d}}{2m} )。\n其他特征值 ( \\lambda_2, \\ldots, \\lambda_n ) 满足 ( |\\lambda_i| &lt; 1 )，当 ( t \\to \\infty ) 时，它们的贡献衰减为零。\n\n初始分布的分解：\n将初始分布 ( p_0 ) 表示为 ( P ) 的特征向量线性组合：\n[\np_0 = c_1 \\pi + \\sum_{i=2}^n c_i v_i\n]\n其中 ( v_i ) 是对应特征值 ( \\lambda_i ) 的特征向量。经过 ( t ) 步迭代后：\n[\np_t = P^t p_0 = c_1 \\pi + \\sum_{i=2}^n c_i \\lambda_i^t v_i\n]\n当 ( t \\to \\infty ) 时，第二项趋近于零，因此 ( p_t \\to \\pi = \\frac{\\vec{d}}{2m} )。\n\n定理及证明步骤详解\n定理陈述\n对有限连通无向图的随机游走，其ε-混合时间上界为：\n[\nt_{\\text{mix}}(\\epsilon) \\leq \\frac{1}{\\lambda} \\log\\left(\\frac{n}{\\epsilon}\\right),\n]\n其中 (\\lambda = \\min{1 - \\alpha_2, 1 - |\\alpha_n|})，(\\alpha_2) 和 (\\alpha_n) 分别是归一化转移矩阵的第二大和最小特征值。\n\n证明步骤详解\n1. 特征向量分解与转移矩阵展开\n假设转移矩阵 (W) 对应的归一化邻接矩阵 (\\mathcal{A}) 具有正交正规特征向量基 ({v_1, v_2, \\ldots, v_n})，对应的特征值为 (\\alpha_1 \\geq \\alpha_2 \\geq \\cdots \\geq \\alpha_n)。对于初始分布 (p_0)，可分解为：\n[\np_0 = c_1 v_1 + c_2 v_2 + \\cdots + c_n v_n,\n]\n其中 (v_1) 对应稳态分布 (\\pi)（即 (\\alpha_1 = 1)）。经过 (t) 步转移后，分布为：\n[\np_t = W^t p_0 = c_1 \\alpha_1^t v_1 + c_2 \\alpha_2^t v_2 + \\cdots + c_n \\alpha_n^t v_n.\n]\n由于稳态分布 (\\pi = c_1 v_1)，偏差项为：\n[\np_t - \\pi = \\sum_{i=2}^n c_i \\alpha_i^t v_i.\n]\n关键点：\n\n特征向量分解将随机游走的演化分解为稳态项与衰减项的组合。\n稳态对应的特征值 (\\alpha_1 = 1)，非稳态特征值满足 (|\\alpha_i| &lt; 1)，因此衰减项随 (t) 指数消失。\n\n\n2. 范数转换：L1 到 L2 范数\n通过 Cauchy-Schwarz 不等式，将总变差距离（L1 范数）转换为 L2 范数：\n[\n|p_t - \\pi|_1 \\leq \\sqrt{n} |p_t - \\pi|_2,\n]\n其中 (\\sqrt{n}) 的因子源于向量的维度 (n)（即图的顶点数）。\n推导逻辑：\n\nL1 范数定义为 (|x|_1 = \\sum_i |x_i|)，L2 范数为 (|x|_2 = \\sqrt{\\sum_i x_i^2})。\n由 Cauchy-Schwarz 不等式可得 (|x|_1 \\leq \\sqrt{n} |x|_2)，这是因为每个分量 (|x_i|) 的绝对值之和被 (\\sqrt{n}) 和 L2 范数控制。\n\n\n3. 计算 L2 范数的平方\n展开偏差项的 L2 范数平方：\n[\n|p_t - \\pi|2^2 = \\left|\\sum{i=2}^n c_i \\alpha_i^t v_i \\right|2^2 = \\sum{i=2}^n c_i^2 \\alpha_i^{2t},\n]\n由于特征向量正交且单位化（(|v_i|_2 = 1)），交叉项消失，仅剩对角项。\n关键观察：\n\n特征值的衰减速率由 (|\\alpha_i|) 决定。定义 (\\lambda = \\min{1 - \\alpha_2, 1 - |\\alpha_n|})，则对所有 (i \\geq 2)，有 (|\\alpha_i| \\leq 1 - \\lambda)。\n因此，平方和可进一步上界为：\n[\n\\sum_{i=2}^n c_i^2 \\alpha_i^{2t} \\leq (1 - \\lambda)^{2t} \\sum_{i=2}^n c_i^2.\n]\n\n\n4. 初始分布的 L2 范数约束\n由于 (p_0) 是概率分布（(\\sum_i p_0(i) = 1)），其 L2 范数满足：\n[\n|p_0|2^2 = \\sum{i=1}^n p_0(i)^2 \\leq \\sum_{i=1}^n p_0(i) = 1.\n]\n结合特征分解 (p_0 = \\sum_{i=1}^n c_i v_i)，正交性条件给出：\n[\n\\sum_{i=1}^n c_i^2 = |p_0|2^2 \\leq 1 \\quad \\Rightarrow \\quad \\sum{i=2}^n c_i^2 \\leq 1.\n]\n因此，偏差的 L2 范数平方满足：\n[\n|p_t - \\pi|_2^2 \\leq (1 - \\lambda)^{2t}.\n]\n\n5. 指数衰减与混合时间推导\n结合 L1 范数的上界和指数衰减公式：\n[\n|p_t - \\pi|1 \\leq \\sqrt{n} \\cdot (1 - \\lambda)^t \\leq \\sqrt{n} \\cdot e^{-\\lambda t},\n]\n这里利用了不等式 (1 - x \\leq e^{-x})。\n要求总变差距离小于等于 (\\epsilon)，即：\n[\n\\sqrt{n} e^{-\\lambda t} \\leq \\epsilon \\quad \\Rightarrow \\quad t \\geq \\frac{1}{\\lambda} \\log\\left(\\frac{\\sqrt{n}}{\\epsilon}\\right) = \\frac{1}{2\\lambda} \\log\\left(\\frac{n}{\\epsilon^2}\\right).\n]\n最终简化得到混合时间上界：\n[\nt{\\text{mix}}(\\epsilon) \\leq \\frac{1}{\\lambda} \\log\\left(\\frac{n}{\\epsilon}\\right).\n]\n\n补充说明\n正则图与非正则图的区别\n\n正则图：若图是 (d)-正则的，归一化邻接矩阵为 (\\mathcal{A} = \\frac{1}{d} A)，其稳态分布均匀，特征向量基可直接构造，损失因子 (\\sqrt{n}) 可优化为常数。\n非正则图：需使用归一化拉普拉斯矩阵 (\\mathcal{L} = I - D^{-1/2} A D^{-1/2}) 的特征向量基，此时正交性条件可能引入额外因子 (\\sqrt{n})，导致混合时间上界略松。\n\n\n谱间隙的意义\n\n谱间隙 (\\lambda)：决定了随机游走的收敛速度。当 (\\lambda = \\Omega(1))（常数级别），混合时间为 (O(\\log n))，适用于扩展图（如正则图）。\n实际应用：在社交网络或推荐系统中，若图具有强扩展性（大谱间隙），随机游走可在对数步长内均匀采样节点。\n\n\n谱图理论中的连通性与谱性质\n1. 图的连通性与谱的关系\n\n\n第二小特征值（(\\lambda_2)）与连通性\n\n定理：对于图的归一化拉普拉斯矩阵 (\\mathcal{L})，其第二小特征值 (\\lambda_2) 满足：\n[\n\\lambda_2 \\text{ 非常小} \\iff G \\text{ 接近于不连通（存在稀疏割）}.\n]\n解释：\n\n(\\lambda_2) 称为代数连通度（Algebraic Connectivity），反映图的“分割难度”。\n若 (\\lambda_2 \\approx 0)，说明存在一个割 ((S, V \\setminus S)) 使得边界边数 (|\\partial S|) 远小于 (\\min(\\text{vol}(S), \\text{vol}(V \\setminus S)))，即图几乎可被分成两个弱连接的子图。\n例子：在“哑铃图”（两个稠密子图通过单边连接）中，(\\lambda_2 \\approx 0)。\n\n\n\n\n\n第 (k) 小特征值（(\\lambda_k)）与多分量连通性\n\n推广定理：\n[\n\\lambda_k \\text{ 非常小} \\iff G \\text{ 接近于有 } k \\text{ 个连通分量（存在 } k \\text{ 个稀疏分割）}.\n]\n解释：\n\n(\\lambda_k) 接近零时，图可被划分为 (k) 个几乎不交互的子集，每个子集内部稠密，子集间边稀疏。\n应用：谱聚类（Spectral Clustering）利用 (\\lambda_k) 对应的特征向量将图划分为 (k) 个社区。\n\n\n\n\n\n\n2. 算法与构造中的应用\n\n\n谱分割算法\n\n步骤：\n\n计算拉普拉斯矩阵 (\\mathcal{L}) 的前 (k) 个特征向量 (v_1, v_2, \\ldots, v_k)。\n将顶点嵌入到 (\\mathbb{R}^k) 空间，坐标由特征向量分量决定。\n使用 (k)-means 等聚类方法划分顶点。\n\n\n理论依据：特征向量的分量差异对应图中的稀疏割。\n\n\n\n扩展图（Expander Graph）的代数构造\n\n定义：扩展图是高度连通的稀疏图，满足对所有子集 (S)，(|\\partial S| \\geq \\epsilon |S|)（常数 (\\epsilon &gt; 0)）。\n谱性质：扩展图的谱间隙 (\\lambda_2) 远离零（(\\lambda_2 = \\Omega(1))）。\n构造方法：\n\n通过有限域、群论等代数工具显式构造。\n例如：Ramanujan 图的 (\\lambda_2 \\geq 1 - 2\\sqrt{d-1}/d)（接近最优）。\n\n\n\n\n\n\n3. 随机游走混合时间的谱分析\n\n\n混合时间与谱间隙\n\n定理：懒惰随机游走的 (\\epsilon)-混合时间满足：\n[\nt_{\\text{mix}}(\\epsilon) \\leq \\frac{1}{\\lambda} \\log\\left(\\frac{n}{\\epsilon}\\right), \\quad \\lambda = \\min{1 - \\alpha_2, 1 - |\\alpha_n|},\n]\n其中 (\\alpha_2) 是归一化邻接矩阵的第二大特征值。\n关键步骤：\n\n将初始分布 (p_0) 投影到特征向量基，衰减项由 (|\\alpha_i|^t) 控制。\n谱间隙 (\\lambda) 越大，衰减越快，混合时间越短。\n\n\n\n\n\n组合数学与谱间隙的关联\n\nCheeger 不等式：\n[\n\\frac{\\lambda_2}{2} \\leq \\phi(G) \\leq \\sqrt{2\\lambda_2},\n]\n其中 (\\phi(G)) 是 Cheeger 常数（图的展开性）。\n推论：\n\n高扩展性（(\\phi(G)) 大）(\\implies) 大谱间隙（(\\lambda_2) 大）(\\implies) 快速混合（(t_{\\text{mix}}) 小）。\n例如：在 (d)-正则扩展图中，随机游走可在 (O(\\log n)) 步内接近均匀分布。\n\n\n\n\n\n\n总结表格\n\n\n\n概念\n数学描述\n应用场景\n\n\n\n\n代数连通度 ((\\lambda_2))\n(\\lambda_2 \\approx 0 \\iff G) 有稀疏割\n社区检测、图分割\n\n\n第 (k) 小特征值 ((\\lambda_k))\n(\\lambda_k \\approx 0 \\iff G) 有 (k) 个稀疏分割\n谱聚类（划分 (k) 个社区）\n\n\n扩展图\n(\\lambda_2 \\geq \\epsilon &gt; 0)\n伪随机性构造、纠错码设计\n\n\n混合时间\n(t_{\\text{mix}} \\propto \\frac{1}{\\lambda} \\log n)\n马尔可夫链蒙特卡洛（MCMC）采样\n\n\n\n\n进一步研究方向\n\n高阶 Cheeger 不等式：研究 (\\lambda_k) 与多路分割（Multiway Partition）的关系。\n动态图的谱分析：如何快速更新特征值/向量以适应图结构的动态变化。\n非线性谱方法：基于图神经网络的连通性分析与聚类。\n\n通过谱理论，我们得以将图的组合性质（如连通性）与代数性质（如特征值）深度关联，为算法设计与理论分析提供统一框架。\nThinking… (1s elapsed)中文推导与讲解\n[\n\\frac{\\lambda_2}{2};\\le; \\phi(G); \\le; \\sqrt{2,\\lambda_2}\n]\n下面分三部分说明：\n\n预备概念与符号\n易方向（上界）：(\\lambda_2\\le 2\\phi(G))\n难方向（下界）：(\\phi(G)\\le \\sqrt{2\\lambda_2})\n\n\n1. 预备概念与符号\n\n\n图与体积\n• 图 (G=(V,E)) 无向、带权，边权记 (w_{ij}=w_{ji}\\ge 0)。\n• 顶点度数 (\\deg(i)=\\sum_j w_{ij})。\n• 体积 (\\operatorname{vol}(S)=\\sum_{i\\in S}\\deg(i))。\n\n\n切割边数与扩张率（也称 conductance）\n• 切割 (\\partial S={(i,j)\\in E\\mid i\\in S,j\\notin S})。\n• 扩张率\n[\n\\phi(S)=\\frac{w(\\partial S)}{\\min\\bigl(\\operatorname{vol}(S),\\operatorname{vol}(V!\\setminus!S)\\bigr)},\\qquad\n\\phi(G)=\\min_{S\\subset V}\\phi(S).\n]\n\n\n归一化拉普拉斯\n• 记 (D=\\operatorname{diag}(\\deg(i)))，(A=(w_{ij}))。\n• 归一化拉普拉斯 (\\mathcal L = I - D^{-1/2} A D^{-1/2})。\n• 其特征值 (0=\\lambda_1\\le \\lambda_2\\le\\dots\\le\\lambda_n)。\n• 瑞利商\n[\n\\lambda_2=\\min_{\\substack{x\\neq 0\\x\\perp D^{1/2}\\mathbf 1}}\n\\frac{x^\\top \\mathcal L x}{x^\\top x},\n\\qquad\nx^\\top \\mathcal L x=\\frac12\\sum_{(i,j)\\in E}w_{ij}\\Bigl(\\tfrac{x_i}{\\sqrt{\\deg(i)}}-\\tfrac{x_j}{\\sqrt{\\deg(j)}}\\Bigr)^2.\n]\n\n\n\n2. 易方向：(\\lambda_2\\le 2\\phi(G))\n2.1 思路\n要给 (\\lambda_2) 找一个试探向量 (x)，把它代入瑞利商即可得到一个上界。\n最自然的向量是某个切割的指示函数：\n(g_i=1) 若 (i\\in S)，(g_i=-1) 否则。\n但瑞利商要求 (x\\perp D^{1/2}\\mathbf1)。\n只需把 (g) 左乘 (D^{-1/2}) 就能自动满足正交：\n[\nx=D^{-1/2}g.\n]\n2.2 计算瑞利商\n\n\n分母\n[\nx^\\top x = \\sum_{i}\\frac{g_i^{,2}}{\\deg(i)} =\n\\sum_{i}\\frac{1}{\\deg(i)}\n=\\sum_{i\\in S}\\frac{1}{\\deg(i)}+\\sum_{i\\notin S}\\frac{1}{\\deg(i)},\n]\n这个量不会与边界项混在一起，保持原样即可。\n\n\n分子（二次型）\n[\nx^\\top!\\mathcal Lx\n=\\frac12!\\sum_{(i,j)} w_{ij}\\Bigl(\n\\tfrac{g_i}{\\sqrt{\\deg(i)}}-\\tfrac{g_j}{\\sqrt{\\deg(j)}}\\Bigr)^2.\n]\n只有在 (g_i\\neq g_j)（即边跨越切割）时该项非零，且差值绝对值为\n(\\frac1{\\sqrt{\\deg(i)}}+\\frac1{\\sqrt{\\deg(j)}})。\n因此\n[\nx^\\top!\\mathcal Lx\n=\\frac12\\sum_{(i,j)\\in\\partial S} w_{ij}\n\\Bigl(\\tfrac1{\\sqrt{\\deg(i)}}+\\tfrac1{\\sqrt{\\deg(j)}}\\Bigr)^{!2}.\n]\n\n\n估计\n用基本不等式 ((a+b)^2\\le 2(a^2+b^2))：\n[\n\\Bigl(\\tfrac1{\\sqrt{\\deg(i)}}+\\tfrac1{\\sqrt{\\deg(j)}}\\Bigr)^{2}\n\\le 2\\Bigl(\\tfrac1{\\deg(i)}+\\tfrac1{\\deg(j)}\\Bigr).\n]\n于是\n[\nx^\\top!\\mathcal Lx\n\\le \\sum_{(i,j)\\in\\partial S} w_{ij}\n\\Bigl(\\tfrac1{\\deg(i)}+\\tfrac1{\\deg(j)}\\Bigr)\n=\\sum_{i\\in S}\\frac{w(\\partial{i})}{\\deg(i)}\n+\\sum_{j\\notin S}\\frac{w(\\partial{j})}{\\deg(j)}.\n]\n而\n(w(\\partial{i})\\le\\deg(i))，故\n[\nx^\\top!\\mathcal Lx\\le |\\partial S|.\n]\n\n\n组合分子分母\n[\n\\frac{x^\\top\\mathcal Lx}{x^\\top x}\n\\le\n\\frac{|\\partial S|}{\\min(\\operatorname{vol}(S),\\operatorname{vol}(V!\\setminus!S))}\n=\\phi(S);\\le;\\phi(G).\n]\n再用系数 2 的松弛（去掉上一步的 2 倍常数不等式损失）即可：\n[\n\\lambda_2\\le 2,\\phi(G).\n]\n\n\n2.3 关键改动\n原错误把\n(|\\partial S|(\\frac1{\\sqrt{\\operatorname{vol}(S)}}+\\frac1{\\sqrt{\\operatorname{vol}(V\\setminus S)}})^2)\n当成二次型，没有正确考虑每条边两端度数不同。\n改用 指示向量 + 逐边展开 后，完全避免了平均度数假设。\n\n3. 难方向：(\\phi(G)\\le\\sqrt{2\\lambda_2})\n思路：利用 (\\lambda_2) 的特征向量 (f)，把标量值扫阈 (sweep)，总会遇到一个阈值 cut 具有小扩张率。核心工具是离散 Co-area 公式。\n3.1 特征向量预处理\n取满足\n(f\\perp D^{1/2}\\mathbf1)、(f^\\top f=1) 的 (\\lambda_2) 特征向量。\n令\n[\nh_i=\\frac{f_i}{\\sqrt{\\deg(i)}}\\quad(i=1,\\dots,n).\n]\n按 (h_i) 从小到大排序：\n(h_{(1)}\\le h_{(2)}\\le\\dots\\le h_{(n)})。\n3.2 Sweep cut 定义\n对每个阈值 (t\\in\\mathbb R) 定\n(S_t={,i\\mid h_i\\le t\\ })。\n当 (t) 连续增大，(S_t) 从空集逐渐扩张到全体顶点。\n3.3 离散 Co-area 公式\n[\n\\int_{-\\infty}^{+\\infty} w(\\partial S_t),dt\n=\\frac12!\\sum_{(i,j)\\in E}w_{ij}|h_i-h_j|.\n]\n平方并用 Cauchy–Schwarz：\n[\n\\Bigl(\\int w(\\partial S_t),dt\\Bigr)^{2}\n\\le \\Bigl(\\sum_{(i,j)}w_{ij}(h_i-h_j)^2\\Bigr)\n\\Bigl(\\sum_{(i,j)}w_{ij}\\Bigr).\n]\n第一括号就是 (2\\lambda_2)（由瑞利商），第二括号是 (\\operatorname{vol}(V))。\n于是存在某个 (t) 使\n[\nw(\\partial S_t)\n\\le\n\\sqrt{2\\lambda_2,\\operatorname{vol}(V)};\n\\bigl(\\sup_{t}\\mu(t)\\bigr)^{-1},\n]\n其中 (\\mu(t)=\\min\\bigl(\\operatorname{vol}(S_t),\\operatorname{vol}(V\\setminus S_t)\\bigr))。\n3.4 选取“平衡”阈值\n因为 (f\\perp D^{1/2}\\mathbf1)，\n(\\sum_i\\deg(i)h_i=0)。\n故 (h_i) 的加权中位数使两边体积各至少半数。\n取此 (t) 便有\n(\\mu(t)\\ge \\tfrac12\\operatorname{vol}(V))。\n带回不等式：\n[\n\\phi(S_t)=\\frac{w(\\partial S_t)}{\\mu(t)}\n\\le\n\\sqrt{2\\lambda_2}.\n]\n于是\n(\n\\phi(G)\\le\\sqrt{2\\lambda_2}.\n)\n3.5 关键修正\n\n明确写出离散 Co-area，而不是“把和看成积分”。\n使用中位数保证体积平衡，而不是模糊地说“总能找到一个好阈值”。\n每一步都保留常数因子，最终得到 (\\sqrt{2}) 而非错误的 (\\sqrt{\\lambda_2}) 或 (2\\sqrt{\\lambda_2})。\n\n\n4. 逻辑链条回顾\n\n定义所有量（(\\mathcal L,\\lambda_2,\\phi)）。\n易方向：\n• 构造满足正交条件的测试向量。\n• 逐边展开瑞利商避免度数混淆。\n• 直接与 (\\phi(G)) 比较，得到 (\\lambda_2\\le 2\\phi(G))。\n难方向：\n• 取特征向量 → 排序 → 阈值分割。\n• Co-area 公式把“总差额”换成阈值族的“切割量积分”。\n• Cauchy–Schwarz 找到某个阈值 cut，结合中位数平衡体积。\n• 得到 (\\phi(G)\\le\\sqrt{2\\lambda_2})。\n\n至此两向合并，即得 Cheeger 不等式\n[\n\\frac{\\lambda_2}{2};\\le; \\phi(G); \\le; \\sqrt{2,\\lambda_2}.\n]\n\n5. 小结与启示\n\n左边界说明：若图有窄瓶颈，(\\lambda_2) 必然跟着小。\n右边界给出：只要 (\\lambda_2) 小，确实能从特征向量里“扫”出小扩张率切割。\n算法视角：用 Fiedler 向量做 sweep cut 就可近似找到良好社区。\n校正点：任何忽略顶点度数或跳过积分—阈值论证的证明，都可能给出错误常数或乃至错误结论。\n\n","tags":["其他"]},{"title":"noteCircut","url":"/notes.github.io/2025/06/23/noteCircut/","content":"电路网络中的电流与电压求解方法\n给定一个电阻网络，每条边 ( e ) 的电阻为 ( r_e )（或电导率 ( w_e = 1/r_e )），假设从节点 ( s ) 注入 1A 电流，并从节点 ( t ) 流出，如何计算网络内部的电流分布和电压分布？\n更一般地，设 ( b_v ) 表示从外部流入节点 ( v \\in V ) 的净电流：\n\n( b_v &gt; 0 )：电流注入节点 ( v )（如源节点 ( s )）\n( b_v &lt; 0 )：电流流出节点 ( v )（如汇节点 ( t )）\n其他内部节点满足 ( b_v = 0 )（基尔霍夫电流定律）\n\n\n1. 电路定律\n(1) 基尔霍夫电流定律（KCL）\n\n流入节点的电流 = 流出节点的电流\n即，对任意节点 ( v )，所有相邻边的电流 ( i_{vu} ) 满足：\n[\n\\sum_{u: (v,u) \\in E} i_{vu} = b_v \\quad \\forall v \\in V\n]\n（( i_{vu} ) 表示从 ( v ) 流向 ( u ) 的电流）\n\n(2) 欧姆定律\n\n电压差 = 电流 × 电阻\n即，对任意边 ( (u,v) )，有：\n[\n\\phi(u) - \\phi(v) = i_{uv} \\cdot r_{uv} \\quad \\Leftrightarrow \\quad i_{uv} = w_{uv} \\cdot (\\phi(u) - \\phi(v))\n]\n（( \\phi(v) ) 表示节点 ( v ) 的电压，( w_{uv} = 1/r_{uv} ) 是电导率）\n\n\n2. 合并定律，建立方程\n将欧姆定律代入基尔霍夫定律：\n[\nb_v = \\sum_{u: (v,u) \\in E} i_{vu} = \\sum_{u: (v,u) \\in E} w_{vu} (\\phi(v) - \\phi(u))\n]\n整理后得到：\n[\nb_v = \\text{deg}w(v) \\cdot \\phi(v) - \\sum{u: (v,u) \\in E} w_{vu} \\phi(u)\n]\n其中：\n\n( \\text{deg}w(v) = \\sum{u: (v,u) \\in E} w_{vu} ) 是节点 ( v ) 的加权度数（即所有邻边电导率之和）\n\n特别地，如果所有电导率 ( w_{uv} = 1 )，则方程简化为：\n[\nb = L \\phi\n]\n其中 ( L ) 是图的拉普拉斯矩阵（Laplacian Matrix）：\n[\nL_{uv} =\n\\begin{cases}\n\\text{deg}(v) &amp; \\text{如果 } u = v \\\n-1 &amp; \\text{如果 } (u,v) \\in E \\\n0 &amp; \\text{否则}\n\\end{cases}\n]\n这就把电路方程和拉普拉斯矩阵建立了联系！\n电路网络方程的可解性与唯一性分析\n1. 问题建模与矩阵表示\n给定电阻网络 ( G=(V,E) )，每条边 ( e \\in E ) 的电导率为 ( w_e = 1/r_e )，定义以下矩阵：\n\n\n关联矩阵（Incidence Matrix）( B )：\n( B \\in \\mathbb{R}^{|V| \\times |E|} )，每列对应一条边 ( e = (u,v) )，其中 ( B_{u,e} = +1 )，( B_{v,e} = -1 )，其余为 0。\n\n\n电导率对角阵 ( W )：\n( W \\in \\mathbb{R}^{|E| \\times |E|} )，( W_{e,e} = w_e )。\n\n\n拉普拉斯矩阵 ( L )：\n( L = B W B^\\top = \\sum_{e} w_e b_e b_e^\\top )，其中 ( b_e ) 是边 ( e ) 对应的关联矩阵列。\n\n\n为什么 (L = B W B^\\top)？\n\n\n直观理解：\n(B) 提取电压差，(W) 转为电流，(B^\\top) 将电流汇总到节点。\n\n\n数学推导：\n[\n(B W B^\\top \\phi)v = \\sum{e} B_{v,e} w_e (B^\\top \\phi)e = \\sum{u} w_{vu} (\\phi_v - \\phi_u)\n]\n这正是节点 (v) 的净流出电流。\n电流-电压关系：\n[\ni = W B^\\top \\phi, \\quad b = L \\phi = B i\n]\n其中 ( b ) 是外部注入电流向量（( b_s = 1 ), ( b_t = -1 ), 其余为 0），( \\phi ) 是节点电压向量。\n\n\n解释：\n\n(B^\\top \\phi) 计算每条边的电压差（(\\phi_u - \\phi_v)）。\n(W) 乘以电压差，得到电流 (i_e = w_e (\\phi_u - \\phi_v))（欧姆定律）。\n\n\n\n解释：\n\n(L \\phi)：计算每个节点的净流出电流（应等于外部注入 (b)）。\n(B i)：直接对边电流求和，验证节点电流守恒。\n\n\n\n\n2. 方程的可解性\n问题：方程 ( b = L \\phi ) 何时有解？\n结论：\n\n可解条件：( b ) 必须满足 ( \\sum_{v \\in V} b_v = 0 )（即净注入电流为零，符合物理守恒律）。\n物理意义：电流从源节点 ( s ) 注入后必须全部从汇节点 ( t ) 流出，系统才能达到稳态。\n\n数学证明：\n拉普拉斯矩阵 ( L ) 的行和为零（因 ( L \\mathbf{1} = 0 )），故 ( b ) 必须正交于 ( \\mathbf{1} )（即 ( \\mathbf{1}^\\top b = 0 )）。\n\n3. 解的唯一性\n问题：解 ( \\phi ) 是否唯一？\n结论：\n\n解不唯一：若 ( \\phi ) 是解，则 ( \\phi + c \\mathbf{1} )（( c ) 为任意常数）也是解。\n唯一性约束：需固定一个参考电压（如设 ( \\phi_t = 0 )），此时解唯一。\n\n数学解释：\n拉普拉斯矩阵 ( L ) 的秩为 ( |V|-1 )，核空间（null space）为 ( \\text{span}(\\mathbf{1}) )。因此，解仅在相差一个全局电压常数时唯一。\n\n4. 与图论问题的联系\n随机游走：\n\n电压 ( \\phi ) 可解释为从节点 ( s ) 到 ( t ) 的逃逸概率（escape probability）。\n电导率 ( w_e ) 对应转移概率。\n\n网络流：\n\n电流 ( i ) 是满足流量守恒的最小能量流（欧姆定律等价于能量最小化）。\n\n谱图理论：\n\n拉普拉斯矩阵 ( L ) 的特征值反映了网络的连通性（如代数连通度 ( \\lambda_2 ) 与 Cheeger 不等式相关）。\n\n\n拉普拉斯矩阵的秩与解的唯一性分析\n1. 拉普拉斯矩阵的秩缺陷性\n\n\n核心性质：\n拉普拉斯矩阵 ( L ) 不是满秩矩阵，因为 ( L \\mathbf{1} = 0 )（其中 (\\mathbf{1}) 是全1向量）。\n\n物理意义：全局电压平移（(\\phi \\to \\phi + c\\mathbf{1})）不影响电流分布，符合电压的相对性。\n\n\n\n零空间（Nullspace）：\n若图是连通的，( L ) 的零空间仅由 (\\text{span}(\\mathbf{1})) 构成，即：\n[\n\\text{null}(L) = { c \\mathbf{1} \\mid c \\in \\mathbb{R} }\n]\n\n\n2. 方程 ( L \\phi = b ) 的解存在条件\n\n\n引理：若 ( L \\phi = b ) 有解，则必须满足 ( b \\perp \\mathbf{1} )（即 (\\sum_v b_v = 0)）。\n\n证明：\n由于 ( L \\mathbf{1} = 0 )，对任意解 (\\phi)，有：\n[\n\\mathbf{1}^\\top b = \\mathbf{1}^\\top (L \\phi) = (L \\mathbf{1})^\\top \\phi = 0\n]\n物理对应：外部注入电流的代数和为零（电流守恒）。\n\n\n\n连通图的解结构：\n若图连通且 ( b \\perp \\mathbf{1} )，则解存在且可表示为：\n[\n\\phi = \\phi_0 + c \\mathbf{1}, \\quad c \\in \\mathbb{R}\n]\n其中 (\\phi_0) 是特解（如固定 (\\phi_t = 0) 后唯一解）。\n\n\n3. 特征值视角的解释\n\n谱分解：\n设 ( L ) 的特征值为 ( 0 = \\lambda_1 &lt; \\lambda_2 \\leq \\cdots \\leq \\lambda_n )，对应正交特征向量 ( \\mathbf{1}, v_2, \\dots, v_n )。\n\n解的存在性：\n将 ( b ) 投影到特征空间，若 ( b ) 不含 ( \\mathbf{1} ) 分量（即 ( b \\perp \\mathbf{1} )），则解存在。\n解的表达式：\n[\n\\phi = \\sum_{i=2}^n \\frac{\\langle b, v_i \\rangle}{\\lambda_i} v_i + c \\mathbf{1}\n]\n（( \\lambda_2 &gt; 0 ) 保证连通图的可解性）\n\n\n\n4. 物理意义与电路网络\n\n\n电流平衡：\n条件 ( \\sum_v b_v = 0 ) 对应电路中的基尔霍夫电流定律（KCL），即注入电流等于流出电流。\n\n示例：\n若从节点 ( s ) 注入 ( 1\\text{A} )，则必须有节点 ( t ) 流出 ( 1\\text{A} )，其余 ( b_v = 0 )。\n\n\n\n电压唯一性：\n通过固定参考电压（如接地 ( \\phi_t = 0 )），消除零空间自由度，得到唯一解。\n\n\n拉普拉斯矩阵的伪逆与解的结构\n引理\n若 ( b \\perp \\mathbf{1} )，则存在向量 ( \\phi ) 使得 ( L \\phi = b )。\n证明\n\n\n谱分解：\n由于 ( L ) 是对称半正定矩阵，可分解为：\n[\nL = \\sum_{i=2}^n \\lambda_i v_i v_i^\\top\n]\n其中 ( \\lambda_1 = 0 )，对应特征向量 ( v_1 = \\frac{1}{\\sqrt{n}} \\mathbf{1} )，且 ( \\lambda_2, \\dots, \\lambda_n &gt; 0 )（若图连通）。\n\n\n条件 ( b \\perp \\mathbf{1} )：\n由正交性，( b ) 可表示为非零特征向量的线性组合：\n[\nb = \\sum_{i=2}^n a_i v_i\n]\n\n\n构造解 ( \\phi )：\n取：\n[\n\\phi = \\sum_{i=2}^n \\frac{a_i}{\\lambda_i} v_i\n]\n验证：\n[\nL \\phi = \\sum_{i=2}^n \\lambda_i v_i v_i^\\top \\left( \\sum_{j=2}^n \\frac{a_j}{\\lambda_j} v_j \\right) = \\sum_{i=2}^n a_i v_i = b\n]\n\n\n\n伪逆 ( L^\\dagger ) 的定义与性质\n定义伪逆：\n[\nL^\\dagger = \\sum_{i=2}^n \\frac{1}{\\lambda_i} v_i v_i^\\top\n]\n性质：\n\n唯一性：\n\n对任意 ( b \\perp \\mathbf{1} )，( \\phi = L^\\dagger b ) 是唯一满足 ( L \\phi = b ) 且 ( \\phi \\perp \\mathbf{1} ) 的解。\n\n\n通解结构：\n\n方程 ( L \\phi = b ) 的全体解为：\n[\n\\phi = L^\\dagger b + c \\mathbf{1}, \\quad c \\in \\mathbb{R}\n]\n\n\n固定电压的唯一解：\n\n若指定某节点电压（如 ( \\phi_v = 0 )），则解唯一。\n\n\n\n\n物理意义\n\n伪逆的作用：\n\n( L^\\dagger ) 将电流分布 ( b ) 映射到最小范数电压解（即 ( \\phi \\perp \\mathbf{1} )）。\n\n\n平移自由度：\n\n解中的 ( c \\mathbf{1} ) 反映电压的全局参考点可任意选择，不影响电流分布。\n\n\n\n\n一个引理\n引理：$R_{\\text{eff}}(s, t) = b_{st}^\\top L^\\dagger b_{st}$，其中向量$b_{st} \\in \\mathbb{R}^n$满足\n$b_{st}(s) = 1$, $b_{st}(t) = -1$，并且其它位置都为0。\n等效电阻的表达式：\n\n从 ( \\phi = L^\\dagger b ) 和 ( R_{\\text{eff}}(s, t) = \\phi(s) - \\phi(t) ) 出发：\n[\n\\phi(s) = (L^\\dagger b)(s) = \\sum_j L^\\dagger(s, j) b(j) = L^\\dagger(s, s) \\cdot 1 + L^\\dagger(s, t) \\cdot (-1),\n]\n[\n\\phi(t) = (L^\\dagger b)(t) = \\sum_j L^\\dagger(t, j) b(j) = L^\\dagger(t, s) \\cdot 1 + L^\\dagger(t, t) \\cdot (-1).\n]\n因此：\n[\nR_{\\text{eff}}(s, t) = \\phi(s) - \\phi(t) = \\left[ L^\\dagger(s, s) - L^\\dagger(s, t) \\right] - \\left[ L^\\dagger(t, s) - L^\\dagger(t, t) \\right].\n]\n由于 ( L^\\dagger ) 对称，( L^\\dagger(s, t) = L^\\dagger(t, s) )，所以：\n[\nR_{\\text{eff}}(s, t) = L^\\dagger(s, s) + L^\\dagger(t, t) - 2 L^\\dagger(s, t).\n]\n另一方面，( b_{st}^\\top L^\\dagger b_{st} ) 可以展开为：\n[\nb_{st}^\\top L^\\dagger b_{st} = \\sum_i \\sum_j b_{st}(i) L^\\dagger(i, j) b_{st}(j) = L^\\dagger(s, s) - L^\\dagger(s, t) - L^\\dagger(t, s) + L^\\dagger(t, t).\n]\n由于 ( L^\\dagger ) 对称，因此：\n[\nb_{st}^\\top L^\\dagger b_{st} = L^\\dagger(s, s) + L^\\dagger(t, t) - 2 L^\\dagger(s, t) = R_{\\text{eff}}(s, t).\n]\n引理得证。\n\n拉普拉斯矩阵二次型的展开证明\n设图$G=(V,E)$的边带有电阻$r_e$，对应的电导为$c_e = 1/r_e$。拉普拉斯矩阵$L$定义为：\n[\nL_{uv} =\n\\begin{cases}\n\\sum_{w \\sim u} c_{uw} &amp; \\text{若 } u=v \\\nc_{uv} &amp; \\text{若 } u \\neq v \\text{ 且 } (u,v)\\in E \\\n0 &amp; \\text{其他情况}\n\\end{cases}\n]\n步骤1：展开二次型\n考虑电势向量$\\phi$的二次型：\n[\n\\phi^\\top L\\phi = \\sum_{u \\in V} \\sum_{v \\in V} \\phi_u L_{uv} \\phi_v\n]\n步骤2：分离对角线项和非对角线项\n将求和分为$u=v$和$u\\neq v$的情况：\n[\n= \\underbrace{\\sum_{u \\in V} \\phi_u^2 L_{uu}}{\\text{对角线项}} + \\underbrace{\\sum{u \\neq v} \\phi_u L_{uv} \\phi_v}_{\\text{非对角线项}}\n]\n步骤3：代入拉普拉斯矩阵定义\n对于对角线项：\n[\n\\sum_{u \\in V} \\phi_u^2 \\left(\\sum_{w \\sim u} c_{uw}\\right) = \\sum_{u \\in V} \\sum_{e=(u,w)\\in E} \\phi_u^2 c_e\n]\n对于非对角线项：\n[\n\\sum_{u \\neq v} \\phi_u (-c_{uv}) \\phi_v = -\\sum_{e=(u,v)\\in E} \\phi_u \\phi_v c_e \\quad (\\text{每条边计算两次})\n]\n步骤4：合并对角线与非对角线项\n[\n\\phi^\\top L\\phi = \\sum_{e=(u,v)\\in E} \\left[ \\phi_u^2 c_e + \\phi_v^2 c_e - 2\\phi_u \\phi_v c_e \\right]\n]\n步骤5：重组为平方项\n观察到：\n[\n\\phi_u^2 c_e + \\phi_v^2 c_e - 2\\phi_u \\phi_v c_e = c_e (\\phi_u - \\phi_v)^2\n]\n因此：\n[\n\\phi^\\top L\\phi = \\sum_{e=(u,v)\\in E} \\frac{(\\phi_u - \\phi_v)^2}{r_e}\n]\n几何解释\n这个过程实现了从节点空间到边空间的转换：\n\n初始的二次型计算所有节点间的电势交互\n拉普拉斯矩阵的结构保证最终结果仅与相邻节点电势差相关\n每个边贡献的项可以理解为该边上的能量耗散\n\n最终结论\n$\\displaystyle \\phi^\\top L\\phi = \\sum_{e=(u,v)\\in E} \\frac{(\\phi_u - \\phi_v)^2}{r_e}$\n这个等式揭示了图拉普拉斯矩阵的物理意义：它编码了网络中所有边上的电势差能量。在电路理论中，这正好对应焦耳定律给出的能量耗散公式。\n有效电阻与能量耗散的关系\n设$G=(V,E)$为一个无向图，$r_e$为边$e$的电阻值，$i_e$为边$e$上的电流。考虑从源点$s$到汇点$t$的单位电流。\n能量耗散表达式\n网络中的总能量耗散可以表示为：\n[\n\\mathcal{E}(i) = \\sum_{e\\in E} i_e^2 \\cdot r_e\n]\n电势表示\n根据欧姆定律，电流可以表示为电势差：\n[\ni_e = \\frac{\\phi_u - \\phi_v}{r_e}\n]\n其中$\\phi$是电势函数，满足基尔霍夫电流定律$L\\phi = b_{st}$，这里$b_{st} = \\mathbf{1}_s - \\mathbf{1}_t$。\n因此能量耗散可改写为：\n[\n\\mathcal{E}(i) = \\sum_{e=(u,v)\\in E} \\left(\\frac{\\phi_u - \\phi_v}{r_e}\\right)^2 \\cdot r_e = \\sum_{e=(u,v)\\in E} \\frac{(\\phi_u - \\phi_v)^2}{r_e}\n]\n拉普拉斯矩阵形式\n注意到：\n[\n\\phi^\\top L\\phi = \\sum_{u,v} \\phi_u L_{uv} \\phi_v = \\sum_{e=(u,v)\\in E} \\frac{(\\phi_u - \\phi_v)^2}{r_e}\n]\n因此：\n[\n\\mathcal{E}(i) = \\phi^\\top L\\phi\n]\n有效电阻计算\n由于$L\\phi = b_{st}$，且$L$的伪逆$L^\\dagger$满足$\\phi = L^\\dagger b_{st}$，代入得：\n[\n\\mathcal{E}(i) = (L^\\dagger b_{st})^\\top L (L^\\dagger b_{st}) = b_{st}^\\top L^\\dagger b_{st}\n]\n这正是$s$和$t$之间的有效电阻$R_{\\text{eff}}(s,t)$的定义：\n[\nR_{\\text{eff}}(s,t) = b_{st}^\\top L^\\dagger b_{st} = (\\mathbf{1}_s - \\mathbf{1}_t)^\\top L^\\dagger (\\mathbf{1}_s - \\mathbf{1}_t)\n]\n结论\n因此我们证明了：\n[\n\\mathcal{E}(i) = R_{\\text{eff}}(s,t)\n]\n即单位电流下的能量耗散等于$s$和$t$之间的有效电阻。\n有效电阻与单位流的能量最小化定理\nThompson’s Principle 定理陈述\n对于任意图 $G=(V,E)$ 和边上的电阻 $r_e = 1$（$\\forall e \\in E$），有效电阻满足：\n$$\nR_{\\text{eff}}(s,t) \\leq \\mathcal{E}(g)\n$$\n其中 $g$ 是任意单位 $s$-$t$ 流。\n1. 问题形式化\n目标函数与约束条件\n考虑最小化能量：\n[\n\\min_{g} \\mathcal{E}(g) = \\min_{g} \\sum_{e \\in E} g_e^2 \\quad \\text{s.t.} \\quad B g = b_{st}\n]\n其中：\n\n( B ) 是图的关联矩阵（节点-边矩阵），维度为 ( n \\times |E| )。\n( b_{st} ) 是单位流需求向量，满足 ( b_{st}(s) = +1 )，( b_{st}(t) = -1 )，其余节点为 0。\n流 ( g ) 满足基尔霍夫电流定律（流守恒）。\n\n\n2. 拉格朗日乘子法与KKT条件\n拉格朗日函数\n引入拉格朗日乘子 ( \\phi \\in \\mathbb{R}^n )，构造拉格朗日函数：\n[\n\\mathcal{L}(g, \\phi) = \\sum_{e} g_e^2 + \\phi^\\top (B g - b_{st})\n]\n梯度条件\n对 ( g ) 求导并令导数为零：\n[\n\\nabla_g \\mathcal{L} = 2g + B^\\top \\phi = 0 \\quad \\implies \\quad g = -\\frac{1}{2} B^\\top \\phi\n]\n这表明最优流 ( g ) 由某个电势向量 ( \\phi ) 通过 ( B^\\top \\phi ) 确定，符号由电阻方向决定。\n\n3. 代入约束条件\n将 ( g = -\\frac{1}{2} B^\\top \\phi ) 代入约束 ( B g = b_{st} )：\n[\nB \\left(-\\frac{1}{2} B^\\top \\phi \\right) = b_{st} \\quad \\implies \\quad -\\frac{1}{2} B B^\\top \\phi = b_{st}\n]\n注意到 ( L = B B^\\top ) 是图的拉普拉斯矩阵，因此：\n[\nL \\phi = -2 b_{st}\n]\n由于拉普拉斯矩阵 ( L ) 秩为 ( n-1 )，需设定参考点（如 ( \\phi_t = 0 )）后解得：\n[\n\\phi = -2 L^+ b_{st}\n]\n其中 ( L^+ ) 是 ( L ) 的伪逆矩阵。\n\n4. 最优能量与有效电阻的关系\n最优流的能量\n将 ( g = -\\frac{1}{2} B^\\top \\phi ) 代入目标函数：\n[\n\\mathcal{E}(g) = g^\\top g = \\left(-\\frac{1}{2} B^\\top \\phi \\right)^\\top \\left(-\\frac{1}{2} B^\\top \\phi \\right) = \\frac{1}{4} \\phi^\\top B B^\\top \\phi\n]\n利用 ( L = B B^\\top ) 和 ( \\phi = -2 L^+ b_{st} )：\n[\n\\mathcal{E}(g) = \\frac{1}{4} \\phi^\\top L \\phi = \\frac{1}{4} (-2 b_{st}^\\top L^+) L (-2 L^+ b_{st}) = b_{st}^\\top L^+ b_{st}\n]\n有效电阻的定义\n有效电阻 ( R_{\\text{eff}}(s, t) ) 定义为电势差除以单位电流：\n[\nR_{\\text{eff}}(s, t) = \\phi_s - \\phi_t = (\\chi_s - \\chi_t)^\\top \\phi\n]\n其中 ( \\chi_s ) 和 ( \\chi_t ) 是 ( s ) 和 ( t ) 的指示向量。结合 ( \\phi = -2 L^+ b_{st} )，有：\n[\nR_{\\text{eff}}(s, t) = (\\chi_s - \\chi_t)^\\top (-2 L^+ b_{st}) = -2 (\\chi_s - \\chi_t)^\\top L^+ (\\chi_s - \\chi_t)\n]\n由于 ( b_{st} = \\chi_s - \\chi_t )，且 ( L^+ ) 对称，可得：\n[\nR_{\\text{eff}}(s, t) = b_{st}^\\top L^+ b_{st}\n]\n因此，最优能量 ( \\mathcal{E}(g) = R_{\\text{eff}}(s, t) )。\n\n5. 结论\n对任意单位 ( s )-( t ) 流 ( g )，其能量 ( \\mathcal{E}(g) ) 满足：\n[\n\\mathcal{E}(g) \\geq \\mathcal{E}(g^) = R_{\\text{eff}}(s, t)\n]\n其中 ( g^ ) 是最优流，由电势差通过欧姆定律生成。这表明有效电阻是所有可能单位流能量的最小值。\n\n最终结论\n[\nR_{\\text{eff}}(s, t) = \\min_{g: Bg = b_{st}} \\sum_{e} g_e^2 \\quad \\implies \\quad R_{\\text{eff}}(s, t) \\leq \\mathcal{E}(g) \\quad \\forall \\text{单位 } s\\text{-}t \\text{流 } g.\n]\n\n关键点总结\n\nKKT条件 导出了最优流与电势的关系，符合欧姆定律。\n拉普拉斯矩阵伪逆 将电势差与有效电阻直接关联。\n凸优化唯一性 保证了最小能量的存在性，且等于有效电阻。\n\n","tags":["其他"]},{"title":"noteSVD","url":"/notes.github.io/2025/06/23/noteSVD/","content":"定理\n设 ( A = U \\Sigma V^* ) 是 ( A \\in \\mathbb{C}^{m \\times n} ) ( ( m \\geq n ) ) 的奇异值分解，则：\n(1) ( A^*A ) 的特征值是 ( \\sigma_i^2 )，对应的特征向量是 ( v_i )\n证明：\n\n我们有 ( A^* A = (U \\Sigma V^)^ (U \\Sigma V^) = V \\Sigma^ U^* U \\Sigma V^* = V \\Sigma^2 V^* )。\n由于 ( U^* U = I )，所以 ( A^* A = V \\Sigma^2 V^* )。\n因此，( A^* A ) 的特征值为 ( \\sigma_i^2 )，对应的特征向量为 ( v_i )。\n\n(2) ( AA^* ) 的特征值是 ( \\sigma_i^2 ) 和 ( m-n ) 个零，对应的特征向量是 ( u_i )\n证明：\n\n我们有 ( AA^* = (U \\Sigma V^)(U \\Sigma V^)^* = U \\Sigma V^* V \\Sigma^* U^* = U \\Sigma \\Sigma^* U^* )。\n由于 ( V^* V = I_n )，所以 ( AA^* = U \\Sigma \\Sigma^* U^* )。\n注意到 ( \\Sigma ) 是一个 ( n \\times n ) 的对角矩阵，且只有 ( r ) 个非零对角元素，因此 ( AA^* ) 的特征值为 ( \\sigma_i^2 ) 和 ( m-n ) 个零，对应的特征向量为 ( u_i )。\n\n(3) ( |A|_2 = \\sigma_1, |A|_F = \\sqrt{\\sigma_1^2 + \\sigma_2^2 + \\cdots + \\sigma_n^2} )\n证明：\n\n矩阵的谱范数 ( |A|_2 ) 定义为最大的奇异值，即 ( |A|_2 = \\sigma_1 )。\nFrobenius 范数定义为 ( |A|F = \\sqrt{\\sum{i=1}^{n} \\sigma_i^2} )，所以 ( |A|_F = \\sqrt{\\sigma_1^2 + \\sigma_2^2 + \\cdots + \\sigma_n^2} )。\n\n(4) 若 ( \\text{rank}(A) = r \\leq n )，则 ( \\text{Ran}(A) = \\text{span}{u_1, u_2, \\ldots, u_r} )，( \\text{Ker}(A) = \\text{span}{v_{r+1}, v_{r+2}, \\ldots, v_n} )\n证明：\n\n因为 ( A ) 的秩为 ( r )，所以 ( A ) 的列空间 ( \\text{Ran}(A) ) 由 ( r ) 个线性无关的列生成，即 ( \\text{Ran}(A) = \\text{span}{u_1, u_2, \\ldots, u_r} )。\n核空间 ( \\text{Ker}(A) ) 由 ( n-r ) 个线性无关的列生成，即 ( \\text{Ker}(A) = \\text{span}{v_{r+1}, v_{r+2}, \\ldots, v_n} )。\n\n(5) 设 ( x \\in \\mathbb{C}^n ) 且 ( |x|_2 = 1 )，则 ( \\sigma_n \\leq |Ax|_2 \\leq \\sigma_1 )\n证明：\n\n根据奇异值分解，( |Ax|_2 = |U \\Sigma V^* x|_2 = |\\Sigma V^* x|_2 )。\n由于 ( V^* x ) 是一个 ( n )-维向量，且其 2 范数的最大值为 1，( |Ax|_2 ) 的最小值为 ( \\sigma_n )（对应于最小的奇异值），最大值为 ( \\sigma_1 )（对应于最大的奇异值）。\n\n(6) (酉不变性) 设 ( X \\in \\mathbb{C}^{m \\times m} ) 和 ( Y \\in \\mathbb{C}^{n \\times n} ) 是酉矩阵，则 ( \\sigma_i(X^*AY) = \\sigma_i(A) )\n证明：\n\n由于 ( X ) 和 ( Y ) 是酉矩阵，( X^* A Y ) 和 ( A ) 具有相同的奇异值，因为酉矩阵在范数下是等距的，这意味着奇异值不变。\n\n条件数的几何意义\n条件数反映了矩阵将单位球映射到椭球后的最长轴与最短轴之比。即使特征值全为 1，椭球的形状仍可能高度拉伸（由奇异值决定）。\n低秩逼近定理的详细解释\n1. 定理陈述\n设 ( A = U \\Sigma V^* ) 是 ( A \\in \\mathbb{C}^{m \\times n} ) 的细奇异值分解（即紧凑形式的 SVD，仅保留非零奇异值）。定义：\n[\nA_k = \\sum_{i=1}^k \\sigma_i u_i v_i^*\n]\n其中 ( \\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq \\sigma_r &gt; 0 ) 是 ( A ) 的非零奇异值（( r = \\text{rank}(A) )）。则：\n\n( A_k ) 是 所有秩为 ( k ) 的矩阵中，在 2-范数下最接近 ( A ) 的解，即：\n[\n|A - A_k|2 = \\sigma{k+1},\n]\n且 ( A_k ) 满足：\n[\nA_k = \\arg\\min_{\\substack{B \\in \\mathbb{C}^{m \\times n} \\ \\text{rank}(B) = k}} |A - B|_2.\n]\n对于 Frobenius 范数，类似结论成立：\n[\n|A - A_k|F = \\sqrt{\\sum{i=k+1}^r \\sigma_i^2}.\n]\n\n\n2. 直观解释\n矩阵的低秩逼近目标是：用秩为 ( k ) 的矩阵 ( A_k ) 尽可能接近原矩阵 ( A )。\n\n几何意义：将 ( A ) 的作用分解到正交方向（由奇异向量 ( u_i, v_i ) 定义），保留前 ( k ) 个最重要的方向（对应最大奇异值），截断后面的方向。\n应用场景：数据压缩、主成分分析（PCA）、去噪等。\n\n\n3. 为什么 ( A_k ) 是最优解？\n(1) 2-范数的最优性\n\n\n奇异值的性质：\n矩阵的 2-范数 ( |A|2 ) 是其最大奇异值 ( \\sigma_1 )。构造 ( A_k ) 时，保留了前 ( k ) 个奇异值 ( \\sigma_1, \\dots, \\sigma_k )，将后面的奇异值置零。\n因此，误差矩阵 ( A - A_k ) 的奇异值为 ( \\sigma{k+1}, \\dots, \\sigma_r )，其 2-范数为最大剩余奇异值：\n[\n|A - A_k|2 = \\sigma{k+1}.\n]\n\n\n极值性证明（Eckart–Young–Mirsky 定理）：\n对任意秩为 ( k ) 的矩阵 ( B )，其奇异值最多有 ( k ) 个非零值。由于奇异值已按降序排列，保留前 ( k ) 个最大奇异值会最小化剩余奇异值的最大值，即：\n[\n\\sigma_{k+1} \\leq |A - B|2 \\quad \\text{对所有秩为 } k \\text{ 的 } B.\n]\n因此，( A_k ) 达到了下界 ( \\sigma{k+1} )，是最优解。\n\n\n\n(2) Frobenius 范数的最优性\n\n\nFrobenius 范数的定义：\n[\n|A|F = \\sqrt{\\sum{i=1}^r \\sigma_i^2}.\n]\n构造 ( A_k ) 时，截断后 ( k+1 ) 到 ( r ) 的奇异值被舍弃，因此误差为：\n[\n|A - A_k|F = \\sqrt{\\sum{i=k+1}^r \\sigma_i^2}.\n]\n\n\n极值性证明：\n由于 Frobenius 范数是各方向奇异值平方和的平方根，保留前 ( k ) 个最大奇异值会最小化剩余部分的平方和。对任意秩为 ( k ) 的 ( B )，有：\n[\n\\sum_{i=k+1}^r \\sigma_i^2 \\leq |A - B|_F^2,\n]\n因此 ( A_k ) 是最优解。\n\n\n\n矩阵的2-范数等于其最大奇异值σ₁。\n矩阵的2-范数定义为：\n[\n|A|_2 = \\sup \\left{ \\frac{|Ax|_2}{|x|_2} \\mid x \\neq 0 \\right}\n]\n或者等价地：\n[\n|A|_2 = \\max \\left{ |Ax|_2 \\mid |x|_2 = 1 \\right}\n]\n通过奇异值分解（SVD），矩阵A可以分解为 ( A = U\\Sigma V^* )，其中U和V是酉矩阵，Σ是对角矩阵，对角线上的元素是奇异值σ₁ ≥ σ₂ ≥ … ≥ σₙ ≥ 0。\n考虑向量x经过矩阵A作用后的模长：\n[\n|Ax|_2 = |U\\Sigma V^* x|_2\n]\n由于U和V是酉矩阵，不改变向量的模长，令 ( y = V^* x )，则 ( |y|_2 = |x|_2 )，因此：\n[\n|Ax|_2 = |\\Sigma y|_2\n]\n对于单位向量x，y也是单位向量，因此：\n[\n|\\Sigma y|2 = \\sqrt{\\sum{i=1}^n \\sigma_i^2 |y_i|^2}\n]\n当y的分量集中在最大奇异值σ₁对应的位置时，例如y = (1, 0, …, 0)，此时：\n[\n|\\Sigma y|_2 = \\sigma_1\n]\n因此，矩阵A的2-范数即为最大奇异值σ₁。\n进一步验证，考虑矩阵A*A的最大特征值λ₁，其平方根即为最大奇异值σ₁。根据瑞利商，向量x的最大增长倍数为：\n[\n\\sqrt{\\lambda_1} = \\sigma_1\n]\n因此，矩阵的2-范数等于其最大奇异值σ₁。\nQR分解在线性最小二乘的应用\n问题描述\n给定满秩矩阵 ( A \\in \\mathbb{R}^{m \\times n} )（( m \\geq n )），求线性最小二乘问题：\n[\n\\min_{x \\in \\mathbb{R}^n} | Ax - b |_2^2\n]\n的解析解 ( x^* )。\n方法 1：利用 QR 分解的正交补空间投影\n1. QR 分解\n由于 ( A ) 是满秩的，可以进行 QR 分解：\n[\nA = QR\n]\n其中：\n\n( Q \\in \\mathbb{R}^{m \\times n} ) 是 列正交矩阵（即 ( Q^\\top Q = I_n )），\n( R \\in \\mathbb{R}^{n \\times n} ) 是 上三角可逆矩阵（因为 ( A ) 满秩）。\n\n由于 ( m \\geq n )，我们可以将 ( Q ) 扩充成一个完整的正交矩阵：\n[\n[Q, \\hat{Q}] \\in \\mathbb{R}^{m \\times m}\n]\n其中：\n\n( \\hat{Q} \\in \\mathbb{R}^{m \\times (m - n)} ) 是 ( Q ) 的正交补（即 ( Q^\\top \\hat{Q} = 0 ) 且 ( \\hat{Q}^\\top \\hat{Q} = I_{m-n} )）。\n\n2. 残差范数的分解\n利用 ( [Q, \\hat{Q}] ) 的正交性（( [Q, \\hat{Q}]^\\top [Q, \\hat{Q}] = I_m )），残差范数可以写成：\n[\n| Ax - b |_2^2 = | [Q, \\hat{Q}]^\\top (Ax - b) |_2^2\n]\n因为正交变换不改变范数。\n代入 ( A = QR )：\n[\n= | [Q, \\hat{Q}]^\\top (QRx - b) |_2^2\n]\n计算 ( [Q, \\hat{Q}]^\\top ) 与 ( QRx - b ) 的乘积：\n[\n[Q, \\hat{Q}]^\\top (QRx - b) =\n\\begin{bmatrix}\nQ^\\top (QRx - b) \\\n\\hat{Q}^\\top (QRx - b)\n\\end{bmatrix}\n\\begin{bmatrix}\nRx - Q^\\top b \\\n-\\hat{Q}^\\top b\n\\end{bmatrix}\n]\n（因为 ( Q^\\top Q = I )，而 ( \\hat{Q}^\\top Q = 0 )）\n所以：\n[\n| Ax - b |_2^2 = \\left| \\begin{bmatrix}\nRx - Q^\\top b \\\n-\\hat{Q}^\\top b\n\\end{bmatrix} \\right|_2^2 = | Rx - Q^\\top b |_2^2 + | \\hat{Q}^\\top b |_2^2\n]\n3. 最小化条件\n由于 ( | \\hat{Q}^\\top b |_2^2 ) 与 ( x ) 无关，最小化 ( | Ax - b |_2^2 ) 等价于最小化 ( | Rx - Q^\\top b |_2^2 )，而它的最小值是 0（因为 ( R ) 可逆）：\n[\nRx = Q^\\top b\n]\n因此，最小二乘解为：\n[\nx^* = R^{-1} Q^\\top b\n]\n\n方法 2：利用正交投影分解\n1. 投影矩阵\n( QQ^\\top ) 是 ( \\text{Ran}(A) )（( A ) 的列空间）上的 正交投影矩阵，因为：\n\n( \\text{Ran}(A) = \\text{Ran}(Q) )（因为 ( A = QR )），\n( QQ^\\top ) 将任意向量投影到 ( \\text{Ran}(Q) )。\n\n类似地，( I - QQ^\\top ) 是 ( \\text{Ran}(A)^\\perp )（( A ) 的列空间的正交补）上的投影矩阵。\n2. 分解 ( b )\n将 ( b ) 分解为：\n[\nb = QQ^\\top b + (I - QQ^\\top) b\n]\n其中：\n\n( QQ^\\top b ) 是 ( b ) 在 ( \\text{Ran}(A) ) 上的投影，\n( (I - QQ^\\top) b ) 是 ( b ) 在 ( \\text{Ran}(A)^\\perp ) 上的投影。\n\n3. 残差范数的分解\n残差 ( Ax - b ) 可以写成：\n[\nAx - b = Ax - QQ^\\top b - (I - QQ^\\top) b\n]\n由于 ( Ax \\in \\text{Ran}(A) ) 和 ( (I - QQ^\\top) b \\in \\text{Ran}(A)^\\perp )，它们是正交的，所以：\n[\n| Ax - b |_2^2 = | Ax - QQ^\\top b |_2^2 + | (I - QQ^\\top) b |_2^2\n]\n由于 ( A = QR )，且 ( QQ^\\top b ) 是 ( b ) 在 ( \\text{Ran}(A) ) 上的投影：\n[\nAx - QQ^\\top b = QRx - QQ^\\top b\n]\n因为 ( \\text{Ran}(QQ^\\top) = \\text{Ran}(Q) )，所以 ( QQ^\\top b = Q c ) 对某个 ( c \\in \\mathbb{R}^n )。实际上：\n[\nQQ^\\top b = Q (Q^\\top b)\n]\n所以：\n[\nQRx - QQ^\\top b = Q (Rx - Q^\\top b)\n]\n因此：\n[\n| Ax - QQ^\\top b |_2^2 = | Q (Rx - Q^\\top b) |_2^2 = | Rx - Q^\\top b |_2^2\n]\n（因为 ( Q ) 列正交）\n4. 最小化条件\n最小化 ( | Ax - b |_2^2 ) 等价于最小化 ( | Rx - Q^\\top b |_2^2 )，其最小值是 0：\n[\nRx = Q^\\top b\n]\n因此：\n[\nx^* = R^{-1} Q^\\top b\n]\n\n方法 3：正规方程法\n1. 正规方程\n最小二乘问题的解满足 正规方程：\n[\nA^\\top A x = A^\\top b\n]\n2. 代入 QR 分解\n由于 ( A = QR )，代入正规方程：\n[\n(QR)^\\top (QR) x = (QR)^\\top b\n]\n[\nR^\\top Q^\\top Q R x = R^\\top Q^\\top b\n]\n因为 ( Q^\\top Q = I )：\n[\nR^\\top R x = R^\\top Q^\\top b\n]\n3. 解方程\n由于 ( R ) 是可逆的，( R^\\top ) 也是可逆的，可以两边左乘 ( (R^\\top)^{-1} )：\n[\nR x = Q^\\top b\n]\n因此：\n[\nx^* = R^{-1} Q^\\top b\n]\n\n总结\n三种方法最终都得到相同的最小二乘解：\n[\nx^* = R^{-1} Q^\\top b\n]\n其中：\n\n( A = QR ) 是 ( A ) 的 QR 分解，\n( R ) 是上三角可逆矩阵，\n( Q ) 是列正交矩阵。\n\n计算复杂度\n\nQR 分解的计算量约为 ( 2mn^2 )（使用 Householder 变换时），\n当 ( m \\gg n ) 时，比正规方程法（计算 ( A^\\top A ) 需要 ( mn^2 )）稍慢，\n当 ( m = n ) 时，计算量几乎相同。\n\n为什么 QR 分解方法更稳定？\n\n直接计算 ( A^\\top A ) 会导致数值不稳定（条件数 ( \\kappa(A^\\top A) = \\kappa(A)^2 )），\nQR 分解方法避免了计算 ( A^\\top A )，数值稳定性更好。\n\nHouseHolder中的v\n\n( v ) 是反射方向的垂直向量，决定了反射超平面的方向，\n( v = x - y )，其中 ( y ) 是目标向量（如 ( |x| e_1 )），\nHouseholder 变换通过 ( H = I - 2 \\frac{v v^\\top}{v^\\top v} ) 实现反射，\n在 QR 分解中，Householder 变换逐步将 ( A ) 化为 ( R )，并构造正交矩阵 ( Q )。\n\n数值稳定性：\n\n通常选择 ( v = x + \\text{sign}(x_1) |x| e_1 ) 避免 ( v ) 接近零向量，\nHouseholder 变换比 Gram-Schmidt 更稳定，适合大规模数值计算。\n\n\n奇异值分解（SVD）法推导最小二乘解\n1. 奇异值分解（SVD）的定义\n对于列满秩矩阵 ( A \\in \\mathbb{R}^{m \\times n} )（( m \\geq n )），其奇异值分解为：\n[\nA = U \\begin{bmatrix} \\Sigma \\ 0 \\end{bmatrix} V^\\top\n]\n其中：\n\n( U \\in \\mathbb{R}^{m \\times m} ) 是正交矩阵（( U^\\top U = I_m )），可以分块为 ( U = [U_n, \\tilde{U}] )：\n\n( U_n \\in \\mathbb{R}^{m \\times n} )：前 ( n ) 列，对应非零奇异值。\n( \\tilde{U} \\in \\mathbb{R}^{m \\times (m - n)} )：后 ( m - n ) 列，对应零奇异值。\n\n\n( \\Sigma \\in \\mathbb{R}^{n \\times n} ) 是对角矩阵，对角线元素为奇异值 ( \\sigma_1 \\geq \\sigma_2 \\geq \\dots \\geq \\sigma_n &gt; 0 )（因为 ( A ) 列满秩）。\n( V \\in \\mathbb{R}^{n \\times n} ) 是正交矩阵（( V^\\top V = I_n )）。\n\n2. 残差范数的表达\n最小二乘问题的目标是最小化残差范数：\n[\n|Ax - b|_2^2 = \\left| U \\begin{bmatrix} \\Sigma \\ 0 \\end{bmatrix} V^\\top x - b \\right|_2^2\n]\n利用正交矩阵的性质 ( |Uy|_2 = |y|_2 )，可以左乘 ( U^\\top )：\n[\n|Ax - b|_2^2 = \\left| \\begin{bmatrix} \\Sigma \\ 0 \\end{bmatrix} V^\\top x - U^\\top b \\right|_2^2\n]\n将 ( U^\\top b ) 分块为：\n[\nU^\\top b = \\begin{bmatrix} U_n^\\top b \\ \\tilde{U}^\\top b \\end{bmatrix}\n]\n因此：\n[\n|Ax - b|_2^2 = \\left| \\begin{bmatrix} \\Sigma V^\\top x - U_n^\\top b \\ -\\tilde{U}^\\top b \\end{bmatrix} \\right|_2^2 = |\\Sigma V^\\top x - U_n^\\top b|_2^2 + |\\tilde{U}^\\top b|_2^2\n]\n3. 最小化残差范数\n\n第二项 ( |\\tilde{U}^\\top b|_2^2 ) 是固定的（与 ( x ) 无关）。\n第一项 ( |\\Sigma V^\\top x - U_n^\\top b|_2^2 ) 可以最小化为零（因为 ( \\Sigma ) 和 ( V ) 可逆）：\n[\n\\Sigma V^\\top x - U_n^\\top b = 0 \\implies \\Sigma V^\\top x = U_n^\\top b\n]\n解得：\n[\nx = (V^\\top)^{-1} \\Sigma^{-1} U_n^\\top b = V \\Sigma^{-1} U_n^\\top b\n]\n（因为 ( V ) 是正交矩阵，( V^{-1} = V^\\top )）。\n\n4. 解的几何意义\n\n( U_n^\\top b ) 是 ( b ) 在 ( \\text{Ran}(A) )（( A ) 的列空间）上的投影系数。\n( \\Sigma^{-1} ) 对奇异值进行缩放，( V ) 将结果转换回原空间。\n( \\tilde{U}^\\top b ) 是 ( b ) 在 ( \\text{Ran}(A)^\\perp )（( A ) 的左零空间）上的分量，无法被 ( Ax ) 表示。\n\n5. 与QR分解法的对比\n\nQR分解法：( A = QR )，解为 ( x = R^{-1} Q^\\top b )。\nSVD法：( A = U \\begin{bmatrix} \\Sigma \\ 0 \\end{bmatrix} V^\\top )，解为 ( x = V \\Sigma^{-1} U_n^\\top b )。\nSVD法的优势：\n\n数值稳定性更高（尤其当 ( A ) 接近秩亏时）。\n可以直接处理秩亏矩阵（通过截断小奇异值）。\n\n\n\n6. 关键符号总结\n\n( U_n )：对应非零奇异值的左奇异向量。\n( \\tilde{U} )：对应零奇异值的左奇异向量。\n( \\Sigma )：奇异值矩阵（对角矩阵）。\n( V )：右奇异向量矩阵。\n( U_n^\\top b )：( b ) 在 ( \\text{Ran}(A) ) 上的投影。\n( \\tilde{U}^\\top b )：( b ) 在 ( \\text{Ran}(A)^\\perp ) 上的投影。\n\n7. 最终解\n最小二乘解为：\n[\nx^* = V \\Sigma^{-1} U_n^\\top b\n]\n","tags":["其他"]},{"title":"noteRichardsoniteration","url":"/notes.github.io/2025/06/23/noteRichardsoniteration/","content":"这个问题涉及矩阵多项式的特征空间视角以及对称矩阵的梯度下降方法之间的联系。以下我将详细解释这两个视角，并逐步推导和阐明它们之间的关系。\n\n1. 矩阵多项式的特征空间视角\n矩阵多项式的定义\n给定一个矩阵 ( A \\in \\mathbb{R}^{n \\times n} ) 和一个多项式 ( p(x) = c_k x^k + c_{k-1} x^{k-1} + \\cdots + c_1 x + c_0 )，矩阵多项式 ( p(A) ) 定义为：\n[\np(A) = c_k A^k + c_{k-1} A^{k-1} + \\cdots + c_1 A + c_0 I,\n]\n其中 ( I ) 是单位矩阵，( A^k ) 表示矩阵 ( A ) 的 ( k ) 次幂。\n特征空间的性质\n假设矩阵 ( A ) 有特征值 ( \\lambda_1, \\lambda_2, \\dots, \\lambda_n ) 以及对应的特征向量 ( v_1, v_2, \\dots, v_n )，满足：\n[\nA v_i = \\lambda_i v_i.\n]\n对于矩阵多项式 ( p(A) )，我们有：\n[\np(A) v_i = p(\\lambda_i) v_i.\n]\n推导：\n[\np(A) v_i = \\left( c_k A^k + c_{k-1} A^{k-1} + \\cdots + c_1 A + c_0 I \\right) v_i.\n]\n由于 ( A v_i = \\lambda_i v_i )，我们可以计算：\n[\nA^2 v_i = A (A v_i) = A (\\lambda_i v_i) = \\lambda_i (A v_i) = \\lambda_i^2 v_i,\n]\n依次类推，( A^k v_i = \\lambda_i^k v_i )。因此：\n[\np(A) v_i = c_k A^k v_i + c_{k-1} A^{k-1} v_i + \\cdots + c_1 A v_i + c_0 v_i\n= c_k \\lambda_i^k v_i + c_{k-1} \\lambda_i^{k-1} v_i + \\cdots + c_1 \\lambda_i v_i + c_0 v_i\n= \\left( c_k \\lambda_i^k + c_{k-1} \\lambda_i^{k-1} + \\cdots + c_1 \\lambda_i + c_0 \\right) v_i\n= p(\\lambda_i) v_i.\n]\n这表明，如果 ( v_i ) 是 ( A ) 的特征向量，对应的特征值为 ( \\lambda_i )，那么 ( v_i ) 也是 ( p(A) ) 的特征向量，对应的特征值为 ( p(\\lambda_i) )。\n从 ( A \\to p(A) ) 和 ( \\lambda_i \\to p(\\lambda_i) )\n\n矩阵 ( A ) 的特征值 ( \\lambda_1, \\lambda_2, \\dots, \\lambda_n ) 通过多项式 ( p ) 映射为 ( p(\\lambda_1), p(\\lambda_2), \\dots, p(\\lambda_n) )。\n特征向量保持不变，只是特征值被多项式变换。这种映射在谱分析和矩阵函数（如矩阵指数、对数等）中非常重要。\n\n\n2. 对称矩阵与梯度下降的视角\n目标函数\n考虑二次目标函数：\n[\nf(x) = \\frac{1}{2} x^\\top A x - b^\\top x,\n]\n其中 ( A \\in \\mathbb{R}^{n \\times n} ) 是一个对称矩阵（即 ( A = A^\\top )，这保证了 ( A ) 的特征值是实数且特征向量可以构成正交基），( x, b \\in \\mathbb{R}^n )。\n梯度计算\n我们计算目标函数的梯度：\n[\n\\nabla f(x) = \\nabla \\left( \\frac{1}{2} x^\\top A x - b^\\top x \\right).\n]\n\n对于第一项 ( \\frac{1}{2} x^\\top A x )：\n[\n\\nabla \\left( \\frac{1}{2} x^\\top A x \\right) = \\frac{1}{2} (A + A^\\top) x.\n]\n由于 ( A ) 是对称的，( A^\\top = A )，因此：\n[\n\\frac{1}{2} (A + A^\\top) x = \\frac{1}{2} (A + A) x = \\frac{1}{2} \\cdot 2A x = A x.\n]\n对于第二项 ( -b^\\top x )：\n[\n\\nabla (-b^\\top x) = -b.\n]\n因此，梯度为：\n[\n\\nabla f(x) = A x - b.\n]\n\n梯度下降方法\n梯度下降的迭代公式为：\n[\nx_{k+1} = x_k - \\alpha \\nabla f(x_k),\n]\n其中 ( \\alpha ) 是步长。代入梯度：\n[\n\\nabla f(x_k) = A x_k - b,\n]\n得到：\n[\nx_{k+1} = x_k - \\alpha (A x_k - b) = (I - \\alpha A) x_k + \\alpha b.\n]\n这是一个线性迭代过程，形式为：\n[\nx_{k+1} = T x_k + c,\n]\n其中 ( T = I - \\alpha A )，( c = \\alpha b )。\n梯度下降与矩阵多项式的联系\n梯度下降的迭代可以看作是对初始向量 ( x_0 ) 应用一系列矩阵多项式。假设初始点为 ( x_0 )，迭代 ( k ) 次后：\n[\nx_k = (I - \\alpha A)^k x_0 + \\sum_{j=0}^{k-1} (I - \\alpha A)^j \\alpha b.\n]\n这里，矩阵 ( I - \\alpha A ) 是一个多项式（一次多项式）的形式，多次迭代形成了高次多项式 ( (I - \\alpha A)^k )。如果我们考虑误差 ( e_k = x_k - x^* )，其中 ( x^* ) 是目标函数的最优解（满足 ( A x^* = b )，即 ( x^* = A^{-1} b \\）），则：\n[\ne_k = (I - \\alpha A)^k e_0.\n]\n在特征空间中，假设 ( A ) 的特征值为 ( \\lambda_i )，特征向量为 ( v_i )，则 ( I - \\alpha A ) 的特征值为：\n[\n1 - \\alpha \\lambda_i.\n]\n因此，误差在特征向量 ( v_i ) 方向上的分量会按 ( (1 - \\alpha \\lambda_i)^k ) 收敛。收敛速度取决于 ( |1 - \\alpha \\lambda_i| &lt; 1 )，这与矩阵多项式 ( p(A) = (I - \\alpha A)^k ) 的特征值 ( p(\\lambda_i) = (1 - \\alpha \\lambda_i)^k ) 直接相关。\n\n3. 两个视角的联系\n特征空间与梯度下降\n\n矩阵多项式视角：矩阵 ( A ) 的特征值 ( \\lambda_i ) 通过多项式 ( p ) 映射到 ( p(\\lambda_i) )。在梯度下降中，矩阵多项式 ( p(A) = (I - \\alpha A)^k ) 将特征值 ( \\lambda_i ) 映射到 ( (1 - \\alpha \\lambda_i)^k )。这决定了误差在每个特征方向上的收敛速度。\n梯度下降视角：目标函数 ( f(x) = \\frac{1}{2} x^\\top A x - b^\\top x ) 的优化过程通过迭代 ( x_{k+1} = (I - \\alpha A) x_k + \\alpha b ) 逐步逼近最优解 ( x^* = A^{-1} b )。迭代矩阵 ( I - \\alpha A ) 的谱性质（即特征值 ( 1 - \\alpha \\lambda_i )）决定了收敛行为。\n\n对称矩阵的特殊性\n当 ( A ) 是对称矩阵时：\n\n( A ) 的特征值是实数，特征向量正交，这简化了特征空间的分析。\n目标函数 ( f(x) ) 是凸的（若 ( A ) 正定，则严格凸），梯度下降保证收敛到全局最优解。\n梯度下降的收敛速度由 ( A ) 的条件数（最大特征值与最小特征值的比值）决定，因为 ( |1 - \\alpha \\lambda_i| ) 的最大值决定了误差缩小的速度。\n\n多项式优化\n在梯度下降中，矩阵多项式 ( p(A) = (I - \\alpha A)^k ) 的作用是将初始误差 ( e_0 ) 映射到 ( e_k = p(A) e_0 )。为了加速收敛，可以选择更复杂的多项式 ( p(A) )，例如使用多项式预条件子或共轭梯度法（Conjugate Gradient, CG）。CG 方法本质上是通过构造一个最优的多项式 ( p(A) )，使得误差 ( | e_k |_A = \\sqrt{e_k^\\top A e_k} ) 最小化，其中 ( p(\\lambda_i) ) 在特征值范围内尽可能小。\n\n4. 补充：梯度公式中的问题\n在问题中，梯度计算部分提到：\n[\n\\nabla \\left( \\frac{1}{2} x^\\top A x - b^\\top x \\right) = \\frac{1}{2} (A + A^\\top) x - b = A x_k - ?.\n]\n从推导来看：\n[\n\\nabla f(x) = \\frac{1}{2} (A + A^\\top) x - b.\n]\n由于 ( A ) 是对称的，( A = A^\\top )，所以：\n[\n\\frac{1}{2} (A + A^\\top) x = \\frac{1}{2} (A + A) x = A x.\n]\n因此：\n[\n\\nabla f(x) = A x - b.\n]\n在迭代中，( x = x_k ) 时，梯度为：\n[\n\\nabla f(x_k) = A x_k - b.\n]\n问题中的“( A x_k - ? )” 应该是指：\n[\n\\nabla f(x_k) = A x_k - b.\n]\n这里的 ( ? ) 就是 ( b )。如果问题中暗示了其他上下文（例如某种近似或变体），请提供更多细节，我可以进一步分析。\n\n总结\n\n矩阵多项式视角：矩阵 ( A ) 的特征值 ( \\lambda_i ) 通过多项式 ( p ) 映射到 ( p(\\lambda_i) )，特征向量不变。这在分析矩阵函数和迭代方法（如梯度下降）的谱性质时非常有用。\n梯度下降视角：对于对称矩阵 ( A )，目标函数 ( f(x) = \\frac{1}{2} x^\\top A x - b^\\top x ) 的梯度下降迭代可以看作是矩阵多项式 ( (I - \\alpha A)^k ) 的应用，收敛速度由特征值 ( 1 - \\alpha \\lambda_i ) 决定。\n联系：梯度下降的迭代本质上是通过矩阵多项式操作特征空间中的误差分量，特征值的变换 ( \\lambda_i \\to (1 - \\alpha \\lambda_i)^k ) 决定了收敛行为。\n对称矩阵的优势：对称性保证了实特征值和正交特征向量，使得分析和优化更简单，梯度下降收敛到全局最优。\n\n如果有进一步的问题或需要更深入的推导（例如共轭梯度法、预条件子或谱分析），请告诉我！\n这个问题涉及矩阵逆的近似、Richardson迭代的收敛性分析，以及条件数与迭代步数的关系。以下我将详细推导每个部分，帮助你理解问题的核心内容和推导过程。\n\n1. 矩阵逆的近似：( A^{-1} \\approx p(A) )\n目标\n我们希望通过一个多项式 ( p(A) ) 来近似矩阵 ( A ) 的逆 ( A^{-1} )，即：\n[\nA^{-1} \\approx p(A),\n]\n其中 ( p(A) ) 是矩阵 ( A ) 的多项式，形式为：\n[\np(A) = c_k A^k + c_{k-1} A^{k-1} + \\cdots + c_1 A + c_0 I.\n]\n理想情况下，( p(A) A = I )，但我们通常只能找到一个近似，使得 ( p(A) A \\approx I )。\n等价的多项式 ( q(x) )\n为了近似 ( A^{-1} )，我们引入一个辅助多项式：\n[\nq(x) = 1 - x p(x).\n]\n目标是让 ( q(A) = I - A p(A) \\approx 0 )，因为：\n[\nI - A p(A) = 0 \\implies A p(A) = I \\implies p(A) = A^{-1}.\n]\n因此，我们希望找到一个多项式 ( p(x) )，使得：\n[\nq(x) = 1 - x p(x) \\approx 0, \\quad \\forall x \\in {\\lambda_1, \\lambda_2, \\dots, \\lambda_n},\n]\n其中 ( \\lambda_i ) 是矩阵 ( A ) 的特征值。同时，注意到：\n[\nq(0) = 1 - 0 \\cdot p(0) = 1.\n]\n假设 ( A ) 是正定对称矩阵（常见于优化问题），其特征值满足 ( \\lambda_i &gt; 0 )。我们需要：\n\n( q(0) = 1 ),\n( q(x) \\approx 0 ) 对于 ( x \\in [\\lambda_1, \\lambda_n] )，其中 ( \\lambda_1 \\leq \\lambda_i \\leq \\lambda_n ) 是 ( A ) 的最小和最大特征值。\n\n意义\n寻找这样的 ( p(x) ) 是一个多项式逼近问题，类似于用多项式逼近函数 ( 1/x )。在实际中，可以使用切比雪夫多项式或其他优化多项式来构造 ( p(x) )，以最小化 ( |q(x)| ) 在特征值区间 ( [\\lambda_1, \\lambda_n] ) 上的最大值。\n\n2. 求解线性系统 ( Ax = b )\n目标\n我们希望解线性方程组：\n[\nAx = b,\n]\n其解为：\n[\nx^* = A^{-1} b.\n]\n如果我们用多项式 ( p(A) ) 近似 ( A^{-1} )，则：\n[\nx^* \\approx p(A) b.\n]\n注意到 ( p(A) b ) 是 ( A ) 的幂次作用在 ( b ) 上的线性组合：\n[\np(A) b = \\left( c_k A^k + c_{k-1} A^{k-1} + \\cdots + c_1 A + c_0 I \\right) b = c_k A^k b + c_{k-1} A^{k-1} b + \\cdots + c_1 A b + c_0 b.\n]\n因此，( p(A) b ) 属于 Krylov 子空间：\n[\nx^* \\approx p(A) b \\in \\text{span}{b, A b, A^2 b, \\dots}.\n]\n\n3. Richardson 迭代\n迭代公式\nRichardson 迭代是一种简单的迭代方法，用于解 ( Ax = b )。其迭代公式为：\n[\nx_{k+1} = (I - \\alpha A) x_k + \\alpha b,\n]\n初始点设为 ( x_0 = 0 )。其中，( \\alpha ) 是步长（类似梯度下降中的学习率）。\n误差分析\n令误差 ( e_k = x_k - x^* )，其中 ( x^* = A^{-1} b ) 是精确解。则：\n[\ne_{k+1} = x_{k+1} - x^* = (I - \\alpha A) x_k + \\alpha b - x^.\n]\n因为 ( A x^ = b )，所以 ( \\alpha b = \\alpha A x^* )。代入：\n[\ne_{k+1} = (I - \\alpha A) x_k + \\alpha A x^* - x^* = (I - \\alpha A) x_k + (\\alpha A x^* - x^) = (I - \\alpha A) x_k - (I - \\alpha A) x^.\n]\n因此：\n[\ne_{k+1} = (I - \\alpha A) (x_k - x^) = (I - \\alpha A) e_k.\n]\n递归展开：\n[\ne_k = (I - \\alpha A)^k e_0,\n]\n其中 ( e_0 = x_0 - x^ = 0 - x^* = -x^* )（因为 ( x_0 = 0 )）。\n收敛性分析\n误差的收敛取决于矩阵 ( I - \\alpha A ) 的谱半径 ( \\rho(I - \\alpha A) )。假设 ( A ) 是对称正定矩阵，特征值为 ( 0 &lt; \\lambda_1 \\leq \\lambda_2 \\leq \\cdots \\leq \\lambda_n )。则 ( I - \\alpha A ) 的特征值为：\n[\n1 - \\alpha \\lambda_i.\n]\n谱半径定义为：\n[\n\\rho(I - \\alpha A) = \\max_i |1 - \\alpha \\lambda_i|.\n]\n为了保证收敛，需要：\n[\n\\rho(I - \\alpha A) = \\max_i |1 - \\alpha \\lambda_i| &lt; 1.\n]\n这意味着对于所有特征值 ( \\lambda_i )，必须有：\n[\n-1 &lt; 1 - \\alpha \\lambda_i &lt; 1 \\implies 0 &lt; \\alpha \\lambda_i &lt; 2 \\implies 0 &lt; \\alpha &lt; \\frac{2}{\\lambda_i}.\n]\n由于 ( \\lambda_n ) 是最大特征值，约束条件为：\n[\n0 &lt; \\alpha &lt; \\frac{2}{\\lambda_n}.\n]\n谱半径具体为：\n[\n\\rho(I - \\alpha A) = \\max { |1 - \\alpha \\lambda_1|, |1 - \\alpha \\lambda_n| },\n]\n因为 ( \\lambda_1 \\leq \\lambda_i \\leq \\lambda_n )，且 ( 1 - \\alpha \\lambda_i ) 在 ( [1 - \\alpha \\lambda_n, 1 - \\alpha \\lambda_1] ) 之间。\n\n4. 选择最优步长 ( \\alpha )\n优化 ( \\alpha )\n为了最小化谱半径 ( \\rho(I - \\alpha A) )，我们希望：\n[\n|1 - \\alpha \\lambda_1| = |1 - \\alpha \\lambda_n|.\n]\n设：\n[\n1 - \\alpha \\lambda_1 = -(1 - \\alpha \\lambda_n).\n]\n解这个方程：\n[\n1 - \\alpha \\lambda_1 = -1 + \\alpha \\lambda_n \\implies 1 + 1 = \\alpha \\lambda_n + \\alpha \\lambda_1 \\implies 2 = \\alpha (\\lambda_n + \\lambda_1) \\implies \\alpha = \\frac{2}{\\lambda_1 + \\lambda_n}.\n]\n代入 ( \\alpha = \\frac{2}{\\lambda_1 + \\lambda_n} )，计算：\n[\n1 - \\alpha \\lambda_1 = 1 - \\frac{2 \\lambda_1}{\\lambda_1 + \\lambda_n} = \\frac{\\lambda_1 + \\lambda_n - 2 \\lambda_1}{\\lambda_1 + \\lambda_n} = \\frac{\\lambda_n - \\lambda_1}{\\lambda_1 + \\lambda_n}.\n]\n类似地：\n[\n1 - \\alpha \\lambda_n = 1 - \\frac{2 \\lambda_n}{\\lambda_1 + \\lambda_n} = \\frac{\\lambda_1 + \\lambda_n - 2 \\lambda_n}{\\lambda_1 + \\lambda_n} = \\frac{\\lambda_1 - \\lambda_n}{\\lambda_1 + \\lambda_n} = -\\frac{\\lambda_n - \\lambda_1}{\\lambda_1 + \\lambda_n}.\n]\n因此：\n[\n|1 - \\alpha \\lambda_1| = \\frac{\\lambda_n - \\lambda_1}{\\lambda_1 + \\lambda_n}, \\quad |1 - \\alpha \\lambda_n| = \\frac{\\lambda_n - \\lambda_1}{\\lambda_1 + \\lambda_n}.\n]\n谱半径为：\n[\n\\rho(I - \\alpha A) = \\frac{\\lambda_n - \\lambda_1}{\\lambda_1 + \\lambda_n} = \\frac{\\frac{\\lambda_n}{\\lambda_1} - 1}{\\frac{\\lambda_n}{\\lambda_1} + 1} = \\frac{\\kappa - 1}{\\kappa + 1},\n]\n其中 ( \\kappa = \\frac{\\lambda_n}{\\lambda_1} ) 是 ( A ) 的条件数。\n验证\n注意到：\n[\n\\frac{\\kappa - 1}{\\kappa + 1} = 1 - \\frac{2}{\\kappa + 1} = 1 - \\frac{2}{\\frac{\\lambda_n}{\\lambda_1} + 1}.\n]\n这与问题中的表达式一致：\n[\n\\rho(I - \\alpha A) = 1 - \\frac{2}{\\frac{\\lambda_n}{\\lambda_1} + 1}.\n]\n\n5. 收敛步数估计\n误差收敛\n误差满足：\n[\ne_k = (I - \\alpha A)^k e_0.\n]\n在范数中：\n[\n|e_k| \\leq |(I - \\alpha A)^k| |e_0| \\leq [\\rho(I - \\alpha A)]^k |e_0|.\n]\n为了使误差满足 ( |e_k| \\leq \\epsilon |e_0| )，需要：\n[\n[\\rho(I - \\alpha A)]^k \\leq \\epsilon.\n]\n取对数：\n[\nk \\ln \\rho(I - \\alpha A) \\leq \\ln \\epsilon \\implies k \\geq \\frac{\\ln \\epsilon}{\\ln \\rho(I - \\alpha A)}.\n]\n由于 ( \\rho(I - \\alpha A) &lt; 1 )，( \\ln \\rho(I - \\alpha A) &lt; 0 )，所以：\n[\nk \\geq \\frac{\\ln (1/\\epsilon)}{-\\ln \\rho(I - \\alpha A)}.\n]\n近似地，当 ( \\rho = \\frac{\\kappa - 1}{\\kappa + 1} = 1 - \\frac{2}{\\kappa + 1} ) 接近 1 时（即 ( \\kappa ) 较大）：\n[\n-\\ln \\rho \\approx -\\ln \\left( 1 - \\frac{2}{\\kappa + 1} \\right) \\approx \\frac{2}{\\kappa + 1} \\quad (\\text{因为 } \\ln(1 - x) \\approx -x \\text{ 当 } x \\text{ 小时}).\n]\n因此：\n[\nk \\gtrsim \\frac{\\ln (1/\\epsilon)}{\\frac{2}{\\kappa + 1}} = \\frac{\\kappa + 1}{2} \\ln \\frac{1}{\\epsilon}.\n]\n考虑到 ( \\kappa = \\frac{\\lambda_n}{\\lambda_1} )，我们得到：\n[\nk \\sim O\\left( \\left( \\frac{\\lambda_n}{\\lambda_1} + 1 \\right) \\ln \\frac{1}{\\epsilon} \\right) = O\\left( (\\kappa + 1) \\ln \\frac{1}{\\epsilon} \\right).\n]\n这表明收敛步数与条件数 ( \\kappa ) 成正比，条件数越大，收敛越慢。\n\n6. 条件数的作用\n条件数 ( \\kappa = \\frac{\\lambda_n}{\\lambda_1} )\n\n条件数 ( \\kappa ) 衡量了矩阵 ( A ) 的“病态”程度。较大的 ( \\kappa ) 表示特征值分布范围广，迭代方法收敛较慢。\n在 Richardson 迭代中，谱半径 ( \\rho(I - \\alpha A) = \\frac{\\kappa - 1}{\\kappa + 1} ) 接近 1（当 ( \\kappa ) 很大时），导致收敛缓慢。\n条件数直接影响收敛步数，步数与 ( \\kappa ) 成线性关系。\n\n改进方法\n为了克服条件数大的问题，可以使用：\n\n预条件子：引入预条件矩阵 ( M )，将系统转化为 ( M^{-1} A x = M^{-1} b )，减小 ( M^{-1} A ) 的条件数。\n共轭梯度法：通过构造 Krylov 子空间中的最优解，收敛步数从 ( O(\\kappa) ) 降低到 ( O(\\sqrt{\\kappa}) )。\n\n\n总结\n\n矩阵逆近似：通过多项式 ( p(A) ) 近似 ( A^{-1} )，等价于构造 ( q(x) = 1 - x p(x) \\approx 0 )，满足 ( q(0) = 1 )。\nRichardson 迭代：迭代 ( x_{k+1} = (I - \\alpha A) x_k + \\alpha b )，误差 ( e_k = (I - \\alpha A)^k e_0 )，收敛由谱半径 ( \\rho(I - \\alpha A) ) 决定。\n最优步长：选择 ( \\alpha = \\frac{2}{\\lambda_1 + \\lambda_n} )，使 ( \\rho(I - \\alpha A) = \\frac{\\kappa - 1}{\\kappa + 1} = 1 - \\frac{2}{\\kappa + 1} )。\n收敛步数：需要 ( O((\\kappa + 1) \\ln (1/\\epsilon)) ) 步，条件数 ( \\kappa = \\frac{\\lambda_n}{\\lambda_1} ) 是关键因素。\n条件数：较大的 ( \\kappa ) 导致收敛缓慢，可通过预条件子或共轭梯度法改进。\n\n如果你对某些部分（如切比雪夫多项式逼近、预条件子或共轭梯度法的具体实现）有进一步疑问，请告诉我，我可以更深入地推导或解释！\n好的，下面是对上面 Chebyshev 迭代和共轭梯度 (CG) 方法的详细解释和推导的中文翻译，力求流畅准确：\n\n1. Chebyshev 迭代\n目标\nChebyshev 迭代法的目标是通过求解线性方程组 ( Ax = b ) 来逼近逆矩阵 ( A^{-1} )，其中 ( A ) 是一个对称正定 (SPD) 矩阵。该方法将 ( A^{-1} ) 近似为一个多项式 ( p(A) )，使得 ( x^* = A^{-1}b \\approx p(A)b )。 等价地说，我们希望找到一个多项式 ( q(x) = 1 - x p(x) )，满足：\n\n( q(0) = 1 ),\n( q(x) \\approx 0 ) 对于 ( x &gt; 0 ) （特别地，对于 ( x ) 在 ( A ) 的谱内）。\n\n因为 ( A ) 是 SPD 矩阵，它的特征值都是正的，假设 ( \\lambda_i \\in [\\lambda_{\\text{min}}, \\lambda_{\\text{max}}] )，其中 ( \\lambda_{\\text{min}} &gt; 0 )。\n迭代方案\nChebyshev 迭代法的迭代公式为：\n[\nx_{k+1} = (I - \\alpha_k A) x_k + \\alpha_k b\n]\n其中 ( \\alpha_k ) 是标量，用于优化收敛速度。 让我们推导误差传播公式来理解这个过程。\n误差分析\n精确解为 ( x^* = A^{-1}b )。定义第 ( k ) 步的误差：\n[\ne_k = x_k - x^*\n]\n从迭代公式中减去 ( x^* ) 的迭代公式（( A x^* = b )），得到：\n[\nx_{k+1} - x^* = (I - \\alpha_k A) x_k + \\alpha_k b - x^*\n]\n因为 ( b = A x^* )，所以：\n[\n\\alpha_k b = \\alpha_k A x^*\n]\n因此：\n[\nx_{k+1} - x^* = (I - \\alpha_k A) x_k - (I - \\alpha_k A) x^* = (I - \\alpha_k A) (x_k - x^*)\n]\n所以：\n[\ne_{k+1} = (I - \\alpha_k A) e_k\n]\n通过归纳法：\n[\ne_k = \\prod_{i=0}^{k-1} (I - \\alpha_i A) e_0\n]\n通过应用矩阵多项式 ( \\prod_{i=0}^{k-1} (I - \\alpha_i A) ) 来减小误差。 目标是选择 ( \\alpha_i ) 来最小化这个算子的范数。\n与多项式逼近的联系\n因为 ( e_k = \\left( \\prod_{i=0}^{k-1} (I - \\alpha_i A) \\right) e_0 )，我们希望：\n[\n\\left| \\prod_{i=0}^{k-1} (I - \\alpha_i A) \\right|\n]\n尽可能小。 对于 SPD 矩阵 ( A )，该范数取决于应用于 ( A ) 的多项式的特征值。 设这个多项式为：\n[\nP_k(A) = \\prod_{i=0}^{k-1} (I - \\alpha_i A)\n]\n对于 ( A ) 的任何特征值 ( \\lambda_i )，该多项式的值为：\n[\nP_k(\\lambda_i) = \\prod_{i=0}^{k-1} (1 - \\alpha_i \\lambda_i)\n]\n我们需要 ( P_k(\\lambda_i) \\approx 0 ) 对于 ( \\lambda_i \\in [\\lambda_{\\text{min}}, \\lambda_{\\text{max}}] )。 这就是 Chebyshev 多项式发挥作用的地方。\nChebyshev 多项式\n第一类 Chebyshev 多项式定义为：\n[\nT_k(x) = \\cos(k \\arccos(x)), \\quad x \\in [-1, 1]\n]\n它们在 ([-1, 1]) 区间内振荡于 (-1) 和 (1) 之间，并在该区间外迅速增长。为了将它们应用于 ( A ) 的谱，我们通过线性变换将区间 ( [\\lambda_{\\text{min}}, \\lambda_{\\text{max}}] ) 映射到 ([-1, 1])：\n[\nz = \\frac{2\\lambda - (\\lambda_{\\text{max}} + \\lambda_{\\text{min}})}{\\lambda_{\\text{max}} - \\lambda_{\\text{min}}}\n]\n这个变换将 ( \\lambda = \\lambda_{\\text{min}} ) 映射到 ( z = -1 )，将 ( \\lambda = \\lambda_{\\text{max}} ) 映射到 ( z = 1 )。Chebyshev 多项式 ( T_k(z) ) 用于构造 ( P_k(\\lambda) )，使其在 ( [\\lambda_{\\text{min}}, \\lambda_{\\text{max}}] ) 上尽可能小。\n参数 ( \\alpha_k ) 的选择基于 Chebyshev 多项式的根，并调整到区间 ( [\\lambda_{\\text{min}}, \\lambda_{\\text{max}}] )。 具体来说，( T_k ) 在 ([-1, 1]) 上的根被映射回 ( [\\lambda_{\\text{min}}, \\lambda_{\\text{max}}] )，且 ( \\alpha_k = 1/\\lambda_k )，其中 ( \\lambda_k ) 是这些映射的根。 这确保了多项式 ( P_k(\\lambda) ) 在特征值范围内的最大范数上被最小化。\nKrylov 子空间\n注意：\n[\nx_{k+1} = (I - \\alpha_k A) x_k + \\alpha_k b\n]\n从 ( x_0 = 0 ) 开始：\n[\nx_1 = \\alpha_0 b\n]\n[\nx_2 = (I - \\alpha_1 A) (\\alpha_0 b) + \\alpha_1 b = \\alpha_1 b + \\alpha_0 (I - \\alpha_1 A) b\n]\n每次迭代都会添加涉及更高次幂的 ( A ) 应用于 ( b ) 的项。 因此：\n[\nx_k \\in \\text{span}{ b, A b, A^2 b, \\dots, A^{k-1} b }\n]\n这就是 Krylov 子空间 ( \\mathcal{K}_k = \\text{span}{ b, A b, \\dots, A^{k-1} b } )。\nChebyshev 迭代的总结\n\n该方法构造 ( x_k ) 作为 ( A ) 的多项式应用于 ( b )。\n误差 ( e_k = P_k(A) e_0 )，其中 ( P_k(A) ) 使用 Chebyshev 多项式设计，以最小化 ( A ) 的特征值上的谱范数。\n需要估计 ( \\lambda_{\\text{min}} ) 和 ( \\lambda_{\\text{max}} ) 来设置 ( \\alpha_k )。\n对于条件良好的矩阵（小的 ( \\kappa = \\lambda_{\\text{max}} / \\lambda_{\\text{min}} )），收敛速度更快。\n\n\n2. 共轭梯度 (CG)\n目标\n共轭梯度法也用于求解 ( Ax = b )，其中 ( A ) 是一个 SPD 矩阵。它通过利用 ( A ) 内积的几何性质，最小化 Krylov 子空间内的 ( A ) 范数误差。\nA-内积\n定义向量 ( x, y ) 的 ( A )-内积：\n[\n\\langle x, y \\rangle_A = x^\\top A y\n]\n由于 ( A ) 是 SPD 矩阵：\n\n线性性: ( \\langle \\alpha x + \\beta y, z \\rangle_A = \\alpha \\langle x, z \\rangle_A + \\beta \\langle y, z \\rangle_A )。\n对称性: ( \\langle x, y \\rangle_A = \\langle y, x \\rangle_A )。\n正定性: ( \\langle x, x \\rangle_A = x^\\top A x &gt; 0 ) 对于 ( x \\neq 0 )。\n\n相关的 ( A )-范数为：\n[\n| x |_A = \\sqrt{\\langle x, x \\rangle_A} = \\sqrt{x^\\top A x}\n]\n如果满足以下条件，则向量 ( x, y ) 是 ( A )-共轭的（或 ( A )-正交的）：\n[\n\\langle x, y \\rangle_A = x^\\top A y = 0\n]\n优化视角\n考虑二次函数：\n[\nf(x) = \\frac{1}{2} x^\\top A x - b^\\top x\n]\n梯度为：\n[\n\\nabla f(x) = A x - b\n]\n当 ( \\nabla f(x) = 0 ) 时，即 ( A x = b ) 时，达到最小值。计算：\n[\nf(x) = \\frac{1}{2} x^\\top A x - b^\\top x = \\frac{1}{2} (x - x^)^\\top A (x - x^) - \\frac{1}{2} x^{\\top} A x^\n]\n其中 ( x^* = A^{-1} b )。 因此：\n[\nf(x) = \\frac{1}{2} | x - x^* |_A^2 + \\text{常量}\n]\n最小化 ( f(x) ) 等价于最小化 ( | x - x^* |_A )。\nCG 算法\nCG 算法生成迭代点 ( x_k \\in \\mathcal{K}k = \\text{span}{ b, A b, \\dots, A^{k-1} b } )，使得：\n[\nx_k = \\arg\\min{x \\in \\mathcal{K}_k} | x - x^* |_A^2\n]\n定义：\n\n( v_i = x_i - x_{i-1} ) (搜索方向),\n( r_i = b - A x_i ) (残差).\n\n关键性质是 ( v_i ) 是 ( A )-共轭的：\n[\nv_i^\\top A v_j = 0, \\quad \\forall i \\neq j\n]\n搜索方向的共轭性\n引理: 向量 ( { v_i } ) 是 ( A )-共轭的。\n证明:\n假设 ( i &lt; j )。 因为 ( x_j = \\arg\\min_{x \\in \\mathcal{K}j} | x - x^* |A^2 )，所以目标函数在 ( x_j ) 处的梯度：\n[\n\\nabla \\left( \\frac{1}{2} | x - x^* |A^2 \\right) = A x_j - b = -r_j\n]\n必须与标准内积中的 ( \\mathcal{K}j ) 正交（因为 ( A )-范数最小化意味着梯度与子空间正交）。因此：\n[\nr_j^\\top z = 0, \\quad \\forall z \\in \\mathcal{K}j\n]\n因为 ( \\mathcal{K}{j-1} \\subset \\mathcal{K}j )，我们有：\n[\nr_j^\\top z = 0, \\quad \\forall z \\in \\mathcal{K}{j-1}\n]\n类似地，( r{j-1} = b - A x{j-1} ) 与 ( \\mathcal{K}{j-1} ) 正交。现在：\n[\nA v_j = A (x_j - x{j-1}) = A x_j - A x_{j-1} = (b - r_j) - (b - r_{j-1}) = r_{j-1} - r_j\n]\n因为 ( r_{j-1}, r_j \\in \\mathcal{K}_j ) （因为 ( r_i = b - A x_i )，且 ( x_i \\in \\mathcal{K}i )），所以 ( A v_j \\in \\text{span}{ r{j-1}, r_j } )。我们需要证明 ( v_i^\\top A v_j = 0 ) 对于 ( i &lt; j )。\n因为 ( v_i = x_i - x_{i-1} \\in \\mathcal{K}i \\subset \\mathcal{K}{j-1} )，且 ( r_j \\perp \\mathcal{K}{j-1} )，我们有：\n[\nr_j^\\top v_i = 0\n]\n现在计算：\n[\nv_i^\\top A v_j = v_i^\\top (r{j-1} - r_j) = v_i^\\top r_{j-1} - v_i^\\top r_j = v_i^\\top r_{j-1}\n]\n我们需要 ( v_i^\\top r_{j-1} = 0 )。 注意到 ( r_{j-1} \\perp \\mathcal{K}{j-1} )，并且由于 ( i \\leq j-1 )，所以 ( v_i \\in \\mathcal{K}i \\subset \\mathcal{K}{j-1} )。因此：\n[\nv_i^\\top r{j-1} = 0\n]\n因此：\n[\nv_i^\\top A v_j = 0, \\quad \\forall i &lt; j\n]\n向量 ( { v_i } ) 是 ( A )-共轭的。\n推论: Krylov 子空间是：\n[\n\\mathcal{K}i = \\text{span}{ v_1, v_2, \\dots, v_i }\n]\n因为 ( x_i = x{i-1} + v_i = x_{i-2} + v_{i-1} + v_i = \\dots = \\sum_{j=1}^i v_j )，所以 ( x_i \\in \\text{span}{ v_1, \\dots, v_i } )。\n共轭向量的线性无关性\n声明: ( A )-共轭向量是线性无关的。\n证明:\n假设 ( p_1, p_2, \\dots, p_k ) 是 ( A )-共轭的（( p_i^\\top A p_j = 0 ) 对于 ( i \\neq j )），并且是线性相关的：\n[\n\\alpha_1 p_1 + \\dots + \\alpha_k p_k = 0\n]\n计算：\n[\n\\left( \\sum_{i=1}^k \\alpha_i p_i \\right)^\\top A \\left( \\sum_{j=1}^k \\alpha_j p_j \\right) = \\sum_{i,j} \\alpha_i \\alpha_j p_i^\\top A p_j = \\sum_{i=1}^k \\alpha_i^2 p_i^\\top A p_i\n]\n因为 ( p_i^\\top A p_i = | p_i |A^2 &gt; 0 ) （因为 ( A ) 是 SPD 且 ( p_i \\neq 0 )），并且该总和仅在以下情况下为零：\n[\n\\sum{i=1}^k \\alpha_i^2 | p_i |_A^2 = 0 \\implies \\alpha_i = 0, \\forall i\n]\n因此，( p_i ) 是线性无关的。\nCG 迭代公式\n引理: 定义 ( v_i = x_i - x_{i-1} )，( r_i = b - A x_i )。 那么：\n[\nv_i = \\frac{v_i^\\top r_{i-1}}{r_{i-1}^\\top r_{i-1}} \\left( r_{i-1} - \\frac{r_{i-1}^\\top A v_{i-1}}{v_{i-1}^\\top A v_{i-1}} v_{i-1} \\right)\n]\n证明概要:\n因为 ( x_i \\in \\mathcal{K}i )，且 ( \\mathcal{K}i = \\text{span}{ v_1, \\dots, v{i-1}, r{i-1} } ) （因为 ( r_{i-1} = b - A x_{i-1} )，且 ( x_{i-1} \\in \\mathcal{K}{i-1} )），我们可以写成：\n[\nv_i = c_0 r{i-1} + \\sum_{j=1}^{i-1} c_j v_j\n]\n为了找到 ( c_0 )，取与 ( r_{i-1} ) 的内积：\n[\nv_i^\\top r_{i-1} = c_0 r_{i-1}^\\top r_{i-1} + \\sum_{j=1}^{i-1} c_j v_j^\\top r_{i-1}\n]\n因为 ( v_j \\in \\mathcal{K}j \\subset \\mathcal{K}{i-1} )，且 ( r_{i-1} \\perp \\mathcal{K}{i-1} )，所以 ( v_j^\\top r{i-1} = 0 )。因此：\n[\nc_0 = \\frac{v_i^\\top r_{i-1}}{r_{i-1}^\\top r_{i-1}}\n]\n对于 ( c_j )，强制共轭性 ( v_i^\\top A v_j = 0 ) 对于 ( j &lt; i )。 计算：\n[\nv_i^\\top A v_j = \\left( c_0 r_{i-1} + \\sum_{l=1}^{i-1} c_l v_l \\right)^\\top A v_j = c_0 r_{i-1}^\\top A v_j + c_j v_j^\\top A v_j\n]\n因为 ( v_i \\perp_A v_j )，所以我们需要：\n[\nc_0 r_{i-1}^\\top A v_j + c_j v_j^\\top A v_j = 0\n]\n对于 ( j &lt; i-1 )，( v_j \\in \\mathcal{K}j \\subset \\mathcal{K}{i-1} )，且 ( r_{i-1} \\perp \\mathcal{K}{i-1} )，所以 ( r{i-1}^\\top A v_j = v_j^\\top A r_{i-1} = 0 )。 因此，( c_j = 0 ) 对于 ( j &lt; i-1 )。 对于 ( j = i-1 )：\n[\nc_{i-1} = -c_0 \\frac{r_{i-1}^\\top A v_{i-1}}{v_{i-1}^\\top A v_{i-1}}\n]\n所以：\n[\nv_i = c_0 \\left( r_{i-1} - \\frac{r_{i-1}^\\top A v_{i-1}}{v_{i-1}^\\top A v_{i-1}} v_{i-1} \\right)\n]\n在替换 ( c_0 ) 后，这与给定的形式匹配。\n简化的 CG 算法\n定义：\n[\nd_i = \\frac{r_{i-1}^\\top r_{i-1}}{v_i^\\top r_{i-1}} v_i\n]\n那么：\n[\nx_i = x_{i-1} + \\frac{r_{i-1}^\\top r_{i-1}}{d_i^\\top A d_i} d_i\n]\n[\nd_i = r_{i-1} + \\frac{r_{i-1}^\\top r_{i-1}}{r_{i-2}^\\top r_{i-2}} d_{i-1}\n]\n这是标准的 CG 算法，其中 ( d_i ) 是共轭方向，使用残差进行更新。\n误差界\nCG 中的误差满足：\n[\n| x_k - x^* |A^2 \\leq \\inf{\\substack{q(0)=1 \\ \\deg q \\leq k}} \\max_i |q(\\lambda_i)|^2 \\cdot | b |_{A^{-1}}^2\n]\n这是因为 ( x_k ) 是 ( \\mathcal{K}_k ) 中的最佳近似值，并且误差 ( e_k = x_k - x^* ) 位于多项式空间中。 选择多项式 ( q(\\lambda) ) 以最小化特征值 ( \\lambda_i ) 上的最大值，类似于 Chebyshev 迭代，但 CG 会自动适应谱。\n收敛性\nCG 最多在 ( n ) 次迭代中收敛（在精确算术中），因为 Krylov 子空间 ( \\mathcal{K}_n ) 跨越 ( \\mathbb{R}^n )。 在实践中，对于稀疏矩阵或条件良好的 ( A )，CG 的收敛速度比高斯消元法等直接方法快得多。\n\n比较和联系\n\nKrylov 子空间: 这两种方法都在 ( \\mathcal{K}_k = \\text{span}{ b, A b, \\dots, A^{k-1} b } ) 中生成迭代点。\n多项式逼近: 两者都通过多项式 ( p(A) ) 逼近 ( A^{-1} )。 Chebyshev 迭代显式使用 Chebyshev 多项式，需要特征值估计。 CG 通过最小化 ( A ) 范数隐式构造最佳多项式，无需显式特征值信息即可适应谱。\n收敛性: CG 通常对于 SPD 矩阵更有效，因为它直接在 ( A ) 范数中优化误差，而 Chebyshev 迭代依赖于特征值范围上的均匀逼近。\n实现: Chebyshev 需要根据 ( \\lambda_{\\text{min}}, \\lambda_{\\text{max}} ) 调整 ( \\alpha_k )。 CG 使用内积即时计算步长和方向。\n\n\n结论\n\nChebyshev 迭代: 一种基于多项式的方法，通过设计一个在 ( A ) 的谱上很小的多项式来最小化误差，使用 Chebyshev 多项式。 它很有效，但需要特征值估计。\n共轭梯度: 一种自适应方法，可最小化 Krylov 子空间中的 ( A ) 范数误差，使用 ( A ) 共轭搜索方向。 它更稳健，并且通常对于 SPD 系统更快。\n\n如果你想更深入地探索特定部分（例如，编写 CG 代码、数值示例或更深入的误差分析），请告诉我！\n引理的证明推导\n引理重述\n给定对称正定矩阵 ( A ) 和向量 ( b )，定义 Krylov 子空间：\n[ \\mathcal{K}_i = \\text{span}{b, Ab, A^2b, \\dots, A^{i-1}b}, \\quad \\mathcal{K}0 = {0}. ]\n设 ( x_i ) 是 ( \\mathcal{K}i ) 中最小化 ( A )-范数误差的解：\n[ x_i = \\arg\\min{x \\in \\mathcal{K}i} |x - x|A^2, ]\n其中 ( x ) 是 ( Ax* = b ) 的解，( |x|_A = \\sqrt{x^T A x} )。定义：\n\n( v_i = x_i - x_{i-1} )（解的增量），\n( r_i = b - A x_i )（残差）。\n\n需要证明：\n[ v_i = \\frac{v_i^T r_{i-1}}{|r_{i-1}|^2} \\left( r_{i-1} - \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1} \\right). ]\n证明思路\n\n\n最优性条件：\n\n( x_i ) 是 ( \\mathcal{K}i ) 中最小化 ( |x - x*|_A ) 的解，因此残差 ( r_i ) 与 ( \\mathcal{K}_i ) 正交：\n[ \\forall y \\in \\mathcal{K}_i, \\quad y^T r_i = 0. ]\n类似地，( r_{i-1} \\perp \\mathcal{K}_{i-1} )。\n\n\n\n增量方向：\n\n( v_i = x_i - x_{i-1} \\in \\mathcal{K}i )，且 ( v_i ) 必须与 ( \\mathcal{K}{i-1} ) 在 ( A )-内积下正交：\n[ \\forall y \\in \\mathcal{K}_{i-1}, \\quad v_i^T A y = 0. ]\n因此，( v_i ) 可以表示为 ( r_{i-1} ) 与 ( \\mathcal{K}_{i-1} ) 的某种正交化结果。\n\n\n\n构造 ( v_i )：\n\n设 ( v_i ) 的方向为 ( d_i )，其中 ( d_i ) 是 ( r_{i-1} ) 减去其在 ( v_{i-1} ) 方向上的 ( A )-分量：\n[ d_i = r_{i-1} - \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1}. ]\n这样构造的 ( d_i ) 满足 ( d_i \\perp_A \\mathcal{K}_{i-1} )。\n\n\n\n步长确定：\n\n令 ( v_i = c_i d_i )，其中 ( c_i ) 是最优步长。\n由 ( x_i = x_{i-1} + v_i ) 是最优解，残差 ( r_i ) 应与 ( \\mathcal{K}_i ) 正交，从而可推导 ( c_i )。\n\n\n\n系数计算：\n\n利用 ( r_{i-1} \\perp \\mathcal{K}{i-1} ) 和 ( v{i-1} \\in \\mathcal{K}{i-1} )，有 ( v{i-1}^T r_{i-1} = 0 )。\n计算 ( v_i^T r_{i-1} = c_i d_i^T r_{i-1} = c_i |r_{i-1}|^2 )，因此：\n[ c_i = \\frac{v_i^T r_{i-1}}{|r_{i-1}|^2}. ]\n\n\n\n详细证明\n\n\n方向构造：\n\n设 ( v_i = c_i d_i )，其中：\n[ d_i = r_{i-1} - \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1}. ]\n验证 ( d_i \\perp_A v_{i-1} )：\n[\nd_i^T A v_{i-1} = r_{i-1}^T A v_{i-1} - \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1}^T A v_{i-1} = 0.\n]\n因此 ( v_i \\perp_A \\mathcal{K}_{i-1} )。\n\n\n\n步长计算：\n\n由 ( x_i = x_{i-1} + v_i ) 是最优解，残差 ( r_i = b - A x_i ) 满足 ( r_i \\perp \\mathcal{K}_i )。\n特别地，( r_i \\perp v_i )：\n[\nv_i^T r_i = v_i^T (b - A x_i) = v_i^T r_{i-1} - v_i^T A v_i = 0.\n]\n因此：\n[\nv_i^T r_{i-1} = v_i^T A v_i.\n]\n另一方面：\n[\nv_i^T A v_i = c_i^2 d_i^T A d_i, \\quad v_i^T r_{i-1} = c_i d_i^T r_{i-1}.\n]\n由 ( d_i^T r_{i-1} = |r_{i-1}|^2 )（因为 ( v_{i-1}^T r_{i-1} = 0 )），有：\n[\nc_i |r_{i-1}|^2 = c_i^2 d_i^T A d_i \\implies c_i = \\frac{|r_{i-1}|^2}{d_i^T A d_i}.\n]\n但由 ( v_i^T r_{i-1} = c_i |r_{i-1}|^2 )，可得：\n[\nc_i = \\frac{v_i^T r_{i-1}}{|r_{i-1}|^2}.\n]\n这与步长 ( \\alpha_{i-1} ) 的计算一致。\n\n\n\n综合表达式：\n\n将 ( c_i ) 和 ( d_i ) 代入：\n[\nv_i = c_i d_i = \\frac{v_i^T r_{i-1}}{|r_{i-1}|^2} \\left( r_{i-1} - \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1} \\right).\n]\n\n\n\n共轭梯度法过程\n\n\n初始化：\n\n( x_0 = 0 ), ( r_0 = b ), ( p_0 = r_0 ).\n\n\n\n迭代步骤（( i \\geq 1 )）：\n\n计算步长：\n[\n\\alpha_{i-1} = \\frac{r_{i-1}^T r_{i-1}}{p_{i-1}^T A p_{i-1}}.\n]\n更新解：\n[\nx_i = x_{i-1} + \\alpha_{i-1} p_{i-1}.\n]\n更新残差：\n[\nr_i = r_{i-1} - \\alpha_{i-1} A p_{i-1}.\n]\n计算系数：\n[\n\\beta_i = \\frac{r_i^T r_i}{r_{i-1}^T r_{i-1}}.\n]\n更新搜索方向：\n[\np_i = r_i + \\beta_i p_{i-1}.\n]\n\n\n\n终止条件：\n\n当 ( |r_i| ) 足够小时停止。\n\n\n\n\n问题背景：我们在解决什么？\n我们需要解决一个线性方程组 ( Ax = b )，其中：\n\n( A ) 是一个对称正定矩阵（就像一个“公平的规则书”，保证方程有唯一解，而且解起来比较“友好”）。\n( b ) 是一个已知的向量（可以看作是我们想要达到的目标）。\n( x ) 是我们要找的解（我们的“答案”）。\n\n直接求解 ( Ax = b ) 可能很麻烦，尤其是当 ( A ) 很大时（比如一个巨大的矩阵）。所以，我们用一种叫共轭梯度法的迭代方法，像爬山一样一步步接近答案 ( x_* )（真正的解，满足 ( Ax_* = b )）。\n在这个过程中，我们会用到一个叫 Krylov 子空间 的东西，还有一些向量，比如残差 ( r_i )、方向向量 ( v_i )。我们要证明一个关于 ( v_i ) 的公式（引理），然后解释共轭梯度法是怎么工作的。\n\n什么是 Krylov 子空间？\n想象你在一个迷宫里，起点是向量 ( b )。你可以用矩阵 ( A ) 像“魔法”一样，把 ( b ) 变成新的向量：( Ab )、( A^2b )、( A^3b )，等等。这些向量就像迷宫里的不同路径。Krylov 子空间 ( \\mathcal{K}_i ) 就是由这些向量张成的“区域”：\n[\n\\mathcal{K}_i = \\text{span}{b, Ab, A^2b, \\dots, A^{i-1}b}.\n]\n\n当 ( i = 1 )，( \\mathcal{K}_1 = \\text{span}{b} )，只有 ( b ) 这一条路。\n当 ( i = 2 )，( \\mathcal{K}_2 = \\text{span}{b, Ab} )，多了 ( Ab ) 这条路。\n当 ( i = 0 )，( \\mathcal{K}_0 = {0} )，就是“什么也没有”。\n\n我们会在这些子空间里找一个“最接近”真解 ( x_* ) 的近似解 ( x_i )。\n\n什么是 ( A )-范数？\n我们需要一个方法来衡量我们的近似解 ( x_i ) 离真解 ( x_* ) 有多远。这里的“距离”是用 ( A )-范数 来定义的：\n[\n|x - x_|A = \\sqrt{(x - x)^T A (x - x_*)}.\n]\n你可以把 ( A )-范数想象成一个“加权距离”。普通距离是 ( \\sqrt{x^T x} )，但这里用 ( A ) 来调整方向的重要性（因为 ( A ) 是对称正定的，它像一个“放大镜”，让某些方向更重要）。\n我们的目标是：在 ( \\mathcal{K}i ) 中找到 ( x_i )，使得 ( |x_i - x*|_A ) 最小。这就像在迷宫的某块区域里，找到离终点最近的位置。\n\n定义一些关键向量\n\n\n残差 ( r_i )：\n[\nr_i = b - A x_i.\n]\n残差是“误差向量”，告诉你近似解 ( x_i ) 离目标 ( b ) 还有多远。如果 ( x_i = x_* )，那么 ( A x_i = b )，于是 ( r_i = 0 )，说明我们到终点了。\n\n\n增量 ( v_i )：\n[\nv_i = x_i - x_{i-1}.\n]\n这是从上一步的近似解 ( x_{i-1} ) 到当前解 ( x_i ) 的“步伐”。你可以把它看作我们迈出的一步，方向和大小都很重要。\n\n\n\n引理：我们要证明什么？\n我们需要证明：\n[\nv_i = \\frac{v_i^T r_{i-1}}{|r_{i-1}|^2} \\left( r_{i-1} - \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1} \\right).\n]\n这个公式看起来有点吓人，但别慌！我们把它拆开：\n\n左边：( v_i )，是我们从 ( x_{i-1} ) 到 ( x_i ) 的步伐。\n右边：\n\n( r_{i-1} = b - A x_{i-1} )，是上一步的残差，像一个“指南针”，告诉我们还差多远。\n( \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1} )，是从 ( r_{i-1} ) 中减去一部分与 ( v_{i-1} ) 相关的分量（稍后解释）。\n( \\frac{v_i^T r_{i-1}}{|r_{i-1}|^2} )，是一个系数，决定步伐的大小（像“步长”）。\n\n\n\n这个公式在说：我们的新步伐 ( v_i ) 是基于上一步的残差 ( r_{i-1} )，但调整了方向，确保它和之前的步伐 ( v_{i-1} ) 在某种意义上“垂直”（A-正交）。\n\n共轭梯度法：像爬山一样找答案\n在证明引理之前，我们先了解共轭梯度法的大致思路，方便理解为什么公式长这样。\n共轭梯度法就像在山谷里找最低点（真解 ( x_* )）。你从一个起点 ( x_0 ) 开始，每次迈一步，调整方向，尽量快地到达最低点。关键是：\n\n每一步的方向（叫搜索方向 ( p_i )）要很“聪明”，不能重复走过的路。\n方向之间要 A-正交（也叫共轭），意思是 ( p_i^T A p_j = 0 )（当 ( i \\neq j \\））。这就像在不同方向上“垂直”，避免浪费精力。\n步长（叫 ( \\alpha_i )）要选得恰到好处，确保每一步都离目标更近。\n\n在我们的引理里，( v_i = x_i - x_{i-1} ) 就像是“步长 × 方向”。我们要证明它的具体形式。\n\n证明引理：一步步拆解\n1. 最优性条件：为什么 ( x_i ) 是最好的？\n我们知道，( x_i ) 是在 ( \\mathcal{K}i ) 中使得 ( |x_i - x|A ) 最小的解。数学上，这意味着：\n[\n|x_i - x|A^2 = (x_i - x)^T A (x_i - x_)\n]\n要最小化。我们把这个看成一个函数：\n[\nf(x) = (x - x_)^T A (x - x_) = x^T A x - 2 x^T A x_* + x_^T A x_.\n]\n因为 ( A x_* = b )，所以 ( x^T A x_* = x^T b )。于是：\n[\nf(x) = x^T A x - 2 x^T b + \\text{常数}.\n]\n我们要在 ( x \\in \\mathcal{K}_i ) 中让 ( f(x) ) 最小。这就像在一个有限的区域里找最低点。\n关键性质：当 ( x_i ) 是最优解时，残差 ( r_i = b - A x_i ) 会和 ( \\mathcal{K}i ) 中的所有向量“垂直”（标准内积下）：\n[\n\\forall y \\in \\mathcal{K}i, \\quad y^T r_i = 0.\n]\n为什么？因为 ( r_i = b - A x_i = A (x* - x_i) )，所以：\n[\ny^T r_i = y^T A (x* - x_i).\n]\n如果 ( x_i ) 使 ( f(x) ) 最小，梯度 ( \\nabla f(x) = 2 A x - 2 b ) 在 ( \\mathcal{K}i ) 方向上为零，意味着 ( r_i \\perp \\mathcal{K}i )。同样，( r{i-1} \\perp \\mathcal{K}{i-1} )。\n2. 增量 ( v_i ) 是什么？\n因为：\n[\nx_i = x_{i-1} + v_i,\n]\n所以：\n[\nv_i = x_i - x_{i-1}.\n]\n\n( x_{i-1} \\in \\mathcal{K}_{i-1} )，是上一步的最优解。\n( x_i \\in \\mathcal{K}_i )，是当前的最优解。\n( \\mathcal{K}i ) 比 ( \\mathcal{K}{i-1} ) 多了一个方向（比如 ( A^{i-1}b )）。\n\n所以，( v_i ) 必须在 ( \\mathcal{K}i ) 中，但它得是个“新方向”，不能完全重复 ( \\mathcal{K}{i-1} ) 里的内容。类比：你在迷宫里，( x_{i-1} ) 是你之前走到的地方，( v_i ) 是你新迈出的一步，指向 ( \\mathcal{K}_i ) 里的新区域。\n3. 构造 ( v_i ) 的方向\n我们假设 ( v_i ) 可以写成：\n[\nv_i = c_i d_i,\n]\n其中：\n\n( d_i ) 是方向（像“指南针”），在 ( \\mathcal{K}_i ) 中。\n( c_i ) 是步长（决定走多远）。\n\n方向 ( d_i ) 怎么选？在共轭梯度法中，方向要和之前的方向 A-正交，即：\n[\nd_i^T A v_{i-1} = 0.\n]\n这确保我们不会走“回头路”。我们用上一步的残差 ( r_{i-1} = b - A x_{i-1} ) 作为起点，因为它指向我们还需要修正的方向。但 ( r_{i-1} ) 可能包含一些和 ( v_{i-1} ) 相关的成分，我们需要“清理”掉。\n所以，构造：\n[\nd_i = r_{i-1} - \\gamma v_{i-1},\n]\n其中 ( \\gamma ) 是系数，使得 ( d_i \\perp_A v_{i-1} )：\n[\nd_i^T A v_{i-1} = (r_{i-1} - \\gamma v_{i-1})^T A v_{i-1} = r_{i-1}^T A v_{i-1} - \\gamma v_{i-1}^T A v_{i-1} = 0.\n]\n解出：\n[\n\\gamma = \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}}.\n]\n于是：\n[\nd_i = r_{i-1} - \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1}.\n]\n这个 ( d_i ) 就像是从 ( r_{i-1} ) 中“减去”了它在 ( v_{i-1} ) 方向上的投影（用 ( A )-内积），确保新方向和旧方向“垂直”。\n4. 确定步长 ( c_i )\n现在 ( v_i = c_i d_i )，我们需要找 ( c_i )，让 ( x_i = x_{i-1} + v_i ) 是 ( \\mathcal{K}i ) 中最优的解。回忆 ( x_i ) 使残差 ( r_i \\perp \\mathcal{K}i )。特别地，( r_i \\perp v_i )：\n[\nv_i^T r_i = 0.\n]\n因为：\n[\nr_i = b - A x_i = b - A (x{i-1} + v_i) = r{i-1} - A v_i,\n]\n所以：\n[\nv_i^T r_i = v_i^T (r_{i-1} - A v_i) = v_i^T r_{i-1} - v_i^T A v_i = 0.\n]\n这推出：\n[\nv_i^T r_{i-1} = v_i^T A v_i.\n]\n代入 ( v_i = c_i d_i )，有：\n[\nv_i^T r_{i-1} = c_i d_i^T r_{i-1}, \\quad v_i^T A v_i = c_i^2 d_i^T A d_i.\n]\n所以：\n[\nc_i d_i^T r_{i-1} = c_i^2 d_i^T A d_i \\implies c_i = \\frac{d_i^T r_{i-1}}{d_i^T A d_i}.\n]\n现在计算 ( d_i^T r_{i-1} )：\n[\nd_i = r_{i-1} - \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1},\n]\n[\nd_i^T r_{i-1} = r_{i-1}^T r_{i-1} - \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1}^T r_{i-1}.\n]\n重要性质：因为 ( x_{i-1} \\in \\mathcal{K}{i-1} ) 是最优解，( r{i-1} \\perp \\mathcal{K}{i-1} )。而 ( v{i-1} = x_{i-1} - x_{i-2} \\in \\mathcal{K}{i-1} )，所以：\n[\nv{i-1}^T r_{i-1} = 0.\n]\n因此：\n[\nd_i^T r_{i-1} = |r_{i-1}|^2.\n]\n于是：\n[\nc_i = \\frac{|r_{i-1}|^2}{d_i^T A d_i}.\n]\n但引理里给的系数是 ( \\frac{v_i^T r_{i-1}}{|r_{i-1}|^2} )。我们验证：\n[\nv_i = c_i d_i \\implies v_i^T r_{i-1} = c_i d_i^T r_{i-1} = c_i |r_{i-1}|^2.\n]\n所以：\n[\n\\frac{v_i^T r_{i-1}}{|r_{i-1}|^2} = c_i.\n]\n这正好是我们需要的系数！\n5. 组合得到引理\n把 ( c_i ) 和 ( d_i ) 代入：\n[\nv_i = c_i d_i = \\frac{v_i^T r_{i-1}}{|r_{i-1}|^2} \\left( r_{i-1} - \\frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1} \\right).\n]\n这正是我们要证明的公式！虽然公式里 ( v_i ) 出现在两边，但 ( c_i = \\frac{v_i^T r_{i-1}}{|r_{i-1}|^2} ) 是通过最优性条件推导出来的，符合共轭梯度法的逻辑。\n\n共轭梯度法：完整流程\n现在我们明白了引理，来看共轭梯度法是怎么用这些想法一步步工作的。想象你在玩一个寻宝游戏，每次走一步，调整方向，尽量快地找到宝藏（( x_* )）。\n初始化：\n\n选一个起点 ( x_0 )，通常设 ( x_0 = 0 )。\n计算初始残差：( r_0 = b - A x_0 = b )。\n初始方向：( p_0 = r_0 )。（第一步直接朝残差方向走）\n\n迭代（每一步）：\n对于 ( i = 1, 2, \\dots )，做以下步骤：\n\n\n计算步长 ( \\alpha_{i-1} )：\n[\n\\alpha_{i-1} = \\frac{r_{i-1}^T r_{i-1}}{p_{i-1}^T A p_{i-1}}.\n]\n\n( r_{i-1}^T r_{i-1} ) 是残差的大小（告诉你还差多远）。\n( p_{i-1}^T A p_{i-1} ) 是方向的“阻力”（矩阵 ( A ) 影响方向的难度）。\n( \\alpha_{i-1} ) 决定你沿 ( p_{i-1} ) 走多远。\n\n\n\n更新解：\n[\nx_i = x_{i-1} + \\alpha_{i-1} p_{i-1}.\n]\n\n\n更新残差：\n[\nr_i = r_{i-1} - \\alpha_{i-1} A p_{i-1}.\n]\n\n这是因为：\n[\nr_i = b - A x_i = b - A (x_{i-1} + \\alpha_{i-1} p_{i-1}) = (b - A x_{i-1}) - \\alpha_{i-1} A p_{i-1} = r_{i-1} - \\alpha_{i-1} A p_{i-1}.\n]\n\n\n\n计算新方向的系数 ( \\beta_i )：\n[\n\\beta_i = \\frac{r_i^T r_i}{r_{i-1}^T r_{i-1}}.\n]\n\n这决定了新方向如何结合当前残差和旧方向。\n\n\n\n更新方向：\n[\np_i = r_i + \\beta_i p_{i-1}.\n]\n\n新方向是当前残差 ( r_i ) 加上一点旧方向 ( p_{i-1} )，确保它和之前的方向 A-正交。\n\n\n\n检查是否到达终点：\n\n如果 ( |r_i| ) 很小（比如小于 ( 10^{-6} )），说明 ( x_i ) 很接近 ( x_* )，可以停止。\n\n\n\n为什么高效？\n\n残差正交：( r_i^T r_j = 0 )（当 ( i \\neq j \\）），残差不会重复。\n方向 A-正交：( p_i^T A p_j = 0 )（当 ( i \\neq j \\）），每一步都在新方向上前进。\n最多 n 步：理论上，n 次迭代（n 是矩阵维度）就能找到精确解。\n\n\n例子：手动算一步\n假设：\n\n( A = \\begin{bmatrix} 4 &amp; 1 \\ 1 &amp; 3 \\end{bmatrix} )，( b = \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} )。\n初始：( x_0 = \\begin{bmatrix} 0 \\ 0 \\end{bmatrix} )，( r_0 = b = \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} )，( p_0 = r_0 ).\n\n第一步：\n\n步长：\n[\nr_0^T r_0 = 1^2 + 2^2 = 5,\n]\n[\np_0^T A p_0 = \\begin{bmatrix} 1 &amp; 2 \\end{bmatrix} \\begin{bmatrix} 4 &amp; 1 \\ 1 &amp; 3 \\end{bmatrix} \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 2 \\end{bmatrix} \\begin{bmatrix} 6 \\ 7 \\end{bmatrix} = 6 + 14 = 20,\n]\n[\n\\alpha_0 = \\frac{5}{20} = 0.25.\n]\n更新解：\n[\nx_1 = x_0 + \\alpha_0 p_0 = \\begin{bmatrix} 0 \\ 0 \\end{bmatrix} + 0.25 \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} = \\begin{bmatrix} 0.25 \\ 0.5 \\end{bmatrix}.\n]\n更新残差：\n[\nr_1 = r_0 - \\alpha_0 A p_0 = \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} - 0.25 \\begin{bmatrix} 4 &amp; 1 \\ 1 &amp; 3 \\end{bmatrix} \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} = \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} - 0.25 \\begin{bmatrix} 6 \\ 7 \\end{bmatrix} = \\begin{bmatrix} -0.5 \\ 0.25 \\end{bmatrix}.\n]\n新方向系数：\n[\nr_1^T r_1 = (-0.5)^2 + (0.25)^2 = 0.25 + 0.0625 = 0.3125,\n]\n[\n\\beta_1 = \\frac{0.3125}{5} = 0.0625.\n]\n新方向：\n[\np_1 = r_1 + \\beta_1 p_0 = \\begin{bmatrix} -0.5 \\ 0.25 \\end{bmatrix} + 0.0625 \\begin{bmatrix} 1 \\ 2 \\end{bmatrix} = \\begin{bmatrix} -0.4375 \\ 0.375 \\end{bmatrix}.\n]\n\n继续迭代，直到 ( r_i ) 很小。\n\n总结\n引理：我们证明了 ( v_i ) 是通过残差 ( r_{i-1} ) 减去与 ( v_{i-1} ) 的 A-投影，再乘以一个步长系数得到的。这确保了每一步的方向都是“新”的（A-正交），而且步伐大小是最优的。\n共轭梯度法：像一个聪明的导航系统，每次选一个新方向（A-正交），走恰当的距离（步长），在 Krylov 子空间里快速接近真解。\n","tags":["其他"]},{"title":"作业2PV题目整理","url":"/notes.github.io/2025/06/23/%E4%BD%9C%E4%B8%9A2PV%E9%A2%98%E7%9B%AE%E6%95%B4%E7%90%86/","content":"以下是整理后的代码，调整了格式、缩进和变量命名以提高可读性（纯文本格式）：\n\n(1) 使用信号量和P、V操作实现\nstruct &#123;    char readerName[10];    int seatNumber;&#125; Seat[100];  // 阅览室座位数组semaphore mutex, availableSeats;int i;mutex = 1;       // 互斥信号量，初始为1availableSeats = 100;  // 空闲座位数，初始为100// 初始化座位for (int i = 0; i &lt; 100; i++) &#123;    Seat[i].seatNumber = i;    Seat[i].readerName = NULL;&#125;cobeginprocess Reader_i(char readerName[]) &#123;  // i = 1, 2, ...    P(availableSeats);  // 申请一个空闲座位    P(mutex);           // 进入临界区    for (int i = 0; i &lt; 100; i++) &#123;        if (Seat[i].readerName == NULL) &#123;            Seat[i].readerName = readerName;            int assignedSeat = Seat[i].seatNumber;  // 读者获得座位号i            break;        &#125;    &#125;    V(mutex);           // 离开临界区    // 读者在阅览室读书...    P(mutex);           // 再次进入临界区    Seat[i].readerName = NULL;  // 释放座位    V(mutex);    V(availableSeats);  // 增加空闲座位数    // 离开阅览室&#125;coend\n\n(2) 使用管程实现\ntype ReadingRoom = MONITOR &#123;    semaphore R;    int waitingReaders, currentReaders, totalSeats;    char seatOccupants[100];  // 记录每个座位的读者名    totalSeats = 0;           // 已占用座位数初始为0    // 管程接口定义    DEFINE enterRoom(), leaveRoom();    USE enter(), leave(), wait(), signal();    // 读者进入阅览室    void enterRoom(char readerName[]) &#123;        enter();        if (totalSeats &gt;= 100) &#123;            wait(R, waitingReaders);  // 无座位则等待        &#125;        totalSeats++;        for (int i = 0; i &lt; 100; i++) &#123;            if (seatOccupants[i] == NULL) &#123;                seatOccupants[i] = readerName;                int assignedSeat = i;  // 读者获得座位号i                break;            &#125;        &#125;        leave();    &#125;    // 读者离开阅览室    void leaveRoom(char readerName[]) &#123;        enter();        totalSeats--;        for (int i = 0; i &lt; 100; i++) &#123;            if (seatOccupants[i] == readerName) &#123;                seatOccupants[i] = NULL;  // 释放座位                break;            &#125;        &#125;        signal(R, waitingReaders);  // 唤醒一个等待的读者        leave();    &#125;&#125;;cobeginprocess Reader_i() &#123;  // i = 1, 2, ...    ReadingRoom.enterRoom(readerName);  // 进入阅览室    // 读书...    ReadingRoom.leaveRoom(readerName);  // 离开阅览室&#125;coend\n以下是整理后的代码，调整了格式、缩进和变量命名以提高可读性（纯文本格式）：\n\n(1) 使用信号量实现黑白子拣选\nsemaphore whiteSem, blackSem;whiteSem = 1;  // 初始可以拣白子blackSem = 0;  // 初始不能拣黑子cobeginprocess WhiteStonePicker() &#123;    while (true) &#123;        P(whiteSem);    // 申请拣白子权限        PickWhiteStone(); // 拣白子操作        V(blackSem);    // 允许拣黑子    &#125;&#125;process BlackStonePicker() &#123;    while (true) &#123;        P(blackSem);    // 申请拣黑子权限        PickBlackStone(); // 拣黑子操作        V(whiteSem);    // 允许拣白子    &#125;&#125;coend\n\n(2) 使用管程实现黑白子拣选\ntype ChessPicker = MONITOR &#123;    bool canPickWhite;  // 当前是否可以拣白子    semaphore blackQueue, whiteQueue;  // 等待队列    int blackWaitCount, whiteWaitCount;  // 等待进程数        InterfaceModule IM;    DEFINE pickBlack, pickWhite;    USE enter, leave, wait, signal;    void pickBlack() &#123;        enter(IM);        if (!canPickWhite) &#123;  // 如果不能拣黑子            wait(blackQueue, blackWaitCount, IM);  // 加入黑子等待队列        &#125;        canPickWhite = true;  // 设置下次可以拣白子        PickBlackStone();     // 拣黑子操作        signal(whiteQueue, whiteWaitCount, IM);  // 唤醒拣白子进程        leave(IM);    &#125;    void pickWhite() &#123;        enter(IM);        if (canPickWhite) &#123;   // 如果不能拣白子            wait(whiteQueue, whiteWaitCount, IM);  // 加入白子等待队列        &#125;        canPickWhite = false;  // 设置下次可以拣黑子        PickWhiteStone();      // 拣白子操作        signal(blackQueue, blackWaitCount, IM);  // 唤醒拣黑子进程        leave(IM);    &#125;&#125;;cobeginprocess BlackPicker() &#123;    while (true) &#123;        ChessPicker.pickBlack();        // 其他操作    &#125;&#125;process WhitePicker() &#123;    while (true) &#123;        ChessPicker.pickWhite();        // 其他操作    &#125;&#125;coend\n以下是整理后的生产者-消费者问题解决方案，包含信号量和管程两种实现方式（纯文本格式）：\n\n(1) 信号量实现（生产者每次生产3个，消费者每次消费1个）\n// 共享缓冲区定义int buffer[9];          // 环形缓冲区int count = 0;          // 当前缓冲区数据量int getPtr = 0;         // 消费者指针int putPtr = 0;         // 生产者指针// 信号量定义semaphore mutexPut = 1;  // 生产者互斥锁semaphore mutexGet = 1;  // 消费者互斥锁semaphore emptySlots = 3; // 可生产空间（初始可生产3个）semaphore filledSlots = 0; // 可消费数据（初始无可消费）main() &#123;    cobegin        producer_i();        consumer_j();    coend&#125;process producer_i() &#123;    while (true) &#123;        // 生产3个整数        int item1, item2, item3 = generateItems();         P(emptySlots);      // 检查是否有至少3个空位        P(mutexPut);        // 获取生产者锁                // 放入缓冲区        buffer[putPtr] = item1;        putPtr = (putPtr + 1) % 9;        buffer[putPtr] = item2;        putPtr = (putPtr + 1) % 9;        buffer[putPtr] = item3;        putPtr = (putPtr + 1) % 9;                V(mutexPut);        // 释放生产者锁        V(filledSlots);     // 增加3个可消费项        V(filledSlots);        V(filledSlots);    &#125;&#125;process consumer_j() &#123;    int consumedItem;    while (true) &#123;        P(filledSlots);     // 检查是否有可消费项        P(mutexGet);        // 获取消费者锁                consumedItem = buffer[getPtr];        getPtr = (getPtr + 1) % 9;        count++;                // 每消费3个释放1次生产权限        if (count == 3) &#123;            count = 0;            V(emptySlots);        &#125;                V(mutexGet);        // 释放消费者锁        processItem(consumedItem); // 消费数据    &#125;&#125;\n\n(2) 管程实现\ntype BufferManager = MONITOR &#123;    int buffer[9];         // 环形缓冲区    int count = 0;         // 当前数据量    int getPtr = 0;        // 消费位置    int putPtr = 0;        // 生产位置        semaphore producerWait, consumerWait;  // 等待队列    int waitingProducers = 0, waitingConsumers = 0;        InterfaceModule IM;    DEFINE putItems, getItem;    USE enter, leave, wait, signal;    procedure putItems(int item1, int item2, int item3) &#123;        enter(IM);        // 如果剩余空间不足3个则等待        if (count &gt; 6) &#123;            wait(producerWait, waitingProducers, IM);        &#125;                // 放入3个数据        buffer[putPtr] = item1;        putPtr = (putPtr + 1) % 9;        buffer[putPtr] = item2;        putPtr = (putPtr + 1) % 9;        buffer[putPtr] = item3;        putPtr = (putPtr + 1) % 9;        count += 3;                // 唤醒可能等待的消费者        signal(consumerWait, waitingConsumers, IM);        signal(consumerWait, waitingConsumers, IM);        signal(consumerWait, waitingConsumers, IM);        leave(IM);    &#125;    procedure getItem(ref int output) &#123;        enter(IM);        // 缓冲区为空则等待        if (count == 0) &#123;            wait(consumerWait, waitingConsumers, IM);        &#125;                output = buffer[getPtr];        getPtr = (getPtr + 1) % 9;        count--;                // 当缓冲区有空闲时唤醒生产者        if (count &lt; 7) &#123;            signal(producerWait, waitingProducers, IM);        &#125;        // 如果还有数据则唤醒其他消费者        else if (count &gt; 0) &#123;            signal(consumerWait, waitingConsumers, IM);        &#125;        leave(IM);    &#125;&#125;;// 进程定义cobeginprocess producer_i() &#123;    while (true) &#123;        int a, b, c = generateItems();        BufferManager.putItems(a, b, c);    &#125;&#125;process consumer_j() &#123;    while (true) &#123;        int data;        BufferManager.getItem(data);        consumeItem(data);    &#125;&#125;coend\n\n(1) 系统处于安全状态，存在安全序列：P0, P3, P4, P1, P2.\n\n\n\nProcess\nCurrent Avail (A,B,C,D)\nCki - Aki (A,B,C,D)\nAllocation (A,B,C,D)\nCurrent Avail + Allocation (A,B,C,D)\nPossible\n\n\n\n\nP0\n1, 6, 2, 2\n0, 0, 1, 2\n0, 0, 3, 2\n1, 6, 5, 4\nTrue\n\n\nP3\n1, 6, 5, 4\n0, 6, 5, 2\n0, 3, 3, 2\n1, 9, 8, 6\nTrue\n\n\nP4\n1, 9, 8, 6\n0, 6, 5, 6\n0, 0, 1, 4\n1, 9, 9, 10\nTrue\n\n\nP1\n1, 9, 9, 10\n1, 7, 5, 0\n1, 0, 0, 0\n2, 9, 9, 10\nTrue\n\n\nP2\n2, 9, 9, 10\n2, 3, 5, 6\n1, 3, 5, 4\n3, 12, 14, 14\nTrue\n\n\n\n(2) 不能分配，系统会处于不安全状态。\n若我执行 P2 发出的 request(1, 2, 2, 2)，Available = (0, 4, 0, 0)，那后续分配就不能继续满足了\n","tags":["其他"]},{"title":"操作系统：第二章复习笔记","url":"/notes.github.io/2025/06/23/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/","content":"PSW\n程序状态字PSW\nPSW既是操作系统的概念，指记录当前程序运行的动态信息，通常包含：\n程序计数器、指令寄存器、条件码\n中断字、中断允许/禁止、中断屏蔽、处理器模式、内存保护、调试控制\nPSW也是计算机系统的寄存器\n通常设置一组控制与状态寄存器\n也可以专设一个PSW寄存器\n标志划分为三组:状态标志、控制标志和系统标志(更多见P58)\n状态标志：使得一条指令的执行结果影响其后指令的执行，比如溢出等标志\n控制指令：控制操作系统行为，比如模式转换等。\n系统标志：与进程管理有关，用于保护模式。\n\n不同架构的实现差异\n​x86：称为标志寄存器（FLAGS）​，包含CF、ZF、OF等标志。\n​ARM：使用CPSR​（当前程序状态寄存器），包含模式位和条件码。\n​单片机（如8051）​：8位PSW，含CY、AC、OV等位。\n\n内核态\n内核态（Kernel Mode）是操作系统内核运行的特权模式，其本质是CPU的一种硬件级权限状态，用于隔离和保护系统核心资源，确保操作系统的安全性和稳定性。\n​特性\t​内核态\t​用户态\n​权限\t可执行所有指令，访问全部资源\t仅限非特权指令，受限内存访问\n​切换触发\t系统调用、异常、硬件中断\t主动请求内核服务（如open()）\n​典型场景\t中断处理、进程调度、驱动交互\t应用程序运行（如浏览器、编辑器）\ntips：内存映射文件：\nmmap()可将文件映射到用户空间，但首次访问会触发缺页异常，由内核加载数据到内存。\n以下三种方式是唯一能触发用户模式-&gt;内核模式的方式\n中断、异常或系统异常等事件导致用户程序向OS内核切换，触发：用户模式-&gt;内核模式，以下三种方式是唯一能触发的方式:\n程序请求操作系统服务，执行系统调用\n程序运行时发生异常(如发生程序性中断，或者目态执行特权指令)\n程序运行时发生并响应中断(一般是I/O中断)\n内核栈\n内核栈是操作系统内核运行时使用的栈空间，用于保存内核函数调用的上下文信息，包括参数、局部变量、返回地址等。每个进程只有一个核心栈\n用户栈运行在用户态（低特权级），而内核栈运行在内核态（高特权级）。硬件栈指针（如x86的ESP）在特权级切换时会自动指向当前进程的内核栈，避免用户程序通过栈操作破坏内核数据。这种隔离是硬件设计的要求。\n硬件栈指针唯一，但每个进程通过操作系统的动态管理拥有逻辑上独立的用户栈和内核栈，实际切换由CPU和内核协作完成\n中断与异常\n中断 vs 异常的本质区别\n特性\t中断（Interrupt）\t异常（Exception）\n触发方式\t异步（由外部硬件设备触发，与CPU当前执行无关）\t同步（由CPU执行指令时触发，如除零、缺页、非法指令）\n来源\t外部硬件（如键盘、网卡、定时器）\tCPU内部（指令执行错误、缺页、系统调用等）\n是否可预测\t不可预测（随机发生）\t可预测（特定指令必然触发）\n2. 处理时的上下文（用户态/内核态）\n上下文\t中断\t异常\n用户态 vs 内核态\t全部在内核态处理（硬件直接触发CPU切换到内核态）\t大部分在内核态，但缺页异常可能发生在用户态（如访问未映射的内存）\n是否需要进程参与\t不依赖当前进程（如磁盘IO完成中断）\t依赖当前进程（如缺页异常、除零错误）\n关键点：\n缺页异常（Page Fault）是唯一可能在用户态触发的异常，因为用户程序访问无效内存时，CPU会先尝试处理（如加载页面），而不是直接杀死进程。\n其他异常（如非法指令）一般直接终止进程或由内核处理。\n\n\n处理逻辑的差异\n处理逻辑\t中断\t异常\n是否与当前进程相关\t通常无关（如定时器中断、外设中断）\t直接相关（如缺页异常影响当前进程的内存访问）\n能否被阻塞\t不能（要求快速响应，不可睡眠）\t可以阻塞（如缺页异常可能触发磁盘IO）\n嵌套性\t允许嵌套（高优先级中断可打断低优先级中断）\t通常单重（异常处理中一般不再触发同类异常）\n\n\n相互打断的关系\n打断关系\t中断\t异常\n能否被中断打断\t可以（高优先级中断可嵌套）\t可以（异常处理中可能被中断插入）\n能否被异常打断\t不能（中断处理时一般关闭异常）\t通常不能（异常处理是同步的，不会自发触发）\n\n\n典型例子\n中断的例子：\n键盘输入、网卡收到数据、硬盘IO完成、定时器中断。\n异常的例子：\n缺页异常（访问未分配的内存）、除零错误、非法指令、系统调用（通过软中断/异常触发）\n中断or异常的触发\n\n中断/异常的触发\n中断：由外部硬件设备（如键盘、网卡、定时器）异步触发。\n\n异常：由CPU执行指令时同步触发（如缺页、除零、非法指令）。\n\n中断/异常响应流程\n(1) 发现中断源，提出请求\n中断：CPU在每个指令周期末尾检查中断引脚（如x86的INTR/NMI），确认是否有硬件中断请求。\n异常：CPU在执行指令时直接检测到错误（如访问非法地址），主动触发异常。\n(2) 检查中断/异常是否被屏蔽\n(3) 优先级仲裁\n(4) 保存现场（上下文切换）\nCPU自动完成以下操作：\n保存PSW（程序状态字）：包括标志寄存器（如EFLAGS）、中断屏蔽状态等。\n保存PC（程序计数器）：即下一条待执行指令的地址。\n切换到内核态：将CPU模式从用户态切换到内核态（通过修改CS段寄存器等）。\n保存其他寄存器：部分架构可能需手动保存通用寄存器（如x86的中断处理程序需保存eax、ecx等）。\n(5) 跳转到处理程序\nCPU根据中断向量表（如x86的IDT）找到对应的中断/异常处理程序地址，并跳转执行。\n中断：调用外设驱动的中断服务例程（ISR）。\n异常：调用内核的异常处理程序（如缺页处理、终止进程等）。\n(6) 处理程序执行\n(7) 恢复现场\n(8) 返回原程序\n\n中断屏蔽与中断优先级\n对比维度\t中断屏蔽\t中断优先级\n定义\t通过软件或硬件手段暂时禁止CPU响应某些中断。\t硬件或软件规定的中断响应顺序，高优先级中断可抢占低优先级。\n核心作用\t选择性关闭中断，确保关键代码不被干扰。\t决定中断处理的顺序，解决多个中断同时发生的竞争问题。\n目的\t避免中断干扰（确保原子性、实时性）。\t协调中断竞争（确定谁先被处理）。\n动态性\t可随时通过软件动态启用/禁用。\t优先级通常静态配置（启动时由硬件/OS设定）。\n影响范围\t全局或部分中断失效。\t仅影响响应顺序，不禁止中断。\nLinux内核处理流程\n用户态进程运行\n│\n├─ 中断触发 → 快中断 → 保存部分寄存器 → 快速处理 → ret_from_intr → 返回用户态\n│               │\n│               └─ 慢中断 → 保存全部寄存器 → 上半部处理 → 调度下半部（do_softirq）\n│                                               │\n├─ 异常触发 → 系统调用 → 保存现场 → 调用sys_call_table → ret_from_sys_call\n│               │                              │\n│               └─ 缺页异常 → 分配内存 → 重试指令\n│\n└─ 返回路径公共部分：\n├─ 检查TIF_NEED_RESCHED → 调用schedule()\n├─ 处理信号（do_signal）\n└─ 恢复用户态（iret）\n上半部 vs 下半部：\n上半部：立即执行（如硬件应答），不可中断。\n下半部：延迟处理（如网络协议栈），可被新中断打断。\n进程的定义\n进程是一个具有一定独立功能的程序关于某个数据集合的一次运行活动\n进程是操作系统进行资源分配和调度的一个独立单位\n一个进程包括五个实体部分，分别是：\n(OS管理运行程序的)数据结构P（就是进程控制块PCB）\n(运行程序的)内存代码C\n(运行程序的)内存数据D\n(运行程序的)通用寄存器信息R\n(OS控制程序执行的)程序状态字信息PSW\n\nPCB内容：​进程标识符（PID）​：唯一标识进程的数字或字符串。\n​进程状态：如运行（running）、就绪（ready）、阻塞（blocked）等。\n​CPU现场信息：通用寄存器、指令计数器（PC）、栈指针（SP）、程序状态字（PSW）等，用于进程切换时恢复执行现场。\n​资源清单：分配的内存、打开的文件、I/O设备等。\n​调度信息：优先级、等待事件（如等待I/O完成）。\n​同步与通信机制：信号量、消息队列等，用于进程间同步和通信。\n\n四种状态转换\n运行态→等待态：等待资源、I/O、信号量\n等待态→就绪态：资源满足、I/O结束、信号量完成\n运行态→就绪态：运行时间片到(倒计时到，不缺少其他东西，只缺少CPU，退回就绪态)、有更高优先权进程，低级调度问题\n以上四个状态转换，一个不能少，一个也不能多，其他的转换不存在的原因如下：\n没有就绪态到等待态:到等待态需要内核参与。\n没有等待态到运行态:等待的资源还没有就绪，无法进入运行态。\n七个状态\n新添加的状态\n新建态:对应于进程被创建的状态，尚未进入就绪队列，创建进程的两个步骤\n为新进程分配所需资源和建立必要的管理信息\n设置进程为就绪态，等待被调度执行\n终止态:\n进程完成认为到达正常结束点\n出现无法克服的错误而异常终止\n操作系统及有终止权的进程所终止时所处的状态，处于终止态的进程不再被调度执行\n下一步就将被系统撤销，最终从系统中消失。\n挂起就绪态:表明进程具备运行条件，但目前在外存中，只有它被对换到内存才能调度执行。\n挂起等待态:表明进程正在等待某一个事件发生且在外存中。\n\n进程挂起的源头\n到目前为止:随着不断创建进程，当系统资源尤其是内存资源已经不能满足进程运行的要求时，必须把某些进程挂起，对换到磁盘对换区中，释放它占有的某些资源，暂时不参与低级调度，起到平滑系统负荷的目的；也可能系统出现故障，需要暂时挂起一些进程，以便故障消除后再接触挂起并恢复进程运行。\n进程挂起的原因是多种多样的。\n解决办法：剥夺某些进程的内存及其他资源，调入OS管理的对换区，不参加进程调度，待适当时候再调入内存、恢复资源、参与运行，这就是进程挂起\n挂起态与等待态有着本质区别\n进程挂起:没有任何资源\n进程等待:占有已申请到的资源处于等待\n\n进程映像到底是个什么玩意\n进程映像是进程在某一时刻的完整快照，包括其代码、数据、状态以及执行环境\n\n\n\n组成部分\n描述\n存储位置\n是否共享\n\n\n\n\n进程控制块（PCB, Process Control Block）\n内核数据结构，存储进程的标识、状态、资源占用、调度信息等（如 task_struct in Linux）。\n内核内存\n否（每个进程独立）\n\n\n进程程序块（Text Segment / Code Segment）\n可执行代码（机器指令），通常是只读的（如程序的 .text 段）。\n内存（代码区）\n是（多个进程可共享同一代码，如 fork() 后的父子进程）\n\n\n进程数据块（Data Segment）\n包含全局变量、静态变量（.data 段）、堆（heap，动态分配内存）、栈（stack，局部变量和函数调用链）。\n内存（数据区）\n否（私有地址空间）\n\n\n进程核心栈（Kernel Stack）\n进程在内核态执行时使用的栈（如系统调用、中断处理），存储函数调用帧、局部变量等。\n内核内存\n否（每个进程独立）\n\n\n环境变量和命令行参数\n进程启动时传递的参数（argv）和环境变量（envp）。\n用户栈附近的内存区域\n否\n\n\n打开的文件描述符表\n记录进程打开的文件、套接字等资源（如 fd_table）。\n内核内存\n否（但子进程可继承）\n\n\n寄存器上下文（Register Context）\n进程被切换时保存的 CPU 寄存器值（如 eax、eip、esp）。\nPCB 或内核栈\n否\n\n\n后面三个不是考试的内容\n\n\n\n\n\n\nPCB内容\n10.2.1. 标识信息\n用于存放唯一标识该进程的信息\n系统分配的标识号\n系统分配的进程组标识号\n用户定义的进程名\n用户定义的进程组名\n10.2.2. 现场信息\n用于存放该进程运行时的处理器现场信息\n用户可见寄存器内容：数据寄存器、地址寄存器\n控制与状态寄存器内容：PC、IR、PSW\n栈指针内容：核心栈与用户栈指针\n10.2.3. 控制信息\n用于存放与管理、调度进程相关的信息\n调度相关信息：状态、等待事件/原因、优先级\n进程组成信息：代码/数据地址、外存映像地址\n队列指引元：进程队列指针、父子兄弟进程指针\n通信相关信息：消息队列、信号量、锁\n进程特权信息：如内存访问权限、处理器特权\n处理器使用信息：占用的处理器、时间片、处理器使用时间/已执行总时间、记账信息\n资源清单信息：如正占有的资源、已使用的资源\nstruct task_struct &#123;    // 标识信息    pid_t pid;                      // 进程ID    pid_t pgrp;                     // 进程组ID    char comm[16];                  // 进程名    // 现场信息    struct pt_regs *thread;         // 寄存器上下文    unsigned long kstack;           // 内核栈指针    // 控制信息    volatile long state;            // 进程状态    int prio;                       // 优先级    struct mm_struct *mm;           // 内存管理（代码/数据地址）    struct files_struct *files;     // 文件描述符表    struct list_head children;      // 子进程链表    u64 utime, stime;               // CPU 时间统计    // ... 其他字段（信号处理、命名空间等）&#125;;\n原语\n原语是由若干条指令构成的完成某种特定功能的程序，执行上具有不可分割性(保证对核心资源的访问是正确的，原语涉及到的资源都是共享核心资源，只能是唯一的)，进入原语区间，立刻关闭中断完成，然后再开中断响应。\n处理器模式切换与上下文状态\n\n用户空间 - 进程上下文\n场景：普通应用程序在用户态运行\n特点：\n资源访问：受限，不能执行特权指令\n调度：可以被抢占或主动让出CP\n内核空间 - 进程上下文\n场景：内核代表某个进程在内核态执行（如处理系统调用）\n特点：\n特权级别：运行在内核态（Ring 0/x86）\n内存访问：可以访问全部内存空间\n栈使用：使用核心栈（每个进程有独立的内核栈）\n关联性：与特定进程关联，可以访问进程的task_struct\n可调度性：可以被抢占（现代内核支持内核态抢占）\n典型情况：系统调用执行、某些类型的异常处理\n内核空间 - 中断上下文\n场景：硬件中断触发的中断服务例程(ISR)执行\n特点：\n触发方式：由硬件中断异步触发\n关联性：不与任何特定进程关联\n栈使用：可能使用中断栈或当前进程的内核栈（架构依赖）\n限制：\n不能睡眠或调用可能引起调度的函数\n不能访问用户空间内存\n应该尽快完成处理\n典型情况：硬件中断处理（网络包到达、磁盘IO完成等）\n内核线程\n场景：纯内核线程的执行（如kswapd、kworker等）\n特点：\n特权级别：内核态\n内存访问：只有内核空间，没有用户空间映射\n栈使用：使用独立的内核栈\n调度：像普通进程一样被调度\n用途：执行后台维护任务，可以执行需要睡眠的操作\n实际例子\n用户进程调用read()：\n\n开始：用户态进程上下文\n执行syscall指令→切换到内核进程上下文\n可能需要等待磁盘→进程睡眠\n磁盘中断到达→中断上下文处理\n中断处理完成后唤醒进程→回到内核进程上下文\n系统调用返回→回到用户进程上下文\n内存回收：\nkswapd内核线程（内核线程上下文）定期运行\n当内存不足时触发缺页异常→进入内核进程上下文\n可能需要从磁盘换入页面→发送IO请求\n磁盘中断到达→中断上下文处理完成IO\n唤醒等待进程\n\n自问：linux中task_struct里面都有什么？尽量完整的给出？他是如何区分进程和线程的？\n​1. 进程/线程标识\n​pid_t pid：进程 ID（唯一标识）。\n​pid_t tgid：线程组 ID（同一进程的线程共享 tgid，主线程的 pid == tgid）。\n​struct task_struct group_leader：线程组的领头线程（主线程）。\n​struct list_head thread_group*：同一线程组的所有线程链表。\n​2. 进程状态\n​volatile long state：进程状态，取值包括：\nTASK_RUNNING（运行/就绪）\nTASK_INTERRUPTIBLE（可中断睡眠）\nTASK_UNINTERRUPTIBLE（不可中断睡眠）\nTASK_STOPPED（暂停）\nEXIT_ZOMBIE（僵尸状态）。\n​3. 调度信息\n​int prio, static_prio, normal_prio：优先级（静态、动态）。\n​unsigned int rt_priority：实时进程优先级。\n​struct sched_entity se：CFS 调度实体（时间片、权重等）。\n​struct sched_class sched_class：调度策略（SCHED_FIFO、SCHED_RR、SCHED_OTHER）。\n​4. 内存管理\n​struct mm_struct mm：进程内存描述符（代码段、堆栈、页表等）。\n​struct mm_struct active_mm：活跃内存（内核线程可能借用用户进程的 mm）。\n​unsigned long stack*：内核栈指针。\n​5. 文件系统\n​struct files_struct files：打开的文件描述符表。\n​struct fs_struct fs：文件系统信息（如当前工作目录）。\n​6. 信号处理\n​struct signal_struct signal：信号描述符。\n​sigset_t blocked*：阻塞的信号掩码。\n​struct sigpending pending：待处理的信号队列。\n​7. 进程关系\n​struct task_struct parent：父进程。\n​struct list_head children*：子进程链表。\n​struct list_head sibling：兄弟进程链表。\n​8. 其他关键字段\n​struct thread_struct thread：CPU 寄存器状态（上下文切换时保存）。\n​struct exec_domain exec_domain：可执行文件格式（如 ELF）。\n​struct ptrace_context ptrace：调试跟踪信息。\n​如何区分进程和线程？\nLinux 内核不严格区分进程和线程，均用 task_struct 表示，区别在于资源共享方式：\n​进程：\n独立的 mm_struct（内存空间）。\n独立的 files_struct（文件描述符）。\n独立的 signal_struct（信号处理）。\n通过 fork() 创建，默认不共享资源。\n​线程：\n共享父进程的 mm_struct、files_struct、signal_struct。\n通过 clone() 创建，指定标志如 CLONE_VM（共享内存）、CLONE_FILES（共享文件）。\n同一线程组的线程 tgid 相同。\n线程共享的和独立的资源\n线程共享的资源\n同一进程中的所有线程完全共享以下资源：\n\n内存地址空间（代码段、数据段、堆、共享库等）\n\n一个线程修改全局变量会立即影响其他线程\n动态分配的内存(malloc/new)对所有线程可见\n\n\n文件描述符表\n\n一个线程打开的文件其他线程可以直接使用\n\n\n信号处理程序\n\n信号处理函数是进程级别的设置\n\n\n进程属性\n\n用户ID、组ID、工作目录等\n\n\n\n线程独立的资源\n1. 线程执行状态\n2. 线程上下文（保护现场）\n3. 独立的程序计数器（PC）\n4. 执行堆栈\n5. 静态存储区的局部变量\n  static __thread int tls_var;  // 每个线程有独立副本\n\n不同于普通的静态变量（所有线程共享）\n\n6. 线程控制块(TCB)\n实际内存布局示例\n进程地址空间├── 代码段 (所有线程共享)├── 数据段 (全局变量，共享)├── 堆 (动态分配内存，共享)├── 共享库 (共享)├── 线程1栈 (私有)├── 线程2栈 (私有)├── ...└── 线程局部存储区 (TLS，每个线程有独立副本)\n辨析：在单线程进程中：进程栈就是线程栈，两者是同一个栈结构\n在多线程进程中：主线程的栈就是传统意义上的&quot;进程栈&quot;，其他线程有自己的独立栈\n在Linux中：\n主线程栈通常位于地址空间的高地址区域（如x86_64上约在0x7ffffffff000）\n新线程栈通过mmap()分配（默认约8MB，含保护页）\n注意：内核级线程是内核调度的基本单元，因此同一进程的多个线程可被分配到不同CPU核心并行执行。\n维度\t进程（资源）\t线程（执行）\n管理内容\t内存、文件、权限等静态资源\tCPU时间片、执行状态等动态资源\n操作者\t内核资源管理器\t内核调度器\n共享性\t进程间资源默认隔离\t同一进程的线程共享所有资源\n您提到的这些线程操作实际上是传统操作系统理论中对线程状态转换的抽象描述，可能来自教材或特定系统的术语。下面我将结合现代操作系统的通用实现，为您逐一解释这些操作的含义及其与线程状态的关系：\n线程操作与状态转换对应关系\n\n\n\n操作\n触发动作\n状态变化\n现代系统对应操作\n\n\n\n\n孵化\n创建新线程\n无→就绪\npthread_create()\n\n\n封锁\n线程主动/被动停止执行\n运行→等待（阻塞）\npthread_mutex_lock()/read()\n\n\n活化\n唤醒被阻塞的线程\n等待→就绪\npthread_cond_signal()\n\n\n剥夺\n强制收回线程CPU使用权\n运行→就绪\n时间片耗尽（内核调度）\n\n\n指派\n分配CPU给线程\n就绪→运行\n内核调度器选择线程\n\n\n结束\n线程执行完毕或被终止\n运行/等待→终止\npthread_exit()\n\n\n\n\n\n为何没有“挂起”：\n挂起（Suspend）通常涉及将线程/进程资源换出内存（与存储设备交互），属于资源管理范畴。线程作为执行单位，其状态仅描述CPU调度行为，故不包含挂起。\n\n\n现代系统的差异：\n\n术语差异：现代POSIX线程库可能不使用这些传统术语，但底层原理一致。\n扩展状态：实际系统可能有更细的状态（如TASK_INTERRUPTIBLE）。\n\n\n\n用户级线程的特殊性：\n若线程在用户空间管理（如协程），则“剥夺”“指派”由用户态调度器完成，不经过内核。\n\n\nKLT与ULT\n内核级线程和用户级线程的本质区别\n\n管理主体不同：内核级线程由操作系统直接管理，用户级线程由用户态线程库管理。\n调度方式不同：内核级线程可被独立调度（支持多核并行），用户级线程由进程统一调度（阻塞会影响整个进程）。\n性能开销不同：内核级线程切换需内核介入（开销大），用户级线程切换在用户态完成（高效但无法跨核）。\n\nLinux选择1:1模型的核心逻辑是：\n用内核的复杂性换取开发者/硬件的效率最大化。这种设计使得从嵌入式设备到超级计算机都能获得一致的线程语义，同时避免M:N模型的调试噩梦——“幽灵式卡顿”（即用户态与内核态调度器视图不一致导致的问题）。\n用户态线程是轻量级线程（仍依赖OS），协程是用户态更彻底的轻量化并发（完全自主调度）。\n内核级线程 KLT, Kernel-Level Threads\n线程管理的所有工作由OS内核来做，并提供了一个应用程序设计接口API，供开发者使用KLT，\n创建时：内核为其创建进程和一个基线程，线程实行过程中通过内核的创建线程原语来创建其他线程。\nOS直接调度KLT，KLT用于解决物理并行性问题，内核可以感知到所有的内核级线程，可以控制器其数据结构，内核调度在线程的基础上进行。\n用户级线程ULT, User-Level Threads\n用户空间运行的线程库，提供多线程应用程序的开发和运行支撑环境。任何应用程序均需通过线程库进行程序设计，再与线程库连接后运行\n线程管理的所有工作都由应用程序完成，内核没有感知到线程的存在，内核感知到的单位是进程。\nKLT的三态模型，由系统调度负责\nULT的三态模型，由用户调度负责\n活跃态的ULT代表绑定KLT的三态\n\n当ULT处于 ​活跃态 时，意味着它 ​绑定到了一个KLT，此时该ULT的状态 ​完全由KLT的状态决定：\n若KLT被内核调度为 ​运行态 → ULT表现为“正在执行”。\n若KLT被内核置为 ​阻塞态​（如发起阻塞式系统调用）→ 绑定的ULT也被迫阻塞（即使ULT本身未调用阻塞操作）。\n活跃态的ULT运行时可激活用户调度，非阻塞系统调用可使用Jacketing启动用户调度，调整活跃态ULT\n\nlinux pthread混合模型\n为什么说它是混合模型？\n特性\t用户级线程(ULT)特点\t内核级线程(KLT)特点\tLinux pthread实现\n线程创建/销毁\t完全在用户空间\t需要内核介入\t用户API+内核支持\n调度实体\t内核只看到进程\t内核看到每个线程\t内核看到每个线程\n上下文切换\t用户空间完成\t内核完成\t内核完成\n多核并行\t难以实现\t天然支持\t完全支持\n阻塞影响\t整个进程阻塞\t仅阻塞单个线程\t仅阻塞单个线程\n线程局部存储\t用户库实现\t需要内核支持\t两者协作实现\n自问：进程间通信方式AND线程\n进程间通信方式性能对比与数据验证\n以下是主要进程间通信(IPC)方式的性能对比，基于实际测试和文献数据，并补充了共享内存等更多通信途径的详细信息。\n进程间通信方式性能对比表\n当然！我会帮你在原有的表格中加入“文件映射”这一项，并提供对应的详细信息。\n\n\n\n\n通信方式\n数据传递路径\n典型延迟\n带宽\n适用场景\n\n\n\n\n线程共享内存\n直接CPU缓存访问\n10-100 ns\n10-100 GB/s\n同一进程内线程间通信\n\n\n进程共享内存\n内存映射文件/区域 → 用户态\n100-500 ns\n1-10 GB/s\n需要高频数据交换的进程间通信\n\n\n管道(pipe)\n内核缓冲区拷贝 → 用户态\n1-10 μs\n100-500 MB/s\n父子进程间顺序通信\n\n\n命名管道(FIFO)\n内核缓冲区拷贝 → 用户态\n2-15 μs\n100-500 MB/s\n任意进程间顺序通信\n\n\n消息队列\n内核内存分配 + 两次拷贝\n10-50 μs\n50-200 MB/s\n结构化消息传递\n\n\nUnix域套接字\n内核缓冲区拷贝 → 用户态\n5-20 μs\n200-800 MB/s\n本地高性能IPC\n\n\nTCP套接字\n网络协议栈处理 → 内核缓冲区 → 用户态\n50-200 μs\n10-100 MB/s\n跨网络通信\n\n\n信号\n内核信号队列 → 用户态信号处理\n1-10 μs\n-\n简单事件通知\n\n\n文件映射（mmap）\n文件在磁盘存储 → 内存映射区域（用户态）映射到虚拟地址空间\n100-500 ns\n1-10 GB/s\n大文件访问、频繁读写、跨进程共享\n\n\n\n\n“文件映射（mmap）”\n映射过程：\n进程请求将文件映射到其虚拟地址空间（调用mmap()）。\n操作系统在虚拟地址空间中为这块区域建立映射关系，标记为“已映射”。\n数据访问：\n进程直接访问映射区域，就像访问普通内存一样。\n读取或修改映射区域中的数据，实际上是在操作内存缓存（页缓存）中的内容。\n数据同步：\n当进程修改映射区域中的数据时，操作系统会在后台将更改同步到磁盘上的文件（如果映射是可写的）。\n反之，文件内容也会在磁盘上更新。\n数据传递路径总结：\n用户空间内存（映射区域）&lt;→（由操作系统管理）&lt;→ 磁盘文件**\n这里没有显式的“拷贝”操作（除初始化映射时），是直接访问文件的内容。\n与进程共享内存对比\n\n\n\n方面\n文件映射（mmap）\n共享内存\n\n\n\n\n依赖\n磁盘I/O，页缓存\n纯内存，无磁盘依赖\n\n\n延迟\n较高（页面缺失，磁盘访问）\n低（直接内存访问）\n\n\n操作复杂性\n依赖操作系统的页管理和同步策略\n直接内存操作，简单快速\n\n\n适用场景\n大文件访问、需要持久化的共享数据\n高频率、低延迟的进程间通信\n\n\n\n\n1. 线程共享内存\n\n由于它们属于同一进程，多个线程可以直接读取和写入相同的内存地址。\nCPU的缓存（如L1、L2、L3）也会帮助加快访问速度。\n不需要经过操作系统或内核的中转，几乎是“直接”访问。\n\n2. 进程共享内存\n数据传递路径：\n\n通过内存映射文件或区域（比如mmap）映射到两个进程的用户空间内存中。\n进程可以直接读写这块共享内存区域。\n详细说明：\n操作系统创建一块共享内存区域，并映射到两个或多个进程的虚拟地址空间中。\n进程通过访问自己的虚拟地址，间接地读写共享内存。\n这里没有数据在内核和用户空间之间复制，除了初始化映射时。\n\n3. 管道(pipe)\n数据传递路径：\n\n一个进程将数据写入内核缓冲区（由内核管理）。\n另一个进程从这个缓冲区读取数据。\n\n详细说明：\n\n写入方将数据写入管道的内核缓冲区（拷贝操作：用户空间→内核空间）。\n读取方从缓冲区读取数据（拷贝：内核空间→用户空间）。\n这是内核缓冲区扮演中介角色。\n\n4. 命名管道（FIFOs）\n数据传递路径：\n\n类似普通管道，但可以在任意两个进程之间（不一定父子关系）。\n数据写入到内核缓冲区，然后由另一端读取。\n\n详细说明：\n\n进程A写入数据到FIFO的内核缓冲区（用户空间→内核空间拷贝）。\n进程B从缓冲区读取数据（内核空间→用户空间拷贝）。\n这种方式允许不同进程之间通信。\n\n5. 消息队列\n数据传递路径：\n\n由内核管理一块特殊的内存区域，用于存储消息。\n进程将消息放入队列（两次拷贝：用户空间→内核空间，内核空间→用户空间），\n其他进程从队列中取出消息。\n结构化消息传递，适合传递有格式的数据。\n\n6. Unix域套接字\n数据传递路径：\n\n通过内核缓冲区传输数据。\n数据从发送端的用户空间拷贝到内核缓冲区，\n接收端再从内核缓冲区拷贝到用户空间。\n\n7. TCP套接字\n数据传递路径：\n\n经过网络协议栈处理（TCP/IP协议）\n数据从用户空间拷贝到内核缓冲区，\n经过网络传输到远端，\n另一端的内核缓冲区再拷贝到远端用户空间。\n数据在用户空间和内核空间之间有多次拷贝，网络传输有一定延迟。\n\n8. 信号\n数据传递路径：\n\n内核将信号放入信号队列（由内核管理），\n用户空间的信号处理程序在适当时被调用。\n\n详细说明：\n\n信号是一种异步事件通知机制。\n内核通知进程某个事件发生（如中断、定时器），通过信号队列。\n用户程序在信号处理函数中响应。\n\nJacketing技术\n把阻塞式系统调用改造成非阻塞式的:解决一个ULT的阻塞导致整个进程阻塞，避免进程因此从运行态→阻塞态，如此的频繁切换会带来比较大的开销。\n当线程陷入系统调用时，执行Jacketing程序。\n由Jacketing程序来检查资源使用情况，以决定是否执行进程切换或传递控制权给另一个线程\nJacketing 技术通过用户态拦截系统调用，模拟非阻塞行为（如立即返回 EAGAIN），并在后台异步检查资源就绪后补发真实调用，从而避免线程阻塞和进程切换的开销。其核心是用户态欺骗 + 异步轮询 + 延迟执行，实现阻塞操作的非阻塞化。\n自问：java线程池\nJava线程池通过复用内核级线程（KLT）和任务队列协调逻辑与物理并行性：\n\n物理并行性：固定数量的KLT（如newFixedThreadPool(4)）直接执行任务，匹配CPU核心数以最大化计算加速（如矩阵运算）。\n逻辑并行性：超额任务（如10万HTTP请求）暂存于阻塞队列（如LinkedBlockingQueue），由KLT异步处理，实现高并发。\n动态调节：参数corePoolSize（常驻KLT）、maxPoolSize（突发扩容）和workQueue（队列容量）平衡资源开销与吞吐量。例如，newWorkStealingPool()基于ForkJoin框架自动优化并行任务调度。\n\n优势：避免线程频繁创建/销毁的开销，通过队列解耦任务提交与执行，同时支持计算密集型（物理并行）和IO密集型（逻辑并发）场景。\nI/O密集型任务（HTTP请求多数时间在等待网络响应）\n线程阻塞时，线程池会自动调度其他任务\n处理器调度\n\n\n\nFCFS (先来先服务) 非抢占\nRR (时间片轮转) 抢占\nSPN (最短进程优先) 非抢占，真正操作系统没有办法使用\nSRT (最短剩余时间优先) 抢占，真正操作系统没有办法使用\nHRRF (最高响应比优先) 非抢占，真正操作系统没有办法使用\nFeedback (多级反馈调度) 抢占\n\nSPN是一种非抢占式调度，会选择处理时间最短的进程，短进程将会越过长进程，优先获得调度，又称为SJF\n问题:\n需要预知作业所需的CPU运行时间\n忽略了作业的等待时间：只要持续不断地提供更短的进程，长进程就有可能饿死，同样也会服务不到。\n分时、实时处理仍然不理想。\nSRT，Shortest Remaining Time，最短剩余时间优先\nSRT是一种抢占式调度，调度器总是选择预期剩余时间更短的进程\n当一个新进程加入就绪队列，他可能比当前运行的进程具有更短的剩余时间，只要新进程进入就绪队列，调度器就可能抢占当前正在运行的进程\n\nRR(时间片轮转调度算法)\n本质也是先来先服务，但是要按照时间片来进行调度\n\n\n\n\n\n\n\n","tags":["操作系统往年卷"]},{"title":"文件管理笔记","url":"/notes.github.io/2025/06/23/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E7%AC%94%E8%AE%B0/","content":"用户打开文件表、系统打开文件表和主存活动inode表的作用及其相互关系：\n\n1. 用户打开文件表（文件描述符表）\n\n位置：位于每个进程的PCB（进程控制块）中，是一个名为files_struct的结构。\n作用：\n\n每个进程独立维护自己的打开文件列表，通过**文件描述符（fd）**来索引。\nfd是一个整数（如0、1、2分别对应标准输入、输出、错误），是进程访问文件的句柄。\n\n\n表项内容：\n\n每个表项存储一个指针（fp），指向系统打开文件表中的某个表项（file结构）。\n\n\n特点：\n\n进程通过fd操作文件时，内核会通过fp找到系统级文件信息。\n不同进程的fd可能指向同一个系统打开文件表项（例如父子进程继承文件描述符）。\n\n\n\n\n2. 系统打开文件表（file_struct）\n\n位置：内核内存区，全局共享，最多256项（具体数量取决于内核配置）。\n作用：\n\n解决多进程共享文件或同一文件被多次打开的问题。\n每次打开文件（即使同一文件）会创建一个独立的file结构，记录当前操作的上下文。\n\n\n表项内容：\n\n文件当前偏移量（读写位置）。\n文件访问模式（读、写、追加等）。\n指向主存活动inode的指针。\n\n\n关键特性：\n\n多file对应一个inode：同一文件被多次打开时，每个file有自己的偏移量，但共享同一个inode。\n父子进程共享：子进程继承父进程的file结构，共享偏移量（除非显式调用dup或fork后独立操作）。\n\n\n\n\n3. 主存活动inode表\n\n位置：内核内存区，缓存频繁访问的磁盘inode。\n作用：\n\n避免每次文件操作都从磁盘读取inode，提升性能。\n维护文件的元数据（如权限、大小、磁盘块位置等）。\n\n\n表项内容：\n\n磁盘inode的完整信息（如UID、GID、大小、时间戳等）。\n文件数据块的磁盘地址。\n引用计数（被多少个file结构引用）。\n\n\n关键特性：\n\n动态加载：当文件被打开时，其inode从磁盘调入内存；引用计数为0时可能被回收。\n共享与同步：多个file可能指向同一个inode，修改inode会反映到所有关联的file（如文件大小变化）。\n\n\n\n\n三者的协作流程\n\n\n进程打开文件：\n\n内核在主存活动inode表中查找或加载文件的inode。\n创建系统打开文件表项（file结构），初始化偏移量等，并指向inode。\n在进程的用户打开文件表中分配一个fd，指向对应的file结构。\n\n\n\n进程读写文件：\n\n通过fd找到file结构，获取当前偏移量。\n通过file找到inode，进而定位磁盘数据块。\n更新file中的偏移量（除非是O_APPEND模式，此时直接同步inode中的文件大小）。\n\n\n\n文件关闭：\n\n释放fd，减少file和inode的引用计数。\n若inode引用计数为0，可能写回磁盘并释放内存。\n\n\n\n\n以下是文件创建过程 create(&quot;path&quot;, 0775) 的详细步骤解析，结合文件系统的磁盘和内存结构：\n\n1. 目录检索与inode分配\n\n目录检索：\n\n内核解析路径&quot;path&quot;，逐级查找目录项（如/ → path），确认父目录存在且用户有写权限。\n检查path下是否已存在同名文件，若存在则可能报错（除非指定覆盖）。\n\n\n分配磁盘inode：\n\n从磁盘的空闲inode位图中找到一个未使用的inode编号（假设为inode_num）。\n在磁盘的inode表中初始化该inode的元数据（如i_mode=0775、i_nlink=1、i_size=0等）。\n\n\n更新目录：\n\n在父目录的数据块中添加新目录项，格式为：（文件名：newfile, inode编号：inode_num）。\n\n\n\n\n2. 主存活动inode表初始化\n\n加载inode到内存：\n\n将磁盘上刚分配的inode_num对应的inode读入主存活动inode表。\n初始化内存中的inode结构：i_mode = 0775;     // 文件权限：rwxrwxr-xi_nlink = 1;       // 初始链接数（仅当前目录项引用）i_uid = 调用进程UID; // 文件所有者i_gid = 调用进程GID; // 文件所属组i_size = 0;        // 初始文件大小为0i_blocks = 0;      // 尚未分配磁盘块\n\n\n\n引用计数：活动inode的引用计数置为1（被即将创建的file结构引用）。\n\n\n3. 系统打开文件表（file_struct）初始化\n\n分配file结构：\n\n在全局的系统打开文件表中分配一个空闲表项（struct file）。\n初始化关键字段：f_mode = O_WRONLY | O_CREAT; // 以写方式创建f_offset = 0;                // 初始读写位置为文件开头f_flags = 写特征位;           // 标记为可写f_inode = 活动inode的指针;    // 指向内存中的inodef_count = 1;                 // 引用计数（被用户打开文件表引用）\n\n\n\n\n\n4. 用户打开文件表（文件描述符表）关联\n\n分配文件描述符（fd）：\n\n在调用进程的files_struct（用户打开文件表）中找到一个最小空闲序号（如fd=3）。\n将该表项的指针指向刚创建的系统打开文件表项（file结构）。\n\n\n返回fd：\n\n将fd（如3）返回给用户进程，后续通过fd操作文件。\n\n\n\n\n5. 指针连接关系\n最终数据结构间的关联如下：\n进程PCB → files_struct[fd] → file_struct → 活动inode → 磁盘inode\n\n用户层：通过fd（如3）读写文件。\n内核层：通过file结构管理当前打开实例的偏移量，通过inode管理文件元数据。\n\n\n示例流程\n用户调用create(&quot;dir/newfile&quot;, 0775)：\n\n检查dir是否存在，权限合法。\n分配磁盘inode（假设inode_num=100），初始化磁盘inode。\n在dir的目录数据块中添加条目：(&quot;newfile&quot;, 100)。\n内存中加载inode 100，设置权限、链接数等。\n创建file结构，关联inode，返回fd=3给进程。\n\nf_count 和 i_count\n\n1. f_count（文件表项引用计数）\n\n位置：\nf_count 位于 系统打开文件表（File Table）的表项 中。\n\n系统打开文件表是一个内核全局数据结构，每个表项（struct file）包含：struct file &#123;    mode_t f_mode;      // 文件访问模式    loff_t f_pos;       // 当前读写偏移（f_offset）    atomic_t f_count;   // 引用计数（f_count）    struct inode *f_inode; // 指向对应的 inode    // 其他字段...&#125;;\n\n\n\n作用：\n记录有多少个 用户打开文件表项（即进程的文件描述符） 引用了该系统打开文件表项。\n\n当进程通过 dup()、fork() 或多次 open() 同一个文件时，多个文件描述符可能共享同一个系统打开文件表项，此时 f_count 会递增。\n关闭文件时，f_count 减 1；若变为 0，则释放该系统打开文件表项。\n\n\n\n\n2. i_count（活动 inode 引用计数）\n\n位置：\ni_count 位于 内存中的活动 inode（VFS inode） 中（struct inode）。\n\n活动 inode 是内核为已打开文件维护的运行时数据结构，与磁盘上的静态 inode 分离：struct inode &#123;    atomic_t i_count;    // 引用计数（i_count）    unsigned long i_nlink; // 磁盘 inode 的硬链接数    struct super_block *i_sb; // 所属文件系统    // 其他字段...&#125;;\n\n\n\n作用：\n记录有多少个 系统打开文件表项 或 内核其他模块 引用了该活动 inode。\n\n当不同进程通过不同路径（不同 open() 调用）访问同一文件时，每个 open() 会创建独立的系统打开文件表项，但这些表项指向同一个活动 inode，此时 i_count 递增。\n关闭文件时，i_count 减 1；若变为 0，则将内存中的活动 inode 写回磁盘（若脏）并释放。\n\n\n\n\n关键区别\n\n\n\n计数器\n存储位置\n作用场景\n\n\n\n\nf_count\n系统打开文件表（struct file）\n跟踪共享同一个 文件偏移和状态 的进程（如 fork() 或 dup() 产生的共享）。\n\n\ni_count\n内存中的活动 inode（struct inode）\n跟踪共享同一个 文件数据 的进程（如不同进程独立调用 open() 同一个文件）。\n\n\n\n\n示例场景\n\n\nf_count &gt; 1：\n进程 A 和 B 通过 fork() 共享同一个文件描述符，它们会共用同一个系统打开文件表项（f_count=2），读写偏移同步变化。\n\n\ni_count &gt; 1：\n进程 A 和 B 分别调用 open(&quot;/tmp/file&quot;)，生成两个独立的系统打开文件表项（f_count=1 每个），但指向同一个活动 inode（i_count=2），读写偏移独立。\n\n\n\n重点：为什么不在磁盘 inode 中？\n\n磁盘上的 inode 是静态的，仅记录文件的持久属性（如权限、大小、数据块位置等）。\ni_count 和 f_count 是运行时动态共享的临时状态，由内核在内存中管理，无需持久化到磁盘。\n\n你提到的教材内容涉及文件系统的挂载（Mounting）和硬链接（Hard Link）的限制，这是操作系统管理多磁盘/分区时的重要机制。下面我会逐步拆解这段话的含义，并用实例说明。\n\n1. 单磁盘 vs 多磁盘的文件目录树\n(1) Windows 风格（多棵目录树）\n\n盘符分配：每个物理磁盘或分区被分配一个盘符（如 C:\\、D:\\），形成独立的目录树。\n\n例如：\n\nC:\\Users\\file.txt 和 D:\\Data\\file.txt 是两棵完全独立的目录树。\n\n\n特点：\n\n不同磁盘的文件路径通过盘符区分，inode 号只需在各自磁盘内唯一。\n跨磁盘访问文件需明确指定盘符（如 D:\\Data\\file.txt）。\n\n\n\n\n\n(2) UNIX/Linux 风格（单棵目录树）\n\n挂载（Mounting）：所有磁盘/分区通过挂载到根目录（/）下的某个子目录，整合成一棵统一的目录树。\n\n例如：\n\n根文件系统挂载在 /，另一个磁盘挂载到 /mnt/disk2。\n文件路径可能是 /home/user/file.txt（根磁盘）和 /mnt/disk2/file.txt（另一磁盘）。\n\n\n特点：\n\n用户看到的是单一的目录树，无需关心文件实际在哪个磁盘。\n不同磁盘的 inode 号可能重复（因为各自文件系统独立管理 inode）。\n\n\n\n\n\n\n2. Inode 的唯一性问题\n\nInode 的本质：\n\nInode 是文件系统内部的元数据结构，用于标识文件（存储权限、大小、数据块位置等）。\nInode 号仅在同一个文件系统内唯一。\n\n\n多磁盘/分区的冲突：\n\n磁盘A 和 磁盘B 可能同时存在 inode 号为 100 的文件，但这两个文件完全不同。\n当挂载后整合成一棵目录树时，系统如何区分这两个 inode 100？\n\n\n\n解决方案：\n\n文件系统挂载隔离：\n\n内核会记录每个挂载点的文件系统信息（如设备ID）。\n访问文件时，内核不仅检查 inode 号，还会确认其所属的文件系统。\n\n例如：\n\n/home/file（inode 100，设备ID 1）\n/mnt/disk2/file（inode 100，设备ID 2）\n系统通过设备ID + inode 号唯一标识文件。\n\n\n\n\n\n\n\n\n3. 为什么禁止跨文件系统的硬链接？\n(1) 硬链接的实现原理\n\n硬链接本质是多个目录项指向同一个 inode。\n\n例如：\n\n创建硬链接：ln /disk1/file /disk2/link。\n此时 /disk1/file 和 /disk2/link 的目录项会指向相同的 inode。\n\n\n\n\n硬链接的限制：\n\n硬链接必须与目标文件在同一个文件系统内（即相同的设备ID）。\n因为不同文件系统的 inode 号可能重复，无法跨文件系统唯一标识文件。\n\n\n\n(2) 跨文件系统的后果\n\n假设允许跨文件系统硬链接：\n\nln /disk1/file /disk2/link（disk1 和 disk2 是不同的文件系统）。\n若 disk1 的 inode 100 和 disk2 的 inode 100 冲突，系统无法区分该链接指向哪个文件。\n文件系统卸载时，硬链接可能指向无效数据。\n\n\n\n(3) 替代方案：软链接（符号链接）\n\n软链接是一个独立文件，存储目标文件的路径（而非 inode）。\n\n例如：\n\nln -s /disk1/file /disk2/link（允许跨文件系统）。\n\n\n特点：\n\n可以跨文件系统。\n若目标文件被删除，软链接会失效（“悬空链接”）。\n\n\n\n\n\n成组链接法\n成组链接法是一种高效管理磁盘空闲块的方法，结合了分组和链表的思想，通过减少磁盘I/O操作提升性能。以下是其分配和归还算法的详细解释：\n成组链接法的核心结构\n\n分组管理：空闲块被划分为多个组，每组包含若干空闲块及指向下一组的指针。\n超级块：驻留在内存中，记录当前组的信息，包括空闲块数量、下一组指针及当前组的空闲块列表。初始时加载第一个组的信息。\n\n分配算法\n\n检查当前组：若超级块中空闲块数量 &gt; 0，直接分配一个块（通常从列表末尾取出），并减少空闲块计数。\n组耗尽处理：若当前组空闲块计数减至0：\n\n读取当前组指向的下一组的头信息（通过下一组指针）。\n将下一组的信息加载到超级块中，更新空闲块列表和指针。\n若无下一组（指针为空），表明无空闲块可分配，返回错误。\n\n\n\n示例：\n\n当前组有100个块，分配第100个块后计数为0。\n将下一组（如块200）的信息加载到超级块，后续分配从新组继续。\n\n归还算法\n\n直接归还：若当前组未满（空闲块数 &lt; 组大小上限），将释放的块加入空闲列表，计数加1。\n组已满处理：若当前组已满：\n\n将超级块当前信息（计数、下一组指针、空闲列表）写入待释放块。\n更新超级块：下一组指针指向该释放块，空闲列表重置为仅含此块，计数设为1。\n\n\n\n示例：\n\n当前组已满100块，释放块300。\n将当前组信息存入块300，超级块指向块300，空闲列表为[300]，计数为1。\n\n优势与特点\n\n减少I/O操作：通过内存中的超级块批量处理，仅在组切换时访问磁盘。\n高效链表管理：通过分组形成链式结构，避免遍历长链表。\n动态扩展：释放时自动生成新组，适应空间变化。\n\n关键细节\n\n组头结构：每个组的首个块存储下一组指针、本组空闲块数及空闲块列表。\n超级块作用：作为缓存，加速分配和释放操作。\n\n总结\n成组链接法通过分组和链表的结合，优化了空闲块管理。分配时优先使用当前组，耗尽后切换；归还时若组满则创建新组。这种设计显著降低了磁盘访问频率，提升了存储管理效率。\n\n理解你的问题！你描述的流程是文件访问中从用户态系统调用到物理I/O操作的完整操作系统处理链条，包含了逻辑文件控制、访问控制、物理文件控制和I/O执行四层子系统。让我们通过一个具体例子来演示全过程：\n\n📂 案例场景\n用户操作：运行程序执行 read(fd, buf, 4096)，读取文件 /home/user/data.txt 的4KB数据（该文件大小为8KB，存储在Ext4文件系统上）\n\n🔄 操作系统处理全过程（分层解析）\n✅ 第1层：用户接口与语法检查\n\n系统调用触发\n\n用户程序调用 read(fd, buf, 4096)，通过软中断（如 syscall指令）进入内核态\n\n\n语法检查\n\n内核检查：\n\nfd 是否有效（是否存在进程打开文件表中）\nbuf 地址是否在用户空间合法\nsize 是否为非负整数\n\n\n失败处理：如参数非法返回 EINVAL\n\n\n\n\n✅ 进入逻辑文件控制子系统\n\n\n✅ 第2层：逻辑文件控制子系统\n\n路径解析\n\n通过 fd 找到文件描述符表 → 打开文件表项 → inode编号（假设inode=123）\n\n\n文件结构解析\n\n查询inode元数据：\n\n文件大小：8192 Bytes\n块大小：4KB（Ext4默认）\n物理结构：Extent树（现代Ext4结构）\n\n\n\n\n逻辑地址转换\n\n计算当前读写位置（假设偏移量 offset=0）：\n\n逻辑块号 = offset / block_size = 0\n块内偏移 = 0\n\n\n此次读取只需一个完整块（4KB）\n\n\n\n\n📊 输出：目标数据在逻辑块0（文件内相对位置）\n\n\n✅ 第3层：文件保护子系统\n\n身份识别\n\n获取调用进程的UID/GID（假设UID=1000）\n\n\n权限验证\n\n检查inode权限位：-rw-r--r--\n比对：\n\n所有者权限：1000可读写 → 允许读操作\n其他用户：只读权限 → 符合要求\n\n\n\n\n访问控制\n\n若配置了SELinux：检查进程上下文标签是否允许读取该文件\n\n\n\n\n🔐 验证通过，允许操作\n\n\n✅ 第4层：物理文件控制子系统\n\n缓存管理\n\n查询页缓存（Page Cache）：\n\n逻辑块0是否已缓存 → 假设未命中\n\n\n\n\n物理地址转换\n\n通过inode的Extent树查找逻辑块0 → 物理块号（如磁盘块号1024）\n\n\n空间管理\n\n读操作无需分配新空间\n\n\nI/O请求封装\n\n构造bio请求：struct bio &#123;   .bi_sector = 1024 * 8,   // 1024块 * 每块8扇区   .bi_size   = 4096,       // 请求大小   .bi_io_vec → 指向内核缓存页&#125;\n\n\n\n\n\n💾 输出：物理I/O请求（从磁盘块1024读取4KB数据）\n\n\n✅ 第5层：I/O控制子系统\n\nI/O调度\n\n请求加入块设备队列（如deadline调度器）\n可能合并相邻I/O请求（本例无相邻请求）\n\n\n驱动执行\n\nSATA磁盘流程：sequenceDiagram   CPU-&gt;&gt;磁盘控制器： 发送DMA命令 (LBA=8192, size=4096)   磁盘控制器-&gt;&gt;磁盘缓存： 读取数据到控制器缓存   磁盘控制器-&gt;&gt;内存： DMA传输到内核缓存页   磁盘控制器-&gt;&gt;CPU： 触发中断 IRQ 45\n\n\n\n中断处理\n\n中断服务例程(ISR)确认I/O完成\n唤醒等待进程\n\n\n\n\n🔄 最终结果交付\n\n数据拷贝\n\n从内核缓存页复制4096字节到用户空间buf\n\n\n更新元数据\n\n文件偏移量更新：offset += 4096\n\n\n用户态返回\n\n系统调用返回成功读取字节数：4096\n\n\n\n","tags":["操作系统往年卷/2020-OS"]},{"title":"操作系统：并发编程","url":"/notes.github.io/2025/06/23/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","content":"读者写者问题的伪代码实现\n\n1. 读者优先（可能导致写者饥饿）\nsemaphore rw_mutex = 1;  // 读写互斥锁semaphore mutex = 1;     // 保护读者计数器的互斥锁int reader_count = 0;    // 当前读者数量// 读者进程Reader() &#123;    while (true) &#123;        P(mutex);                // 保护reader_count        if (reader_count == 0) &#123;  // 第一个读者需要获取读写锁            P(rw_mutex);        &#125;        reader_count++;        V(mutex);        // 执行读操作        read_data();        P(mutex);        reader_count--;        if (reader_count == 0) &#123;  // 最后一个读者释放读写锁            V(rw_mutex);        &#125;        V(mutex);    &#125;&#125;// 写者进程Writer() &#123;    while (true) &#123;        P(rw_mutex);      // 获取读写锁        // 执行写操作        write_data();        V(rw_mutex);      // 释放读写锁    &#125;&#125;\n特点：读者可以并发读，但可能导致写者长期等待（饥饿）。\n\n2. 写者优先（避免写者饥饿）\nsemaphore rw_mutex = 1;    // 读写互斥锁semaphore mutex = 1;       // 保护reader_countsemaphore w = 1;           // 写者优先锁int reader_count = 0;// 读者进程Reader() &#123;    while (true) &#123;        P(w);              // 写者优先：新读者需等待写者完成        P(mutex);        if (reader_count == 0) &#123;            P(rw_mutex);        &#125;        reader_count++;        V(mutex);        V(w);        read_data();        P(mutex);        reader_count--;        if (reader_count == 0) &#123;            V(rw_mutex);        &#125;        V(mutex);    &#125;&#125;// 写者进程Writer() &#123;    while (true) &#123;        P(w);              // 获取写者优先锁        P(rw_mutex);       // 获取读写锁        write_data();        V(rw_mutex);        V(w);    &#125;&#125;\n特点：写者优先获取锁，避免饥饿，但读者可能延迟。\n\n3. 公平竞争（先来先服务）\nsemaphore rw_mutex = 1;    // 读写互斥锁semaphore mutex = 1;       // 保护reader_countsemaphore queue = 1;       // 公平队列锁int reader_count = 0;// 读者进程Reader() &#123;    while (true) &#123;        P(queue);          // 进入公平队列        P(mutex);        if (reader_count == 0) &#123;            P(rw_mutex);        &#125;        reader_count++;        V(mutex);        V(queue);        read_data();        P(mutex);        reader_count--;        if (reader_count == 0) &#123;            V(rw_mutex);        &#125;        V(mutex);    &#125;&#125;// 写者进程Writer() &#123;    while (true) &#123;        P(queue);          // 进入公平队列        P(rw_mutex);        V(queue);          // 释放队列锁（允许其他进程排队）        write_data();        V(rw_mutex);    &#125;&#125;\n特点：通过队列锁实现先来先服务，平衡读者和写者的优先级。\n/** * 非公平锁同步器实现类，继承自Sync（Sync应继承AbstractQueuedSynchronizer） * 非公平锁特性：新请求锁的线程无需进入等待队列，可直接与队列中线程竞争锁资源 * 优点：减少线程切换开销，提高吞吐量 * 缺点：可能导致线程饥饿（长时间无法获取锁） */static final class NonfairSync extends Sync &#123;    /**     * 加锁操作入口方法     * 实现非公平锁核心逻辑：直接尝试插队获取锁，失败后再走正常获取流程     */    final void lock() &#123;        // 第一步直接尝试CAS修改同步状态（体现非公平性）        // compareAndSetState(0, 1)：        // 原子操作尝试将state从0改为1，成功表示立即获得锁        if (compareAndSetState(0, 1)) &#123;            // 设置当前线程为独占资源持有者            setExclusiveOwnerThread(Thread.currentThread());        &#125; else &#123;            // 快速获取失败，执行常规锁获取流程（可能进入等待队列）            // 调用AQS的acquire方法，内部会调用tryAcquire尝试获取锁            acquire(1);        &#125;    &#125;    /**     * 尝试非公平方式获取锁（重写AQS的tryAcquire方法）     * @param acquires 请求获取锁的次数（固定为1，在重入时会累加）     * @return 是否成功获取锁     */    protected final boolean tryAcquire(int acquires) &#123;        final Thread current = Thread.currentThread();  // 获取当前线程引用        int c = getState();  // 获取当前同步状态值                // Case 1：锁处于未锁定状态（state=0）        if (c == 0) &#123;            // 再次尝试CAS设置state（非公平性体现：不检查等待队列直接竞争）            if (compareAndSetState(0, acquires)) &#123;                setExclusiveOwnerThread(current);  // 成功获取，设置独占线程                return true;            &#125;            // CAS失败说明有其它线程竞争成功，继续返回false        &#125;        // Case 2：锁已被持有，检查是否是当前线程（锁重入逻辑）        else if (current == getExclusiveOwnerThread()) &#123;            int nextc = c + acquires;  // 计算新的重入次数                        // 溢出检查（理论上int最大值足够大，此检查为防御性编程）            if (nextc &lt; 0)  // 当超过int最大值时会溢出为负数                throw new Error(&quot;Maximum lock count exceeded&quot;);                        setState(nextc);  // 更新重入次数（此处无需CAS，因为只有持有线程会修改）            return true;        &#125;        // 两种情况都不满足，获取锁失败        return false;    &#125;&#125;\n// 公平锁实现类static final class FairSync extends Sync &#123;    // 加锁操作    final void lock() &#123;        acquire(1);    &#125;    // 尝试公平方式加锁，重写父类 tryAcquire 方法    protected final boolean tryAcquire(int acquires) &#123;        final Thread current = Thread.currentThread();        int c = getState();        if (c == 0) &#123;            // 1）判断等待队列是否有线程处于等待状态，如果没有，尝试获取锁；如果有，就进入等待队列            // 2）采用CAS方式修改线程同步状态，如果成功返回true            if (!hasQueuedPredecessors() &amp;&amp;                compareAndSetState(0, acquires)) &#123;                setExclusiveOwnerThread(current);                return true;            &#125;        &#125;        else if (current == getExclusiveOwnerThread()) &#123;            // 支持当前线程，重复获得锁，将state值加1            int nextc = c + acquires;            if (nextc &lt; 0)                throw new Error(&quot;Maximum lock count exceeded&quot;);            setState(nextc);            return true;        &#125;        return false;    &#125;&#125;\n/** * 判断当前线程是否需要排队（公平锁核心方法） * 返回true表示存在有效的前驱节点（当前线程需要排队） * 返回false表示可以直接尝试获取锁 *  * 注：此方法的正确性依赖于以下条件： * 1. head节点必须在tail节点之前初始化 * 2. head.next的准确性（当当前线程是队列第一个时） */public final boolean hasQueuedPredecessors() &#123;    Node t = tail;  // 获取尾节点（反向初始化顺序读取）    Node h = head;  // 获取头节点    Node s;        // Case 1：队列非空（h != t）    // 注意：头尾不相等时，队列至少包含一个实际等待节点（非虚节点）    if (h != t) &#123;        s = h.next;  // 获取头节点的后继（第一个等待节点）                // Case 1.1：s == null 说明存在并发修改（两种情况）：        // 1. 其他线程刚完成锁释放，正在初始化新head（此时实际有等待节点）        // 2. 其他线程正在插入新节点（但尚未连接next指针）        // 这两种情况都需要保守返回true（让当前线程排队）        if (s == null) &#123;            return true;        &#125;         // Case 1.2：s.thread != 当前线程        // 说明队列第一个等待节点不是当前线程，需要排队        else if (s.thread != Thread.currentThread()) &#123;            return true;        &#125;        // Case 1.3：s.thread == 当前线程        // 说明当前线程已是队列第一个等待者，无需排队    &#125;        // Case 2：队列为空（h == t）或当前线程是队列第一个等待者    // 可以直接尝试获取锁    return false;&#125;\nAQS 内部维护一个共享资源变量和线程等待队列，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是 CLH 队列的变体实现的，将暂时获取不到锁的线程加入到等待队列中，待条件允许的时候将线程从队列中取出并进行唤醒。\n\n总结下来，用大白话说就是，AQS是基于 CLH 队列，使用volatile修饰共享变量state，线程通过CAS方式去改变state状态值，如果成功则获取锁成功，失败则进入等待队列，等待被唤醒的线程同步器框架。\n\n共享模式\nAQS使用了模板方法设计模式\n\n\n\n方法\n描述\n\n\n\n\nprotected boolean isHeldExclusively()\n判断当前线程是否独占资源。仅需在用到Condition时实现。\n\n\nprotected boolean tryAcquire(int arg)\n独占模式尝试获取资源。成功返回true，失败返回false。\n\n\nprotected boolean tryRelease(int arg)\n独占模式尝试释放资源。成功返回true，失败返回false。\n\n\nprotected int tryAcquireShared(int arg)\n共享模式尝试获取资源。返回负数表示失败；0表示成功但无剩余；正数表示成功且有剩余。\n\n\nprotected boolean tryReleaseShared(int arg)\n共享模式尝试释放资源。成功且需唤醒后续等待线程时返回true。\n\n\n\n1. 信号量（Semaphore）源码解析\npublic class Semaphore implements java.io.Serializable &#123;    private final Sync sync; // 基于AQS的同步器    // 构造方法（默认非公平模式）    public Semaphore(int permits) &#123;        sync = new NonfairSync(permits); // 初始化许可数量    &#125;    // 获取许可（阻塞直到成功）    public void acquire() throws InterruptedException &#123;        sync.acquireSharedInterruptibly(1); // 共享式获取1个许可    &#125;    // 释放许可    public void release() &#123;        sync.releaseShared(1); // 共享式释放1个许可    &#125;    abstract static class Sync extends AbstractQueuedSynchronizer &#123;        Sync(int permits) &#123;            setState(permits); // 用AQS的state存储许可数        &#125;        // 非公平模式尝试获取        final int nonfairTryAcquireShared(int acquires) &#123;            for (;;) &#123;                int available = getState();                int remaining = available - acquires;                if (remaining &lt; 0 ||                     compareAndSetState(available, remaining)) // CAS更新                    return remaining; // 返回剩余许可数            &#125;        &#125;        // 共享模式释放        protected final boolean tryReleaseShared(int releases) &#123;            for (;;) &#123;                int current = getState();                int next = current + releases;                if (next &lt; current) // 溢出检查                    throw new Error(&quot;Maximum permit count exceeded&quot;);                if (compareAndSetState(current, next))                    return true;            &#125;        &#125;    &#125;&#125;\n核心机制：\n\n使用AQS的state记录可用许可数\n获取许可时通过CAS减少state值\n释放许可时通过CAS增加state值\n当许可不足时线程进入CLH队列等待\n\n2. 读写锁（ReadWriteLock）源码解析\npublic class ReentrantReadWriteLock implements ReadWriteLock &#123;    private final ReentrantReadWriteLock.ReadLock readerLock;    private final ReentrantReadWriteLock.WriteLock writerLock;    final Sync sync;    // 构造方法    public ReentrantReadWriteLock() &#123;        this(false); // 默认非公平模式    &#125;    // 读写锁分离实现    public static class ReadLock implements Lock &#123;        private final Sync sync;        protected ReadLock(ReentrantReadWriteLock lock) &#123;            sync = lock.sync;        &#125;                public void lock() &#123;            sync.acquireShared(1); // 共享模式获取读锁        &#125;    &#125;    public static class WriteLock implements Lock &#123;        private final Sync sync;        protected WriteLock(ReentrantReadWriteLock lock) &#123;            sync = lock.sync;        &#125;                public void lock() &#123;            sync.acquire(1); // 独占模式获取写锁        &#125;    &#125;    abstract static class Sync extends AbstractQueuedSynchronizer &#123;        // state高16位表示读锁，低16位表示写锁        static final int SHARED_SHIFT = 16;        static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;        // 获取读锁数量        static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125;                // 获取写锁数量        static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125;    &#125;&#125;\n核心机制：\n\n使用AQS state的高16位记录读锁数量，低16位记录写锁数量\n读锁使用共享模式，允许多线程并发获取\n写锁使用独占模式，获取时会阻塞所有读写线程\n支持锁降级（写锁→读锁）但禁止锁升级\n\n3. CountDownLatch源码解析\npublic class CountDownLatch &#123;    private final Sync sync;    // 构造方法    public CountDownLatch(int count) &#123;        if (count &lt; 0) throw new IllegalArgumentException();        this.sync = new Sync(count); // 初始化计数器    &#125;    // 等待机制    public void await() throws InterruptedException &#123;        sync.acquireSharedInterruptibly(1); // 共享式等待    &#125;    // 计数器减1    public void countDown() &#123;        sync.releaseShared(1); // 共享式释放    &#125;    private static final class Sync extends AbstractQueuedSynchronizer &#123;        Sync(int count) &#123;            setState(count); // 用state存储计数器        &#125;        protected int tryAcquireShared(int acquires) &#123;            return getState() == 0 ? 1 : -1; // 0表示完成        &#125;        protected boolean tryReleaseShared(int releases) &#123;            for (;;) &#123;                int c = getState();                if (c == 0) return false;                int nextc = c-1;                if (compareAndSetState(c, nextc))                    return nextc == 0; // 返回是否触发唤醒            &#125;        &#125;    &#125;&#125;\n核心机制：\n\n初始化时设置state为线程数\n每完成一个线程调用countDown()递减state\n当state=0时唤醒所有等待线程\n\n4. CyclicBarrier源码解析\npublic class CyclicBarrier &#123;    private final ReentrantLock lock = new ReentrantLock();    private final Condition trip = lock.newCondition();    private final int parties;  // 屏障阈值    private int count;          // 当前等待数    private Runnable barrierCommand; // 屏障触发动作    // 构造方法    public CyclicBarrier(int parties, Runnable barrierAction) &#123;        this.parties = parties;        this.count = parties;        this.barrierCommand = barrierAction;    &#125;    public int await() throws InterruptedException &#123;        lock.lock();        try &#123;            int index = --count;            if (index == 0) &#123;  // 最后一个到达线程                try &#123;                    barrierCommand.run(); // 执行屏障任务                    nextGeneration();     // 重置屏障                    return 0;                &#125; finally &#123;                    if (!ranAction) breakBarrier();                &#125;            &#125;            // 非最后线程进入等待            trip.await();            return index;        &#125; finally &#123;            lock.unlock();        &#125;    &#125;    private void nextGeneration() &#123;        trip.signalAll();  // 唤醒所有线程        count = parties;   // 重置计数器    &#125;&#125;\n核心机制：\n\n使用ReentrantLock+Condition实现同步\n每代（Generation）维护独立的计数器\n最后一个到达线程执行回调并唤醒其他线程\n支持重复使用（区别于CountDownLatch）\n\n对比总结\n\n\n\n工具类\n核心特性\n是否可重用\n典型场景\n\n\n\n\nSemaphore\n控制资源访问并发数\n是\n连接池/限流\n\n\nReadWriteLock\n读写分离的锁策略\n是\n读多写少的数据结构\n\n\nCountDownLatch\n一次性线程协调\n否\n主线程等待子线程完成\n\n\nCyclicBarrier\n可循环使用的线程屏障\n是\n多阶段任务同步\n\n\n\njava管程和霍尔管程\n基础概念回顾\n\n管程（Monitors）：是一种同步机制，用于保护共享数据。它像一个“房间”，只有一个线程（或进程）可以进入（称为“互斥访问”）。管程通常包括共享变量、操作方法和条件变量（用于线程等待和唤醒）。\nJava管程：基于MESA模型，由Java语言内置支持（如synchronized关键字或Lock接口）。它处理线程同步的方式更注重效率和实用性。\n霍尔管程：基于Hoare模型，通常在学术或理论环境中讨论，需要手动实现（如使用信号量）。它强调严格的顺序和精确性。\n关键术语：\n\n信号（signal）：一个线程通知另一个线程“条件已满足”，让它从等待状态醒来。\n等待（wait）：线程暂停执行，直到条件满足。\n虚假唤醒（spurious wakeup）：线程被唤醒，但条件实际上没有满足（常见于Java管程）。\n\n\n\n\n一、核心差异\n这一部分讨论了Java管程和霍尔管程在核心机制上的主要区别。核心差异主要体现在线程如何唤醒和处理条件变量。\n\n\n线程唤醒策略\n这点解释了当一个线程（例如线程A）使用信号唤醒另一个线程（例如线程B）时，两者处理的差异。\n\n\nJava管程（MESA模型）：\n在Java管程中，当线程A调用signal()（或notify()）来唤醒线程B时，线程B不会立即开始执行。它会被添加到一个“入口等待队列”（一种线程队列），然后必须重新竞争锁（例如synchronized锁）才能进入管程。线程A不会立即停止；它会继续执行自己的代码，直到它自己退出管程。这避免了频繁的上下文切换（线程从暂停到运行的切换），提高了效率。\n为什么这样设计？ MESA模型是为了适应多核CPU和高并发环境。它不强制线程立即切换，而是让线程通过竞争锁来决定执行顺序，这更灵活但也可能导致一些不确定性。\n代码示例解释：\n  while (条件不满足) &#123;  // MESA模型必须用while循环检查条件    condition.await();  // 线程等待，直到被signal()唤醒&#125;\n这里，while (条件不满足)是一个循环检查。假设线程B在等待某个条件（如“队列不为空”）。当线程A调用signal()唤醒它时，线程B会醒来，但必须重新检查条件（因为可能有其他线程抢先执行，导致条件又变了）。如果不使用while循环，而只用if语句，可能会导致“虚假唤醒”问题（详见下一点）。总之，这个策略让Java管程更适合实际应用，但需要程序员小心处理。\n\n\n霍尔管程（Hoare模型）：\n在霍尔管程中，当线程A调用signal()唤醒线程B时，线程A会立即阻塞（暂停执行），而线程B会直接获得锁并开始执行。直到线程B完成执行并退出管程后，线程A才会恢复。这是一种严格的顺序执行，确保唤醒的线程B能立即接管控制权。\n为什么这样设计？ Hoare模型更注重理论上的精确性，它假设信号操作是“原子”的（即不可中断的），这样可以避免竞争条件（race condition）。但这会导致更高的开销，因为系统必须强制线程切换。\n\n\n\n\n条件变量处理\n这点讨论了如何处理线程等待的条件，以及潜在的问题。\n\n\nJava管程：Java管程的notify()或signal()方法可能导致虚假唤醒。虚假唤醒是指线程B被唤醒后，发现等待的条件实际上没有满足（例如，其他线程改变了条件）。这是因为MESA模型中，唤醒不是完全可靠的（操作系统或其他因素可能导致意外唤醒）。为了应对这个，Java推荐使用while循环来反复检查条件，就像上面的代码示例那样。这样，即使线程被虚假唤醒，它也会重新等待，直到条件真正满足。\n详细原因：在多线程环境中，信号可能被延迟或与其他操作交织，导致线程醒来时条件已变。这让Java管程更“现实”，但增加了编程复杂度。\n\n\n霍尔管程：霍尔管程的signal()是原子操作，不会发生虚假唤醒。一旦线程A发送信号，线程B就会立即执行，并且条件被保证已满足。这是因为Hoare模型强制线程A阻塞，确保线程B在安全的环境中运行。\n详细原因：这种设计更“理想化”，适合教学或需要精确控制的场景，但实际实现起来更复杂，因为它需要操作系统级别的支持。\n\n\n\n\n\n二、实现机制对比\n这一部分通过表格对比了两者的实现细节。我会逐行解释表格中的每个特性。\n\n\n\n特性\nJava管程\n霍尔管程\n\n\n\n\n模型基础\nMESA模型（Java内置实现）\nHoare模型（需手动模拟）\n\n\n锁获取方式\n通过synchronized或ReentrantLock\n需自行实现信号量PV操作\n\n\n线程切换开销\n较低（减少上下文切换）\n较高（强制线程切换）\n\n\n适用场景\n高并发系统（如Java并发包）\n学术研究或特定同步需求\n\n\n\n\n\n模型基础：\nJava管程基于MESA模型，这是一种现代的线程同步模型，由Java虚拟机（JVM）直接支持。你可以用简单的代码（如synchronized块）实现管程，而不需要额外工具。霍尔管程基于Hoare模型，这是一个更早的理论模型，通常需要程序员手动模拟（如使用信号量），所以它不适合日常编程。\n\n\n锁获取方式：\n在Java管程中，线程通过synchronized关键字（自动获取对象锁）或ReentrantLock（手动锁）来进入管程。这很方便，因为Java内置了这些机制。\n在霍尔管程中，你需要自己实现锁逻辑，通常使用信号量（一种更底层的同步工具）。信号量的PV操作（P:等待资源，V:释放资源）需要手动编写，这增加了复杂性。\n\n\n线程切换开销：\nJava管程的开销较低，因为它避免不必要的上下文切换（例如，在MESA模型中，线程A不会立即阻塞）。这意味着CPU资源利用更高效，适合高负载系统。\n霍尔管程的开销较高，因为它强制线程立即切换（线程A阻塞，线程B立即运行），这会涉及更多CPU时间和内存开销。\n\n\n适用场景：\nJava管程适合高并发系统，比如Web服务器或Java并发包（如java.util.concurrent），因为它高效且易用。霍尔管程更适合学术研究、教学演示或需要严格顺序的特定需求（如嵌入式系统），但在实际开发中很少使用。\n\n\n\n三、相同点\n这一部分列出了两者的共同之处。尽管它们在细节上不同，但这些相同点是管程机制的核心。\n\n\n互斥访问\n两者都确保同一时刻只有一个线程可以进入管程，从而保护共享资源免受并发访问的干扰。这就像一个门卫，只允许一个访客进入房间，避免冲突。\n详细解释：在多线程程序中，如果多个线程同时访问共享变量（如一个银行账户余额），可能会导致数据错误。管程通过互斥（mutex）机制解决这个问题，无论Java管程还是霍尔管程，都能实现这一功能。\n\n\n条件变量支持\n两者都使用类似wait()和signal()的机制，让线程等待特定条件并在条件满足时唤醒。这是一种协作方式，让线程之间相互通信。\n详细解释：例如，在生产者-消费者问题中，生产者线程可能调用signal()来通知消费者线程“商品已生产”。Java管程用Condition.await()和Condition.signal()实现，霍尔管程用类似的自定义操作。这让管程不仅仅是互斥，还能处理复杂的同步场景。\n\n\n封装性\n两者都将共享变量和相关的操作方法封装到一个“单元”中，确保线程安全。\n详细解释：这类似于面向对象的封装原则。共享数据（如变量）和操作（如加锁、等待）被放在一起，外部线程无法直接访问内部细节，从而减少错误。例如，在Java中，你可以用一个类来实现管程，里面包含synchronized方法。\n\n\n\n四、本质区别图示\n这一部分用流程图展示了线程唤醒的差异。我会用文字详细解释这些流程。\n\n\nJava管程唤醒流程：\n线程A.signal() → 线程B进入入口队列 → 线程A继续执行 → 线程B竞争锁\n详细解释：假设线程A和线程B都在管程中。线程A调用signal()后，它只是把线程B从等待队列移到入口队列，但线程A不会停下来。它继续执行自己的任务。线程B醒来后，必须加入锁竞争（可能有其他线程也在竞争），只有获胜后才能执行。这可能导致线程B需要等待一段时间，但整体效率较高。\n\n\n霍尔管程唤醒流程：\n线程A.signal() → 线程A立即阻塞 → 线程B直接执行 → 线程B退出后线程A恢复\n详细解释：线程A调用signal()后，它立即暂停（阻塞），系统直接让线程B运行。线程B执行完后，系统才允许线程A继续。这确保了严格的顺序，但可能导致性能问题，因为每次信号都涉及强制切换。\n\n\n\n五、选择建议\n这一部分给出了在实际场景中选择哪种管程的建议。\n\n\n优先Java管程：在需要高性能和低延迟的场景（如互联网服务）时，选择Java管程。\n详细解释：Java管程基于MESA模型，更适合现代多核CPU和大规模并发。它内置于Java中，易于使用，且开销小。例如，在开发一个处理数千用户请求的Web应用时，Java管程能高效管理线程，而不会因频繁切换导致系统变慢。\n\n\n考虑霍尔管程：在需要严格顺序执行或教学演示时（需自行实现），选择霍尔管程。\n详细解释：霍尔管程基于Hoare模型，更适合理论研究或需要精确控制的场景（如操作系统课程）。但是，由于它需要手动实现（如使用信号量），在实际项目中不常见。注：Java选择MESA模型是因为它更简单、实用，而Hoare模型更注重理论纯度。\n\n\n","tags":["操作系统往年卷/2020-OS"]},{"title":"最小二乘法笔记","url":"/notes.github.io/2025/06/23/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E7%AC%94%E8%AE%B0/","content":"根据我们的上述定义, 如果 $\\phi_0, \\dots, \\phi_n$ 为一组正交基, 这意味着\n$\\int_a^b w(x) \\phi_i(x) \\phi_j(x) dx = 0 \\ (i \\ne j)$, 而由内积的正定性, 我们有\n$\\int_a^b w(x) \\phi_i^2(x) dx = \\alpha_i &gt; 0$.\n而又由基的性质, $\\forall P(x), \\deg P \\le n, P(x) = \\sum_{i=0}^n a_i \\phi_i(x)$, 且线性表出方式唯一.\n故我们的误差函数 $E(a_0, \\dots, a_n) = \\int_a^b w(x) [f(x) - \\sum_{i=0}^n a_i \\phi_i(x)]^2 dx$\n同样地, 我们最小化误差, 令 $\\frac{\\partial E}{\\partial a_i} = 0$\n得到$\\int_a^b w(x) f(x) \\phi_i(x) dx = a_i \\alpha_i$\n解得 $a_i = \\frac{\\int_a^b w(x) f(x) \\phi_i(x) dx}{\\alpha_i} = \\frac{\\int_a^b w(x) f(x) \\phi_i(x) dx}{\\int_a^b w(x) \\phi_i^2(x) dx}$ (最小二乘解)\n我们发现: 不同的 $a_i$ 之间不再具有联系, 方程的求解变得异常简单.\n多项式最小二乘解的推导\n当目标函数为任意 ( n ) 次多项式 ( p(x) = a_0 + a_1 x + a_2 x^2 + \\dots + a_n x^n ) 时，最小二乘法的目标是找到系数 ( \\bm{a} = (a_0, a_1, \\dots, a_n)^T )，使得拟合多项式与数据点 ( {(x_i, y_i)}_{i=1}^m ) 的残差平方和最小。以下是具体推导过程：\n\n1. 定义误差函数\n残差平方和（误差函数）为：\n[\nE = \\sum_{i=1}^m \\left( y_i - p(x_i) \\right)^2 = \\sum_{i=1}^m \\left( y_i - \\sum_{k=0}^n a_k x_i^k \\right)^2.\n]\n\n2. 对参数求偏导并置零\n对每个系数 ( a_j ) 求偏导数，令其等于零以最小化误差：\n[\n\\frac{\\partial E}{\\partial a_j} = 2 \\sum_{i=1}^m \\left( y_i - \\sum_{k=0}^n a_k x_i^k \\right)(-x_i^j) = 0 \\quad (j=0,1,\\dots,n).\n]\n整理后得到方程组：\n[\n\\sum_{i=1}^m y_i x_i^j = \\sum_{k=0}^n a_k \\sum_{i=1}^m x_i^{j+k} \\quad (j=0,1,\\dots,n).\n]\n\n3. 构造矩阵形式\n将方程写成矩阵形式 ( A^T A \\bm{a} = A^T \\bm{y} )，其中：\n\n设计矩阵 ( A )：\n[\nA =\n\\begin{bmatrix}\n1      &amp; x_1    &amp; x_1^2  &amp; \\cdots &amp; x_1^n \\\n1      &amp; x_2    &amp; x_2^2  &amp; \\cdots &amp; x_2^n \\\n\\vdots &amp; \\vdots &amp; \\vdots &amp;        &amp; \\vdots \\\n1      &amp; x_m    &amp; x_m^2  &amp; \\cdots &amp; x_m^n\n\\end{bmatrix}.\n]\n右端项 ( A^T \\bm{y} )：\n[\nA^T \\bm{y} =\n\\begin{bmatrix}\n\\sum_{i=1}^m y_i \\\n\\sum_{i=1}^m y_i x_i \\\n\\sum_{i=1}^m y_i x_i^2 \\\n\\vdots \\\n\\sum_{i=1}^m y_i x_i^n\n\\end{bmatrix}.\n]\n系数矩阵 ( A^T A )：\n[\nA^T A =\n\\begin{bmatrix}\nm              &amp; \\sum x_i       &amp; \\sum x_i^2     &amp; \\cdots &amp; \\sum x_i^n     \\\n\\sum x_i       &amp; \\sum x_i^2     &amp; \\sum x_i^3     &amp; \\cdots &amp; \\sum x_i^{n+1} \\\n\\vdots         &amp; \\vdots         &amp; \\vdots         &amp;        &amp; \\vdots         \\\n\\sum x_i^n     &amp; \\sum x_i^{n+1} &amp; \\sum x_i^{n+2} &amp; \\cdots &amp; \\sum x_i^{2n}\n\\end{bmatrix}.\n]\n\n\n4. 正规方程\n最终方程组为：\n[\nA^T A \\bm{a} = A^T \\bm{y},\n]\n其解为：\n[\n\\bm{a} = (A^T A)^{-1} A^T \\bm{y}.\n]\n\n关键点分析\n\n\n正交基的简化作用：\n\n若多项式基 ( {1, x, x^2, \\dots, x^n} ) 正交，则 ( A^T A ) 为对角阵，系数可直接通过投影计算：\n[\na_j = \\frac{\\sum_{i=1}^m y_i x_i^j}{\\sum_{i=1}^m x_i^{2j}} \\quad (j=0,1,\\dots,n).\n]\n非正交时需求逆矩阵，可能面临数值不稳定问题。\n\n\n\n与傅里叶级数的对比：\n\n傅里叶分析中，基函数 ( {\\cos(kx), \\sin(kx)} ) 天然正交，可直接投影（如历史讨论）。\n多项式基一般不正交，需通过正规方程求解。\n\n\n\n\n结论\n任意多项式的最小二乘解通过构造设计矩阵 ( A )、求解正规方程 ( A^T A \\bm{a} = A^T \\bm{y} ) 得到。其本质是误差函数的平方和最小化在非正交基下的推广，核心步骤为：\n\n定义误差函数，\n对参数求导并构造线性方程组，\n通过矩阵运算求解系数。\n\n多项式基的正交化与最小二乘解的简化推导\n在多项式最小二乘问题中，若采用标准基 ( {1, x, x^2, \\dots, x^n} )，设计矩阵 ( A ) 的条件数可能较大，导致数值不稳定。通过 正交化基函数，可简化计算并提高数值稳定性。以下是具体推导过程：\n\n1. 定义内积\n假设有 ( m ) 个数据点 ( {(x_i, y_i)}{i=1}^m )，定义离散内积：\n[\n\\langle f, g \\rangle = \\sum{i=1}^m f(x_i) g(x_i).\n]\n目标是构造一组正交多项式基 ( {q_0(x), q_1(x), \\dots, q_n(x)} )，满足：\n[\n\\langle q_j, q_k \\rangle = 0 \\quad (j \\neq k).\n]\n\n2. 应用 Gram-Schmidt 正交化\n从标准基 ( {1, x, x^2, \\dots, x^n} ) 出发，逐步生成正交基：\n\n\n初始化：\n[\nq_0(x) = 1.\n]\n\n\n递归正交化（对 ( k=1,2,\\dots,n )）：\n[\nq_k(x) = x^k - \\sum_{j=0}^{k-1} \\frac{\\langle x^k, q_j \\rangle}{\\langle q_j, q_j \\rangle} q_j(x).\n]\n每一步从 ( x^k ) 中减去其在已有正交基方向上的投影。\n\n\n\n3. 正交基下的最小二乘解\n目标多项式表示为正交基的线性组合：\n[\np(x) = a_0 q_0(x) + a_1 q_1(x) + \\dots + a_n q_n(x).\n]\n误差函数为：\n[\nE = \\sum_{i=1}^m \\left( y_i - \\sum_{k=0}^n a_k q_k(x_i) \\right)^2.\n]\n\n4. 求解系数\n由于基正交，对 ( a_j ) 求偏导数并置零时，交叉项消失：\n[\n\\frac{\\partial E}{\\partial a_j} = -2 \\sum_{i=1}^m \\left( y_i - \\sum_{k=0}^n a_k q_k(x_i) \\right) q_j(x_i) = 0.\n]\n利用正交性 ( \\langle q_j, q_k \\rangle = 0 \\ (j \\neq k) )，化简得：\n[\na_j = \\frac{\\langle y, q_j \\rangle}{\\langle q_j, q_j \\rangle} = \\frac{\\sum_{i=1}^m y_i q_j(x_i)}{\\sum_{i=1}^m q_j(x_i)^2}.\n]\n无需解线性方程组，系数直接通过投影计算。\n\n5. 矩阵形式的简化\n若设计矩阵 ( Q ) 的列为正交基函数值：\n[\nQ =\n\\begin{bmatrix}\nq_0(x_1) &amp; q_1(x_1) &amp; \\cdots &amp; q_n(x_1) \\\nq_0(x_2) &amp; q_1(x_2) &amp; \\cdots &amp; q_n(x_2) \\\n\\vdots   &amp; \\vdots    &amp;        &amp; \\vdots   \\\nq_0(x_m) &amp; q_1(x_m) &amp; \\cdots &amp; q_n(x_m)\n\\end{bmatrix},\n]\n则正规方程简化为对角系统：\n[\nQ^T Q \\bm{a} = Q^T \\bm{y} \\quad \\Rightarrow \\quad a_j = \\frac{(Q^T \\bm{y})j}{(Q^T Q){jj}}.\n]\n\n正交化的优势\n\n数值稳定性：避免 ( A^T A ) 的条件数过大。\n计算效率：系数独立计算，无需矩阵求逆。\n逐步拟合：可逐步增加多项式次数，无需重新计算已有系数。\n\n\n示例：离散 Chebyshev 多项式\n在区间 ([-1,1]) 上，若选 Chebyshev 节点 ( x_i = \\cos\\left(\\frac{(2i-1)\\pi}{2m}\\right) )，通过正交化得到的基与 Chebyshev 多项式相关，能进一步优化逼近效果。\n\n结论\n通过正交化多项式基，将最小二乘问题转化为对角系统，显著简化计算并提升稳定性。这一方法结合了线性代数中的正交投影思想，是解决高次多项式拟合问题的实用工具。\n定理 (Gram-Schimidt)\n$\\phi_0, \\dots, \\phi_n$ 为 $[a, b]$ 上关于权函数 $w(x)$ 正交的多项式基。可以由以下方式求得：\n$\\phi_0(x) = 1, \\phi_1(x) = x - B_1$，而 $B_1 = \\frac{\\int_a^b x w(x) \\phi_0^2(x) dx}{\\int_a^b w(x) \\phi_0^2(x) dx}$。\n而当 $k \\ge 2$ 时，我们有统一形式 $\\phi_k(x) = x \\phi_{k-1}(x) - B_k \\phi_{k-1}(x) - C_k \\phi_{k-2}(x)$。\n其中，$B_k = \\frac{\\int_a^b x w(x) \\phi_{k-1}^2(x) dx}{\\int_a^b w(x) \\phi_{k-1}^2(x) dx}$， $C_k = \\frac{\\int_a^b x w(x) \\phi_{k-1}(x) \\phi_{k-2}(x) dx}{\\int_a^b w(x) \\phi_{k-2}^2(x) dx}$。\nGram-Schmidt 方法看似繁琐，实则十分简单。它就是向量的 Schmidt 正交化方法在多项式正交化方面的推广罢了。根本的想法都是完全一致的，仅仅在细节上略有差别。\n实际示例：构造离散正交多项式基\n假设数据点为 ( x_1=1,, x_2=2,, x_3=3 )，定义离散内积：\n[\n\\langle f, g \\rangle = f(1)g(1) + f(2)g(2) + f(3)g(3).\n]\n以 ( n=2 ) 为例，演示如何从基 ( {1, x, x^2} ) 构造正交基 ( {q_0(x), q_1(x), q_2(x)} )。\n\n1. 构造 ( q_0(x) )\n直接取常数项基：\n[\nq_0(x) = 1.\n]\n\n2. 构造 ( q_1(x) )\n从 ( x ) 中减去其在 ( q_0(x) ) 方向的投影：\n[\nq_1(x) = x - \\frac{\\langle x, q_0 \\rangle}{\\langle q_0, q_0 \\rangle} q_0(x).\n]\n计算内积：\n[\n\\langle x, q_0 \\rangle = 1 \\cdot 1 + 2 \\cdot 1 + 3 \\cdot 1 = 6, \\quad \\langle q_0, q_0 \\rangle = 1^2 + 1^2 + 1^2 = 3.\n]\n则：\n[\nq_1(x) = x - \\frac{6}{3} \\cdot 1 = x - 2.\n]\n验证正交性：\n[\n\\langle q_1, q_0 \\rangle = (-1)(1) + 0(1) + 1(1) = 0.\n]\n\n3. 构造 ( q_2(x) )\n从 ( x^2 ) 中减去其在 ( q_0(x) ) 和 ( q_1(x) ) 方向的投影：\n[\nq_2(x) = x^2 - \\frac{\\langle x^2, q_0 \\rangle}{\\langle q_0, q_0 \\rangle} q_0(x) - \\frac{\\langle x^2, q_1 \\rangle}{\\langle q_1, q_1 \\rangle} q_1(x).\n]\n计算各内积：\n\n( \\langle x^2, q_0 \\rangle = 1^2 \\cdot 1 + 2^2 \\cdot 1 + 3^2 \\cdot 1 = 14 ),\n( \\langle x^2, q_1 \\rangle = 1^2 \\cdot (-1) + 2^2 \\cdot 0 + 3^2 \\cdot 1 = 8 ),\n( \\langle q_1, q_1 \\rangle = (-1)^2 + 0^2 + 1^2 = 2 ).\n\n代入公式：\n[\nq_2(x) = x^2 - \\frac{14}{3} \\cdot 1 - \\frac{8}{2} \\cdot (x-2) = x^2 - 4x + \\frac{10}{3}.\n]\n验证正交性：\n\n( \\langle q_2, q_0 \\rangle = \\frac{1}{3} \\cdot 1 + \\left(-\\frac{2}{3}\\right) \\cdot 1 + \\frac{1}{3} \\cdot 1 = 0 ),\n( \\langle q_2, q_1 \\rangle = \\frac{1}{3} \\cdot (-1) + \\left(-\\frac{2}{3}\\right) \\cdot 0 + \\frac{1}{3} \\cdot 1 = 0 ).\n\n\n正交基结果\n最终正交基为：\n[\n\\begin{cases}\nq_0(x) = 1, \\\nq_1(x) = x - 2, \\\nq_2(x) = x^2 - 4x + \\dfrac{10}{3}.\n\\end{cases}\n]\n\n应用：拟合数据点的最小二乘解\n假设数据点为 ( {(1, y_1), (2, y_2), (3, y_3)} )，拟合多项式为：\n[\np(x) = a_0 q_0(x) + a_1 q_1(x) + a_2 q_2(x).\n]\n系数可直接计算：\n[\na_j = \\frac{\\langle y, q_j \\rangle}{\\langle q_j, q_j \\rangle} \\quad (j=0,1,2).\n]\n\n结论\n通过具体数值演示了 Gram-Schmidt 正交化过程，展示了如何从 ( {1, x, x^2} ) 构造正交基。正交化后，最小二乘系数无需解线性方程组，直接通过投影计算。\n","tags":["其他"]},{"title":"期末复习_作业答案整理","url":"/notes.github.io/2025/06/23/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0_%E4%BD%9C%E4%B8%9A%E7%AD%94%E6%A1%88%E6%95%B4%E7%90%86/","content":"6\n\n\n\n\n\n\n\n4\n\n![\n](image-8.png)\n\n","tags":["其他"]},{"title":"操作系统：第三章复习笔记","url":"/notes.github.io/2025/06/23/%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/","content":"可变分区方式的内存分配\n内存分配算法整理\n\n\n\n算法\n分配策略\n优点\n缺点\n适用场景\n\n\n\n\n最先适应 (First-Fit)\n从头找第一个足够大的\n简单高效，适合大作业\n低/高地址利用不均，回收麻烦\n通用\n\n\n邻近适应 (Next-Fit)\n从上次位置开始找\n查找更快，空间均衡\n可能分割大空闲区\n中等负载\n\n\n最优适应 (Best-Fit)\n找最小的足够大的\n减少大分区浪费\n产生小碎片，查找慢\n中小作业\n\n\n最坏适应 (Worst-Fit)\n找最大的分区\n减少小碎片\n可能耗尽大分区\n中小作业\n\n\n快速适应 (Quick-Fit)\n维护常用大小链表\n查找极快\n合并复杂，额外开销\n特定场景\n\n\n\n最常用：最先适应（简单高效） &gt; 邻近适应 &gt; 最优适应。\n外部碎片 内部碎片\n内部零头（Internal Fragmentation）​\n​定义：分配给进程的内存块比实际需求大，导致块内部有未使用的空间。\n外部零头（External Fragmentation）​\n​定义：内存中存在多个分散的小空闲区，但每个单独的空闲区都太小，无法满足进程需求。\n​最先适应（First-Fit）​：倾向于使用低地址的大空闲区，可能保留高地址的大块空闲区，外零头较少。\n​最坏适应（Worst-Fit）​：总是分配最大的空闲区，减少小碎片产生，但可能耗尽大分区。\n​最优适应（Best-Fit）​：​最激进地切割空闲区，故外零头问题最严重。\n页式存储管理\n\n\n\n概念\n定义\n作用\n\n\n\n\n页号\n进程虚拟地址空间的逻辑划分单元编号（如4KB一页的序号）\n标识虚拟内存中的逻辑页位置\n\n\n页框号\n物理内存中实际存储块的编号（与页大小相同的物理块，也称页帧号/Physical Frame）\n定位数据在物理内存中的实际存储位置\n\n\n\n关键区别：\n\n页号属于虚拟地址空间（进程视角），页框号属于物理地址空间（硬件视角）。\n页表的核心功能就是完成页号→页框号的映射（如下图所示）：虚拟地址 = [页号][页内偏移]           ↓ 页表转换物理地址 = [页框号][页内偏移]\n\n\n\n反置页表\n正向页表（每个进程一个）：​\n​索引：​ 虚拟页号 (VPN)\n​表项内容：​ 物理页框号 (PFN) + 标志位\n​大小：​ 与进程的虚拟地址空间大小成正比（每个可能的虚拟页都有一个表项，即使该页未使用）。\n​反置页表（整个系统一个）：​\n​索引：​ 物理页框号 (PFN) (隐含在表项位置中)\n​表项内容：​ 进程ID (PID) + 虚拟页号 (VPN) + 标志位\n​大小：​ 与物理内存大小成正比（每个物理页框对应一个表项）。\n适用场景：​ 主要用在物理内存相对较小而虚拟地址空间非常大的系统中（如64位系统），或者嵌入式系统等资源受限环境。\n反置页表的页表项\n页号：虚拟地址页号\n进程标志符：使用该页的进程号(页号和进程标志符结合起来标志一个特定进程的虚拟地址空间的一页)\n标志位：有效、引用、修改、保护和锁定等标志信息\n链指针：哈希链，如果某个项没有链项，则该域为空(允许用一个单独的位来表示)\n\n段式\n页式存储管理中页的划分对程序员不可见。\n段式存储管理中段的划分对程序员可见。\n分段是信息的逻辑单位，由源程序的逻辑结构所决定，用户可见\n段长可根据用户需要来规定，段起始地址可从任何主存地址开始。\n分段方式中，源程序(段号，段内位移)经连结装配后地址仍保持二维结构。\n分页是信息的物理单位，与源程序的逻辑结构无关，用户不可见，\n页长由系统确定，页面只能以页大小的整倍数地址开始\n分页方式中，源程序(页号，页内位移)经连结装配后地址变成了一维结构\n\n传统教科书中的段页式 = ​分段（逻辑划分）+ 分页（物理划分）​：\n程序地址空间被划分为逻辑段​（代码、数据、堆、栈等）。\n每个逻辑段被独立分页​（即段内地址再被拆分为页号和页内偏移）。\n​硬件流程：CPU生成地址（段号, 段内偏移）→ 段表 → 得到段基址和线性地址 → 线性地址通过页表 → 物理地址。\n页式\n需要扩充页表项，至少包含如上信息，指出：\n主存驻留标志：指出页面是否已经装入内存。1表示在内存中可以被正常访问，0表示不能立即访问，产生缺页异常。\n修改位：被设置后，该页被调出内存前必须先写回磁盘，保障数据一致性\n保护位：限制页面访问权限\n引用位：在页面被引用无论是读写时设置，用来帮助系统进行页面淘汰。\n内存块号：页面对应的页框号，用来地址转换\n\n维度\t全局替换\t局部替换\n置换范围\t全系统物理帧\t当前进程分配的帧\n帧分配方式\t动态（按需调整）\t静态（预先固定）\n公平性\t低（强者通吃）\t高（隔离保护）\n适用场景\t通用计算（如Linux/Windows）\t实时系统、嵌入式系统\n全局页面替换策略\nOPT页面调度算法(Belady算法)\n算法描述：当要调入新页面时，首先淘汰以后不再访问的页，然后选择距现在最长时间后再访问的页。\n该方法由Belady提出，称为BeLady算法，又称最佳算法(OPT)\nOPT只可以模拟，不可以实现，因为永远无法预知之后的事情。\n这种算法可以用作衡量其他各种算法的标准\n先进先出页面调度算法(FIFO)\n算法描述：首先淘汰最先调入主存的那一页，或者说主存驻留时间最长的那一页(常驻的除外)\n模拟的是程序执行的顺序性，有一定合理性，并不能很好模拟程序的循环性。\n根据估计，缺页中断率也是最佳算法的2-3倍。\n\n最近最少用LRU页面调度算法\n淘汰最近一段时间较久未被访问的那一页，即那些刚被使用过的页面，可以马上还要被使用到。\n模拟了程序执行的局部属性，既考虑了循环性，又兼顾了顺序性\nLRU算法得到模拟实现：模拟是相当的不严谨，非常粗粒度的一个模拟。\n引用位法：每页建立一个引用标志，供硬件使用，设置一个时间间隔中断，发生时将页引用标志置0，访问页面时将引用标志置为1，页面置换的时候选择标志为0的页面，在选中淘汰页时，将所有的页的引用为全部置为0\n计数法：每页添加页面引用计数器，根据计数器选择最小的，定时清空页面引用计数器\n计时法：每页添加计时单元，引用时，将绝对时间记录进入计时单元，定时清空计时单元。\n老化算法：设置一个多位寄存器，被访问将最左侧设置为1，定时将寄存器右移，缺页中断时找到最小值的寄存器界面淘汰，被采用较多。\n第二次机会页面替换算法(SCR，Second Chance Replacement)\n将FIFO算法和页表中引用位结合。\n算法描述：\n首先检查FIFO页面队列队首\n引用位为0，则淘汰该页面\n引用位为1，将引用位清0，并将该页面移到队列尾部\n如果第一遍全为1，则循环\n最不常用LFU的页面调度算法\n淘汰最近一段时间内访问次数较少的页面，对OPT的模拟性比LRU更好\n算法过程：基于时间间隔中断，并给每一页设置一个计数器，时间间隔中断发生后，所有计数器清0，每访问页1次就给计数器加1，选择计数最小的页面淘汰\n伙伴算法与slab\n伙伴系统的分配和回收过程\n分配过程：当系统需要内存时，从对应大小的链表中查找空闲块。如果没有找到，就向更大的内存块查找，并将其分裂为合适的大小进行分配。\n伙伴系统分配内存的过程较为复杂。首先，当系统需要内存时，会根据所需内存的大小确定对应的页阶（order）。然后从对应页阶的链表中查找空闲块。如果在该链表中没有找到空闲块，就会向更大页阶的链表查找。例如，当需要一个 128 个页的页块时，先检查 128 个页的页块链表是否有空闲块。如果没有，则查 256 个页的页块链表；如果有空闲块的话，则将 256 个页的页块分成两份，一份使用，一份插入 128 个页的页块链表中。如果还是没有，就查 512 个页的页块链表；如果有的话，就分裂为 128、128、256 三个页块，一个 128 的使用，剩余两个插入对应页块链表。\n其实伙伴系统算法有如下3个基本条件需要满足：\n两个内存块的大小相同\n两个内存块的地址连续\n两个内存块必须是从同一个大的内存块中分离出来的\n小于 4KB 的内存分配：Slab 分配器\n伙伴系统的最小分配单位是 4KB 页框，分配更小内存会产生内部碎片。​Slab 分配器​（及其演进版本 SLUB/SLOB）专门解决此问题，为内核对象提供精细化分配。\n\n​Slab 的核心机制\n​对象缓存池：\n为高频小对象（如 task_struct、inode）创建专用缓存（kmem_cache），预分配并初始化对象。\n​内存来源：\n从伙伴系统申请整页（4KB），再划分为多个小对象（如 64B、128B）。\n​分配流程：\n优先从 ​Per-CPU 本地缓存 获取空闲对象（无锁操作）。\n若本地缓存空，从 ​部分空闲的 Slab 补充对象。\n若无可用 Slab，向伙伴系统申请新页并初始化新 Slab。\n4MB+： vmalloc\n伙伴系统（Buddy System）分配的内存空间是虚拟地址连续且物理地址连续的，而 vmalloc 分配的内存是虚拟地址连续但物理地址不连续的\nvmalloc 是 Linux 内核提供的内存分配函数之一，它用于在虚拟地址空间中分配连续的内存块。与 kmalloc 主要用于物理内存的分配不同，vmalloc 分配的内存并不要求物理内存是连续的，但它确保分配的虚拟地址空间是连续的。\n在Linux内核中对于物理上连续的分配方式，采用伙伴系统和slub分配器分配内存，但是知道物理上连续的映射是最好的分配方式，但并不总能成功地使用。在分配一大块内存时，可能竭尽全力也无法找到连续的内存块。针对这种情况内核提供了一种申请一片连续的虚拟地址空间，但不保证物理空间连续，也就是vmalloc接口。\n\nvmalloc的工作方式类似于kmalloc，只不过前者分配的内存虚拟地址连续，而物理地址则无需连续，因此不能用于dma缓冲区\n通过vmalloc获得的页必须一个一个地进行映射，效率不高，因此不得已时才使用，同时vmalloc分配的一般是大块内存\nvmalloc分配的一般是高端内存，只有当内存不够的时候，才会分配低端内存\nslab：\n三级结构\n层级\t作用\nSlab缓存\t每个缓存管理同一类型对象（如task_struct），包含多个Slab。\nSlab\t一组连续的物理页（来自伙伴系统），划分为多个对象槽（Object Chunk）。\n对象\t实际分配的内存单元，大小固定（如task_struct占1KB）。\n状态分类\nFull Slab：所有对象已被分配。\nPartial Slab：部分对象空闲（优先从此分配）。\nEmpty Slab：所有对象空闲（可返还给伙伴系统）。\nSlab分配器不直接处理任意大小的内存请求，而是通过以下方式分层管理：\n专用缓存（kmem_cache）\n为高频使用的内核对象（如task_struct）预定义固定大小的缓存（通过kmem_cache_create创建）。\n对象大小由类型本身决定（如sizeof(struct task_struct)）。\n通用缓存（kmalloc）\n提供一组预定义尺寸的Slab缓存（如32B、64B、128B、…、8KB等2的幂次方大小）。\n当调用kmalloc(size)时，内核选择最小适配的Slab缓存（如申请100B→分配128B的Slab）。\n","tags":["操作系统往年卷"]},{"title":"算子范数note","url":"/notes.github.io/2025/06/23/%E7%AE%97%E5%AD%90%E8%8C%83%E6%95%B0note/","content":"Euclid范数的酉不变性：\n对于向量 $X$ 和酉矩阵 $U$，有：\n$|UX|_2 = \\sqrt{(UX)^H UX} = \\sqrt{X^H U^H UX} = \\sqrt{X^H X} = |X|_2$\n即：\n$|UX|_2 = |X|_2$\n无穷范数是最大值的证明\n要证明对于复数 ( x_1, x_2, \\ldots, x_n )，有\n[\n\\lim_{p \\to \\infty} \\left( |x_1|^p + |x_2|^p + \\cdots + |x_n|^p \\right)^{1/p} = \\max { |x_1|, |x_2|, \\ldots, |x_n| },\n]\n其中 ( |x_i| ) 表示复数 ( x_i ) 的模长。\n证明过程如下：\n设 ( M = \\max { |x_1|, |x_2|, \\ldots, |x_n| } )，并假设 ( |x_k| = M ) 对于某个 ( k )。对于任意 ( p &gt; 0 )，有\n[\n|x_k|^p \\leq |x_1|^p + |x_2|^p + \\cdots + |x_n|^p \\leq n \\cdot M^p.\n]\n取 ( p )-th 根，得到\n[\nM \\leq \\left( \\sum_{i=1}^n |x_i|^p \\right)^{1/p} \\leq n^{1/p} \\cdot M.\n]\n当 ( p \\to \\infty )，( n^{1/p} \\to 1 )，因此由夹逼定理，\n[\n\\lim_{p \\to \\infty} \\left( \\sum_{i=1}^n |x_i|^p \\right)^{1/p} = M.\n]\n即\n[\n\\lim_{p \\to \\infty} \\left( |x_1|^p + |x_2|^p + \\cdots + |x_n|^p \\right)^{1/p} = \\max { |x_1|, |x_2|, \\ldots, |x_n| }.\n]\n证毕。\nFrobenius 范数的详细解释\n对于一个 ( m \\times n ) 的实（或复）矩阵 ( A )，其 Frobenius 范数定义为：\n[\n| A |F = \\sqrt{ \\sum{i=1}^m \\sum_{j=1}^n |a_{ij}|^2 }\n]\n用矩阵的迹表示\n[\n| A |_F = \\sqrt{ \\text{tr}(A^T A) } = \\sqrt{ \\text{tr}(A A^T) }\n]\n乘法不等式（次可乘性）\n如果 ( A ) 是 ( m \\times n ) 矩阵，( B ) 是 ( n \\times p ) 矩阵，则：\n[\n| AB |_F \\leq | A |_F \\cdot | B |_F\n]\n与谱范数的关系\nFrobenius 范数与 谱范数（spectral norm, ( | A |_2 )) 满足：\n[\n| A |_2 \\leq | A |_F \\leq \\sqrt{r} | A |_2\n]\n其中 ( r = \\text{rank}(A) )。\n与奇异值的关系\n设 ( \\sigma_1, \\sigma_2, \\ldots, \\sigma_r ) 是 ( A ) 的非零奇异值，则：\n[\n| A |_F = \\sqrt{ \\sigma_1^2 + \\sigma_2^2 + \\cdots + \\sigma_r^2 }\n]\n算子范数\n| 范数表示 ( |     | A   |  | )                         | 定义                                 | 说明                                                                                                      |\n| ---------- | — | — |\n| $          |     | A   |  | {\\infty}$ (最大行和范数) | $\\max{1 \\le i \\le m} \\sum_{j=1}^{n} | a_{ij}                                                                                                    | $    | 将矩阵的每一行元素的绝对值加起来，取最大值。                                            |\n| $          |     | A   |  | 1$ (最大列和范数)        | $\\max{1 \\le j \\le n} \\sum_{i=1}^{m} | a_{ij}                                                                                                    | $    | 将矩阵的每一列元素的绝对值加起来，取最大值。                                            |\n| $          |     | A   |  | 2$ (谱范数/算子范数)     | $\\sqrt{\\lambda{\\max}(A^H A)}$       | $A^H$ 是 $A$ 的共轭转置。 $\\lambda_{\\max}(A^H A)$ 是矩阵 $A^H A$ 的最大特征值。 也是矩阵$A$的最大奇异值。 |\n| $          |     | A   |  | F$ (Frobenius范数)       | $\\sqrt{\\sum{i=1}^{m} \\sum_{j=1}^{n} | a_{ij}                                                                                                    | ^2}$ | 将矩阵所有元素平方后加起来，再开根号。 相当于将矩阵看作一个向量，然后取其欧几里得范数。 |\n| $          |     | A   |  | {\\max}$ (最大模范数)     | $\\max{i,j}                          | a_{ij}                                                                                                    | $    | 矩阵中绝对值最大的元素。                                                                |\nEuclid空间是一个定义了一个二元实函数“内积”（即是向量）的线性空间。\n课上内容\n给定矩阵 $A \\in \\mathbb{R}^{m \\times n}$，向量 $b \\in \\mathbb{R}^m$，求 $x \\in \\mathbb{R}^n$ 使得 $Ax = b$.\n\n\n假设向量 $b$ 有误差，变成 $b + e$， $x$ 会怎么变化？\n\n\n$x = A^{-1}b \\rightarrow x = A^{-1}(b+e)$\n\n\n该线性方程组的条件数 $\\text{cond}(A) = \\frac{x \\text{的相对误差}}{b \\text{的相对误差}}$.\n\n\n记 $e$ 为 $b$ 的误差，则 $x$ 的误差为 $A^{-1}e$。任取一种向量范数，\n$\\text{cond}(A) = \\max_{e, b \\neq 0} \\frac{\\frac{|A^{-1}e|}{|A^{-1}b|}}{\\frac{|e|}{|b|}} = \\max_{e, b \\neq 0} \\frac{|A^{-1}e|}{|e|} \\frac{|b|}{|A^{-1}b|} = \\max_{e \\neq 0} \\frac{|A^{-1}e|}{|e|} \\max_{x \\neq 0} \\frac{|Ax|}{|x|}$\n\n\n矩阵的算子范数 $|A| := \\max_{x \\neq 0} \\frac{|Ax|}{|x|}$\n\n\n因此条件数 $\\text{cond}(A) = |A| \\cdot |A^{-1}|$\n\n\n条件数越大，表示问题越敏感，输入数据的微小扰动可能会导致解的巨大变化。 条件数越接近于1，表示问题越稳定。\n严格对角占优矩阵 (Strictly Diagonally Dominant Matrix)\n定义：我们称矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 为严格对角占优，如果它满足以下条件：\n$\\forall i \\in {1, 2, …, n},  |a_{ii}| &gt; \\sum_{j=1, j \\neq i}^{n} |a_{ij}|$\n换句话说，对于矩阵的每一行，对角线元素的绝对值必须大于该行所有其他元素绝对值之和。\n定理：\n如果方阵 $A$ 是严格对角占优的，则 $A$ 是可逆的，而且对于所有向量 $b$ 和初始猜测 $x^{(0)}$，对线性方程组 $Ax = b$ 使用 Jacobi 迭代都会收敛到唯一解。\n\n\nJacobi 迭代： Jacobi 迭代是一种求解线性方程组的迭代方法。它通过不断迭代更新解向量 $x$ 的每个分量，直到收敛到一个稳定值。 对于方程 $Ax = b$, Jacobi 迭代的公式可以写成如下形式：\n$x_i^{(k+1)} = \\frac{1}{a_{ii}} \\left(b_i - \\sum_{j=1, j \\neq i}^{n} a_{ij} x_j^{(k)} \\right)$， 其中 $x_i^{(k)}$ 表示第 $i$ 个分量在第 $k$ 次迭代的值。\n\n\n收敛性： 严格对角占优性保证了 Jacobi 迭代的收敛性。这意味着，无论我们选择什么样的初始猜测 $x^{(0)}$，Jacobi 迭代最终都会收敛到线性方程组 $Ax=b$ 的唯一解。\n\n\n重要性： 严格对角占优矩阵在数值线性代数中很重要，因为它们保证了某些迭代方法（如 Jacobi 迭代和 Gauss-Seidel 迭代）的收敛性。这在求解大型稀疏线性方程组时非常有用。\n\n\nρ(A) 的定义\nρ(A) (读作 “rho of A”) 是矩阵 A 的所有特征值的绝对值的最大值。 更正式地：\n$$ ρ(A) = max{|λ_1|, |λ_2|, …, |λ_n|}$$\n其中 $$λ_1, λ_2, …, λ_n$$ 是矩阵 A 的所有特征值（包括复数特征值）\n命题： $\\rho(A) &lt; 1$  当且仅当 $\\lim_{k\\to\\infty} A^k = 0$ (即 $A^k$ 收敛到零矩阵)。\n证明 $\\lim_{k\\to\\infty} A^k = 0 \\Rightarrow \\rho(A) &lt; 1$：\n设 $\\lambda$ 是 $A$ 的一个特征值， $v$ 是对应的特征向量。 那么 $Av = \\lambda v$。 因此，$A^k v = \\lambda^k v$。\n假设 $\\lim_{k\\to\\infty} A^k = 0$。 这意味着对于任何向量 $x$， $\\lim_{k\\to\\infty} A^k x = 0$。  特别地，$\\lim_{k\\to\\infty} A^k v = 0$。\n所以，$\\lim_{k\\to\\infty} \\lambda^k v = 0$。  因为 $v$ 是一个非零向量（特征向量的定义），所以必须有 $\\lim_{k\\to\\infty} \\lambda^k = 0$。\n这意味着 $|\\lambda| &lt; 1$。  因为 $\\lambda$ 是 $A$ 的任意特征值，所以 $A$ 的所有特征值的绝对值都小于 1。  因此，$\\rho(A) = \\max{|\\lambda_i|} &lt; 1$。\n结论：\n$\\rho(A) &lt; 1$  是 $\\lim_{k\\to\\infty} A^k = 0$ 的一个充分必要条件。 也就是说，这两个命题是等价的。  如果一个成立，另一个也一定成立。\n当 $A^k \\to 0$ (即 $\\rho(A) &lt; 1$) 的时候，对任意初始值都收敛的原因如下：\n考虑迭代过程 $x_{k+1} = Ax_k + b$。  固定点 $x^$ 满足 $x^ = Ax^* + b$。\n方法一：误差分析\n定义误差 $e_k = x_k - x^*$。  那么：\n$e_{k+1} = x_{k+1} - x^* = (Ax_k + b) - (Ax^* + b) = A(x_k - x^*) = Ae_k$\n因此， $e_k = A^k e_0 = A^k (x_0 - x^*)$。\n如果 $\\rho(A) &lt; 1$，那么 $\\lim_{k\\to\\infty} A^k = 0$。\n所以，$\\lim_{k\\to\\infty} e_k = \\lim_{k\\to\\infty} A^k (x_0 - x^*) = 0$。\n这意味着 $\\lim_{k\\to\\infty} x_k = x^$，即迭代收敛到固定点，且收敛性与初值$x_0$ 无关。 $|e_k| = |A^k(x_0-x^)| \\le |A^k| |x_0 - x^*| \\to 0$\n方法二：迭代展开\n$x_k = Ax_{k-1} + b = A(Ax_{k-2} + b) + b = A^2 x_{k-2} + Ab + b = \\dots = A^k x_0 + A^{k-1}b + A^{k-2}b + \\dots + Ab + b$\n可以写成：\n$x_k = A^k x_0 + \\sum_{i=0}^{k-1} A^i b = A^k x_0 + (A^{k-1} + A^{k-2} + \\dots + A + I)b$\n因为 $\\rho(A) &lt; 1$，所以 $\\lim_{k\\to\\infty} A^k = 0$。 并且 $\\sum_{i=0}^{\\infty} A^i = (I - A)^{-1}$ （这是一个矩阵几何级数）。\n因此：\n$\\lim_{k\\to\\infty} x_k = \\lim_{k\\to\\infty} A^k x_0 + \\lim_{k\\to\\infty}  \\sum_{i=0}^{k-1} A^i b = 0 + (I - A)^{-1} b = (I - A)^{-1} b$\n固定点 $x^$ 满足 $x^ = Ax^* + b$，因此 $x^* = (I - A)^{-1} b$。\n所以， $\\lim_{k\\to\\infty} x_k = x^* = (I - A)^{-1} b$。\n同样，迭代收敛到固定点，与初值 $x_0$ 无关。\n总结\n当 $\\rho(A) &lt; 1$ 时，误差会随着迭代次数的增加而减小（趋向于0），或者说迭代值会逐渐逼近固定点，与初始值无关。 这两种方法都展示了收敛性，并说明了为什么初值不影响最终的收敛结果。\nJacobi 迭代和 Gauss-Seidel 迭代\n1. Jacobi 迭代\n\n原理： Jacobi 迭代是一种求解线性方程组 $Ax = b$ 的迭代方法。它的基本思想是将系数矩阵 $A$ 分解为对角矩阵 $D$，下三角矩阵 $L$ 和上三角矩阵 $U$，即 $A = D - L - U$，然后将方程组转化为 $x = D^{-1}(L + U)x + D^{-1}b$ 的形式，并进行迭代求解。\n公式： 将 $A = D - L - U$ 代入 $Ax = b$，得到：\n$(D - L - U)x = b$\n$Dx = (L + U)x + b$\n$x = D^{-1}(L + U)x + D^{-1}b$\n因此，Jacobi 迭代的迭代公式为：\n$x^{(k+1)} = D^{-1}(L + U)x^{(k)} + D^{-1}b$\n或者写成逐个分量的形式：\n$x_i^{(k+1)} = \\frac{1}{a_{ii}} \\left(b_i - \\sum_{j=1, j \\neq i}^{n} a_{ij} x_j^{(k)}\\right)$,  $i = 1, 2, \\dots, n$\n其中，$x^{(k)}$ 表示第 $k$ 次迭代的解向量，$a_{ij}$ 是矩阵 $A$ 的元素，$b_i$ 是向量 $b$ 的元素。\n收敛性条件： Jacobi 迭代的收敛性取决于迭代矩阵 $B_J = D^{-1}(L + U)$ 的谱半径 $\\rho(B_J)$。\n\n如果 $\\rho(B_J) &lt; 1$，则 Jacobi 迭代收敛。\n充分条件：\n\n矩阵 $A$ 是严格对角占优矩阵（Strictly Diagonally Dominant）：对于所有 $i$，满足 $|a_{ii}| &gt; \\sum_{j=1, j \\neq i}^{n} |a_{ij}|$。\n矩阵 $A$ 是不可约的对角占优矩阵。\n\n\n\n\n算法步骤：\n\n将矩阵 $A$ 分解为 $D - L - U$。\n计算迭代矩阵 $B_J = D^{-1}(L + U)$ 和向量 $f = D^{-1}b$。\n选择初始向量 $x^{(0)}$。\n迭代计算 $x^{(k+1)} = B_J x^{(k)} + f$，直到满足收敛条件（例如，$|x^{(k+1)} - x^{(k)}| &lt; \\epsilon$，其中 $\\epsilon$ 是一个很小的正数）。\n\n\n优点：\n\n每次迭代的计算量较小。\n算法简单，容易实现。\n\n\n缺点：\n\n收敛速度可能较慢。\n收敛条件较为苛刻，可能不收敛。\n需要存储多个向量，占用内存空间较大。\n\n\n\n2. Gauss-Seidel 迭代\n\n原理： Gauss-Seidel 迭代也是一种求解线性方程组 $Ax = b$ 的迭代方法。与 Jacobi 迭代类似，它也将系数矩阵 $A$ 分解为 $A = D - L - U$。不同之处在于，Gauss-Seidel 迭代在计算 $x_i^{(k+1)}$ 时，会立即使用已经计算出的 $x_1^{(k+1)}, x_2^{(k+1)}, \\dots, x_{i-1}^{(k+1)}$，而不是像 Jacobi 迭代那样使用上一轮迭代的值。\n公式： 将 $A = D - L - U$ 代入 $Ax = b$，得到：\n$(D - L - U)x = b$\n$(D - L)x = Ux + b$\n$x = (D - L)^{-1}Ux + (D - L)^{-1}b$\n因此，Gauss-Seidel 迭代的迭代公式为：\n$x^{(k+1)} = (D - L)^{-1}Ux^{(k)} + (D - L)^{-1}b$\n或者写成逐个分量的形式：\n$x_i^{(k+1)} = \\frac{1}{a_{ii}} \\left(b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)}\\right)$,  $i = 1, 2, \\dots, n$\n收敛性条件： Gauss-Seidel 迭代的收敛性取决于迭代矩阵 $B_{GS} = (D - L)^{-1}U$ 的谱半径 $\\rho(B_{GS})$。\n\n如果 $\\rho(B_{GS}) &lt; 1$，则 Gauss-Seidel 迭代收敛。\n充分条件：\n\n矩阵 $A$ 是严格对角占优矩阵。\n矩阵 $A$ 是对称正定矩阵。\n\n\n\n\n算法步骤：\n\n将矩阵 $A$ 分解为 $D - L - U$。\n选择初始向量 $x^{(0)}$。\n对于 $i = 1, 2, \\dots, n$，依次计算 $x_i^{(k+1)} = \\frac{1}{a_{ii}} \\left(b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)}\\right)$。\n重复步骤 3，直到满足收敛条件。\n\n\n优点：\n\n通常比 Jacobi 迭代收敛速度更快。\n只需要存储一个向量，占用内存空间较小。\n\n\n缺点：\n\n每次迭代的计算量比 Jacobi 迭代略大。\n收敛性分析比 Jacobi 迭代更复杂。\n不适合并行计算，因为计算依赖于之前的结果。\n\n\n\n","tags":["其他"]},{"title":"面经","url":"/notes.github.io/2025/06/23/%E9%9D%A2%E7%BB%8F/","content":"0519\n幻读和GapLock\n先后两次执行相同的范围查询，却“前后结果不一样”：第二次多了（或少了）一些行——这些新出现（或消失）的行就称为“phantom rows”，现象称为幻读。\n例子（隔离级别：READ COMMITTED）\n\n事务 A：   START TRANSACTION;   SELECT * FROM orders WHERE amount &gt; 100;     -- 假设此时返回 5 行   ```  2. 同时，事务 B 插入了一条满足 amount &gt; 100 的新记录，并提交。  3. 事务 A 再次执行同样的查询：     ```sql   SELECT * FROM orders WHERE amount &gt; 100;   ```     这次会看到 6 行，多出来的那行就是“幻读”——之前不存在、现在却出现了。---Gap Lock（间隙锁） &amp; Next-Key Lock  InnoDB 在可重复读（REPEATABLE READ）及以上隔离级别下，对以下操作（UPDATE/DELETE/SELECT … FOR UPDATE/LOCK IN SHARE MODE）会使用 **Next-Key Lock**，本质上是：- Record Lock：锁住已有索引键值对应的记录  - Gap Lock：锁住两个相邻索引值之间的“间隙”（不含边界的记录本身）  这样，对一个范围 `a &lt; col ≤ b`，InnoDB 会在 `a` 和 `b` 之间，以及它们各自的左右相邻记录之间，全部加上 Gap Lock。  为什么 Gap Lock 能防止幻读？  - 事务 A 首次读到某个范围后，对该范围施加了 Gap Lock。  - 这样，事务 B 就 **无法** 在这个范围内插入任何新行（因为插入要占用某个间隙，而该间隙已被锁定）。  - 所以，即使事务 B 提交，事务 A 再次查询时，也不会看到“新幻影”——范围内的行集保持不变。简而言之，Gap Lock 在索引的“空白”上也加锁，阻止并发事务往原先读取过的范围插入新记录，从而杜绝幻读。“(*) 通过间隙锁可避免幻读，但需显式加锁”核心点：InnoDB 在默认的可重复读隔离级别下，可以通过加间隙锁（Gap Lock） 来避免幻读。但：如果没有显式地在事务中加锁（比如没有用 SELECT ... FOR UPDATE 或 LOCK IN SHARE MODE），那么幻读仍然可能发生。## Redis原子化操作的底层原理？Lua 脚本 (EVAL)将多条命令写在一个 Lua 脚本里，提交给 Redis 后，服务器会在脚本执行期间 完全阻塞 事件循环。脚本内所有调用 redis.call(...) 的命令都在同一个上下文里连贯执行，中途不会被打断。这样就保证了跨命令的复杂逻辑也能做到“要么全做完要么不做”。## RedLock### 1. 证明RedLock的正确性  RedLock的正确性基于以下设计原则和反驳争议的论点：  #### **核心保证机制**  - **多数派原则**：客户端需在过半（如5个实例中的3个）Redis实例上成功获取锁，确保即使部分节点故障，锁仍有效。  - **时钟误差容忍**：Redis作者Antirez指出，RedLock仅需时钟大体一致（允许微小误差），通过运维避免大幅时钟跳跃即可满足要求。  - **锁持有时间校验**：客户端在获取锁后计算实际耗时（T2-T1），若超过锁的过期时间则主动放弃锁，避免因网络延迟或GC导致锁冲突。  ---### 2. 设置唯一标识（UUID）和过期时间的原因  #### **唯一标识（UUID）的作用**  - **防误删锁**：释放锁时需验证UUID，确保只有锁的持有者能删除锁，避免其他客户端误删。    - *示例*：客户端A持有锁后因GC暂停，锁过期被客户端B获取。若A恢复后尝试释放锁，因UUID不匹配，无法删除B的锁。  - **避免锁冲突**：唯一标识确保锁的全局唯一性，防止不同客户端的锁请求混淆。  #### **过期时间（TTL）的作用**  - **防止死锁**：若客户端崩溃未主动释放锁，过期时间确保锁自动释放，避免资源永久阻塞。  - **活性保证**：限制锁的最大持有时间，确保其他客户端在超时后有机会获取锁。  ## Spring AOP及代理模式的实现？代理模式在Spring AOP中的实现​###（1）JDK动态代理​适用条件：目标对象实现了至少一个接口。​原理：基于Java反射机制，通过Proxy.newProxyInstance()生成代理对象，代理类实现与目标对象相同的接口。## 1. 核心概念- **Proxy 类**    `java.lang.reflect.Proxy`，Java 自带的动态代理入口，负责在运行时生成代理类字节码，并加载到 JVM。- **InvocationHandler 接口**    代理实例方法调用时的“调度中心”，所有对代理实例的方法调用，都会被转给它的 `invoke(...)` 方法去处理。- **目标对象（target）**    真正要被增强的对象，必须实现了一个或多个接口。---## 2. 代码回顾```javapublic class JdkProxyHandler implements InvocationHandler &#123;    private Object target;    public Object createProxy(Object target) &#123;        this.target = target;        // 生成并返回代理对象        return Proxy.newProxyInstance(            target.getClass().getClassLoader(),            target.getClass().getInterfaces(),            this        );        return Proxy.newProxyInstance(            target.getClass().getClassLoader(),            target.getClass().getInterfaces(),            this        );    &#125;    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        System.out.println(&quot;前置通知&quot;);        Object result = method.invoke(target, args);  // 调用真实对象方法        System.out.println(&quot;后置通知&quot;);        return result;    &#125;&#125;\n\n\n\n\ncreateProxy(...)：\n调用 Proxy.newProxyInstance，传入\n\n类加载器（和目标类一致）\n接口列表（目标对象实现的接口）\n当前 InvocationHandler 实例（把增强逻辑写在 invoke 里）\n\n\n\ninvoke(...)：\n真正发生“代理增强”的地方：前置处理 → 反射调用真实方法 → 后置处理。\nJDK 动态代理的限制：\n只能代理接口，无法直接给普通类（没有接口）生成代理。\n如果目标类没有任何接口，通常用 CGLIB、ByteBuddy 等库，它们是基于生成子类字节码来做代理。\n\n\nCGLIB代理\nCGLIB通过ASM字节码操作框架在运行时动态生成目标类的子类，并在子类中重写非final方法。代理类通过方法拦截器（MethodInterceptor）​将方法调用委托给用户定义的增强逻辑\nimport net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;public class CglibProxy implements MethodInterceptor &#123;    public Object createProxy(Class&lt;?&gt; targetClass) &#123;        Enhancer enhancer = new Enhancer();        enhancer.setSuperclass(targetClass);        enhancer.setCallback(this);        return enhancer.create();    &#125;    @Override    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123;        System.out.println(&quot;前置通知&quot;);        Object result = proxy.invokeSuper(obj, args);        System.out.println(&quot;后置通知&quot;);        return result;    &#125;&#125;\n关键步骤\n\n\n生成代理类：\n\n使用Enhancer类指定目标类（父类），生成其子类字节码。\n子类会继承目标类的所有非final方法，并重写这些方法以插入拦截逻辑。\n\n\n\n方法拦截：\n\n代理类重写的方法会调用MethodInterceptor.intercept()，该方法接收四个参数：\n\nobj：代理对象。\nmethod：目标方法。\nargs：方法参数。\nproxy：方法代理（用于调用父类原始方法）。\n\n\n\n\n\n与JDK动态代理的对比\n\n\n\n特性\nCGLIB代理\nJDK动态代理\n\n\n\n\n代理方式\n继承目标类，生成子类\n实现目标接口，生成接口实现类\n\n\n性能\n更高（直接调用父类方法，无反射开销）\n较低（反射调用接口方法）\n\n\n限制\n无法代理final类或方法\n只能代理实现了接口的类\n\n\n适用场景\nSpring AOP（无接口时默认使用）\n微服务接口代理\n\n\n\nSpring中的应用？\n@Aspect     // 表示这是一个切面类@Component  // 让Spring能自动扫描并管理这个Beanpublic class TxAspect &#123;    // 定义切入点：匹配com.example.service包下所有类的所有方法    @Pointcut(&quot;execution(* com.example.service.*.*(..))&quot;)    public void txPoint() &#123;&#125;        // 在切入点方法执行前执行    @Before(&quot;txPoint()&quot;)    public void begin() &#123; System.out.println(&quot;开启事务&quot;); &#125;        // 在切入点方法正常返回后执行    @AfterReturning(&quot;txPoint()&quot;)    public void commit() &#123; System.out.println(&quot;提交事务&quot;); &#125;        // 在切入点方法抛出异常时执行    @AfterThrowing(&quot;txPoint()&quot;)    public void rollback() &#123; System.out.println(&quot;回滚事务&quot;); &#125;&#125;\n和一个业务 Bean：\n@Servicepublic class UserServiceImpl implements UserService &#123;  public void register(String user) &#123; … &#125;&#125;\n\n启动时扫描到 TxAspect，生成一个 DefaultPointcutAdvisor，其中封装了 AspectJMethodBeforeAdvice、AspectJAfterReturningAdvice、AspectJAfterThrowingAdvice。\nAnnotationAwareAspectJAutoProxyCreator 在 postProcessAfterInitialization(userServiceImpl, &quot;userService&quot;) 时：\n\n发现该 Bean 类匹配切点 → 创建 ProxyFactory → 组装所有 AdviceChain → 调用 getProxy()。\n\n\n对外暴露的 userService 实际是一个代理。\n当客户端调用 userService.register(&quot;zhang&quot;) 时：\n\n代理的 invoke()（或 intercept()）被触发 → 构建 MethodInvocation 链 → 执行：\n\nAspectJMethodBeforeAdvice（开启事务）\n目标方法 register\nAspectJAfterReturningAdvice（提交事务）\n如果抛异常，则执行 AspectJAfterThrowingAdvice（回滚事务）\n\n\n\n\n\n0522\nJava中static和final关键字的联系与区别\n核心区别\nstatic和final是Java中两个独立但经常结合使用的关键字，它们的主要区别在于：\n\nstatic表示&quot;静态的&quot;，强调属于类而非对象，所有实例共享同一份拷贝\nfinal表示&quot;最终的&quot;，强调不可修改，变量值不能改、方法不能重写、类不能继承\n\n1. 修饰变量时的区别\n\n\n\n特性\nstatic变量\nfinal变量\n\n\n\n\n访问方式\n可通过类名直接访问\n需通过对象实例访问(除非也是static)\n\n\n线程安全\n非线程安全(需同步)\n线程安全(不可变)\n\n\n初始化时机\n类加载时初始化\n声明时或构造函数中初始化\n\n\n共享性\n所有实例共享同一份\n每个实例可以有自己的final变量\n\n\n存储位置\n方法区的静态区域\n基本类型在栈，引用类型在堆\n\n\n修改性\n可以修改\n初始化后不能修改\n\n\n\n2. 修饰方法时的区别\n\n\n\n特性\nstatic方法\nfinal方法\n\n\n\n\n调用方式\n通过类名调用\n通过对象实例调用\n\n\n重写性\n可被继承但不能重写(隐藏)\n不能被子类重写\n\n\n访问限制\n只能访问静态成员\n可以访问所有成员\n\n\n多态性\n不支持多态(静态绑定)\n支持多态(除非private)\n\n\n\n3. 修饰类时的区别\n\n\n\n特性\nstatic类(仅内部类)\nfinal类\n\n\n\n\n定义范围\n只能是内部类\n可以是任何类\n\n\n继承性\n可以继承其他类\n不能被继承\n\n\n实例化\n不依赖外部类实例\n可以正常实例化\n\n\n方法默认修饰\n方法不默认final\n所有方法隐式final\n\n\n\nJVM动态绑定\nJVM使用虚方法表(vtable)实现动态绑定：\n每个类都有一个虚方法表，包含该类所有可重写方法的入口地址\n子类继承父类的虚方法表，然后替换重写方法的入口地址\n调用方法时，JVM根据对象的实际类查找虚方法表，找到正确的方法实现\nread commit vs serializable\n关键区别总结\n\n\n\n特性\nRead Committed\nSerializable\n\n\n\n\n锁范围\n仅锁定现有行和部分间隙\n锁定所有可能影响的间隙（Next-Key Lock）\n\n\n锁释放时机\n行锁在读取后立即释放\n锁持续到事务结束\n\n\n索引依赖\n未覆盖的索引间隙可能导致幻读\n所有索引范围被锁定\n\n\n并发性能\n高\n低（锁冲突多）\n\n\n\n\n实现细节（以 MySQL InnoDB 为例）\n\n\nRead Committed：\n\n仅对访问到的行加行锁，间隙锁仅在唯一索引唯一性检查时使用。\n允许其他事务在未锁定的间隙插入数据。\n\n\n\nSerializable：\n\n所有读取操作自动转换为 SELECT ... FOR SHARE，对查询涉及的索引范围加 Next-Key Lock。\n完全禁止其他事务在锁定范围内插入或删除。\n\n\n\nHashMap\n\n1. HashMap 的基本工作原理\nHashMap 底层是一个 Node&lt;K,V&gt;[] 数组（JDK 1.7 叫 Entry[]），每个元素要么为 null，要么是一个链表／红黑树的头节点。\n\n\nput(K key, V value)\n\n计算 hash = hash(key)；\n如果 table 未初始化，则调用 resize() 初始化（默认容量 16）；\n根据 index = (table.length–1) &amp; hash 定位桶位置；\n若 table[index] 为 null，直接创建 new Node(key, value) 放入；\n否则遍历链表／树：\n\n找到相同 key，则覆盖 value；\n否则插入新节点（JDK 1.7 链表头插，JDK 1.8 链表尾插并可能触发“树化”）；\n\n\n插入后若 size &gt; threshold(=capacity×loadFactor)，则触发 resize() 扩容。\n\n\n\nget(Object key)\n\n计算 hash 和 index；\n遍历 table[index] 上的链表／树，按 key.equals() 找到即返回 value，否则返回 null。\n\n\n\nV get(Object key) &#123;  int hash = spread(key.hashCode());  Node&lt;K,V&gt; e = table[(n-1) &amp; hash];  while (e != null) &#123;    if (e.hash==hash &amp;&amp; Objects.equals(e.key, key))      return e.value;    e = e.next;  &#125;  return null;&#125;\n\nconcurrentHashMap\nJDK 1.8 实现（CAS + synchronized + 链表/树化）\n\n去掉 Segment，底层直接是 Node&lt;K,V&gt;[] table；\n初始化 table：采用 CAS 保证只有一个线程完成第一次初始化；\nput 操作：\n\nCAS 尝试将新节点放入空桶；\n若 CAS 失败（已有节点或并发竞争），对该桶头节点加 synchronized(bin) 锁，安全地在链表尾部插入或在必要时树化；\n解锁后，如需扩容，则发起一次 “单线程” 扩容（转移节点时用 CAS 标记前驱为 forwardingNode，其它线程在访问时可以帮忙迁移）；\n\n\nget 操作：\n\n全程无锁，只做 volatile 读 + 链表／树遍历。\n\n\n扩容（resize）：\n\n不再一次性锁整个 table，而是通过 CAS+forwardingNode 让多个线程协作“分段”搬运节点；\n\n\n优点：更轻量级的并发控制，高并发下性能优；内存开销更小。\n\nBean\n以下是整理的 Spring Bean 生命周期执行过程的逻辑流程图，按阶段划分并标注关键步骤：\n\nSpring Bean 生命周期完整流程\n1. 实例化阶段\n\n步骤1：Spring 容器启动，扫描并加载 Bean 定义（BeanDefinition）。\n步骤2：通过反射调用构造方法实例化 Bean（默认使用无参构造，或指定构造器）。\n\n2. 属性注入阶段\n\n步骤3：依赖注入（DI），通过 setter 或字段注入完成 Bean 的属性赋值（如 @Autowired、@Value）。\n\n3. Aware 接口回调（感知容器信息）\n\n步骤4：若实现 BeanNameAware，调用 setBeanName(String beanId) 传入 Bean 的 ID。\n步骤5：若实现 BeanFactoryAware，调用 setBeanFactory(BeanFactory factory) 传入工厂实例。\n步骤6：若实现 ApplicationContextAware，调用 setApplicationContext(ApplicationContext ctx) 传入应用上下文。\n\n4. 初始化前阶段（BeanPostProcessor 前置处理）\n\n步骤7：若存在 BeanPostProcessor，调用 postProcessBeforeInitialization(Object bean, String beanName)（AOP 代理在此生成）。\n\n5. 初始化阶段\n\n步骤8：若实现 InitializingBean，调用 afterPropertiesSet() 方法。\n步骤9：若配置了 init-method 或使用 @PostConstruct，调用指定的初始化方法。\n\n6. 初始化后阶段（BeanPostProcessor 后置处理）\n\n步骤10：若存在 BeanPostProcessor，调用 postProcessAfterInitialization(Object bean, String beanName)。此时 Bean 已完全就绪，可被使用。\n\n7. 使用阶段\n\n步骤11：\n\nSingleton：Bean 被放入 Spring IoC 单例缓存池，由容器管理生命周期。\nPrototype：Bean 交给调用方管理，Spring 不再跟踪其生命周期。\n\n\n\n8. 销毁阶段\n\n步骤12：若实现 DisposableBean，调用 destroy() 方法。\n步骤13：若配置了 destroy-method 或使用 @PreDestroy，调用指定的销毁方法。\n\n","tags":["其他"]},{"title":"谱分解note","url":"/notes.github.io/2025/06/23/%E8%B0%B1%E5%88%86%E8%A7%A3note/","content":"正交基线性组合的推导\n任意向量可以表示为一组正规正交基 ${v_i}$ 的线性组合，并给出了几个关键公式。让我们一步步推导这些结果。\n正交基的性质\n首先，我们有一组正规正交基 ${v_i}$，这意味着：\n\n$v_i^T v_j = 0$ 当 $i \\neq j$ (正交性)\n$v_i^T v_i = 1$ (单位向量，即正规化)\n\n恒等矩阵的表示\n$$I = \\sum_i v_i v_i^T$$\n推导：\n对于正交基，如果我们对任意向量 $x$ 应用上述和式：\n$$\\left(\\sum_i v_i v_i^T\\right)x = \\sum_i v_i (v_i^T x)$$\n由于 $v_i^T x$ 是标量，它表示 $x$ 在 $v_i$ 方向上的投影分量。因此，上式实际上是将 $x$ 分解为各个正交方向的分量，然后再重新组合，结果仍为 $x$。这正是恒等矩阵的作用，所以 $\\sum_i v_i v_i^T = I$。\n矩阵 $A$ 的谱分解\n$$Av_i = \\lambda_i v_i \\Rightarrow A = \\sum_i \\lambda_i v_i v_i^T$$\n推导：\n这里 $v_i$ 是矩阵 $A$ 的特征向量，$\\lambda_i$ 是对应的特征值。要证明 $A = \\sum_i \\lambda_i v_i v_i^T$，我们可以验证对任意特征向量 $v_j$，应用两边得到相同结果：\n左边：$Av_j = \\lambda_j v_j$\n右边：\n$$\\left(\\sum_i \\lambda_i v_i v_i^T\\right)v_j = \\sum_i \\lambda_i v_i (v_i^T v_j)$$\n由于正交性，当 $i \\neq j$ 时，$v_i^T v_j = 0$；当 $i = j$ 时，$v_i^T v_j = 1$。因此：\n$$\\sum_i \\lambda_i v_i (v_i^T v_j) = \\lambda_j v_j$$\n两边结果相同，因此 $A = \\sum_i \\lambda_i v_i v_i^T$。这就是矩阵的谱分解表示。\n矩阵 $A$ 的逆矩阵\n$$A^{-1} = \\sum_i \\lambda_i^{-1} v_i v_i^T, \\quad \\text{if } A^{-1} \\text{ exists.}$$\n推导：\n当所有 $\\lambda_i \\neq 0$ 时，$A$ 是可逆的。我们需要证明 $A \\cdot A^{-1} = I$：\n$$A \\cdot A^{-1} = \\left(\\sum_i \\lambda_i v_i v_i^T\\right) \\cdot \\left(\\sum_j \\lambda_j^{-1} v_j v_j^T\\right)$$\n使用矩阵乘法的分配律展开：\n$$A \\cdot A^{-1} = \\sum_i \\sum_j \\lambda_i \\lambda_j^{-1} (v_i v_i^T) (v_j v_j^T)$$\n进一步计算内部矩阵乘积：\n$$(v_i v_i^T) (v_j v_j^T) = v_i (v_i^T v_j) v_j^T =\n\\begin{cases}\nv_i v_j^T &amp; \\text{if } i = j \\\n0 &amp; \\text{if } i \\neq j\n\\end{cases}$$\n因此：\n$$A \\cdot A^{-1} = \\sum_i \\lambda_i \\lambda_i^{-1} v_i v_i^T = \\sum_i v_i v_i^T = I$$\n这证明了 $A^{-1} = \\sum_i \\lambda_i^{-1} v_i v_i^T$。\n矩阵 $A$ 的伪逆 (Moore-Penrose 逆)\n$$A^+ = \\sum_{i:\\lambda_i\\neq 0} \\lambda_i^{-1} v_i v_i^T$$\n推导：\n当矩阵 $A$ 不是满秩（即有些 $\\lambda_i = 0$）时，$A$ 不可逆。伪逆 $A^+$ 是逆矩阵概念的推广，仅在非零特征值对应的子空间上计算&quot;逆&quot;。\n从计算角度看，伪逆忽略了零特征值对应的特征向量，只在非零特征值对应的子空间上计算逆。故有：\n$$A^+ = \\sum_{i:\\lambda_i\\neq 0} \\lambda_i^{-1} v_i v_i^T$$\n我们可以验证伪逆满足以下性质：\n\n$AA^+A = A$\n$A^+AA^+ = A^+$\n$(AA^+)^T = AA^+$\n$(A^+A)^T = A^+A$\n\n这些性质可以通过将 $A$ 和 $A^+$ 的谱分解表示代入方程并利用正交基的性质来验证。\n以上就是正交基线性组合表示矩阵的一系列重要公式的详细推导。\n格什戈林圆盘定理（Gershgorin Circle Theorem）详解\n格什戈林圆盘定理是矩阵分析中的一个重要结果，它提供了矩阵特征值位置的估计。我将详细解释这个定理及其证明。\n定理内容\n定理指出：\n\n设 $A$ 为 $n \\times n$ 矩阵，定义 $R_i := \\sum_{j \\neq i} |a_{ij}|$（即第 $i$ 行除对角元素外所有元素的绝对值之和）\n则 $A$ 的所有特征值都位于复平面上的某些圆盘 $D(a_{ii}, R_i)$ 内\n\n这里，$D(a_{ii}, R_i)$ 表示以对角元素 $a_{ii}$ 为圆心，$R_i$ 为半径的圆盘。\n证明解释\n证明的关键步骤如下：\n\n\n选取特征值和特征向量：\n\n取 $A$ 的一个特征值 $\\lambda$ 和对应的特征向量 $v$\n设 $i$ 使得 $|v_i|$ 为向量 $v$ 中绝对值最大的分量\n\n\n\n特征值方程：\n\n根据特征值定义 $Av = \\lambda v$\n这意味着 $\\sum_j a_{ij} v_j = \\lambda v_i$\n将此式改写为 $\\sum_{j \\neq i} a_{ij} v_j = (\\lambda - a_{ii})v_i$\n\n\n\n推导不等式：\n\n$|\\lambda - a_{ii}| = |\\sum_{j \\neq i} \\frac{a_{ij} v_j}{v_i}|$\n$\\leq \\sum_{j \\neq i} | \\frac{a_{ij} v_j}{v_i}|$\n$\\leq \\sum_{j \\neq i} |a_{ij}| \\cdot |\\frac{v_j}{v_i}|$\n由于 $|v_i|$ 是最大值，所以 $|\\frac{v_j}{v_i}| \\leq 1$\n因此 $|\\lambda - a_{ii}| \\leq \\sum_{j \\neq i} |a_{ij}| = R_i$\n\n\n\n结论：\n\n这表明特征值 $\\lambda$ 到对角元素 $a_{ii}$ 的距离不超过 $R_i$\n因此 $\\lambda$ 必须位于以 $a_{ii}$ 为圆心，$R_i$ 为半径的圆盘内\n\n\n\n定理意义\n\n这个定理提供了矩阵特征值的位置估计，不需要求解特征方程。\n所有特征值都位于 $n$ 个圆盘的并集内。\n如果圆盘互不相交，则每个圆盘恰好包含一个特征值。\n对角占优的矩阵（即 $|a_{ii}| &gt; R_i$）可以确保所有特征值非零。\n\n这个定理在数值分析、矩阵稳定性分析和迭代方法收敛性证明中有广泛应用。\n不，行格尔绍戈林圆盘（Row Gershgorin disc）和列格尔绍戈林圆盘（Column Gershgorin disc）不一定等价，但所有特征值都必须位于它们的并集中。让我详细解释一下，并用LaTeX格式化。\n定义\n\n行格尔绍戈林圆盘（Row Gershgorin disc）： 对于一个 $n \\times n$ 矩阵 $A$，第 $i$ 个行格尔绍戈林圆盘的中心是 $a_{ii}$，半径是该行中非对角线元素的绝对值之和，即 $R_i = \\sum_{j \\neq i} |a_{ij}|$.\n列格尔绍戈林圆盘（Column Gershgorin disc）： 对于一个 $n \\times n$ 矩阵 $A$，第 $j$ 个列格尔绍戈林圆盘的中心是 $a_{jj}$，半径是该列中非对角线元素的绝对值之和，即 $C_j = \\sum_{i \\neq j} |a_{ij}|$.\n\n定理回顾\n格尔绍戈林圆盘定理指出：\n\n$A$ 的所有特征值位于行圆盘的并集中：  $\\lambda(A) \\subseteq \\bigcup_{i=1}^{n} D(a_{ii}, R_i)$\n$A$ 的所有特征值位于列圆盘的并集中：  $\\lambda(A) \\subseteq \\bigcup_{j=1}^{n} D(a_{jj}, C_j)$\n\n行盖尔圆盘和列盖尔圆盘通常不完全等价。 为了更好地估计特征值的位置，通常将行圆盘和列圆盘的并集结合起来考虑。 也就是说：\n$\\lambda(A) \\subseteq \\left( \\bigcup_{i=1}^{n} D(a_{ii}, R_i) \\right) \\cap \\left( \\bigcup_{j=1}^{n} D(a_{jj}, C_j) \\right)$\n这样的估计会更加精确。\nBauer-Fike定理及其证明\n定理陈述\n设 $\\mu$ 是矩阵 $A+E \\in \\mathbb{R}^{n\\times n}$ 的一个特征值，且存在可逆矩阵 $P$ 使得 $P^{-1}AP=D=\\text{diag}(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n)$，则有：\n$$\\min_{\\lambda\\in\\sigma(A)}|\\lambda-\\mu|\\leq |P^{-1}|_p|P|_p|E|_p$$\n其中 $|\\cdot|_p$ 表示 $p$ 范数，$p=1,2,\\infty$。\n证明步骤\n\n\n首先，我们只需考虑 $\\mu\\notin\\sigma(A)$ 的情况（即 $\\mu$ 不是 $A$ 的特征值）。此时 $D-\\mu I$ 非奇异。\n\n\n设 $x$ 是 $A+E$ 对应于特征值 $\\mu$ 的特征向量，则：\n$$(A+E-\\mu I)x=0$$\n\n\n左乘 $P^{-1}$ 得到：\n$$(D-\\mu I)(P^{-1}x)=-(P^{-1}EP)(P^{-1}x)$$\n\n\n因此：\n$$P^{-1}x=-(D-\\mu I)^{-1}(P^{-1}EP)(P^{-1}x)$$\n\n\n$P^{-1}x$ 是非零向量。对上式两边取 $p$ 范数：\n$$|(D-\\mu I)^{-1}(P^{-1}EP)|_p\\geq 1$$\n\n\n对角矩阵 $(D-\\mu I)^{-1}$ 的范数为：\n$$|(D-\\mu I)^{-1}|p=\\frac{1}{m},\\quad \\text{其中} \\quad m=\\min{\\lambda\\in\\sigma(A)}|\\lambda-\\mu|$$\n\n\n根据范数的性质，有：\n$$|P^{-1}|_p|E|_p|P|_p\\geq m$$\n\n\n这就证明了定理中的不等式 (1.5)。\n补充说明\n\n\n条件数 $\\text{cond}(P)=|P^{-1}||P|$ 是特征值扰动的放大系数。\n\n\n由于将 $A$ 对角化的相似变换矩阵 $P$ 不是唯一的，因此定义：\n$$\\nu(A)=\\inf{\\text{cond}(P)|P^{-1}AP=\\text{diag}(\\lambda_1,\\lambda_2,\\cdots,\\lambda_n)}$$\n\n\n$\\nu(A)$ 称为特征值问题的条件数。当 $\\nu(A)$ 较小时，矩阵微小扰动只会带来特征值的微小扰动。\n\n\n实际应用中，$\\nu(A)$ 难以计算，有时只对一个特定的 $P$ 计算 $\\text{cond}(P)$ 来代替 $\\nu(A)$。\n\n\n这个定理的重要意义在于：它给出了矩阵受扰动后，其特征值偏离原特征值的上界估计，这个上界与矩阵的条件数和扰动大小有关。\n第 $k$ 个特征值 $\\lambda_k$\n现在我们看更一般的 $\\lambda_k$（第 $k$ 个特征值），它稍微复杂一点，因为它需要在某些限制条件下找最大或最小值。公式有两种等价的表达方式：\n第一种表达：$\\lambda_k = \\min_{x \\neq 0, x^\\top v_i = 0, \\forall i \\in {1, \\dots, k-1}} \\frac{x^\\top A x}{x^\\top x}$\n\n意思：\n你要找一个方向 $x$，让 $\\frac{x^\\top A x}{x^\\top x}$ 尽量小，但有个条件：$x$ 必须跟前 $k-1$ 个特征向量（$v_1, v_2, \\dots, v_{k-1}$）垂直。\n通俗解释：\n想象你在 $n$ 维空间里，前 $k-1$ 个特征向量是已经占好的“最佳方向”（对应 $\\lambda_1$ 到 $\\lambda_{k-1}$）。现在你不能走这些方向，只能找一个新的方向，尽量让 $A$ 的效果最小。这个最小值就是 $\\lambda_k$。\n\n第二种表达：$\\lambda_k = \\max_{U: \\dim U = k} \\min_{x \\in U, x \\neq 0} \\frac{x^\\top A x}{x^\\top x}$\n\n意思：\n你先挑一个 $k$ 维的空间 $U$（包含 $k$ 个独立方向），然后在这个空间里找一个方向 $x$，让 $\\frac{x^\\top A x}{x^\\top x}$ 最小。接着，在所有可能的 $k$ 维空间中，挑一个让这个最小值最大的。结果就是 $\\lambda_k$。\n通俗解释：\n假设你在选一个 $k$ 人团队，每个人代表一个方向。你要保证团队里最差的表现（最小拉伸）尽可能好。$\\lambda_k$ 就是你能找到的最优团队的最差表现。\n\n\n另一种角度：$\\lambda_k = \\max_{x \\neq 0, x^\\top v_i = 0, \\forall i \\in {k+1, \\dots, n}} \\frac{x^\\top A x}{x^\\top x}$\n\n意思：\n这次你找一个方向 $x$，让 $\\frac{x^\\top A x}{x^\\top x}$ 尽量大，但 $x$ 必须跟后面的特征向量（$v_{k+1}, \\dots, v_n$）垂直。\n通俗解释：\n你把后面 $n-k$ 个较小的特征值方向“封锁”掉，只在剩下的空间里找最大的拉伸效果，结果就是 $\\lambda_k$。\n\n\n如果 $A$ 是正定阵，\n$$\n\\frac{x^T A x}{x^T x} = \\max_{x\\neq 0} \\frac{x^T A x}{|x|2^2} = \\lambda{\\max}(A)\n$$\n则\n$$\n\\text{cond}_2(A) = |A|_2|A^{-1}|_2\n$$\n$$\n|A|2 = \\max{|x|2 \\leq 1} \\sqrt{x^T A^T A x} = \\sqrt{\\lambda{\\max}(A^T A)}\n$$\n这里假设$A$是正定矩阵\n否则要写成奇异值\n$$\n\\text{cond}2(A) = \\frac{\\lambda{\\max}(A)}{\\lambda_{\\min}(A)}\n$$\nCayley-Hamilton 定理证明\n定理 (Cayley-Hamilton)\n对于任意 $n \\times n$ 矩阵 $A$，如果我们定义其特征多项式 $q_A(x) = \\det(A - xI)$，则：\n$$q_A(A) = 0$$\n其中 $0$ 表示 $n \\times n$ 的零矩阵。\n证明 (sketch)\n我们首先考虑 $A$ 是可对角化的情况。\n步骤 1: 特征多项式的性质\n假设 $A$ 是可对角化的，那么 $q_A(A)$ 也必然是可对角化的。\n步骤 2: 特征值与特征向量分析\n取 $A$ 的任一特征值 $\\lambda \\in \\mathbb{R}$ 和对应的特征向量 $v$ 满足 $Av = \\lambda v$。\n步骤 3: 特征多项式作用于特征向量\n由步骤 1 的观察可知，$v$ 也是 $q_A(A)$ 的特征向量，且其对应的特征值为：\n$$q_A(A)v = q_A(\\lambda)v$$\n步骤 4: 特征多项式在特征值处的取值\n由特征多项式的定义，对于任意特征值 $\\lambda$，有：\n$$q_A(\\lambda) = \\det(A - \\lambda I) = 0$$\n步骤 5: 推导 $q_A(A)$ 的特征值\n因此：\n$$q_A(A)v = q_A(\\lambda)v = 0 \\cdot v = 0$$\n这表明 $q_A(A)$ 的每个特征向量对应的特征值均为 0。\n步骤 6: 结论\n由于 $q_A(A)$ 可对角化，且其所有特征值均为 0，因此 $q_A(A)$ 只能是全零矩阵。\n对于不可对角化的矩阵，可以通过 Jordan 标准型或极限论证完成证明。\n最小二乘法：\n求 $\\lambda$ 以最小化 $||Ax - \\lambda x||_2^2$\n$||Ax - \\lambda x||_2^2 = ||Ax||_2^2 + \\lambda^2 ||x||_2^2 - 2\\lambda x^\\top Ax$\n法线方程：$\\lambda = \\frac{x^\\top Ax}{x^\\top x}$, Rayleigh quotient!\n定理：\n对于实数对称矩阵 $A$，假设近似特征向量 $x$ 满足 $||x||_2 = 1$，并且实数 $\\lambda$ 满足 $||Ax - \\lambda x||_2 &lt; \\epsilon$，则有\n$\\min_{1 \\leq j \\leq n} |\\lambda_j - \\lambda| &lt; \\epsilon$\n证明：\n对于实数对称矩阵，可以选择特征向量 $v_1, v_2, \\dots, v_n$ 使得它们是正交且归一化的。 展开 $x = \\alpha_1 v_1 + \\alpha_2 v_2 + \\dots + \\alpha_n v_n$\n$||Ax - \\lambda x||2^2 = \\left| \\sum{j=1}^n \\alpha_j (\\lambda_j - \\lambda) v_j \\right|_2^2$\n$= \\sum_{j=1}^n \\alpha_j^2 (\\lambda_j - \\lambda)^2 ||v_j||_2^2$\n$= \\sum_{j=1}^n \\alpha_j^2 (\\lambda_j - \\lambda)^2$\n$\\geq \\min_{1 \\leq j \\leq n} (\\lambda_j - \\lambda)^2 \\sum_{j=1}^n \\alpha_j^2$\n其中 $\\sum_{j=1}^n \\alpha_j^2 = ||x||_2^2 = 1$， 所以 $\\epsilon^2 &gt; ||Ax - \\lambda x||2^2 \\geq \\min{1 \\leq j \\leq n} (\\lambda_j - \\lambda)^2$\n因此 $\\epsilon &gt; \\min_{1 \\leq j \\leq n} |\\lambda_j - \\lambda|$\n","tags":["其他"]},{"title":"设备管理笔记","url":"/notes.github.io/2025/06/23/%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86%E7%AC%94%E8%AE%B0/","content":"一、层次结构框架\n典型I/O子系统分为五层（如图5-3）：\n\n用户层I/O软件（库函数、SPOOLing）\n设备独立性软件（命名映射、缓冲管理）\n设备驱动程序（硬件命令转换）\n中断处理程序（硬件信号处理）\n硬件层（控制器、设备）\n\n二、层级间交互机制\n1. 用户层与设备无关层的接口\n\n系统调用传递：用户程序通过read/write等系统调用进入内核态，例如printf调用会触发write系统调用\n参数标准化：用户层传递逻辑设备名（如/dev/sda），设备无关层通过逻辑设备表（LUT）将其映射为物理设备地址\n错误屏蔽：设备无关层过滤底层硬件错误（如磁盘重试机制），仅向上报告无法处理的异常\n\n2. 设备无关层与驱动层的协作\n\n请求封装：将逻辑I/O请求（如文件偏移量）转换为物理块地址，并通过设备控制表（DCT）选择对应驱动程序\n资源调度：执行I/O调度算法（如磁盘电梯算法），合并相邻请求优化性能\n缓冲区管理：在内核空间建立数据缓冲区，协调用户空间与设备速度差异（如PageCache机制）\n\n3. 驱动层与硬件控制器的交互\n\n寄存器操作：驱动程序向设备控制器的命令寄存器写入操作码（如SCSI命令），设置DMA传输参数\n状态轮询：通过控制器状态寄存器检测设备就绪状态，或等待中断信号\n协议适配：将标准I/O命令转换为设备专属指令序列（如不同品牌打印机的控制码）\n\n4. 硬件层与中断处理的联动\n\n中断触发：设备完成操作后通过中断控制器（如APIC）向CPU发送信号\n上下文保存：中断处理程序保存被中断进程的寄存器状态到内核栈\n状态反馈：读取控制器状态寄存器，将结果写入内核缓冲区并唤醒阻塞进程\n\n三、关键数据流示例（以磁盘读取为例）\n\n用户层：fread()调用触发系统调用read(fd, buf, size)\n设备无关层：\n\n检查文件权限\n将文件偏移转换为物理扇区号\n分配内核缓冲区并加入I/O调度队列\n\n\n驱动层：\n\n向磁盘控制器发送READ SECTOR命令\n设置DMA传输目标地址为内核缓冲区\n\n\n硬件层：\n\n磁盘控制器执行寻道操作\nDMA引擎直接将数据写入内核缓冲区\n\n\n中断处理：\n\nDMA完成中断触发后，将数据从内核缓冲区复制到用户缓冲区\n唤醒等待该I/O完成的进程\n\n\n\n四、分层设计的优势\n\n接口标准化：每层仅暴露抽象接口（如驱动层的read/write方法），隐藏实现细节\n错误隔离：设备驱动故障不会导致上层崩溃（如USB设备异常仅影响对应驱动）\n扩展性：新增设备只需实现驱动层，无需修改上层逻辑（如NVMe SSD兼容SATA接口）\n性能优化：各层独立实现缓存策略（用户层缓冲区 vs 内核PageCache）\n\n五、跨层优化技术\n\n零拷贝（Zero-Copy）：绕过内核缓冲区，直接让用户空间与DMA引擎交互\n异步I/O：通过io_uring等机制实现请求批量提交和完成事件通知\n直接内存访问（DMA）：硬件控制器直接访问内存，减少CPU介入\n\n","tags":["操作系统往年卷/2020-OS"]},{"title":"面经4","url":"/notes.github.io/2025/06/23/%E9%9D%A2%E7%BB%8F4/","content":"0528\n\nbinlog是什么？\nMySQL的binlog（Binary Log）是一种二进制日志文件，记录了所有对数据库的修改操作（如INSERT、UPDATE、DELETE等），但不包括查询语句（如SELECT）。它以事件形式存储，包含操作的时间、执行时长等信息。\n\n主要作用：\n​数据恢复：通过回放binlog可将数据库恢复到特定时间点。\n​主从复制：主库的binlog会被同步到从库，实现数据实时同步。\n​审计：记录所有数据变更，用于安全审计。\nbinlog的三种格式：\n​Statement-based：记录SQL语句，日志量小但可能因非确定性函数导致主从不一致。\n​Row-based：记录行数据变更，精确但日志量大。\n​Mixed：混合模式，自动选择Statement或Row格式。\n2. MySQL中的日志类型及区别\nMySQL主要日志类型包括：\n​binlog​（二进制日志）：\n作用：数据恢复、主从复制、审计。\n存储引擎无关，由Server层实现。\n​redo log​（重做日志）：\n作用：保证事务的持久性，崩溃恢复时重放未提交的事务。\nInnoDB特有，物理日志，记录页面的修改。\n​undo log​（回滚日志）：\n作用：实现事务回滚和MVCC（多版本并发控制）。\nInnoDB特有，逻辑日志，记录修改前的数据。\nGET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。\nPOST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。\n当使用 ETag 字段实现的协商缓存的过程：\n当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；\n当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期：\n如果没有过期，则直接使用本地缓存；\n如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；\n服务器再次收到请求后，会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较：\n如果值相等，则返回 304 Not Modified，不会返回资源；\n如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；\n如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源\nHTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞。\n注意!!!\n实际上 HTTP/1.1 管道化技术不是默认开启，而且浏览器基本都没有支持，所以后面所有文章讨论 HTTP/1.1 都是建立在没有使用管道化的前提。大家知道有这个功能，但是没有被使用就行了\n非对称加密的用途主要在于通过「私钥加密，公钥解密」的方式，来确认消息的身份，我们常说的数字签名算法，就是用的是这种方式，不过私钥加密内容不是内容本身，而是对内容的哈希值加密。\n然后把你爸爸的「个人信息 + 公钥 + 数字签名」打包成一个数字证书，也就是说这个数字证书包含你爸爸的公钥。\nTLS如何为HTTP提供安全性？——以一次完整HTTPS请求为例\nTLS（Transport Layer Security）通过加密、身份验证和完整性保护三大机制，将不安全的HTTP协议升级为安全的HTTPS。以下是一次完整HTTPS请求的详细流程，展示TLS如何逐步建立安全通信：\n\n1. 客户端发起HTTPS请求（Client Hello）\n\n步骤：\n用户在浏览器输入 https://example.com，浏览器（客户端）向服务器发起TCP连接（默认端口443）。\n关键动作：\n\n发送支持的TLS版本（如TLS 1.3）。\n列出支持的加密套件（如 TLS_AES_256_GCM_SHA384）。\n生成随机数 Client Random（用于后续密钥生成）。\n\n\n\n\n2. 服务器响应（Server Hello）\n\n步骤：\n服务器选择双方均支持的TLS版本和加密算法，并返回：\n\nServer Random（另一个随机数）。\n数字证书（包含服务器公钥、域名、CA签名等）。\n（可选）要求客户端证书（用于双向认证）。\n\n\n证书作用：\n\n验证服务器身份（防止中间人攻击）。\n提供公钥用于密钥交换（如RSA或ECDHE）。\n\n\n\n\n3. 客户端验证证书\n\n验证内容：\n\nCA可信性：检查证书是否由受信任的CA（如Let’s Encrypt）签发。\n有效期：确保证书未过期。\n域名匹配：证书中的域名与请求的 example.com 一致。\n吊销状态：通过OCSP或CRL检查证书是否被吊销。\n\n\n若验证失败：浏览器显示警告（如“证书无效”）。\n\n\n4. 密钥交换（Key Exchange）\n\n非对称加密阶段：\n\nRSA方式：\n客户端生成 Pre-Master Secret，用服务器公钥加密后发送，服务器用私钥解密。\nECDHE（推荐）：\n双方通过椭圆曲线Diffie-Hellman算法动态生成 Pre-Master Secret，支持前向保密（即使私钥泄露，历史会话也无法解密）。\n\n\n生成会话密钥：\n客户端和服务器使用 Client Random + Server Random + Pre-Master Secret，通过伪随机函数（PRF）生成：\n\n对称加密密钥（如AES-256密钥）。\nMAC密钥（用于校验数据完整性）。\n\n\n\n\n5. 握手完成（Finished）\n\n步骤：\n双方发送加密的 Finished 消息，验证握手是否成功。\n作用：\n\n确认密钥协商无误。\n确保通信未被篡改。\n\n\n\n\n6. 安全数据传输（对称加密）\n\n加密方式：\n使用协商的对称密钥（如AES-256）加密所有HTTP请求和响应。\n完整性保护：\n每条消息附加HMAC（如SHA-256）或AEAD（如AES-GCM）标签，防止数据被篡改。\n示例：\n\n加密的HTTP请求：GET /login HTTPS/1.1 → 加密为乱码传输。\n服务器解密后处理，返回加密的响应。\n\n\n\n\nHTTP/2 做了什么优化？\nHTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。\nHTTP/2 是 HTTP 协议的重大升级，旨在解决 HTTP/1.1 的性能瓶颈，提升网络传输效率。以下是 HTTP/2 的主要改进点，结合技术细节和实际应用场景展开说明：\n\n1. 二进制分帧层（Binary Framing Layer）\n\n问题：HTTP/1.1 使用文本格式（如 GET / HTTP/1.1），解析效率低且易出错。\n改进：\n\n引入二进制分帧层，将消息拆分为更小的帧（Frame），每个帧包含：\n\n类型（如 HEADERS、DATA、PRIORITY）。\n流标识符（Stream ID）：标记帧所属的请求/响应流。\n长度和标志位：控制帧的边界和特性。\n\n\n\n\n\n\n2. 多路复用（Multiplexing）\n\n问题：HTTP/1.1 的队头阻塞（HOL Blocking）导致请求必须串行处理，并发需多个 TCP 连接（浏览器限制 6-8 个）。\n改进：\n\n在单个 TCP 连接上并行传输多个请求/响应，通过 Stream ID 区分不同流。\n帧可乱序发送，接收方按流 ID 重组。\n\n\n\n\n3. 头部压缩（HPACK 算法）\n\n问题：HTTP/1.1 头部冗余（如 Cookie、User-Agent 重复传输），平均占用 800-1400 字节/请求。\n改进：\n\nHPACK 算法：\n\n静态表：预定义 61 个常见字段（如 :method: GET 用索引 2 表示）。\n动态表：缓存自定义字段，后续请求用索引代替。\nHuffman 编码：压缩字段值。\n\n\n效果：头部大小减少 85-90%。\n\n\n\n\n4. 服务器推送（Server Push）\n\n问题：HTTP/1.1 需客户端解析 HTML 后才发现依赖资源（如 CSS/JS），导致多次 RTT。\n改进：\n\n服务器可主动推送关联资源（如 PUSH_PROMISE 帧推送 CSS）。\n客户端可通过 RST_STREAM 拒绝冗余推送。\n\n\n优化建议：\n\n推送关键资源（如首屏 CSS），体积控制在 50KB 以内。\n​HTTP/2 中的 Stream（流）概念详解\nHTTP/2 的核心改进之一是引入了 ​Stream（流）​ 机制，它彻底改变了 HTTP/1.1 的串行请求-响应模型，实现了真正的多路复用（Multiplexing）。以下是 Stream 的核心特性和工作原理：\n​1. Stream 的定义\n​Stream 是 HTTP/2 连接中的虚拟双向通道，用于承载独立的请求和响应。\n每个 Stream 由唯一的 ​Stream ID 标识（31 位无符号整数），客户端发起的 Stream ID 为奇数，服务器发起的为偶数。\n​帧（Frame）是 Stream 的最小传输单位，例如：\nHEADERS 帧：传输 HTTP 头部。\nDATA 帧：传输实际数据（如 HTML、图片）。\nPRIORITY 帧：设置优先级。\n​2. Stream 的核心特性\n​**(1) 多路复用（Multiplexing）​**\n​单 TCP 连接支持多个并发 Stream：\n在 HTTP/1.1 中，浏览器需要建立多个 TCP 连接（通常 6-8 个）以实现并发，而 HTTP/2 只需 ​1 个 TCP 连接即可并行处理数百个 Stream。\n​示例：客户端可以同时发送 Stream 1（请求 HTML）和 Stream 3（请求 JS），服务器可以交错返回它们的帧（如 A1 -&gt; B1 -&gt; A2 -&gt; B2）。\n​**(2) 帧的乱序与有序**\n​不同 Stream 的帧可以乱序发送：\n接收方通过 Stream ID 重新组装帧，因此不同 Stream 的帧可以交替传输（如 A1 -&gt; B1 -&gt; A2 -&gt; B2）。\n​同一 Stream 的帧必须有序：\n例如，Stream 1 的 HEADERS 帧必须排在 DATA 帧之前，否则会导致解析错误。\n\n\n\n​## MySQL为什么选择B+树？\n​更少的磁盘I/O\nB+树的非叶子节点仅存储索引，使得单节点可存储更多键值，​降低树高，减少查询时的磁盘访问次数。\n​稳定的查询性能\n所有查询均需访问叶子节点，时间复杂度恒为O(log n)，避免B树因数据位置不同导致的性能波动。\n​高效的范围查询\n叶子节点的链表结构使范围查询只需定位起始点后顺序遍历，无需回溯。\n​更适合磁盘存储\nB+树的节点大小通常设计为磁盘块（如16KB），​充分利用预读特性，减少随机I/O。\n​支持覆盖索引\n二级索引的叶子节点直接存储主键值，避免回表（如查询字段全在索引中时\nJMM happens-before\nHappens-Before 原则是 JMM 中定义的操作间的顺序规则，确保操作的有序性和可见性。具体包括以下八个规则：\n程序次序规则：一个线程中的每个操作，按照程序代码的顺序发生。\n监视器锁规则：一个解锁操作发生在同一个锁的随后的加锁操作之前。\nvolatile 变量规则：对一个 volatile 变量的写操作发生在对该变量的随后的读操作之前。\n线程启动规则：在一个线程中对另一个线程的 Thread.start() 调用发生在这个新线程的每一个操作之前。\n线程终止规则：一个线程中的所有操作都发生在另一个线程检测到这个线程已经终止（通过 Thread.join() 返回）之前。\n线程中断规则：对线程的中断操作（Thread.interrupt()）发生在被中断线程检测到中断事件（通过 Thread.interrupted() 或 Thread.isInterrupted()）之前。\n对象终结规则：一个对象的构造函数执行结束发生在这个对象的 finalize() 方法之前。\n传递性：如果操作 A Happens-Before 操作 B，操作 B Happens-Before 操作 C，那么操作 A Happens-Before 操作 C。\n秒杀\n瞬时流量的承接\n​问题：秒杀开始瞬间可能产生百万级QPS，需避免系统崩溃。\n​解决方案：\n​分层过滤：\n​前端限流：按钮置灰+动态URL防刷。\n​CDN缓存静态页面，减少后端请求。\n​Nginx限流：令牌桶算法限制每秒请求数（如limit_req模块）。\n​异步削峰：请求先入消息队列（如Kafka/RabbitMQ），后端异步处理订单。\n​独立部署：秒杀服务与主业务隔离，避免资源竞争。\n​2. 防止超卖\n​问题：高并发下库存扣减可能超量。\n​解决方案：\n​预扣库存：Redis原子操作（DECR）预减库存，避免直接访问DB。\n​分布式锁：Redis的SETNX或Redisson锁保证扣库存原子性。\n​乐观锁：SQL条件控制（如UPDATE stock SET count=count-1 WHERE count&gt;=1）。\n​最终一致性：MQ异步同步库存至数据库。\n​3. 预防黑产\n​问题：机器脚本刷单、僵尸账号占库存。\n​解决方案：\n​验证码：图形/滑块验证码拦截脚本请求。\n​行为分析：检测异常点击频率、鼠标轨迹。\n​设备指纹：记录IP、设备ID限制重复请求。\n​账号分级：限制低等级账号参与或设置购买上限。\n​4. 避免对正常服务的影响\n​问题：秒杀流量挤占常规业务资源。\n​解决方案：\n​服务隔离：秒杀使用独立集群、DB分库。\n​熔断降级：非核心功能（如推荐服务）自动关闭（Hystrix/Sentinel）。\n​动态扩容：云服务器弹性伸缩应对峰值。\n​5. 兜底方案\n​问题：极端情况下系统容灾。\n​解决方案：\n​降级策略：静态页展示“活动火爆”提示，或排队页面。\n​数据回滚：超卖时通过事务日志补偿库存。\n​多活部署：跨机房容灾，故障自动切换。\nRabbitMQ 和 Kafka\n核心架构差异\n​RabbitMQ\n​代理模式：基于AMQP协议，采用智能代理（Broker）架构，由Exchange、Queue、Binding组成，支持复杂路由规则（如Direct、Fanout、Topic）。\n​推送模型：消息由Broker主动推送给消费者，适合低延迟场景。\n​垂直扩展：通过增加单节点资源提升性能，适合中小规模系统。\n​Kafka\n​流平台：基于分区日志的分布式设计，消息按顺序追加到分区，支持高吞吐和水平扩展。\n​拉取模型：消费者主动从分区拉取消息，牺牲延迟换取高吞吐。\n​持久化：消息默认保留多天，支持回溯和批量处理。\n关键功能对比\n​对比项\t​RabbitMQ\t​Kafka\n​消息顺序\t单队列严格有序（FIFO）\t单分区有序，全局无序\n​吞吐量\t万级QPS（依赖ACK机制）\t百万级QPS，适合大数据流\n​消息可靠性\t支持ACK、重试、死信队列\t无内置重试，需自行实现\n​消息留存\t消费后默认删除\t长期留存，支持回溯\n​路由灵活性\t支持多协议（AMQP/MQTT等）和复杂路由\t仅Topic分区，路由简单\n​延迟\t毫秒级（推送模型）\t较高（拉取模型）\n​3. 适用场景\n​优先选择RabbitMQ的情况\n​企业级应用：需要严格消息顺序、复杂路由（如金融交易）。\n​低延迟任务：如实时通知、任务队列。\n​灵活错误处理：内置ACK和重试机制，适合容错要求高的场景。\n​优先选择Kafka的情况\n​大数据流处理：如日志聚合、实时分析（如用户行为跟踪）。\n​高吞吐场景：如电商秒杀、IoT设备数据。\n​事件溯源：需长期存储和回溯消息（如审计日志）\nRabbitMQ vs Kafka 在你的项目中的适用性分析\n你的Tomato-Mall电商项目目前选择了RabbitMQ作为消息队列解决方案，这是一个合适的选择。以下是详细分析为什么RabbitMQ比Kafka更适合你的项目：\n1. 消息处理模式\nRabbitMQ更适合你的场景：\n\n你的项目主要处理业务事件（订单超时、支付结果）而非数据流\n需要即时处理消息（如订单超时后立即释放库存）\n消息消费后通常不需要长期保留\n\nKafka的不足：\n\nKafka设计用于高吞吐量数据流处理，消息会持久化较长时间\n对于你的即时业务处理场景显得&quot;过重&quot;\n\n2. 消息传递语义\nRabbitMQ优势：\n\n提供了你需要的精确一次投递语义（通过ACK机制）\n支持死信队列（已在你的订单超时处理中使用）\n内置消息优先级（虽然你的项目目前未使用）\n\nKafka的局限：\n\n默认是&quot;至少一次&quot;语义，实现精确一次较复杂\n没有原生的死信队列概念\n\n3. 延迟消息处理\nRabbitMQ的优势：\n\n你的项目使用RabbitMQ的延迟队列插件处理订单超时\n配置简单直观（如你的orderDelayQueue）\n\nKafka的不足：\n\n没有内置延迟消息支持\n需要自行实现时间轮等复杂机制\n\n4. 消息量级和吞吐\n你的项目特点：\n\n电商系统消息量中等（订单、支付相关）\n不需要极高吞吐（每天万级消息已足够）\n消息大小较小（主要是订单ID、状态等）\n\nRabbitMQ足够应对：\n\n单节点可支持数万TPS\n消息体积小，不会成为瓶颈\n\nKafka的优势无法发挥：\n\nKafka的百万级TPS优势在你的场景中不需要\n会增加不必要的复杂性\n\n5. 运维复杂度\nRabbitMQ更简单：\n\n你的配置已经展示了简单易用的特点\n轻量级，适合中小型项目\n社区支持好，问题容易解决\n\nKafka更复杂：\n\n需要Zookeeper协调\n配置调优复杂\n资源消耗更大\n\nSpring @Transactional 事务传播行为详解\n@Transactional 的事务传播行为(Propagation Behavior)定义了多个事务方法相互调用时，事务应该如何传播。这是 Spring 事务管理的核心特性之一，理解它对设计复杂业务逻辑至关重要。\n传播行为类型\nSpring 提供了 7 种传播行为，通过 Propagation 枚举定义：\n\nREQUIRED（默认）\n​行为：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新事务\n​适用场景：大多数业务方法的默认选择\n​示例：\n@Transactional(propagation = Propagation.REQUIRED)\npublic void methodA() {\n// 如果调用方有事务，则加入；否则新建事务\nmethodB();\n}\n\n@Transactional(propagation = Propagation.REQUIRED)\npublic void methodB() {\n// 加入methodA的事务\n}\n2. SUPPORTS\n​行为：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务方式执行\n​适用场景：查询方法，可以适应调用方的事务需求\n​示例：\n@Transactional(propagation = Propagation.SUPPORTS)\npublic void queryData() {\n// 如果调用方有事务，则加入；否则无事务执行\n}\n3. MANDATORY\n​行为：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常\n​适用场景：强制要求必须在事务中执行的方法\n​示例：\n@Transactional(propagation = Propagation.MANDATORY)\npublic void mandatoryOperation() {\n// 必须在事务中调用，否则抛出IllegalTransactionStateException\n}\n4. REQUIRES_NEW\n​行为：创建一个新事务，如果当前存在事务，则挂起当前事务\n​适用场景：需要独立事务执行的方法，不受外层事务影响\n​示例：\n@Transactional(propagation = Propagation.REQUIRES_NEW)\npublic void logOperation() {\n// 总是新建事务，外层事务回滚不影响此方法\n}\n5. NOT_SUPPORTED\n​行为：以非事务方式执行操作，如果当前存在事务，则挂起该事务\n​适用场景：不需要事务支持的方法，如某些日志记录\n​示例：\n@Transactional(propagation = Propagation.NOT_SUPPORTED)\npublic void nonTransactionalMethod() {\n// 无事务执行，即使调用方有事务也会被挂起\n}\n6. NEVER\n​行为：以非事务方式执行，如果当前存在事务，则抛出异常\n​适用场景：严格要求不能在事务中执行的方法\n​示例：\n@Transactional(propagation = Propagation.NEVER)\npublic void mustNotInTransaction() {\n// 如果调用方有事务，则抛出异常\n}\n7. NESTED\n​行为：如果当前存在事务，则在嵌套事务内执行；如果当前没有事务，则创建一个新事务\n​适用场景：需要部分回滚的复杂业务场景\n​示例：\n@Transactional(propagation = Propagation.NESTED)\npublic void nestedOperation() {\n// 在外层事务中创建保存点(SAVEPOINT)\n// 可以独立回滚而不影响外层事务\n}\n传播行为对比表\n传播行为\t当前存在事务\t当前无事务\nREQUIRED\t加入当前事务\t创建新事务\nSUPPORTS\t加入当前事务\t非事务执行\nMANDATORY\t加入当前事务\t抛出异常\nREQUIRES_NEW\t挂起当前事务，创建新事务\t创建新事务\nNOT_SUPPORTED\t挂起当前事务，非事务执行\t非事务执行\nNEVER\t抛出异常\t非事务执行\ngapLock nextKeyLock时机\n可重复读（Repeatable Read）隔离级别下间隙锁（Gap Lock）和 Next - Key Lock 的使用时机\n\n范围查询时 使用邻键锁 ：\n当在可重复读隔离级别下， 执行带有范围条件的查询语句时：如\nSELECT… FROM table WHERE column BETWEEN value1 AND value2 FOR UPDATE\n或\nSELECT… FROM table WHERE column &gt; value1 AND column &lt; value2 FOR UPDATE\n会使用间隙锁和 Next - Key Lock。\n例如，在一个按年龄字段索引的用户表中，执行\nSELECT * FROM users WHERE age BETWEEN 20 AND 30 FOR UPDATE，\n如果表中存在年龄为 20、25、30 的用户记录，那么会锁定年龄在 (20, 25]、(25, 30] 以及 20 和 30 对应的记录行，防止其他事务在这个年龄范围内插入新记录，避免幻读问题。\n插入操作引发时 使用邻键锁 ：\n如果在一个事务中，先进行范围查询，然后准备插入一条新记录，而这条新记录的值处于之前查询的范围区间内，也会触发间隙锁和 Next - Key Lock。\n假设事务 A 先执行SELECT * FROM products WHERE price &gt; 100 AND price &lt; 200 FOR UPDATE，之后事务 A 准备插入一条price为 150 的新商品记录，此时会锁定 (100, 200) 这个区间，防止其他事务在该区间插入数据，确保事务 A 再次查询该范围时，数据的一致性。\n唯一索引冲突检测时 使用邻键锁 ：\n当插入或更新数据时，如果涉及到唯一索引，并且在可重复读隔离级别下，为了防止其他事务在同一时刻插入相同唯一值的数据，会使用 Next - Key Lock。\n例如，在一个用户表中，email字段设置为唯一索引，当一个事务执行下面的sql ，\nINSERT INTO users (name, email) VALUES (‘张三’, ‘zhangsan@example.com’)\n会锁定email索引上对应值的 Next - Key 范围，确保在事务完成前，其他事务不能插入相同email的记录，保证唯一索引的约束性和数据一致性。\n\n","tags":["其他"]},{"title":"项目问题准备","url":"/notes.github.io/2025/06/23/%E9%A1%B9%E7%9B%AE%E9%97%AE%E9%A2%98%E5%87%86%E5%A4%87/","content":"索引\n一、索引类型分类\n\n普通索引 (Standard Index)\n用户表(users)\n\nidx_users_username: 普通索引\nidx_users_email: 普通索引\nidx_users_telephone: 普通索引\n商品表(products)\nidx_products_title: 普通索引\nidx_products_price: 普通索引\nidx_products_rate: 普通索引\n库存表(stockpiles)\nidx_stockpiles_amount: 普通索引\n\n外键索引 (Foreign Key Index)\n规格表(specifications)\n\nidx_specifications_product_id: 外键索引\n库存表(stockpiles)\nidx_stockpiles_product_id: 外键索引\n广告表(advertisements)\nidx_product_id: 外键索引\n\n复合索引 (Composite Index)\n规格表(specifications)\n\nidx_specifications_item_value: 复合索引(item, value)\n购物车表(carts)\nidx_carts_user_product: 复合索引(user_id, product_id)\n\n唯一索引 (已存在)\n用户表(users)\n\ntelephone字段已定义为UNIQUE，自动创建唯一索引\n二、各类索引的得失分析\n\n普通索引\n优点:\n\n加速WHERE条件查询\n提高ORDER BY排序效率\n支持覆盖索引查询(当查询只包含索引列时)\n缺点:\n占用额外存储空间\n降低INSERT/UPDATE/DELETE速度(需要维护索引)\n可能导致优化器选择不理想的执行计划\n适用场景:\n高频查询条件字段\n需要排序或分组的字段\n选择性高的字段(不同值多的字段)\n\n外键索引\n优点:\n\n加速表连接操作\n保证参照完整性\n优化关联查询性能\n缺点:\n增加外键约束检查开销\n可能影响批量导入性能\n级联操作可能带来性能问题\n适用场景:\n所有外键关系字段都应建立\n频繁进行JOIN操作的表\n\n复合索引\n优点:\n\n支持多列组合查询\n可以实现索引覆盖\n减少单列索引数量\n缺点:\n列顺序很重要，设计不当会失效\n只对最左前缀有效\n占用更多空间\n适用场景:\n经常同时查询多个字段\n有固定查询模式的场景\n需要覆盖索引优化查询\n一、阿里巴巴手册对外键的建议\n阿里巴巴《Java开发手册》确实建议：\n\n不要使用数据库外键约束（FOREIGN KEY constraint）\n但需要建立外键索引（即在外键字段上创建普通索引）\n\n原因分析：\n\n\n外键约束的缺点：\n\n性能开销：每次DML操作都需要检查外键约束\n并发问题：容易引发死锁\n扩展困难：分库分表时难以维护外键关系\n耦合度高：业务逻辑与数据强耦合\n\n\n\n外键索引的优点：\n\n提高JOIN查询性能\n保证查询优化器能选择最优执行计划\n不引入约束检查的开销\n\n\n\n二、外键索引的原理\n1. 基本工作原理\n外键索引本质上是一个普通的B+树索引，只是它建立在外键字段上，用于：\n\n加速表连接操作\n优化关联查询\n支持嵌套循环连接(Nested Loop Join)算法\n\n2. 与有约束外键的区别\n\n\n\n特性\n有约束的外键\n外键索引\n\n\n\n\n分库分表兼容性\n难以实现\n容易实现\n\n\n约束检查\n有，保证数据完整性\n无\n\n\n存储结构\n约束+索引\n纯索引\n\n\n级联操作\n支持CASCADE/SET NULL等\n不支持\n\n\n性能影响\nDML操作有额外开销\n只有查询优化\n\n\n\n3. 索引选择算法\n当执行JOIN查询时，优化器会：\n\n检查连接字段是否有索引\n评估不同连接算法(Nested Loop, Hash Join, Merge Join)的成本\n优先选择有索引的字段作为驱动表\n\n三、实际应用建议\n1. 应该建立外键索引的情况\n\n所有需要JOIN的关联字段\n高频查询的关联条件\nOLTP系统中核心业务表的关联字段\n\n2. 不建议建立的情况\n\n极少参与查询的关联字段\n数据量极小(如配置表)的关联\n写多读少的场景\n\n3. 最佳实践示例\n-- 不建议（添加外键约束）ALTER TABLE orders ADD CONSTRAINT fk_user_id FOREIGN KEY (user_id) REFERENCES users(user_id);-- 建议（只创建外键索引）CREATE INDEX idx_orders_user_id ON orders(user_id);\n四、性能影响对比\n1. 有外键约束时\n-- 插入订单时需要检查用户是否存在INSERT INTO orders(user_id, ...) VALUES (100, ...);-- 数据库需要执行：-- 1. 检查users表中是否存在user_id=100的记录-- 2. 如果不存在则拒绝插入-- 3. 如果存在则完成插入\n2. 只有外键索引时\n-- 插入订单时没有约束检查INSERT INTO orders(user_id, ...) VALUES (100, ...);-- 数据库只需：-- 1. 直接插入数据-- 2. 更新索引-- 查询时仍能高效JOINSELECT * FROM orders JOIN users ON orders.user_id = users.user_id;-- 可以使用orders.user_id上的索引加速连接\n五、总结\n\n外键索引≠外键约束：前者是性能优化手段，后者是数据完整性机制\n互联网应用推荐做法：\n\n应用层维护数据一致性\n数据库层建立外键索引优化查询\n避免使用数据库外键约束\n\n\n索引选择原则：\n\n评估查询模式\n监控索引使用情况\n定期优化冗余索引\n\n\n\n\n\n\n算法\n有无索引要求\n时间复杂度\n内存消耗\n适用场景\n外键索引优势\n\n\n\n\nNested Loop\n内表连接字段需索引\nO(M * log N)\n低\n中小表连接，驱动表小\n大幅降低内表查找成本\n\n\nHash Join\n无需索引\nO(M + N)\n高\n大表等值连接，无索引场景\n无直接优势\n\n\nMerge Join\n两表都需有序\nO(M + N)\n低\n已排序的大表连接\n间接优势（索引可帮助排序）\n\n\n\nCaffeine\n一、Caffeine 核心原理\n\n整体架构\nCaffeine 是一个高性能的 Java 缓存库，基于 Google Guava 缓存 API 重新设计，具有以下核心组件：\n\n哈希表：使用并发哈希表存储缓存条目\n访问队列：维护 LRU (最近最少使用) 顺序\n写入队列：维护写入顺序\n淘汰策略：基于大小、时间和引用类型的组合策略\n\n缓存淘汰算法\nCaffeine 采用 Window TinyLFU 算法，结合了：\n\nTinyLFU：频率草图(count-min sketch)统计访问频率\nLRU：保留最近访问的项目\n分段缓存：分为主缓存区、保护区和边缓存区\n\n并发控制\n使用 Striped 非阻塞数据结构\n\n读写分离设计\n无锁并发优化\n问题群 2: 业务逻辑与服务层实现\n1. 基础问题: 请简要描述一下订单服务的功能和流程。\n核心流程：\n​用户结算：从购物车中选择商品，触发 /api/cart/checkout 接口。\n​创建订单：生成订单并预占库存（OrderService.createOrder()）。\n​支付跳转：调用支付宝接口生成支付页面（OrderController.pay()）。\n​异步回调：支付宝回调通知支付结果（OrderController.payNotify()）。\n​状态更新：根据回调更新订单状态为“支付成功”并扣减库存。\n​超时释放：通过 RabbitMQ 延迟队列自动释放超时订单的库存。\n// OrderController 中的支付跳转逻辑@PostMapping(&quot;/&#123;orderId&#125;/pay&quot;)public void pay(@PathVariable Integer orderId, HttpServletResponse response) throws Exception &#123;    Order order = orderService.getOrderById(orderId);    // 生成支付宝支付链接并返回给前端    AlipayClient alipayClient = new DefaultAlipayClient(...);    AlipayTradePagePayRequest request = new AlipayTradePagePayRequest();    request.setBizContent(...); // 封装订单信息    String form = alipayClient.pageExecute(request).getBody();    response.getWriter().write(form); // 返回支付页面&#125;\n问题群 3: 缓存策略与使用\n\n基础问题: 你在项目中使用了哪些缓存技术？它们的作用是什么？\n\n答案：\n项目中使用了 ​Redis 和 ​Caffeine 两种缓存技术：\n​Redis：\n​作用：作为分布式缓存，存储高频访问数据（如广告信息、商品详情），支持跨服务节点的数据共享和一致性。\n​代码体现：RedisConfig 中配置了多个 RedisTemplate（如 advertisementRedisTemplate 和 productRedisTemplate），用于不同类型数据的序列化。\n​Caffeine：\n​作用：作为本地缓存（JVM 级别），缓存访问频率极高的数据（如广告元数据），减少 Redis 的网络开销。\n​代码体现：CacheConfig 中配置了 Caffeine 缓存管理器，设置容量和过期时间。\n​Redisson：\n​作用：提供分布式锁（如 RLock），防止缓存击穿。\n​代码体现：RedissonConfig 中初始化 RedissonClient。\n\n\n深入问题: 请解释一下你是如何实现缓存穿透的防护的？使用了哪些策略？\n\n\n优化问题: 在缓存失效时，你如何使用分布式锁来防止缓存击穿？具体的实现是什么样的？\n\n\n复杂问题: 你能描述一下在预热缓存时的具体步骤吗？为什么要定期更新缓存？\n\n\n进一步挖掘: 对于缓存的命中率，你如何进行监控和分析？如果发现缓存命中率低，你会采取什么措施？\n经过测试：在10000并发请求下还能保证错误率为0\n以下为原理：\n1. 缓存穿透防护\n空值缓存：当数据库查询结果为空时，缓存空列表（Collections.emptyList()），并设置较短的TTL（NULL_CACHE_TTL）。避免恶意请求穿透缓存直接访问数据库。\n双重检查锁：在未命中缓存时，通过分布式锁控制仅一个线程查询数据库，其他线程等待或降级，防止并发穿透。\n\n\n缓存击穿防护\n分布式锁（Redisson）：使用 RLock 实现分布式锁，确保缓存失效时仅一个线程重建数据。\n非阻塞锁竞争：通过 tryLock(100ms) 控制锁等待时间，避免线程长时间阻塞，超时后触发降级逻辑，保障可用性。\n\n\n缓存雪崩防护\n分片存储与随机TTL：将数据分片为多个键（如 PRODUCT_LIST_CACHE_KEY::chunk_0），每个分片设置基础TTL加随机偏移值（ThreadLocalRandom.current().nextInt(30_000)），避免所有缓存同时失效。\n异步批量写入：使用Redis Pipeline批量写入分片数据，减少网络开销，提升性能。\n\n\n高并发查询优化\n分页加载数据库：通过分页查询（Pageable）避免单次大数据量查询导致数据库或内存压力。\n异步缓存重建：主线程返回数据后异步执行缓存重建，减少用户请求延迟，通过分片存储和Pipeline写入提升效率。\n\n\n降级与回退策略\n锁超时降级：若获取锁失败或超时（如100ms内未获得锁），直接查询数据库并返回部分数据（如 PageRequest.of(0, 100)），避免系统雪崩。\n异常捕获：捕获分布式锁和缓存操作异常，降级到数据库查询，确保最终可用性。\n\n\n代码逻辑：\n1. 构建缓存 Key:\n\n1.1 根据商品 id 构建 Redis 缓存 Key: PRODUCT_CACHE_KEY + id\n\n2. 尝试从缓存中获取:\n\n\n2.1 使用 productRedisTemplate.opsForValue().get(key) 从 Redis 缓存中获取 Product 对象。\n\n\n2.2 如果缓存命中:\n\n2.2.1 空值判断:\n\n2.2.1.1 检查 product.getId() == -1\n2.2.1.2 如果是 true (空值):\n\n记录日志: “命中空值缓存，商品ID：{}”\n返回 null (防止缓存穿透)\n\n\n\n\n2.2.2 正常缓存:\n\n2.2.2.1 如果 product.getId() != -1\n\n记录日志: “从缓存中获取商品信息，商品ID：{}”\n返回 product\n\n\n\n\n\n\n\n2.3 如果缓存未命中:\n\n进入步骤 3 (从数据库加载)\n\n\n\n3. 防止缓存击穿 (使用分布式锁):\n\n\n3.1 获取分布式锁: 使用 Redisson 获取名为 &quot;product_lock_&quot; + id 的锁\n\n\n3.2 尝试获取锁:  lock.lock()\n\n\n3.3 双重检查: (获取锁后再次检查缓存)\n\n3.3.1 再次使用 productRedisTemplate.opsForValue().get(key) 从 Redis 获取 Product\n3.3.2 如果缓存命中:\n\n记录日志: “从缓存中获取商品信息，商品ID：{}”\n返回 product\n\n\n3.3.3 如果缓存仍然未命中:\n\n进入步骤 4 (从数据库加载)\n\n\n\n\n\n4. 从数据库加载数据:\n\n4.1 调用 productRepository.findByIdWithSpecifications(id) 从数据库获取 Product 对象\n\n5. 处理数据库查询结果:\n\n\n5.1 如果数据库中不存在该商品 (product == null):\n\n5.1.1 防止缓存穿透:\n\n创建一个新的 Product 对象\n设置 product.setId(-1) (标记为空值)\nproductRedisTemplate.opsForValue().set(key, product, NULL_CACHE_TTL) (缓存空值并设置过期时间)\n记录日志: “缓存空值，商品ID：{}”\n返回 null\n\n\n\n\n\n5.2 如果数据库中存在该商品 (product != null):\n\n5.2.1 防止缓存雪崩:\n\n计算随机过期时间:  randomTtl = CACHE_TTL.toMillis() + (long)(Math.random() * 60000)\n\n\n5.2.2 productRedisTemplate.opsForValue().set(key, product, randomTtl, TimeUnit.MILLISECONDS) (将商品信息存入缓存并设置随机过期时间)\n记录日志: “将商品信息存入缓存，商品ID：{}”\n返回 product\n\n\n\n6. 释放锁:\n\n6.1  在 finally 块中执行 lock.unlock() (确保锁始终被释放，避免死锁)\n\n空值缓存实现简单，能精确判断数据是否存在，但内存消耗不可控，易受恶意攻击，适合小型系统。\n布隆过滤器内存效率高，抗攻击性强，但存在误判率，数据更新复杂，适合大型系统。\n实际应用中，建议采用组合方案：布隆过滤器 + 空值缓存 + 分布式锁，构建多层防御体系。\n选型策略方面：\n\n小型系统、高一致性要求： 优先使用空值缓存 + 分布式锁。\n大型系统、高并发随机Key攻击风险： 必须引入布隆过滤器，建议组合使用。\n金融级系统： 可考虑使用支持删除操作的。\n超高并发场景： 在Nginx层添加Lua + Bloom Filter实现前置拦截。\n\n生产环境建议：\n\n监控告警： 监控Redis内存使用率（空值缓存）和误判率（布隆过滤器）。\n兜底策略： 始终保留空值缓存作为最后防线。\n过滤器优化： 使用Redisson的RBloomFilter或布谷鸟过滤器。\n冷启动方案： 分批次异步加载数据到过滤器。\n\nJWT\nJWT结构： 由Header、Payload和Signature三部分组成。Header和Payload可解码，但Signature是防篡改的关键。\n防篡改机制： JWT通过Signature来防止Payload被篡改。篡改Payload会导致Signature无效，服务器会拒绝该Token。用户无法在不知道密钥的情况下生成有效的Signature。\n加密类型：\n对称加密 (HMAC + SHA256)： 使用同一密钥签名和验证，速度快但密钥共享存在安全风险。\n非对称加密 (RSA/ECDSA)： 使用私钥签名，公钥验证，安全性更高但计算开销更大。\n实践建议：\n客户端只需验证Token的场景 (API访问) 推荐使用非对称加密。\n内部服务间通信可考虑使用对称加密。\n务必安全存储密钥。\n敏感信息不要放在Payload中。\n问题群 5: 消息队列与异步处理\n\n基础问题: 请简要介绍一下你在项目中使用的消息队列技术。\n深入问题: 在订单处理中，为什么选择使用消息队列？它带来了哪些好处？\n优化问题: 如何确保消息的可靠性和顺序性？你在实现中考虑了哪些细节？\n复杂问题: 如果消费者处理消息失败，系统会如何恢复？你在设计中是否考虑了死信队列？\n进一步挖掘: 请描述一下如何使用RabbitMQ实现延迟队列？在实际应用中遇到了哪些挑战？\n\n库存释放机制\n主要机制：OrderTimeoutConsumer 监听延迟队列，超时后调用 handleExpiredOrder 释放库存。\n兜底机制：ScheduledTask 定时扫描过期订单，防止消息丢失或处理失败。\n冗余设计：确保极端情况下（如 RabbitMQ 宕机）仍能通过定时任务恢复。\nRedis AND Caffeine\n1. 数据访问特性\n\n\n\n特性\nCaffeine（本地）\nRedis（分布式）\n\n\n\n\n延迟\n&lt; 1 μs（纯内存，无网络）\n≈ 0.2–2 ms（网络＋内存）\n\n\n吞吐\n极高（线程局部，几百万 QPS）\n高（依赖网络、单线程事件循环）\n\n\n容量\n受单机 JVM 堆内存限制（几十 MB–几 GB）\n水平可扩展，受集群内存限制\n\n\n一致性／共享\n不支持跨实例共享，只在同一 JVM 内可见\n多客户端／多实例可见，天然分布式\n\n\n持久化\n不支持；JVM 重启即空\n支持 RDB/AOF 持久化\n\n\n高级数据结构\n仅简单 Key→Value\nlist、set、zset、hash、stream、bitmaps、geospatial…\n\n\n\n\n2. 适用场景\n2.1 当选 Caffeine\n\n单机或无须跨实例共享\n\n方法结果缓存（@Cacheable 场景）：计算密集型、重复调用的纯函数（如费率限流、业务规则校验等）。\n配置／元数据、白名单、字典表等小体量静态参照。\n热点数据，一秒内多次读写：如本地计数器、短期限流、短期重试次数。\n\n\n超低延迟要求\n\n频繁访问、毫秒级以下延迟场景，完全消除网络抖动。\n\n\n资源隔离\n\n避免所有缓存压力打到集中式 Redis，利用本地内存分摊热点。\n\n\nSLA 容忍度低\n\n即使 Redis 故障，服务本地缓存依然可用（降级模式）。\n\n\n\n2.2 当选 Redis\n\n跨实例／跨进程共享\n\n分布式 Session、统一权限信息、用户登录态集中管理。\n分布式限流、漏桶／令牌桶全局计数器。\n\n\n大容量或长生命周期\n\n多 GB—TB 级别的数据缓存（商品图片元数据、大规模配置）。\n缓存持久化后可冷启动。\n\n\n复杂数据结构与功能\n\n排行榜（Sorted Set）、消息队列（List/Stream）、社交关系（Set）、地理位置（GEO）。\n发布/订阅、事务、Lua 脚本、Bitmaps/HyperLogLog 等。\n\n\n高可用／可扩展\n\n主从复制、哨兵、Cluster 分片，支持线上扩容、故障切换。\n\n\n\n\n3. 混合使用：二级缓存策略\n常见做法是在 应用内层 用 Caffeine 作「近缓存（L1）」、在 网络层 用 Redis 作「主缓存（L2）」，以兼顾超低延迟和数据一致性／共享。\n工作流程示例：\n\n读请求先查 L1（Caffeine）\n未命中再查 L2（Redis），并回填 L1\n写／更新同时写 Redis，再 Invalid L1／主动刷新 L1\n\n这样可以\n\n显著降低 Redis 压力\n保证分布式一致性（短期内有小概率读到过期 L1，可配合 TTL 或消息总线做通知）\n\n缓存策略对比\n\n\n\n维度\nCache Aside（旁路缓存）\nWrite-Through（同步写入）\n\n\n\n\n定义\n应用主动管理：读操作先查缓存，未命中时从后端加载并写入缓存；写操作更新数据库后再或删除缓存。\n写操作同时写入缓存和数据库，保证写入过程中的强一致性；读操作只查缓存（未命中可回源并填充缓存）。\n\n\n读流程\n1. 应用→缓存查询2. 缓存未命中 → 应用→数据库查询3. 将结果写入缓存 → 返回结果\n1. 应用→缓存查询2. 缓存未命中 → 应用→数据库查询并写入缓存 → 返回结果\n\n\n写流程\n1. 应用→数据库写入2. 写成功后，应用显式删除或更新缓存（使后续读到最新数据）\n1. 应用→数据库写入2. 同步更新缓存（写数据到缓存后才返回）\n\n\n优点\n- 简单灵活，读多写少场景常用- 缓存只存热数据，避免无用缓存- 可自行控制缓存失效时机\n- 写入实时更新缓存，读操作命中率高- 保证缓存与数据库强一致性- 应用逻辑更简单，无需显式管理缓存失效\n\n\n缺点\n- 写操作后需手动维护缓存；若忘记删除/更新缓存会导致读到旧数据- 首次读有额外的数据库延迟\n- 每次写都要双写，写延迟增加、数据库负载较大- 若缓存写入失败，需要额外补偿或重试机制\n\n\n适用场景\n- 读多写少、能容忍一定数据短暂不一致- 热点数据自下而上加载- 应用能严格控制何时失效或更新缓存\n- 强一致性要求高的场景- 写入频率适中，能接受写延迟- 希望简化应用层缓存管理逻辑\n\n\n\nredis-cli INFO memory | grep used_memory\nredis-cli INFO keyspace | grep “^db”\n为什么用消息队列\n​解耦性：\n支付和订单超时处理是核心业务，但它们的执行时长和成功率不应阻塞主流程。通过消息队列，支付回调（payNotify）只需发送消息到MQ，后续处理（如更新订单状态、库存扣减）由消费者异步完成，避免支付宝回调接口因处理时间长而超时。\n示例：OrderController.payNotify 发送消息到 payment.exchange 后立即返回&quot;success&quot;，避免支付宝重复回调。\n​异步提速：\n同步处理需等待所有步骤完成（如支付验证、订单更新、库存操作），而异步将耗时操作（如库存锁定）交给消费者，缩短接口响应时间。\n​可靠性：\n消息队列提供持久化、重试和死信机制。例如，在 PaymentResultConsumer 中，若处理支付结果失败，可通过 basicNack 重试或进入死信队列，避免数据不一致。\n​流量削峰：\n高并发时，MQ作为缓冲区，避免瞬间流量压垮数据库。订单创建和支付回调的高峰期，消息可堆积在队列中逐步消费。\nTTL+DLX vs 插件：优缺点对比**\n​方案\t​优点\t​缺点\t​适用场景\nTTL+DLX\t无需插件，兼容性好\t队列级固定TTL，无法单消息定制延迟\t所有订单统一超时时间\nx-delayed-message\t消息级延迟，灵活控制\t需安装插件，运维复杂\t动态延迟（如不同订单）\n​项目选择插件的原因：\n订单超时时间可能动态调整（例如促销活动延长支付时间），插件支持每条消息独立设置延迟。\n手动确认 vs 自动确认**\n​手动确认优势：\n确保消息处理成功后才确认。例如，在 PaymentResultConsumer 中，只有订单状态更新成功后才发送 basicAck，避免消息丢失。\n自动确认在消费者接收消息后立即确认，若后续处理失败，消息无法恢复。\nlogin\nQ4.1（认证流程）\n认证流程：​\n​提交凭证：用户发送登录请求到 AccountController.login，携带用户名和密码。\n​验证凭证：服务层校验密码（BCrypt 哈希比对）。\n​生成令牌：JwtUtil 生成 JWT，载荷包含 userId、username、role，签名使用密钥。\n​返回令牌：令牌通过响应头返回客户端。\n​后续请求：客户端在 Authorization 头携带 Bearer 。\n​拦截器验证：JwtInterceptor 验证签名、过期时间，解析出 userId 和 username 存入请求属性。\n​控制器访问：通过 @RequestAttribute(“userId”) 获取用户身份。\nJWT 载荷信息：​\n​包含字段：userId（唯一标识用户）、username（显示用）、role（授权用）。\n​安全考量：\n​不存储敏感信息​（如密码）。\n​签名防篡改：确保令牌完整性。\n​短期有效期：通过 exp 字段限制令牌生命周期。\nJPA\n当你先执行一条查询拿到 N 条父实体（例如：SELECT * FROM product），然后在循环里依次访问其延迟加载的子集合（如 product.getSpecifications()），就会针对每一个父实体再发起一次子查询。\n总共产生 1（父查询）+ N（每个父实体一个子查询） 条 SQL，故称 N+1 问题。\nSELECT p., s.\nFROM product p\nLEFT JOIN specification s ON s.product_id = p.id;\n通过 JPQL 的 JOIN FETCH，Hibernate 会在一条 SQL 里同时把 Product 和它的 specifications 一并加载\n花旗杯\n拦截器 等等\nLoginInterceptor 与 CorsFilter 的执行顺序及跨域鉴权协作\n执行顺序：\nCorsFilter 作为 @Order(Ordered.HIGHEST_PRECEDENCE)，优先执行，处理跨域请求的CORS头。\nLoginInterceptor 作为后续拦截器，进行鉴权。\n跨域与鉴权的协作：\nCorsFilter确保浏览器允许跨域请求（设置Access-Control-Allow-Origin等），使请求能到达后端。\n后端的LoginInterceptor在请求到达后，校验请求头中的token，确认用户身份。\n这样即使跨域请求允许发起，鉴权也能在请求到达后端进行。\n","tags":["其他"]},{"title":"准备0603","url":"/notes.github.io/2025/06/23/%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%870603/","content":"数据库中B+树相对于B树的优点总结\n\n\n更高效的磁盘I/O\n\nB+树的非叶子节点仅存储键值和指针（不存储实际数据），使得单个节点能容纳更多索引项，从而降低树的高度，减少磁盘I/O次数。\n所有数据仅存储在叶子节点，查询时需访问叶子节点，但通过减少中间节点的数据冗余，整体I/O效率更高。\n\n\n\n\n更优的范围查询性能\n\nB+树的叶子节点通过链表相连，范围查询时只需遍历链表即可，无需回溯上层节点；而B树需多次跨层访问。\n例如，查询区间[a, b]时，B+树只需定位到起始叶子节点后顺序扫描，时间复杂度接近O(n)。\n\n\n\n更稳定的查询性能\n\nB+树的查询必须到达叶子节点，路径长度固定，性能稳定；B树可能在中间节点提前终止查询，导致性能波动。\n\n\n\n更适合顺序访问与全表扫描\n\n叶子节点的链表结构支持高效顺序遍历，适合全表扫描或排序操作；B树需复杂的中序遍历。\n\n\n\n更优的并发控制  ！！\n\nB+树的叶子节点独立存储数据，更新操作通常仅影响局部叶子节点，减少锁竞争，适合高并发场景。\nB树的分裂/合并可能涉及更多层级，并发控制复杂度更高。\n\n\n\n缓存友好性\n\nB+树的数据集中在叶子节点且连续存储，预读机制能更高效利用磁盘缓存。\n\n\n\n适应大规模数据\n\nB+树的扁平化结构使其在处理海量数据时仍能保持较低高度，而B树可能因数据分散导致深度增加。\n\n\n\n索引失效的常见场景\n违反最左前缀原则：联合索引未从最左列开始使用18\n使用OR条件：查询条件包含OR且OR两边字段不全有索引58\n对索引列运算：如WHERE age+1=20或使用函数WHERE YEAR(create_time)=202318\n类型不一致：字符串列与数字比较WHERE name=1232\nLIKE以通配符开头：WHERE name LIKE '%张’12\n使用!=或&lt;&gt;：WHERE status != 128 范围查询(&gt;,&lt;,BETWEEN,LIKE)会使右侧列索引失效\nIS NULL/IS NOT NULL：某些情况下会导致索引失效2\n全表扫描更快：当MySQL优化器判断全表扫描比索引更快时8\nInnoDB的MVCC（多版本并发控制）机制通过隐藏列、Undo Log和Read View协同工作，实现高并发下的数据一致性。以下是插入和访问数据的完整过程及底层细节：\n\nMVCC 插入and查找数据的完整过程\n一、插入数据的完整过程\n\n\n分配事务ID\n事务开始时，系统分配一个全局递增的事务ID（trx_id），例如trx_id=100。\n\n\n写入隐藏列\n插入新行时，InnoDB为数据行添加三个隐藏字段：\n\nDB_ROW_ID：唯一行ID（若未显式定义主键则自动生成）。\nDB_TRX_ID：记录操作该行的事务ID（即trx_id=100）。\nDB_ROLL_PTR（回滚指针）：指向该行在Undo Log中的历史版本，初始为NULL（因无历史版本）。\n\n\n\n生成Undo Log记录\n在Undo Log中记录插入前的状态（逻辑为空），用于事务回滚时删除该行。\n\n\n更新聚簇索引\n数据写入聚簇索引的叶子节点，同时更新非聚簇索引（若有）。\n\n\n\n二、访问（查询）数据的完整过程\n步骤1：创建Read View（可见性判断依据）\n事务首次执行SELECT时生成Read View，包含：\n\ntrx_ids：当前所有活跃事务ID列表（如[101, 102]）。\nup_limit_id：最小活跃事务ID（如101）。\nlow_limit_id：系统下一个将分配的事务ID（如103）。\n\n步骤2：遍历版本链，判断可见性\n对于目标数据行，从最新版本开始，沿DB_ROLL_PTR回溯版本链，按规则判断可见性：\n\n若行记录的DB_TRX_ID &lt; up_limit_id\n说明该版本在Read View创建前已提交，可见（例如DB_TRX_ID=99）。\n若DB_TRX_ID &gt;= low_limit_id\n说明该版本在Read View创建后才生成，不可见（例如DB_TRX_ID=103）。\n若DB_TRX_ID在[up_limit_id, low_limit_id)区间：\n\n在trx_ids列表中：生成该版本的事务仍活跃（未提交），不可见（如DB_TRX_ID=101）。\n不在trx_ids列表中：生成该版本的事务已提交，可见（如DB_TRX_ID=95）。\n\n\n\n步骤3：返回匹配版本\n找到首个可见版本后返回数据；若全不可见则返回空。\n\n示例场景（事务ID=100查询某行）：\n\n版本链：当前版本(trx_id=102) → 历史版本(trx_id=90)\nRead View：trx_ids=[101, 102], up_limit_id=101, low_limit_id=103\n判断：\n\n当前版本trx_id=102在trx_ids中 → 不可见。\n历史版本trx_id=90 &lt; up_limit_id(101) → 可见，返回此版本数据。\n\n\n\n\n\n三、关键机制详解\n\n\n版本链管理\n\n每次更新/删除时，旧数据拷贝至Undo Log，新行DB_TRX_ID更新为当前事务ID，DB_ROLL_PTR指向旧版本。\n删除操作标记DB_TRX_ID为删除事务ID，不立即物理删除。\n\n\n\n隔离级别的影响\n\n\n\n隔离级别\nRead View生成策略\n效果\n\n\n\n\n读已提交 (RC)\n每次SELECT都生成新Read View\n可能读到其他事务已提交的修改\n\n\n可重复读 (RR)\n事务首次SELECT生成Read View并复用\n全程读取同一快照，避免不可重复读\n\n\n\n\n\nPurge机制\n后台线程定期清理不再被任何事务引用的Undo Log版本（如已提交事务的旧版本）。\n\n\n\n四、流程图解\ngraph TD    A[事务开始] --&gt; B[插入数据]    B --&gt; C1[分配trx_id]    C1 --&gt; C2[写入隐藏字段]    C2 --&gt; C3[生成Undo Log]    C3 --&gt; D[更新索引]    E[查询数据] --&gt; F&#123;首次SELECT?&#125;    F --&gt;|是| G[创建Read View]    F --&gt;|否| H[复用Read View]    G/H --&gt; I[遍历版本链]    I --&gt; J&#123;检查DB_TRX_ID&#125;    J --&gt;|可见| K[返回数据]    J --&gt;|不可见| L[回溯上一版本]    L --&gt; J\n此机制确保：\n\n插入时：生成新版本并关联事务ID。\n查询时：通过Read View过滤版本链，实现无锁快照读。\n更新/删除时：创建新版本，旧版本进入Undo Log。\n\n限流与降级\n多级降级策略：\n一级降级：关闭非核心服务（如推荐、评论）\n二级降级：简化核心业务流程（如跳过风控检查）\n三级降级：静态化返回结果（如直接返回&quot;秒杀已结束&quot;）\n用户请求\n↓ (100万QPS)\n前端限流（验证码、按钮控制）\n↓ (30万QPS)\nNginx限流（IP限制、频率控制）\n↓ (10万QPS)\n网关限流（API配额、集群限流）\n↓ (1万QPS)\n服务限流（线程池、信号量）\n↓ (1000QPS)\n数据库（最终写入）\n用户在前端点击秒杀按钮\n前端进行防重复点击和请求频率限制\n请求发出，后端进行限流（QPS/IP限制）\n请求进入排队队列（如果系统压力大）\n排队到达，后端确认库存（预减库存）\n若库存充足，订单成功，库存减一\n若库存不足或系统压力大，采取降级措施（快速失败、功能降级）\n前端根据后端返回显示用户最终状态（成功/失败/排队中）\n线程池\n当前线程数 &lt; corePoolSize\n​行为：直接创建新线程（核心线程）处理任务。\n​示例：若corePoolSize=2，提交第1、2个任务时会立即创建2个线程执行。\n​当前线程数 ≥ corePoolSize 且队列未满\n​行为：任务放入队列等待执行。\n​示例：corePoolSize=2，队列容量=3。提交第3、4、5个任务时，任务进入队列，由空闲的核心线程处理。\n​队列已满且线程数 &lt; maximumPoolSize\n​行为：创建非核心线程处理新任务。\n​示例：maximumPoolSize=5，队列已满时，提交第6、7个任务会创建第3、4个线程（非核心线程）。\n​线程数 = maximumPoolSize 且队列已满\n​行为：触发拒绝策略（如抛出异常AbortPolicy或由调用线程执行CallerRunsPolicy）。\n​示例：maximumPoolSize=5，队列已满时，提交第8个任务会触发拒绝策略。\n如何选择队列？\n场景\t推荐队列\t理由\n高吞吐，允许任务积压\tLinkedBlockingQueue\t避免频繁创建/销毁线程，但需警惕OOM。\n严格控制队列长度\tArrayBlockingQueue\t防止资源耗尽，配合maximumPoolSize实现弹性扩容。\n低延迟，拒绝任务堆积\tSynchronousQueue\t任务直接执行或拒绝，适合短任务且要求快速响应的场景。\n按优先级处理任务\tPriorityBlockingQueue\t适用于任务有明确优先级的场景（如VIP用户请求优先）。\n​\n\nspring单例模式\nSpring 框架中的单例模式是其 IoC 容器的核心设计之一，通过单例注册表（如 ConcurrentHashMap）实现 Bean 的全局唯一性。以下从实现机制、线程安全、作用域对比和应用场景四个维度详细解析：\n\n⚙️ 一、实现机制：单例注册表与缓存\n\n\n单例注册表（singletonObjects）\nSpring 使用 DefaultSingletonBeanRegistry 类管理单例 Bean，其核心是一个线程安全的 ConcurrentHashMap：\npublic class DefaultSingletonBeanRegistry &#123;    private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;();    // 注册单例 Bean    public void registerSingleton(String beanName, Object singletonObject) &#123;        singletonObjects.put(beanName, singletonObject);    &#125;    // 获取单例 Bean    public Object getSingleton(String beanName) &#123;        return singletonObjects.get(beanName);    &#125;&#125;\n\n首次请求时创建 Bean 实例并存入注册表。\n后续请求直接返回缓存中的实例，避免重复创建。\n\n\n\nBean 生命周期管理\n\n初始化：容器启动时默认初始化单例 Bean（可通过 @Lazy 改为延迟加载）。\n依赖注入：通过 @Autowired 注入的依赖均为同一实例。\n销毁：容器关闭时调用单例 Bean 的销毁方法（如 @PreDestroy）。\n\n\n\n\n🔒 二、线程安全：容器安全 ≠ Bean 安全\nSpring 仅保证实例唯一性，不保证 Bean 内部状态的线程安全：\n\n容器层安全：注册表使用 ConcurrentHashMap 和双重检查锁（DCL），避免多线程重复创建。\n业务层风险：若单例 Bean 含可变状态（如计数器），需开发者自行同步：@Servicepublic class CounterService &#123;    private int count = 0; // 可变状态    // 需同步保护    public synchronized void increment() &#123;        count++;    &#125;&#125;\n解决方案：\n\n无状态设计（推荐）：避免成员变量，用局部变量或参数传递数据。\n同步机制：synchronized、ReentrantLock。\n线程安全类：如 AtomicInteger、ConcurrentHashMap。\n\n\n\n\n🔄 三、作用域对比：单例 vs 其他作用域\nSpring 支持 6 种 Bean 作用域，单例（singleton）为默认值：\n\n\n\n作用域\n生命周期\n适用场景\n线程安全需求\n\n\n\n\nSingleton\n容器启动到关闭\n无状态服务（如工具类、配置）\n需开发者保障\n\n\nPrototype\n每次请求创建新实例\n有状态对象（如用户会话）\n实例隔离，无需同步\n\n\nRequest\nHTTP 请求内有效\nWeb 请求级数据（如表单对象）\n实例隔离\n\n\nSession\nHTTP 会话内有效\n用户会话数据（如购物车）\n实例隔离\n\n\n\n\n💡 为何默认单例？\n\n性能优势：减少对象创建/GC 开销。\n资源复用：如数据库连接池、配置信息。\n符合 Spring 设计哲学：容器管理无状态服务。\n\n\n\n🛠️ 四、典型应用场景\n\n基础设施 Bean\n数据库连接池（DataSource）、事务管理器（TransactionManager）等全局唯一资源。\n无状态服务\n工具类（StringUtils）、业务逻辑层（Service）。\n配置类 Bean\n系统配置（@Configuration 类），如 API 密钥、路径常量。\n\n\n⚠️ 注意事项\n\n循环依赖：单例 Bean 的循环依赖通过三级缓存解决（早期暴露引用）。\n作用域切换：需非单例时，显式声明 @Scope(&quot;prototype&quot;)。\n测试影响：单例的全局状态可能污染单元测试，建议用 @DirtiesContext 重置容器。\n\n\n💎 总结\nSpring 的单例模式通过注册表缓存实现 Bean 全局唯一，默认适用于无状态服务以提升性能。其线程安全性需开发者根据业务状态设计保障，多线程共享可变数据时需同步控制。理解单例与其他作用域的差异（如原型模式隔离状态），是合理设计 Spring 应用的关键。\nspring适配器\n当然可以！下面我会为你深入讲解适配器模式（Adapter Pattern），特别是在Spring MVC 中 Controller 的实现场景下的应用与设计思想。\n\n一、适配器模式（Adapter Pattern）简介\n1. 定义\n\n适配器模式属于结构型设计模式，其核心思想是在接口不兼容的两个类之间引入一个“适配器”，使得原本不兼容的接口可以协同工作。\n意图：让原本因接口不匹配而无法一起工作的类能够合作。\n\n2. 经典示意\n\n目标接口（Target）：客户端期待的接口。\n适配者（Adaptee）：现有的接口或类，不符合目标接口。\n适配器（Adapter）：实现目标接口，内部调用适配者的方法，从而实现兼容。\n\n\n二、Spring MVC 中的适配器模式应用\n1. 背景\n\n在Spring MVC中，不同类型的Controller（如 @Controller、HttpRequestHandler、Controller接口实现）可能有不同的调用方式和接口定义。\n为了统一调用入口，Spring定义了**HandlerAdapter**接口，作为“适配器”角色，将各种不同的Controller封装成一致的调用方式。\n\n2. 核心设计\n\n\n目标接口（Target）：HandlerAdapter，定义了统一的方法：\npublic interface HandlerAdapter &#123;    boolean supports(Object handler);    ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception;&#125;\n\n\n适配者（Adaptee）：各种Controller实现（如 Controller、HttpRequestHandler等），它们有不同的调用方法。\n\n\n适配器（Adapter）：实现HandlerAdapter接口，为不同Controller类型提供统一的调用逻辑。\n\n\n\n三、设计细节\n1. 作用\n\n让Spring MVC框架可以支持多种Controller类型（如@Controller注解的类、Controller接口实现、HttpRequestHandler等），无需在框架内硬编码不同Controller的调用方式。\n通过引入多个HandlerAdapter实现类（如RequestMappingHandlerAdapter、HttpRequestHandlerAdapter等），实现多样化Controller的支持。\n\n2. 典型实现\n\nHttpRequestHandlerAdapter：支持实现了HttpRequestHandler接口的Controller。\nRequestMappingHandlerAdapter：支持基于@RequestMapping的Controller。\n\n每个适配器内部都实现了supports()方法，判断当前handler是否支持，如果支持，则调用handle()方法完成请求处理。\n\n四、深入设计示意（伪代码）\n// 目标接口（统一调用接口）public interface HandlerAdapter &#123;    boolean supports(Object handler);    ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception;&#125;// 适配者（不同Controller类型）public interface Controller &#123;    ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response);&#125;public interface HttpRequestHandler &#123;    void handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception;&#125;// 适配器实现（将不同Controller适配到目标接口）public class ControllerHandlerAdapter implements HandlerAdapter &#123;    public boolean supports(Object handler) &#123;        return (handler instanceof Controller);    &#125;    public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123;        Controller controller = (Controller) handler;        return controller.handleRequest(request, response);    &#125;&#125;public class HttpRequestHandlerAdapter implements HandlerAdapter &#123;    public boolean supports(Object handler) &#123;        return (handler instanceof HttpRequestHandler);    &#125;    public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;        HttpRequestHandler httpHandler = (HttpRequestHandler) handler;        httpHandler.handleRequest(request, response);        // 可能不返回ModelAndView，或返回空        return null;    &#125;&#125;\n调用流程：\n\nDispatcherServlet收到请求。\n根据handler对象（Controller、HttpRequestHandler等），遍历支持的HandlerAdapter，找到支持的适配器。\n由适配器调用实际Controller的处理方法，实现接口统一。\n\n\n五、总结\n\n\n\n角色\n定义\n在Spring MVC中的体现\n\n\n\n\n目标接口（Target）\n一致的调用接口\nHandlerAdapter，定义统一的处理方法\n\n\n适配者（Adaptee）\n不同类型的Controller\nController、HttpRequestHandler等\n\n\n适配器（Adapter）\n实现目标接口，调用适配者\nControllerHandlerAdapter、HttpRequestHandlerAdapter等\n\n\n\n核心思想：通过引入“适配器”层，将不同类型的Controller统一封装到相同的调用接口中，从而实现Spring MVC对多样Controller的支持，增强了框架的扩展性和灵活性。\nLangChain4j 的工具调用（Function Calling/Tools）机制是其最强大的功能之一，它允许大语言模型（LLM）动态调用开发者定义的业务逻辑 API。以下是其工作原理的详细解析：\n\n核心原理：工具调用流程\n\n\n工具注册\n\n开发者使用 @Tool 注解标记业务方法（如数据库操作、API 调用等）\n示例：@Componentpublic class AppointmentTools &#123;    @Tool(&quot;预约挂号&quot;)    public String bookAppointment(Appointment appointment) &#123;        // 业务逻辑：调用数据库服务        return appointmentService.save(appointment);    &#125;&#125;\n\n\n\n\n元数据生成\nLangChain4j 在运行时自动生成工具的 JSON Schema 描述，包括：\n\n工具名称（name）\n功能描述（description）\n参数结构（parameters 的 JSON Schema）\n\n&#123;  &quot;name&quot;: &quot;bookAppointment&quot;,  &quot;description&quot;: &quot;预约挂号&quot;,  &quot;parameters&quot;: &#123;    &quot;type&quot;: &quot;object&quot;,    &quot;properties&quot;: &#123;      &quot;username&quot;: &#123;&quot;type&quot;: &quot;string&quot;&#125;,      &quot;department&quot;: &#123;&quot;type&quot;: &quot;string&quot;&#125;,      &quot;date&quot;: &#123;&quot;type&quot;: &quot;string&quot;, &quot;format&quot;: &quot;date&quot;&#125;    &#125;,    &quot;required&quot;: [&quot;username&quot;, &quot;department&quot;, &quot;date&quot;]  &#125;&#125;\n\n\n模型决策\n\n用户提问时，LangChain4j 将 工具描述 和 用户问题 一起发送给 LLM\nLLM 判断是否需要调用工具：\n\n若需要 → 返回工具调用请求（而非直接回答）\n若不需要 → 直接生成文本回复\n\n\n\n\n\n本地执行\nsequenceDiagram  LLM-&gt;&gt;LangChain4j: 返回工具调用请求（JSON）  LangChain4j-&gt;&gt;ToolExecutor: 解析参数  ToolExecutor-&gt;&gt;业务方法: 反射调用 bookAppointment(...)  业务方法-&gt;&gt;数据库: 执行SQL/API调用  业务方法--&gt;&gt;ToolExecutor: 返回结果  ToolExecutor-&gt;&gt;LLM: 封装工具执行结果  LLM-&gt;&gt;用户: 生成最终回答\n\n\n\n关键技术实现\n1. 动态参数绑定\n\nJSON → Java 对象转换\nLangChain4j 使用 Jackson 将 LLM 返回的 JSON 参数自动反序列化为 Java 对象：// LLM 返回的 JSON 参数&#123;&quot;username&quot;:&quot;张三&quot;, &quot;department&quot;:&quot;内科&quot;, &quot;date&quot;:&quot;2025-04-14&quot;&#125;// 自动转换为 Appointment 对象Appointment appt = objectMapper.readValue(json, Appointment.class);bookAppointment(appt); // 反射调用业务方法\n\n\n2. 工具执行器（ToolExecutor）\n\n核心组件 DefaultToolExecutor 处理：\n\n匹配工具名称\n参数反序列化\n通过反射调用目标方法\n捕获异常并转换为 LLM 可理解的错误消息\n\n\n\n3. 对话管理\n\n当 LLM 决定调用工具时，对话流程变为：用户问题 → LLM 返回工具调用请求（AiMessage） → 执行本地工具 → 将结果作为 ToolExecutionResultMessage 发送给 LLM → LLM 生成最终回复\n\n关键代码：List&lt;Message&gt; messages = Arrays.asList(  UserMessage.from(question),  AiMessage.from(toolCallRequest),       // 工具调用请求  ToolExecutionResultMessage.from(result) // 工具执行结果);ChatResponse response = model.generate(messages);\n\n\n\n为什么能安全调用业务逻辑？\n\n\n沙箱化执行\n\n工具方法在 当前 JVM 中执行，与业务代码共享安全上下文\n无需暴露 API 给外部网络\n\n\n\n参数校验机制\n\n通过 @P 注解定义参数约束：@Toolpublic String cancelAppointment(    @P(value=&quot;身份证号&quot;, required=true) String idCard,    @P(value=&quot;预约日期&quot;) String date) &#123;...&#125;\n\nLangChain4j 自动生成参数校验规则，LLM 必须提供合法参数\n\n\n\n权限控制\n可通过 @ToolMemoryId 绑定用户会话：\n@Toolpublic String getProfile(@ToolMemoryId String userId) &#123;  // 根据 userId 查询数据  return userService.getProfile(userId);&#125;\n\n\n\n与普通 API 调用的本质区别\n\n\n\n特性\n传统 API 调用\nLangChain4j 工具调用\n\n\n\n\n触发方式\n开发者显式调用\nLLM 动态决策触发\n\n\n参数传递\n手动构造参数对象\nLLM 自动生成合规参数\n\n\n执行上下文\n独立 HTTP 请求\n当前 JVM 进程内执行\n\n\n错误处理\n开发者手动处理\n自动转换异常为 LLM 可读消息\n\n\n适用场景\n确定性业务流\n需自然语言理解的灵活场景\n\n\n\n\n实战示例：挂号系统工具调用\n@Tool(name=&quot;预约挂号&quot;, value=&quot;先检查号源再预约&quot;)public String bookAppointment(Appointment request) &#123;    // 1. 检查号源是否可用    boolean available = queryDepartment(        request.getDepartment(),         request.getDate(),         request.getTime()    );        // 2. 执行业务逻辑    if (available) &#123;        appointmentService.save(request);        return &quot;预约成功&quot;;    &#125; else &#123;        throw new RuntimeException(&quot;该时段无号源&quot;);    &#125;&#125;// 调用流程// 用户提问 → &quot;我想预约内科4月14日上午的号&quot;// ↓// LLM 返回工具调用：//   bookAppointment(&#123;//     &quot;department&quot;: &quot;内科&quot;,//     &quot;date&quot;: &quot;2025-04-14&quot;,//     &quot;time&quot;: &quot;上午&quot;//   &#125;)// ↓// LangChain4j 执行 bookAppointment(...)// ↓// 返回结果 → LLM 生成最终回复\n\n总结：核心价值\n\n\n自然语言接口\n用户用自然语言触发复杂业务逻辑（如“取消我周二的预约”）\n\n\n业务逻辑解耦\n业务代码无需感知 AI 模型，只需关注功能实现\n\n\n动态决策能力\nLLM 根据问题语义自动选择工具并生成合规参数\n\n\n安全执行\n通过 JVM 沙箱、参数校验、会话隔离保障安全性\n\n\n这种设计使 LangChain4j 成为连接大语言模型与传统业务系统的桥梁，特别适合需要自然语言交互的复杂业务场景（如医疗挂号、订单管理等）。\n方法区里到底有什么\nJava 堆：是 JVM 中最大的一块内存区域，被所有线程共享，在虚拟机启动时创建，用于存放对象实例。从内存回收角度，堆被划分为新生代和老年代，新生代又分为 Eden 区和两个 Survivor 区（From Survivor 和 To Survivor）。如果在堆中没有内存完成实例分配，并且堆也无法扩展时会抛出 OutOfMemoryError 异常。\n方法区（元空间）：在 JDK 1.8 及以后的版本中，方法区被元空间取代，使用本地内存。用于存储已被虚拟机加载的类信息、常量、静态变量等数据。虽然方法区被描述为堆的逻辑部分，但有 “非堆” 的别名。方法区可以选择不实现垃圾收集，内存不足时会抛出 OutOfMemoryError 异常。\n\n1. 核心职责不同\n\n\n堆（Heap）\n对象生存的土壤：所有通过 new 创建的对象实例（包括数组）都存储于此。\n核心作用：支撑 Java 程序运行时 对象的动态分配和生命周期管理，是垃圾回收（GC）的主战场。\n\n\n方法区（Method Area / Metaspace）\n类元数据的基石：存储与类结构相关的静态信息（不是对象！）。\n核心作用：支撑 JVM 的 类加载机制，记录类的“设计蓝图”（如类名、方法字节码、字段定义等），是程序静态结构的仓库。\n\n\n\n2. 存储内容不同\n\n\n\n特性\n堆（Heap）\n方法区（元空间）\n\n\n\n\n存储对象\n✅ 所有对象实例、数组\n❌ 不存储任何对象实例\n\n\n类信息\n❌\n✅ 类名、父类、接口、访问修饰符\n\n\n方法字节码\n❌\n✅ 方法的代码指令（编译后的字节码）\n\n\n运行时常量池\n❌（但字符串常量池在堆中）\n✅ 类的字面量、符号引用等（在元空间内）\n\n\n静态变量\n❌\n✅ 静态变量（static 修饰的变量）\n\n\n字符串常量池\n✅（JDK7+ 从方法区移至堆）\n❌（JDK7 后不再存储在方法区）\n\n\n\n\n📌 关键差异：堆存“对象”，方法区存“类的描述信息”。\n\n\n3. 内存特性不同\n\n\n\n特性\n堆（Heap）\n方法区（元空间）\n\n\n\n\n内存位置\nJVM 管理的内存区域\nJDK8+：使用本地内存（Native Memory）\n\n\n垃圾回收\n✅ 频繁 GC（分代收集：新生代/老年代）\n✅ 低频率 GC（卸载不再使用的类）\n\n\n内存溢出错误\nOutOfMemoryError: Java heap space\nOutOfMemoryError: Metaspace\n\n\n扩展性\n受 -Xmx 限制，无法突破最大堆大小\n默认无上限（受物理内存限制），可设 -XX:MaxMetaspaceSize\n\n\n线程共享\n✅ 所有线程共享\n✅ 所有线程共享\n\n\n\n\n💡 元空间的本地内存特性：\nJDK8 将方法区从“堆内的永久代”迁移到“本地内存的元空间”，避免了永久代大小受限的问题（不再有 PermGen OutOfMemory），直接使用操作系统的内存。\n\n\n本质总结\n\n\n\n维度\n堆（Heap）\n方法区（Metaspace）\n\n\n\n\n是什么\n对象实例的运行时数据池\n类元数据的存储仓库\n\n\n存什么\nnew 出来的对象\n类的结构信息（非对象！）\n\n\n存在哪\nJVM 管理的堆内存\n操作系统本地内存（JDK8+）\n\n\n为何存在\n动态分配对象内存\n支撑类加载、反射、方法调用等机制\n\n\n\n\n场景比喻\n\n\n堆 → 汽车工厂的组装车间\n流水线上动态生产汽车（对象），空间不足时扩建厂房（扩容），废旧汽车拆解回收（GC）。\n\n\n方法区 → 工厂的设计档案室\n存放汽车设计图纸（类信息）、生产标准（字节码）、零件规格（常量）。档案室独立于车间（本地内存），图纸陈旧时才清理（类卸载）。\n\n\n《深入理解Java虚拟机》书中对方法区（Method Area）存储内容描述如下：它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。\n类信息：包括类的结构信息、类的访问修饰符、父类与接口等信息。\n常量池：存储类和接口中的常量，包括字面值常量、符号引用，以及运行时常量池。\n静态变量：存储类的静态变量，这些变量在类初始化的时候被赋值。\n方法字节码：存储类的方法字节码，即编译后的代码。\n符号引用：存储类和方法的符号引用，是一种直接引用不同于直接引用的引用类型。\n运行时常量池：存储着在类文件中的常量池数据，在类加载后在方法区生成该运行时常量池。\n常量池缓存：用于提升类加载的效率，将常用的常量缓存起来方便使用。\n#String保存在哪里呢？\nThreadLocal内存泄漏\nThreadLocal的实现中，每个Thread维护一个ThreadLocalMap映射表，key是ThreadLocal实例本身，value是真正需要存储的Object。\nThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统GC时，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value。\n如果当前线程迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreadLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。\n这条路径要记得！是ThreadLocalMap -&gt; Entry -&gt; value！这样的\n如何解决此问题？\n第一，使用ThreadLocal提供的remove方法，可对当前线程中的value值进行移除；\n对象头（Object Header）的详细解析\n在对象创建的第四步中，对象头（Object Header）的设置是JVM对对象进行内部管理的关键环节。对象头存储了对象的元数据信息，直接影响JVM的运行时行为（如锁机制、垃圾回收等）。以下从5个维度深入分析：\n\n一、对象头的结构\n对象头由 固定部分 和 可变部分 组成（以64位JVM为例，未开启压缩指针）：\n\n\n\n组成部分\n大小（64位JVM）\n作用\n\n\n\n\nMark Word\n8字节\n存储对象运行时数据：哈希码、GC分代年龄、锁状态等\n\n\nKlass Pointer\n8字节\n指向类元数据的指针（方法区中的Class对象）\n\n\n数组长度\n4字节（可选）\n仅当对象是数组时存在，记录数组长度\n\n\n\n内存布局示例\n|-------------------------------------------------------|| Mark Word (8 bytes) | Klass Pointer (8 bytes) | 数组长度 (4 bytes) | 实例数据... ||-------------------------------------------------------|\n\n二、Mark Word的详细内容\nMark Word是对象头的核心部分，其内容会根据对象状态动态变化（以HotSpot VM为例）：\n不同状态下的存储格式\n\n\n\n对象状态\n存储内容（64位JVM）\n\n\n\n\n无锁态\n25位哈希码 + 4位分代年龄 + 1位偏向锁标志（0） + 2位锁标志（01） + 32位未使用\n\n\n偏向锁\n54位线程ID + 2位Epoch + 4位分代年龄 + 1位偏向锁标志（1） + 2位锁标志（01）\n\n\n轻量级锁\n62位指向栈中锁记录的指针 + 2位锁标志（00）\n\n\n重量级锁\n62位指向监视器（Monitor）的指针 + 2位锁标志（10）\n\n\nGC标记\n62位空（用于标记可回收对象） + 2位锁标志（11）\n\n\n\n\n🔥 关键点：\n\n锁标志位（最后2位）决定当前对象的锁状态（01=无锁/偏向锁，00=轻量级锁，10=重量级锁，11=GC标记）。\n哈希码延迟计算：调用System.identityHashCode()时才生成并存入Mark Word。\n\n\n\n三、Klass Pointer的作用\nKlass Pointer指向方法区中的类元数据（即Class对象），使JVM能够：\n\n确定对象类型：在运行时识别对象属于哪个类。\n访问类信息：通过该指针找到方法表、字段定义等元数据。\n支持多态：结合方法表实现虚方法调用。\n\n压缩指针优化（-XX:+UseCompressedOops）\n\n开启后，Klass Pointer从8字节压缩为4字节，节省内存。\n要求堆内存不超过32GB（否则指针无法压缩）。\n\n\n四、数组长度的特殊处理\n当对象是数组时，对象头会额外增加4字节存储数组长度：\nint[] arr = new int[10];  // 对象头包含长度字段\n\n长度字段的存在让JVM能快速检查数组越界（如ArrayIndexOutOfBoundsException）。\n非数组对象没有此字段。\n\n\n五、对象头与JVM功能的关联\n1. 锁机制\n\n偏向锁：通过Mark Word中的线程ID实现，减少同步开销。\n轻量级锁：将Mark Word替换为指向线程栈锁记录的指针。\n重量级锁：指向Monitor对象（操作系统层面的互斥量）。\n\n2. 垃圾回收\n\n分代年龄：4位存储（最大15），触发GC时年龄+1，超过阈值则晋升老年代。\nGC标记：标记阶段用特殊位标识可回收对象。\n\n3. 内存布局优化\n\n字段重排序：JVM可能根据对象头信息调整实例字段的排列顺序，以节省内存。\n\nJava静态初始化（&lt;clinit&gt;）与对象初始化（&lt;init&gt;）总结\n在Java虚拟机（JVM）中，类的初始化过程被细分为两个截然不同的阶段：静态初始化（对应JVM的&lt;clinit&gt;方法）和对象初始化（对应JVM的&lt;init&gt;方法）。理解这两者的区别对于掌握Java类的生命周期、内存管理以及编写健程、高效的代码至关重要。\n核心差异概述\n\n\n\n特性\n静态初始化 (&lt;clinit&gt;)\n对象初始化 (&lt;init&gt;)\n\n\n\n\n作用范围\n类级别\n对象实例级别\n\n\n执行次数\n每个类在JVM生命周期中仅执行一次\n每次创建对象实例时执行\n\n\n触发时机\n类首次被主动使用时（如第一次 new、访问静态成员、反射加载类并初始化）\n每次执行 new 操作时\n\n\n内容\n静态变量赋初值、静态代码块\n实例变量赋初值、实例代码块、构造方法\n\n\n线程安全\n由JVM隐式保证（线程安全）\n需开发者自行处理（非线程安全）\n\n\n底层方法\n&lt;clinit&gt;\n&lt;init&gt;\n\n\n\n静态初始化（&lt;clinit&gt;）详解\n&lt;clinit&gt; 方法是编译器自动为每个类生成的，它汇集了源码中所有静态变量的显式赋值和静态代码块（static &#123;&#125;）中的逻辑。它的主要作用是完成类本身相关的准备工作，例如初始化静态字段、加载配置等类级别的资源。\n&lt;clinit&gt; 的触发严格且高效。只有在类被首次“主动使用”时（如通过 new 关键字创建实例、直接访问静态变量/方法、通过反射强制初始化等），JVM才会执行 &lt;clinit&gt;。一个类一旦完成初始化，后续的所有使用都不会再次触发 &lt;clinit&gt;。\n尤其重要的是，JVM为 &lt;clinit&gt; 方法的执行提供了线程安全性保证。当多个线程同时尝试初始化同一个类时，JVM会确保只有一个线程执行 &lt;clinit&gt;，其他线程会阻塞等待，直到初始化完成。这使得静态初始化成为实现简单线程安全单例模式的天然温床。\n反编译字节码可以清晰地看到 &lt;clinit&gt; 方法的存在，它按照源码中静态变量和静态块出现的顺序依次执行。\n对象初始化（&lt;init&gt;）详解\n&lt;init&gt; 方法则与类的实例（对象）紧密相关。它也是编译器自动生成的，合并了实例变量的显式赋值、实例代码块（&#123;&#125;）以及构造方法中的逻辑。每次通过 new 关键字创建一个对象时，都会调用该对象的 &lt;init&gt; 方法来初始化该实例特有的状态。\n与 &lt;clinit&gt; 不同，&lt;init&gt; 每次创建新对象时都会执行。这意味着同一个类的不同对象会执行各自独立的初始化过程。&lt;init&gt; 的执行顺序在继承体系中尤为关键：它总是先调用父类的 &lt;init&gt; 方法（通过 invokespecial 指令，对应父类构造器的执行），然后执行当前类的实例变量赋值和实例代码块，最后执行当前类的构造方法体。\n&lt;init&gt; 方法的执行不是线程安全的。多个线程创建各自的对象实例时，它们会独立地执行 &lt;init&gt;。如果对象的初始化逻辑（特别是构造方法或实例块中的代码）涉及到共享资源的修改，开发者必须自行实现同步机制（如使用 synchronized 关键字）来保证线程安全。\n反编译字节码同样会展示 &lt;init&gt; 方法，其中包含了对父类 &lt;init&gt; 的调用以及本类实例变量和实例块的初始化指令。\n关键对比与应用场景\n\n\n初始化顺序： 在一个继承体系中，当创建一个子类对象时，完整的初始化流程是：\n父类静态初始化 (Parent.&lt;clinit&gt;) -&gt; 子类静态初始化 (Child.&lt;clinit&gt;) -&gt; 父类对象初始化 (Parent.&lt;init&gt;) -&gt; 子类对象初始化 (Child.&lt;init&gt;)。静态初始化只发生一次，而对象初始化每次创建子类对象时都会重复。\n\n\n线程安全性： 利用 &lt;clinit&gt; 的线程安全特性可以轻松实现饿汉式单例模式，如 private static Singleton instance = new Singleton();，JVM保证在类加载时安全地创建实例。而懒汉式或其他复杂的对象创建若需线程安全，则需要在 &lt;init&gt; 或调用 &lt;init&gt; 的外部（如工厂方法）进行同步控制。\n\n\n异常处理： &lt;clinit&gt; 执行失败会导致 JVM 抛出 NoClassDefFoundError（而非 ClassNotFoundException），这个类在整个应用生命周期内将无法被正常使用，影响范围广。而 &lt;init&gt; 执行失败通常抛出正常的运行时异常，只影响当前对象的创建，不影响类的可用性或其他对象。\n\n\n标记-清除是非移动式回收算法​（Non-Moving），其设计决定了必须：\n标记阶段：全堆扫描以保证准确性。\n清除阶段：全堆扫描以释放内存。\n所以慢\n各种垃圾回收器\nSerial收集器（复制算法): 新生代单线程收集器，标记和清理都是单线程，优点是简单高效；\nParNew收集器 (复制算法): 新生代收并行集器，实际上是Serial收集器的多线程版本，在多核CPU环境下有着比Serial更好的表现；\nParallel Scavenge收集器 (复制算法): 新生代并行收集器，追求高吞吐量，高效利用 CPU。吞吐量 = 用户线程时间/(用户线程时间+GC线程时间)，高吞吐量可以高效率的利用CPU时间，尽快完成程序的运算任务，适合后台应用等对交互相应要求不高的场景；\nSerial Old收集器 (标记-整理算法): 老年代单线程收集器，Serial收集器的老年代版本；\nParallel Old收集器 (标记-整理算法)： 老年代并行收集器，吞吐量优先，Parallel Scavenge收集器的老年代版本；\nCMS(Concurrent Mark Sweep)收集器（标记-清除算法）： 老年代并行收集器，以获取最短回收停顿时间为目标的收集器，具有高并发、低停顿的特点，追求最短GC回收停顿时间。\nG1(Garbage First)收集器 (标记-整理算法)： Java堆并行收集器，G1收集器是JDK1.7提供的一个新收集器，G1收集器基于“标记-整理”算法实现，也就是说不会产生内存碎片。此外，G1收集器不同于之前的收集器的一个重要特点是：G1回收的范围是整个Java堆(包括新生代，老年代)，而前六种收集器回收的范围仅限于新生代或老年代\nCMS与G1的标记过程对比及STW阶段分析\nCMS（Concurrent Mark-Sweep）和G1（Garbage-First）是两种不同的垃圾回收器，它们在标记过程和STW（Stop-The-World）行为上有显著差异。以下是详细对比：\n\n一、CMS的标记过程与STW阶段\nCMS的设计目标是最小化老年代回收的停顿时间，其标记过程分为以下阶段：\n1. 初始标记（Initial Mark）\n\nSTW：暂停所有应用线程。\n任务：仅标记GC Roots直接引用的老年代对象（不递归标记）。\n耗时：极短（通常几毫秒），因为只扫描直接引用。\n\n2. 并发标记（Concurrent Marking）\n\n并发执行：与用户线程同时运行。\n任务：从初始标记的对象出发，递归标记所有老年代可达对象。\n耗时：较长（取决于老年代对象数量），但无需STW。\n问题：可能产生浮动垃圾（标记期间新产生的垃圾）。\n\n3. 重新标记（Remark）\n\nSTW：暂停所有应用线程。\n任务：修正并发标记期间因用户线程运行导致的引用变化（如新增或删除的引用）。\n优化技术：使用**增量更新（Incremental Update）或卡表（Card Table）**减少扫描范围。\n耗时：比初始标记长，但远短于并发标记（通常10-100ms）。\n\n4. 并发清除（Concurrent Sweep）\n\n并发执行：与用户线程同时运行。\n任务：清理未被标记的垃圾对象（不整理内存，导致碎片化）。\n耗时：较长，但无需STW。\n\n\n二、G1的标记过程与STW阶段\nG1的设计目标是平衡吞吐量和低延迟，其标记过程更复杂，覆盖整个堆（新生代+老年代）：\n1. 初始标记（Initial Mark）\n\nSTW：暂停所有应用线程。\n任务：标记GC Roots直接引用的对象（类似CMS）。\n附加工作：与**年轻代GC（Young GC）**一起执行（借道Young GC的STW）。\n耗时：极短（通常几毫秒）。\n\n2. 并发标记（Concurrent Marking）\n\n并发执行：与用户线程同时运行。\n任务：递归标记整个堆（包括新生代和老年代）的可达对象。\n优化技术：使用**Snapshot-At-The-Beginning（SATB）**算法记录初始快照，减少重新标记工作量。\n耗时：较长，但无需STW。\n\n3. 最终标记（Final Marking）\n\nSTW：暂停所有应用线程。\n任务：处理SATB队列中的引用变化，完成标记。\n耗时：比CMS的重新标记更可控（通常10-50ms）。\n\n4. 清理阶段（Cleanup）\n\n部分STW：\n\nSTW部分：统计存活对象，选择回收收益高的Region（基于G1的回收优先级）。\n并发部分：重置空Region的标记状态。\n\n\n耗时：通常很短（几毫秒）。\n\n5. 复制阶段（Evacuation）\n\nSTW：暂停所有应用线程。\n任务：将存活对象从待回收Region复制到空闲Region（压缩内存）。\n耗时：取决于存活对象数量（通常10-200ms）。\n\n\n三、CMS与G1的关键差异\n\n\n\n维度\nCMS\nG1\n\n\n\n\n作用区域\n仅老年代\n整个堆（新生代+老年代）\n\n\n标记范围\n仅老年代对象\n全堆对象\n\n\nSTW阶段\n初始标记、重新标记\n初始标记、最终标记、清理（部分）、复制\n\n\n并发阶段\n并发标记、并发清除\n并发标记\n\n\n内存整理\n不整理（碎片化严重）\n复制阶段整理（减少碎片）\n\n\n触发条件\n老年代空间不足\n基于Region的回收阈值（默认45%堆占用）\n\n\n适用场景\n低延迟老年代回收\n大堆内存、平衡吞吐量与延迟\n\n\n\n\n四、STW阶段的本质差异\n1. CMS的STW更少但不可控\n\n优点：仅初始标记和重新标记需要STW，适合对延迟敏感的老年代回收。\n缺点：\n\n并发清除不整理内存，最终可能触发Full GC（Serial Old）整理碎片。\n重新标记时间可能因引用变化量波动。\n\n\n\n2. G1的STW更多但可预测\n\n优点：\n\n通过SATB算法和Region分区，使最终标记时间更稳定。\n复制阶段整理内存，避免碎片化问题。\n\n\n缺点：总体STW时间比CMS长，但通过停顿预测模型（-XX:MaxGCPauseMillis）控制。\n\n\n五、如何选择？\n\n选择CMS：若应用需要极低的老年代停顿（如延迟敏感型服务），且堆内存较小（如4-6GB以下）。\n选择G1：若堆内存较大（如6GB以上），或需要平衡吞吐量与延迟（如大数据处理）。\n四个STW过程中，初始标记因为只标记GC Roots，耗时较短。再标记因为对象数少，耗时也较短。清理阶段因为内存分区数量少，耗时也较短。转移阶段要处理所有存活的对象，耗时会较长。\n因此，G1停顿时间的瓶颈主要是标记-复制中的转移阶段STW\n\n浮动垃圾（Floating Garbage）深度解析与CMS/G1差异总结\n在并发垃圾回收器中，为了减少或消除GC时对用户线程的长时间暂停（Stop-The-World, STW），垃圾回收过程的部分或大部分是与用户线程并行进行的。然而，这种并发性引入了一个特有的问题：浮动垃圾（Floating Garbage）。\n什么是浮动垃圾？\n浮动垃圾是指在垃圾回收器执行并发阶段（如并发标记或并发清理）时，由于用户线程仍在运行并修改对象引用关系，导致原本被认为是存活的对象变得不可达（即成为垃圾）。这些新产生的垃圾对象因为它们“出现”在标记或清理过程的“之后”，本轮GC无法识别并回收它们，它们就像“浮”在水面上一样，只能等待下一轮GC周期才能被清理。\n简单来说，如果在并发标记阶段，一个对象 A 被标记为存活，但随后用户线程将指向 A 的唯一引用设置为 null，那么 A 就成为了本轮GC的浮动垃圾。\nCMS 回收器与浮动垃圾\nCMS（Concurrent Mark Sweep）回收器是典型的处理老年代的并发回收器。其核心思想是希望大部分标记和清理工作能够与用户线程并发进行。然而，CMS的设计决定了它必然会产生浮动垃圾，并且浮动垃圾可能导致严重的问题。\nCMS 的主要步骤包括：\n\n初始标记 (STW)：标记GC Roots直接关联的对象。\n并发标记 (Concurrent)：从GC Roots开始遍历对象图，标记所有存活对象。此阶段用户线程运行，可能创建新对象、断开引用，产生浮动垃圾。\n重新标记 (STW)：修正并发标记期间因用户线程活动导致的对象引用变化。虽然尝试修正，但仍无法完全捕捉所有变化。\n并发清理 (Concurrent)：扫描堆，回收未被标记的对象。此阶段用户线程也运行，会继续创建新对象并可能产生新的垃圾，这些新垃圾也成为浮动垃圾。\n\nCMS 回收的特点是非移动式的（Non-moving），即它只负责标记和清除死对象占据的空间，但不整理内存，会产生内存碎片。由于清理是并发进行的，CMS 无法实时地追踪和处理用户线程新产生的浮动垃圾。这些浮动垃圾会一直占据内存空间，直到下一轮GC周期才能被回收。\n为了应对浮动垃圾可能导致的内存不足问题，CMS 必须预留一部分老年代空间。如果预留空间被浮动垃圾耗尽，而用户线程此时需要分配内存或对象需要晋升到老年代，就会触发 Concurrent Mode Failure，此时JVM会紧急启动一个 Full GC（通常是 Serial Old 回收器），这是一个全堆范围的、单线程的、STW的回收过程，会导致应用长时间停顿，严重影响性能。因此，CMS 的一个重要调优参数 -XX:CMSInitiatingOccupancyFraction 就是控制老年代在何种占用比例下启动GC，以尽早回收，留出足够的空间容纳浮动垃圾和新晋升的对象。\nG1 回收器与浮动垃圾\nG1（Garbage-First）回收器是面向大堆的、区域（Region）化的并发回收器。虽然G1也是并发回收器，它也产生浮动垃圾，但处理方式和影响与CMS有显著不同，通常认为G1没有CMS那样突出的“浮动垃圾问题”。\nG1通过以下机制来缓解浮动垃圾的影响：\n\nRegion 分区：G1将堆划分为多个大小相等的 Region。GC时可以针对性地回收部分 Region。\nSATB 标记算法 (Snapshot-At-The-Beginning)：G1在并发标记阶段使用的是 SATB 算法。SATB 会记录标记开始时的对象引用图快照。在并发标记过程中，如果用户线程删除了一个引用，SATB 会通过 Remembered Set 记录下来。SATB 的核心思想是：所有在标记开始时被快照认为是存活的对象，都会被视为存活，即使它们在标记过程中变成了垃圾。这意味着 SATB 会有意地将一部分本应是垃圾的对象标记为存活——这些就是G1中的浮动垃圾。\n筛选回收 (Evacuation)：G1的清理阶段本质上是并行复制。在 Evacuation 阶段（通常有较短的STW），G1会将选中区域（包括新生代和部分老年代）中的存活对象复制到新的空闲 Region 中。原先的 Region 整个被释放。这个复制过程是并行的，且在STW下进行，因此不会产生新的浮动垃圾。\n\nG1的SATB算法产生的浮动垃圾不会导致像CMS那样的 Concurrent Mode Failure。被SATB错误标记为存活的浮动垃圾对象会被复制到新Region中，它们只是延迟到下一轮GC周期才会被回收。G1通过控制每次 Evacuation 回收的 Region 数量（基于用户设置的目标暂停时间）来管理内存回收速率，而不是依赖预留空间来应对随时可能溢出的浮动垃圾。即使G1的并发标记跟不上用户线程分配速率，导致没有足够的空闲Region进行Evacuation，它会增加 Evacuation 的 Region 数量或临时 Full GC，但这种 Full GC 的触发原因和CMS的 CM Failure 不同，也通常优化得比 Serial Old 好。\n总结\n\n\n\n维度\nCMS\nG1\n\n\n\n\n标记算法\n增量更新 (Incremental Update)\n原始快照 (SATB - Snapshot-At-The-Beginning)\n\n\n清理方式\n并发清理 (Sweep - Non-moving)\n并行复制 (Evacuation - Moving)\n\n\n浮动垃圾来源\n并发标记和并发清理阶段用户线程修改引用\n并发标记阶段用户线程修改引用 (SATB特性)\n\n\n浮动垃圾影响\n累积可能导致内存不足，触发 CM Failure (STW)\n被SATB标记为存活，延迟到下一轮回收，不直接导致 CM Failure\n\n\n应对策略\n预留内存空间 (CMSInitiatingOccupancyFraction)\nSATB + Region化 + 并行复制 (延迟清理)\n\n\n\n核心差异在于，CMS的非移动式并发清理与浮动垃圾的产生直接冲突，需要预留空间避免失败；而G1的SATB标记和并行复制机制虽然也产生浮动垃圾，但将其处理推迟到下一轮，并通过Region的管理和复制的方式避免了CMS那种因浮动垃圾填满老年代导致的紧急STW退化。因此，理解浮动垃圾的产生及其在不同回收器中的处理方式，对于选择合适的GC回收器和进行性能调优至关重要。\n\nclass Solution &#123;    public int[] maxSlidingWindow(int[] nums, int k) &#123;         int n = nums.length;         int[] ans = new int[n - k + 1];         Deque&lt;Integer&gt; q = new LinkedList&lt;&gt;();         for (int i = 0;i &lt; n;i++)&#123;            while (!q.isEmpty() &amp;&amp; nums[q.getLast()] &lt;= nums[i])&#123;               q.removeLast();            &#125;            q.addLast();            while (!q.isEmpty() &amp;&amp; i - q.getFirst() &gt;= k)&#123;               q.removeFirst();            &#125;            if (i &gt;= k)&#123;               ans[i-k+1] = q.getFirst();            &#125;         &#125;         return ans;    &#125;&#125;","tags":["其他"]}]