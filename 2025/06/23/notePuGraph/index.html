<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/notes.github.io/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/notes.github.io/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/notes.github.io/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/notes.github.io/images/logo.svg" color="#222">

<link rel="stylesheet" href="/notes.github.io/css/main.css">


<link rel="stylesheet" href="/notes.github.io/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chenzhan20050128.github.io","root":"/notes.github.io/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="图的邻接矩阵最大特征值上下界证明设图 $$ G $$ 的邻接矩阵为 $$ A $$，其最大特征值为 $$ \alpha_1 $$，平均度 $$ d_{\text{avg}} &#x3D; \frac{2|E|}{n} $$，最大度数为 $$ \Delta &#x3D; \deg_{\max}(G) $$。需证明：$$d_{\text{avg}} \leq \alpha_1 \leq \Delta$">
<meta property="og:type" content="article">
<meta property="og:title" content="notePuGraph">
<meta property="og:url" content="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/notePuGraph/index.html">
<meta property="og:site_name" content="cz Blog">
<meta property="og:description" content="图的邻接矩阵最大特征值上下界证明设图 $$ G $$ 的邻接矩阵为 $$ A $$，其最大特征值为 $$ \alpha_1 $$，平均度 $$ d_{\text{avg}} &#x3D; \frac{2|E|}{n} $$，最大度数为 $$ \Delta &#x3D; \deg_{\max}(G) $$。需证明：$$d_{\text{avg}} \leq \alpha_1 \leq \Delta$">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-06-23T10:56:58.000Z">
<meta property="article:modified_time" content="2025-06-23T10:56:58.279Z">
<meta property="article:author" content="Chen Zhan">
<meta property="article:tag" content="其他">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/notePuGraph/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>notePuGraph | cz Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/notes.github.io/atom.xml" title="cz Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/notes.github.io/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">cz Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Hello World</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/notes.github.io/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/notes.github.io/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/chenzhan20050128" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/notePuGraph/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes.github.io/images/woshicaigou.jpg">
      <meta itemprop="name" content="Chen Zhan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cz Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          notePuGraph
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-23 18:56:58" itemprop="dateCreated datePublished" datetime="2025-06-23T18:56:58+08:00">2025-06-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="图的邻接矩阵最大特征值上下界证明"><a href="#图的邻接矩阵最大特征值上下界证明" class="headerlink" title="图的邻接矩阵最大特征值上下界证明"></a>图的邻接矩阵最大特征值上下界证明</h3><p>设图 $$ G $$ 的邻接矩阵为 $$ A $$，其最大特征值为 $$ \alpha_1 $$，平均度 $$ d_{\text{avg}} &#x3D; \frac{2|E|}{n} $$，最大度数为 $$ \Delta &#x3D; \deg_{\max}(G) $$。需证明：<br>$$d_{\text{avg}} \leq \alpha_1 \leq \Delta$$</p>
<hr>
<h4 id="上界证明（-alpha-1-leq-Delta"><a href="#上界证明（-alpha-1-leq-Delta" class="headerlink" title="上界证明（$$ \alpha_1 \leq \Delta $$)"></a><strong>上界证明（$$ \alpha_1 \leq \Delta $$)</strong></h4><ol>
<li><p><strong>特征值与特征向量定义</strong><br>设 $$ \alpha_1 $$ 为 $$ A $$ 的最大特征值，对应的特征向量为 $$ \bm{v} $$，满足：<br>$$A\bm{v} &#x3D; \alpha_1 \bm{v}$$<br>假设 $$ \bm{v} $$ 是单位向量（即 $$ |\bm{v}|_2 &#x3D; 1 $$）。</p>
</li>
<li><p><strong>选择最大分量</strong><br>取 $$ \bm{v} $$ 中绝对值最大的分量为 $$ v_j $$，即：<br>$$|v_j| &#x3D; \max_{i} |v_i| &gt; 0$$<br>根据特征方程，对第 $$ j $$ 行有：<br>$$\alpha_1 v_j &#x3D; \sum_{i&#x3D;1}^n A_{j,i} v_i$$</p>
</li>
<li><p><strong>绝对值的三角不等式</strong><br>取绝对值后：<br>$$|\alpha_1| |v_j| &#x3D; \left| \sum_{i&#x3D;1}^n A_{j,i} v_i \right| \leq \sum_{i&#x3D;1}^n |A_{j,i}| |v_i|$$<br>因为邻接矩阵元素 $$ A_{j,i} \in {0,1} $$，且 $$ |v_i| \leq |v_j| $$，可得：<br>$$\sum_{i&#x3D;1}^n |A_{j,i}| |v_i| \leq \sum_{i&#x3D;1}^n A_{j,i} |v_j| &#x3D; \deg(j) |v_j| \leq \Delta |v_j|$$</p>
</li>
<li><p><strong>化简不等式</strong><br>结合上述结果：<br>$$|\alpha_1| |v_j| \leq \Delta |v_j|$$<br>因 $$ |v_j| &gt; 0 $$，两边约去后得：<br>$$|\alpha_1| \leq \Delta$$<br>由于 $$ \alpha_1 $$ 是实对称矩阵（无向图）的最大特征值，必为非负实数，故：<br>$$\alpha_1 \leq \Delta$$</p>
</li>
</ol>
<hr>
<h4 id="下界证明（-d-text-avg-leq-alpha-1"><a href="#下界证明（-d-text-avg-leq-alpha-1" class="headerlink" title="下界证明（$$ d_{\text{avg}} \leq \alpha_1 $$)"></a><strong>下界证明（$$ d_{\text{avg}} \leq \alpha_1 $$)</strong></h4><ol>
<li><strong>Rayleigh商性质</strong><br>最大特征值 $$ \alpha_1 $$ 满足：<br>$$\alpha_1 &#x3D; \max_{\bm{x} \neq \bm{0}} \frac{\bm{x}^T A \bm{x}}{\bm{x}^T \bm{x}}$$<br>取 $$ \bm{x} &#x3D; \bm{1} $$（全1向量），则：<br>$$\bm{x}^T A \bm{x} &#x3D; \sum_{i,j} A_{i,j} &#x3D; 2|E|$$<br>分母为：<br>$$\bm{x}^T \bm{x} &#x3D; n$$<br>因此：<br>$$\alpha_1 \geq \frac{2|E|}{n} &#x3D; d_{\text{avg}}$$</li>
</ol>
<hr>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h4><p>结合上下界结果，得：<br>$$\boxed{d_{\text{avg}} \leq \alpha_1 \leq \Delta}$$<br><strong>关键点</strong>：</p>
<ul>
<li><strong>上界</strong>：通过特征向量分量的最大性，结合邻接矩阵的稀疏性（每行非零元素数为度数）。</li>
<li><strong>下界</strong>：利用Rayleigh商与全1向量的计算，将最大特征值与平均度关联。</li>
</ul>
<h3 id="引理证明详解"><a href="#引理证明详解" class="headerlink" title="引理证明详解"></a>引理证明详解</h3><p><strong>引理</strong>：对于二分图 $$ G $$，若 $$ \alpha $$ 是邻接矩阵 $$ A(G) $$ 的特征值且重数为 $$ k $$，则 $$ -\alpha $$ 也是 $$ A(G) $$ 的特征值，重数同样为 $$ k $$。</p>
<hr>
<h4 id="1-邻接矩阵的分块结构"><a href="#1-邻接矩阵的分块结构" class="headerlink" title="1. 邻接矩阵的分块结构"></a><strong>1. 邻接矩阵的分块结构</strong></h4><p>设二分图 $$ G $$ 的两个顶点集为 $$ U $$ 和 $$ V $$，其邻接矩阵可表示为分块形式：<br>$$A &#x3D; \begin{pmatrix}<br>0 &amp; B \<br>B^T &amp; 0<br>\end{pmatrix},$$<br>其中 $$ B $$ 是 $$ |U| \times |V| $$ 的矩阵，描述 $$ U $$ 到 $$ V $$ 的边，且 $$ B^T $$ 是 $$ B $$ 的转置。</p>
<hr>
<h4 id="2-特征值与特征向量的对应关系"><a href="#2-特征值与特征向量的对应关系" class="headerlink" title="2. 特征值与特征向量的对应关系"></a><strong>2. 特征值与特征向量的对应关系</strong></h4><p>假设 $$ \begin{pmatrix} x \ y \end{pmatrix} $$ 是 $$ A $$ 的特征向量，对应特征值 $$ \alpha $$，即：<br>$$A \begin{pmatrix} x \ y \end{pmatrix} &#x3D; \alpha \begin{pmatrix} x \ y \end{pmatrix}.$$<br>展开分块矩阵乘法，得到方程组：<br>$$\begin{cases}<br>B y &#x3D; \alpha x, \<br>B^T x &#x3D; \alpha y.<br>\end{cases}$$</p>
<hr>
<h4 id="3-构造-alpha-的特征向量"><a href="#3-构造-alpha-的特征向量" class="headerlink" title="3. 构造 $$ -\alpha $$ 的特征向量"></a><strong>3. 构造 $$ -\alpha $$ 的特征向量</strong></h4><p>考虑向量 $$ \begin{pmatrix} x \ -y \end{pmatrix} $$，计算其作用：<br>$$A \begin{pmatrix} x \ -y \end{pmatrix} &#x3D; \begin{pmatrix}<br>0 &amp; B \<br>B^T &amp; 0<br>\end{pmatrix} \begin{pmatrix} x \ -y \end{pmatrix} &#x3D; \begin{pmatrix} -B y \ B^T x \end{pmatrix}.$$<br>代入 $$ B y &#x3D; \alpha x $$ 和 $$ B^T x &#x3D; \alpha y $$，得：<br>$$A \begin{pmatrix} x \ -y \end{pmatrix} &#x3D; \begin{pmatrix} -\alpha x \ \alpha y \end{pmatrix} &#x3D; -\alpha \begin{pmatrix} x \ -y \end{pmatrix}.$$<br>这表明 $$ \begin{pmatrix} x \ -y \end{pmatrix} $$ 是 $$ A $$ 对应特征值 $$ -\alpha $$ 的特征向量。</p>
<hr>
<h4 id="4-重数的等价性"><a href="#4-重数的等价性" class="headerlink" title="4. 重数的等价性"></a><strong>4. 重数的等价性</strong></h4><ul>
<li><p><strong>线性无关性保持</strong>：<br>若 $$ \alpha $$ 的重数为 $$ k $$，则存在 $$ k $$ 个线性无关的特征向量 $$ \left{ \begin{pmatrix} x_1 \ y_1 \end{pmatrix}, \dots, \begin{pmatrix} x_k \ y_k \end{pmatrix} \right} $$。<br>构造对应的向量组 $$ \left{ \begin{pmatrix} x_1 \ -y_1 \end{pmatrix}, \dots, \begin{pmatrix} x_k \ -y_k \end{pmatrix} \right} $$。<br><strong>验证线性无关性</strong>：<br>假设存在标量 $$ c_1, \dots, c_k $$ 使得：<br>$$\sum_{i&#x3D;1}^k c_i \begin{pmatrix} x_i \ -y_i \end{pmatrix} &#x3D; \begin{pmatrix} 0 \ 0 \end{pmatrix}.$$<br>拆分分量得：<br>$$\sum_{i&#x3D;1}^k c_i x_i &#x3D; 0 \quad \text{和} \quad -\sum_{i&#x3D;1}^k c_i y_i &#x3D; 0.$$<br>由于原向量组线性无关，唯一解为 $$ c_1 &#x3D; \dots &#x3D; c_k &#x3D; 0 $$，故变换后的向量组仍线性无关。</p>
</li>
<li><p><strong>对称性保证重数相等</strong>：<br>邻接矩阵 $$ A $$ 是实对称矩阵，其特征值均为实数，且不同特征值对应的特征向量正交。<br>若 $$ \alpha \neq 0 $$，则 $$ \alpha $$ 和 $$ -\alpha $$ 为不同特征值，其重数由矩阵的谱定理保证相等（因特征空间维度相同）。</p>
</li>
</ul>
<hr>
<h4 id="5-零特征值的特殊情况"><a href="#5-零特征值的特殊情况" class="headerlink" title="5. 零特征值的特殊情况"></a><strong>5. 零特征值的特殊情况</strong></h4><p>当 $$ \alpha &#x3D; 0 $$ 时，$$ -\alpha &#x3D; 0 $$，重数显然相同。此时特征向量满足 $$ B y &#x3D; 0 $$ 和 $$ B^T x &#x3D; 0 $$，其解空间的维度由矩阵 $$ B $$ 的秩决定，对 $$ \alpha $$ 和 $$ -\alpha $$ 一致。</p>
<hr>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a><strong>总结</strong></h4><p>通过分块矩阵的结构分析、特征向量的符号变换以及线性无关性保持，可严格证明：<br>$$\text{重数}(\alpha) &#x3D; \text{重数}(-\alpha) &#x3D; k.$$</p>
<hr>
<h2 id="引理证明："><a href="#引理证明：" class="headerlink" title="引理证明："></a><strong>引理证明</strong>：</h2><p><strong>条件</strong>：设 $$ G $$ 是简单无向图，其邻接矩阵 $$ A $$ 的特征值满足 $$ \alpha_i &#x3D; -\alpha_{n-i+1} $$ 对所有 $$ i $$ 成立。</p>
<p><strong>目标</strong>：证明 $$ G $$ 是二分图（即不含奇数长度的环）。</p>
<p><strong>证明步骤</strong>：</p>
<ol>
<li><p><strong>特征值幂和为零</strong>：<br>对于任意奇数 $$ k $$，特征值的 $$ k $$ 次幂之和满足<br>$$\sum_{i&#x3D;1}^n \alpha_i^k &#x3D; 0.$$<br><em>推导</em>：由条件 $$ \alpha_i &#x3D; -\alpha_{n-i+1} $$，特征值成对互为相反数。对每一对 $$ (\alpha_i, -\alpha_i) $$，其奇数次幂和为 $$ \alpha_i^k + (-\alpha_i)^k &#x3D; 0 $$。若 $$ n $$ 为奇数，中间特征值必为 $$ 0 $$，贡献为 $$ 0 $$。故总和为 $$ 0 $$。</p>
</li>
<li><p><strong>矩阵幂的迹为零</strong>：<br>邻接矩阵 $$ A^k $$ 的迹为<br>$$\text{trace}(A^k) &#x3D; \sum_{i&#x3D;1}^n \alpha_i^k &#x3D; 0.$$<br><em>依据</em>：矩阵的迹等于其特征值的和，且 $$ A^k $$ 的特征值为 $$ \alpha_i^k $$。</p>
</li>
<li><p><strong>闭合走路不存在</strong>：<br>$$ \text{trace}(A^k) $$ 的组合意义为长度为 $$ k $$ 的闭合走路总数。由于迹为零，且 $$ (A^k)<em>{i,i} \geq 0 $$ 对每个顶点 $$ i $$，故<br>$$(A^k)</em>{i,i} &#x3D; 0 \quad \text{对所有顶点} , i , \text{和奇数} , k.$$<br>因此，图中不存在长度为 $$ k $$ 的闭合走路（包括简单环）。</p>
</li>
<li><p><strong>排除奇环</strong>：<br>若存在奇数长度环，其对应闭合走路会使 $$ (A^k)_{i,i} \geq 1 $$，与 $$ \text{trace}(A^k) &#x3D; 0 $$ 矛盾。故 $$ G $$ 不含任何奇数长度的环。</p>
</li>
<li><p><strong>二分图判定</strong>：<br>图论定理指出，无奇环的图必为二分图。因此，$$ G $$ 是二分图。</p>
</li>
</ol>
<p><strong>结论</strong>：邻接矩阵特征值关于零对称的图 $$ G $$ 必为二分图，证毕。</p>
<h3 id="拉普拉斯矩阵（Laplacian-Matrix）详解"><a href="#拉普拉斯矩阵（Laplacian-Matrix）详解" class="headerlink" title="拉普拉斯矩阵（Laplacian Matrix）详解"></a>拉普拉斯矩阵（Laplacian Matrix）详解</h3><h4 id="1-基本定义"><a href="#1-基本定义" class="headerlink" title="1. 基本定义"></a>1. <strong>基本定义</strong></h4><p>给定一个无向图 $$ G &#x3D; (V, E) $$，其拉普拉斯矩阵 $$ L(G) $$ 定义为：<br>$$L(G) &#x3D; D(G) - A(G)$$</p>
<ul>
<li><strong>度矩阵 $$ D(G) $$</strong>：对角矩阵，对角线元素 $$ D_{u,u} &#x3D; \text{deg}(u) $$，表示顶点 $$ u $$ 的度数，非对角线元素为 0。</li>
<li><strong>邻接矩阵 $$ A(G) $$</strong>：矩阵元素 $$ A_{u,v} &#x3D; 1 $$ 当且仅当边 $$ uv \in E $$，否则为 0。</li>
</ul>
<h4 id="2-正则图的拉普拉斯矩阵"><a href="#2-正则图的拉普拉斯矩阵" class="headerlink" title="2. 正则图的拉普拉斯矩阵"></a>2. <strong>正则图的拉普拉斯矩阵</strong></h4><p>对于 <strong>$$ d $$-正则图</strong>（每个顶点的度数均为 $$ d $$），度矩阵可写为：<br>$$D(G) &#x3D; dI$$<br>其中 $$ I $$ 是单位矩阵。因此，拉普拉斯矩阵简化为：<br>$$L(G) &#x3D; dI - A(G)$$</p>
<ul>
<li><strong>特征空间关系</strong>：正则图的邻接矩阵 $$ A(G) $$ 和拉普拉斯矩阵 $$ L(G) $$ <strong>共享相同的特征向量</strong>，且特征值满足线性关系：<br>$$\lambda_L &#x3D; d - \lambda_A$$<br>其中 $$ \lambda_L $$ 是 $$ L(G) $$ 的特征值，$$ \lambda_A $$ 是 $$ A(G) $$ 的对应特征值。<br><strong>例子</strong>：在 3-正则图中，若 $$ A $$ 的特征值为 3, 1, -2，则 $$ L $$ 的特征值为 0, 2, 5（因为 $$ 3 - 3 &#x3D; 0 $$, $$ 3 - 1 &#x3D; 2 $$, $$ 3 - (-2) &#x3D; 5 $$）。</li>
</ul>
<h4 id="3-一般图的拉普拉斯矩阵"><a href="#3-一般图的拉普拉斯矩阵" class="headerlink" title="3. 一般图的拉普拉斯矩阵"></a>3. <strong>一般图的拉普拉斯矩阵</strong></h4><p>对于非正则图，度矩阵 $$ D(G) $$ 不再是标量矩阵，因此：<br>$$L(G) &#x3D; D(G) - A(G)$$</p>
<ul>
<li><strong>特征空间差异</strong>：由于 $$ D(G) $$ 的对角元素（度数）不再一致，$$ L(G) $$ 和 $$ A(G) $$ 的 <strong>特征向量不再相同</strong>，特征值之间也无简单线性关系。<br><strong>例子</strong>：若图包含一个度数为 2 的顶点和一个度数为 1 的顶点，$$ D(G) $$ 和 $$ A(G) $$ 的相互作用复杂，导致特征空间独立。</li>
</ul>
<h4 id="4-拉普拉斯矩阵的边分解"><a href="#4-拉普拉斯矩阵的边分解" class="headerlink" title="4. 拉普拉斯矩阵的边分解"></a>4. <strong>拉普拉斯矩阵的边分解</strong></h4><p>拉普拉斯矩阵可分解为 <strong>单边贡献</strong> 的和：<br>$$L(G) &#x3D; \sum_{e \in E} L_e$$<br>其中每条边 $$ e &#x3D; (u, v) $$ 对应的矩阵 $$ L_e $$ 定义为：<br>$$L_e &#x3D; b_e b_e^\top$$</p>
<ul>
<li><strong>关联向量 $$ b_e $$</strong>：向量 $$ b_e $$ 的长度为顶点数 $$ |V| $$，定义如下：<br>$$b_e(u) &#x3D; 1, \quad b_e(v) &#x3D; -1, \quad \text{其他位置为} \ 0.$$<br><strong>展开形式</strong>：例如，若边 $$ e $$ 连接顶点 1 和 2，则：<br>$$b_e &#x3D; [1, -1, 0, \dots, 0]^\top$$<br>$$L_e &#x3D; b_e b_e^\top &#x3D; \begin{bmatrix}<br>1 &amp; -1 &amp; 0 &amp; \cdots \<br>-1 &amp; 1 &amp; 0 &amp; \cdots \<br>0 &amp; 0 &amp; 0 &amp; \cdots \<br>\vdots &amp; \vdots &amp; \vdots &amp; \ddots<br>\end{bmatrix}$$</li>
<li><strong>求和验证</strong>：将所有边的 $$ L_e $$ 相加：<ul>
<li>对角线元素：每个顶点 $$ u $$ 的度数为与其相连的边数，因此 $$ \sum_{e \ni u} L_e(u,u) &#x3D; \text{deg}(u) $$，对应 $$ D(G) $$。</li>
<li>非对角线元素：边 $$ uv $$ 对应的 $$ L_e $$ 在位置 $$ (u,v) $$ 和 $$ (v,u) $$ 处为 -1，累加后对应 $$ -A(G) $$。<br>因此：<br>$$\sum_{e \in E} L_e &#x3D; D(G) - A(G) &#x3D; L(G)$$</li>
</ul>
</li>
</ul>
<h4 id="5-分解的意义"><a href="#5-分解的意义" class="headerlink" title="5. 分解的意义"></a>5. <strong>分解的意义</strong></h4><ul>
<li><strong>物理意义</strong>：每条边独立地对拉普拉斯矩阵产生“局部影响”，整体效果通过叠加实现。</li>
<li><strong>应用场景</strong>：此分解在 <strong>随机游走</strong>、<strong>电阻网络</strong> 和 <strong>图信号处理</strong> 中用于分析边对全局性质的贡献。</li>
</ul>
<h3 id="拉普拉斯矩阵-L-G-的性质与证明"><a href="#拉普拉斯矩阵-L-G-的性质与证明" class="headerlink" title="拉普拉斯矩阵 $$ L(G) $$ 的性质与证明"></a><strong>拉普拉斯矩阵 $$ L(G) $$ 的性质与证明</strong></h3><h4 id="1-定义回顾"><a href="#1-定义回顾" class="headerlink" title="1. 定义回顾"></a><strong>1. 定义回顾</strong></h4><p>给定无向图 $$ G &#x3D; (V, E) $$，其拉普拉斯矩阵 $$ L(G) $$ 定义为：<br>$$L(G) &#x3D; D(G) - A(G)$$<br>其中：</p>
<ul>
<li>$$ D(G) $$ 是<strong>度矩阵</strong>（对角矩阵，$$ D_{u,u} &#x3D; \text{deg}(u) $$），</li>
<li>$$ A(G) $$ 是<strong>邻接矩阵</strong>（$$ A_{u,v} &#x3D; 1 $$ 当且仅当 $$ uv \in E $$）。</li>
</ul>
<p>拉普拉斯矩阵可以分解为所有边的贡献之和：<br>$$L(G) &#x3D; \sum_{e \in E} L_e, \quad \text{其中} \quad L_e &#x3D; b_e b_e^\top$$<br>其中 $$ b_e $$ 是边 $$ e &#x3D; (u, v) $$ 的<strong>关联向量</strong>：<br>$$b_e(u) &#x3D; 1, \quad b_e(v) &#x3D; -1, \quad \text{其余位置为} \ 0.$$</p>
<hr>
<h3 id="2-性质-1：-mathbf-1-是-L-G-的特征向量，对应特征值-0"><a href="#2-性质-1：-mathbf-1-是-L-G-的特征向量，对应特征值-0" class="headerlink" title="2. 性质 1：$$ \mathbf{1} $$ 是 $$ L(G) $$ 的特征向量，对应特征值 0"></a><strong>2. 性质 1：$$ \mathbf{1} $$ 是 $$ L(G) $$ 的特征向量，对应特征值 0</strong></h3><p><strong>证明</strong>：</p>
<ul>
<li>由于 $$ L(G) &#x3D; D(G) - A(G) $$，计算 $$ L(G) \mathbf{1} $$：<br>$$(L(G) \mathbf{1})<em>u &#x3D; \text{deg}(u) \cdot 1 - \sum</em>{v \sim u} 1 &#x3D; \text{deg}(u) - \text{deg}(u) &#x3D; 0$$<br>因此：<br>$$L(G) \mathbf{1} &#x3D; \mathbf{0} &#x3D; 0 \cdot \mathbf{1}$$<br>这说明 $$ \mathbf{1} $$ 是 $$ L(G) $$ 的特征向量，对应特征值 0。</li>
</ul>
<p><strong>直观解释</strong>：</p>
<ul>
<li>拉普拉斯矩阵的每一行代表一个顶点的度数减去其邻居的影响，而 $$ \mathbf{1} $$ 是一个均匀向量，使得所有顶点的度数贡献和邻居贡献相互抵消，最终得到 0。</li>
</ul>
<hr>
<h3 id="3-性质-2：-L-G-是半正定矩阵（-L-G-succeq-0-）"><a href="#3-性质-2：-L-G-是半正定矩阵（-L-G-succeq-0-）" class="headerlink" title="3. 性质 2：$$ L(G) $$ 是半正定矩阵（$$ L(G) \succeq 0 $$）"></a><strong>3. 性质 2：$$ L(G) $$ 是半正定矩阵（$$ L(G) \succeq 0 $$）</strong></h3><p><strong>证明</strong>：</p>
<ul>
<li>利用拉普拉斯矩阵的边分解：<br>$$L(G) &#x3D; \sum_{e \in E} b_e b_e^\top$$</li>
<li>对于任意向量 $$ x \in \mathbb{R}^n $$，计算二次型：<br>$$x^\top L(G) x &#x3D; x^\top \left( \sum_{e \in E} b_e b_e^\top \right) x &#x3D; \sum_{e \in E} x^\top b_e b_e^\top x$$</li>
<li>由于 $$ b_e^\top x &#x3D; x_u - x_v $$（其中 $$ e &#x3D; (u, v) $$），因此：<br>$$x^\top L(G) x &#x3D; \sum_{e &#x3D; (u, v) \in E} (x_u - x_v)^2 \geq 0$$<br>因为平方项非负，所以 $$ L(G) $$ 是半正定的。</li>
</ul>
<p><strong>关键步骤解释</strong>：</p>
<ul>
<li><strong>$$ x^\top b_e b_e^\top x &#x3D; (b_e^\top x)^2 &#x3D; (x_u - x_v)^2 $$</strong>：<ul>
<li>由于 $$ b_e $$ 仅在 $$ u $$ 和 $$ v $$ 处有非零值（1 和 -1），所以：<br>$$b_e^\top x &#x3D; \sum_{i&#x3D;1}^n b_e(i) x_i &#x3D; x_u - x_v$$</li>
<li>因此，$$ x^\top b_e b_e^\top x &#x3D; (x_u - x_v)^2 $$，即每条边贡献一个平方差项。</li>
</ul>
</li>
</ul>
<p><strong>结论</strong>：</p>
<ul>
<li>由于 $$ x^\top L(G) x $$ 是所有边的平方差之和，且 $$ (x_u - x_v)^2 \geq 0 $$，所以 $$ L(G) $$ 是半正定的。</li>
<li>最小特征值为 0，因为 $$ L(G) \mathbf{1} &#x3D; \mathbf{0} $$，即存在非零向量 $$ \mathbf{1} $$ 使得二次型为 0。</li>
</ul>
<hr>
<h3 id="定理"><a href="#定理" class="headerlink" title="定理"></a><strong>定理</strong></h3><p>给定图 $$ G $$，它是连通的当且仅当拉普拉斯矩阵 $$ L(G) $$ 的特征值 0 的重数为 1。</p>
<hr>
<h3 id="证明（⇐）：不连通图的情况"><a href="#证明（⇐）：不连通图的情况" class="headerlink" title="证明（⇐）：不连通图的情况"></a><strong>证明（⇐）：不连通图的情况</strong></h3><p>假设 $$ G $$ 不连通，则 $$ G $$ 可划分为至少两个连通分量 $$ V_1 $$ 和 $$ V_2 $$。此时，$$ L(G) $$ 可表示为分块对角矩阵：<br>$$L(G) &#x3D; \begin{bmatrix}<br>L(G_1) &amp; 0 \<br>0 &amp; L(G_2)<br>\end{bmatrix}$$<br>其中 $$ L(G_1) $$ 和 $$ L(G_2) $$ 分别是子图 $$ G_1 $$ 和 $$ G_2 $$ 的拉普拉斯矩阵。  </p>
<p>由于 $$ G_1 $$ 和 $$ G_2 $$ 各自连通，$$ L(G_1) $$ 和 $$ L(G_2) $$ 均有一个特征值 0，对应的特征向量分别为 $$ \mathbf{1}<em>{V_1} $$（$$ V_1 $$ 上的全 1 向量）和 $$ \mathbf{1}</em>{V_2} $$（$$ V_2 $$ 上的全 1 向量）。因此，$$ L(G) $$ 的零空间由以下线性无关向量张成：<br>$$\begin{bmatrix}<br>\mathbf{1}<em>{V_1} \<br>0<br>\end{bmatrix}, \quad<br>\begin{bmatrix}<br>0 \<br>\mathbf{1}</em>{V_2}<br>\end{bmatrix}$$<br>故特征值 0 的重数至少为 2。  </p>
<p><strong>结论</strong>：若 $$ G $$ 不连通，则 $$ L(G) $$ 的特征值 0 的重数大于 1。</p>
<hr>
<h3 id="证明（⇒）：连通图的情况"><a href="#证明（⇒）：连通图的情况" class="headerlink" title="证明（⇒）：连通图的情况"></a><strong>证明（⇒）：连通图的情况</strong></h3><p>假设 $$ G $$ 连通，且存在向量 $$ x $$ 满足 $$ L(G)x &#x3D; 0 $$。由半正定性：<br>$$x^\top L(G) x &#x3D; \sum_{(i,j) \in E} (x_i - x_j)^2 &#x3D; 0$$<br>因此，对所有边 $$ (i,j) \in E $$，有 $$ x_i &#x3D; x_j $$。由于 $$ G $$ 连通，任意两顶点 $$ i $$ 和 $$ j $$ 可通过路径连接，故 $$ x_i &#x3D; x_j $$ 对所有 $$ i,j \in V $$ 成立。即 $$ x $$ 必为全 1 向量 $$ \mathbf{1} $$ 的标量倍：<br>$$x &#x3D; c \cdot \mathbf{1}$$<br>因此，零空间维度为 1，特征值 0 的重数为 1。  </p>
<p><strong>结论</strong>：若 $$ G $$ 连通，则 $$ L(G) $$ 的特征值 0 的重数为 1。</p>
<hr>
<h2 id="定理证明"><a href="#定理证明" class="headerlink" title="定理证明"></a>定理证明</h2><p><strong>定理</strong>：给定图 $$ G $$，其拉普拉斯矩阵的特征值满足 $$ 0 &#x3D; \lambda_1 \leq \lambda_2 \leq \cdots \leq \lambda_n $$，则<br>$$\lambda_k &#x3D; 0 \quad \text{当且仅当} \quad G , \text{有至少} , k , \text{个连通分量}.$$</p>
<hr>
<h4 id="证明"><a href="#证明" class="headerlink" title="证明"></a><strong>证明</strong></h4><ol>
<li><p><strong>方向（⇒）：若 $$ \lambda_k &#x3D; 0 $$，则 $$ G $$ 至少有 $$ k $$ 个连通分量</strong>  </p>
<ul>
<li><strong>拉普拉斯矩阵的零特征值重数</strong>：<br>由已知，若图 $$ G $$ 有 $$ m $$ 个连通分量，则其拉普拉斯矩阵 $$ L(G) $$ 可表示为分块对角矩阵：<br>$$L(G) &#x3D; \begin{bmatrix}<br>L(G_1) &amp; 0 &amp; \cdots &amp; 0 \<br>0 &amp; L(G_2) &amp; \cdots &amp; 0 \<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \<br>0 &amp; 0 &amp; \cdots &amp; L(G_m)<br>\end{bmatrix},$$<br>其中每个 $$ L(G_i) $$ 对应一个连通分量的拉普拉斯矩阵。  <ul>
<li>每个连通分量 $$ G_i $$ 的 $$ L(G_i) $$ 有一个零特征值（对应特征向量为 $$ \mathbf{1}_{G_i} $$），其余特征值为正。  </li>
<li>因此，$$ L(G) $$ 的零特征值总数为 $$ m $$，即 $$ \lambda_1 &#x3D; \lambda_2 &#x3D; \cdots &#x3D; \lambda_m &#x3D; 0 $$。</li>
</ul>
</li>
<li><strong>结论</strong>：<br>若 $$ \lambda_k &#x3D; 0 $$，则 $$ k \leq m $$，即 $$ G $$ 至少有 $$ k $$ 个连通分量。</li>
</ul>
</li>
<li><p><strong>方向（⇐）：若 $$ G $$ 有至少 $$ k $$ 个连通分量，则 $$ \lambda_k &#x3D; 0 $$</strong>  </p>
<ul>
<li><strong>零特征值的数量</strong>：<br>设 $$ G $$ 有 $$ m \geq k $$ 个连通分量，则 $$ L(G) $$ 的零特征值数量为 $$ m $$。<br>由于特征值按升序排列，前 $$ m $$ 个特征值为零，即：<br>$$\lambda_1 &#x3D; \lambda_2 &#x3D; \cdots &#x3D; \lambda_m &#x3D; 0.$$<br>因此，当 $$ k \leq m $$ 时，$$ \lambda_k &#x3D; 0 $$。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="关键步骤"><a href="#关键步骤" class="headerlink" title="关键步骤"></a><strong>关键步骤</strong></h4><ol>
<li><p><strong>分块对角矩阵的特征值</strong>：  </p>
<ul>
<li>若 $$ G $$ 分解为 $$ m $$ 个连通分量，则 $$ L(G) $$ 的特征值为各子图 $$ L(G_i) $$ 特征值的并集。  </li>
<li>每个 $$ L(G_i) $$ 贡献一个零特征值，其余为正特征值。因此，$$ L(G) $$ 的零特征值数量为 $$ m $$。</li>
</ul>
</li>
<li><p><strong>特征值排序</strong>：  </p>
<ul>
<li>前 $$ m $$ 个特征值为零，即 $$ \lambda_1 &#x3D; \lambda_2 &#x3D; \cdots &#x3D; \lambda_m &#x3D; 0 $$。  </li>
<li>后续特征值为各子图的最小正特征值升序排列，即 $$ \lambda_{m+1} &gt; 0 $$。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="推论"><a href="#推论" class="headerlink" title="推论"></a><strong>推论</strong></h4><ul>
<li><strong>连通性判定</strong>：  <ul>
<li>$$ \lambda_2 &gt; 0 \iff G $$ 是连通的（即 $$ m &#x3D; 1 $$）。  </li>
<li>$$ \lambda_2 &#x3D; 0 \iff G $$ 不连通（即 $$ m \geq 2 $$）。</li>
</ul>
</li>
<li><strong>一般情况</strong>：<br>$$ \lambda_k &#x3D; 0 $$ 当且仅当 $$ G $$ 有至少 $$ k $$ 个连通分量，即零特征值的重数等于连通分量数。</li>
</ul>
<hr>
<h2 id="Perron-Frobenius定理的证明思路简介"><a href="#Perron-Frobenius定理的证明思路简介" class="headerlink" title="Perron-Frobenius定理的证明思路简介"></a>Perron-Frobenius定理的证明思路简介</h2><p>Perron-Frobenius定理是非负矩阵理论的核心成果，针对非负、不可约且非周期的矩阵 $$ A $$，其证明思路可概括如下：</p>
<hr>
<h4 id="1-最大特征值-lambda-1-的重数为1"><a href="#1-最大特征值-lambda-1-的重数为1" class="headerlink" title="1. 最大特征值 $$ \lambda_1 $$ 的重数为1"></a><strong>1. 最大特征值 $$ \lambda_1 $$ 的重数为1</strong></h4><p><strong>核心思路</strong>：  </p>
<ul>
<li><strong>存在性</strong>：通过构造 <strong>Collatz-Wielandt函数</strong> $$ r_A(x) &#x3D; \min_{x_i \neq 0} \frac{(Ax)_i}{x_i} $$，证明存在正向量 $$ x $$ 使得 $$ r_A(x) &#x3D; \lambda_1 $$，即 $$ \lambda_1 $$ 是谱半径 $$ \rho(A) $$（最大特征值）。  </li>
<li><strong>唯一性</strong>：利用 <strong>不可约性</strong>，若存在两个不同的正特征向量对应 $$ \lambda_1 $$，则可通过线性组合构造矛盾，说明代数重数为1。  </li>
<li><strong>关键工具</strong>：Gelfand公式 $$ \rho(A) &#x3D; \lim_{k \to \infty} |A^k|^{1&#x2F;k} $$ 用于证明 $$ \lambda_1 $$ 的极值性。</li>
</ul>
<hr>
<h4 id="2-对应特征向量全为正且符号一致"><a href="#2-对应特征向量全为正且符号一致" class="headerlink" title="2. 对应特征向量全为正且符号一致"></a><strong>2. 对应特征向量全为正且符号一致</strong></h4><p><strong>核心思路</strong>：  </p>
<ul>
<li><strong>非负性到正性</strong>：若 $$ A $$ 不可约，其对应的特征向量 $$ v $$ 非负且非零。通过不可约性，$$ (I + A)^{n-1} $$ 会将任何非零向量映射为正向量，从而 $$ v $$ 必须全正。  </li>
<li><strong>符号一致性</strong>：假设存在分量符号不同，则通过矩阵的不可约性（连通性）推导矛盾，证明所有分量符号一致。</li>
</ul>
<hr>
<h4 id="3-其他特征值满足-lambda-i-lambda-1-2-leq-i-leq-n"><a href="#3-其他特征值满足-lambda-i-lambda-1-2-leq-i-leq-n" class="headerlink" title="3. 其他特征值满足 $$ |\lambda_i| &lt; \lambda_1 , (2 \leq i \leq n) $$"></a><strong>3. 其他特征值满足 $$ |\lambda_i| &lt; \lambda_1 , (2 \leq i \leq n) $$</strong></h4><p><strong>核心思路</strong>：  </p>
<ul>
<li><strong>周期性排除</strong>：若 $$ A $$ 非周期（本原矩阵），存在 $$ m $$ 使 $$ A^m $$ 为正矩阵，此时 $$ \lambda_i^m $$ 的模严格小于 $$ \lambda_1^m $$。  </li>
<li><strong>矛盾法</strong>：假设存在 $$ \lambda_j $$ 满足 $$ |\lambda_j| &#x3D; \lambda_1 $$，则通过复特征值的三角不等式与不可约性矛盾，证明 $$ |\lambda_j| &lt; \lambda_1 $$ 。</li>
</ul>
<hr>
<h2 id="Cheeger不等式与图的连通性度量"><a href="#Cheeger不等式与图的连通性度量" class="headerlink" title="Cheeger不等式与图的连通性度量"></a><strong>Cheeger不等式与图的连通性度量</strong></h2><h4 id="1-图的连通性与拉普拉斯矩阵特征值"><a href="#1-图的连通性与拉普拉斯矩阵特征值" class="headerlink" title="1. 图的连通性与拉普拉斯矩阵特征值"></a><strong>1. 图的连通性与拉普拉斯矩阵特征值</strong></h4><p>对于图 $$ G $$，其拉普拉斯矩阵 $$ L(G) $$ 的特征值满足 $$ 0 &#x3D; \lambda_1 \leq \lambda_2 \leq \cdots \leq \lambda_n $$。  </p>
<ul>
<li><strong>连通性判据</strong>：  <ul>
<li>$$ G $$ 是连通的 $$\iff \lambda_2 &gt; 0$$。  </li>
<li>$$ G $$ 不连通的 $$\iff \lambda_2 &#x3D; 0$$（此时零特征值的重数等于连通分量数）。</li>
</ul>
</li>
</ul>
<h4 id="2-传导率（Conductance）的定义"><a href="#2-传导率（Conductance）的定义" class="headerlink" title="2. 传导率（Conductance）的定义"></a><strong>2. 传导率（Conductance）的定义</strong></h4><p>传导率量化了图 $$ G $$ 的“接近不连通”程度：  </p>
<ul>
<li><strong>顶点子集 $$ S \subseteq V $$ 的传导率</strong>：<br>$$\phi(S) &#x3D; \frac{|\delta(S)|}{\text{vol}(S)}, \quad \text{vol}(S) &#x3D; \sum_{v \in S} \deg(v)$$<br>其中 $$ \delta(S) $$ 是 $$ S $$ 与补集 $$ V \setminus S $$ 之间的边集。  </li>
<li><strong>图的传导率</strong>：<br>$$\phi(G) &#x3D; \min_{S: \text{vol}(S) \leq m} \phi(S), \quad m &#x3D; \frac{1}{2}\text{vol}(V)$$<br>$$ \phi(G) $$ 越小，图越容易通过稀疏割（Sparse Cut）分离。</li>
</ul>
<h4 id="3-Cheeger不等式"><a href="#3-Cheeger不等式" class="headerlink" title="3. Cheeger不等式"></a><strong>3. Cheeger不等式</strong></h4><p>Cheeger不等式建立了 $$ \lambda_2 $$ 与 $$ \phi(G) $$ 的关系：<br>$$\frac{\lambda_2}{2} \leq \phi(G) \leq \sqrt{2 \lambda_2}$$<br><strong>解释</strong>：  </p>
<ul>
<li><strong>下界</strong>：若 $$ \lambda_2 $$ 小，则 $$ \phi(G) $$ 也小，表明存在稀疏割。  </li>
<li><strong>上界</strong>：传导率低时，$$ \lambda_2 $$ 必小，反映图接近不连通。</li>
</ul>
<h4 id="4-扩展图（Expander-Graph）与稀疏割"><a href="#4-扩展图（Expander-Graph）与稀疏割" class="headerlink" title="4. 扩展图（Expander Graph）与稀疏割"></a><strong>4. 扩展图（Expander Graph）与稀疏割</strong></h4><ul>
<li><strong>扩展图</strong>：$$ \phi(G) $$ 为常数（如 0.1），具有强连通性，常用于设计鲁棒网络。  </li>
<li><strong>稀疏割</strong>：$$ \phi(S) $$ 极小的子集 $$ S $$，对应图的分割瓶颈，应用于：  <ul>
<li><strong>图像分割</strong>：通过最小化传导率分离前景&#x2F;背景。  </li>
<li><strong>社区检测</strong>：识别社交网络中的紧密群体。  </li>
<li><strong>VLSI设计</strong>：优化电路布局以减少交叉干扰。</li>
</ul>
</li>
</ul>
<h2 id="Cheeger不等式"><a href="#Cheeger不等式" class="headerlink" title="Cheeger不等式"></a><strong>Cheeger不等式</strong></h2><p>是图论中一个重要的结果，它将图的展开性（通过Cheeger常数度量）与图的谱性质（通过拉普拉斯矩阵的特征值）联系起来。下面分步证明Cheeger不等式的两个方向，并特别关注归一化拉普拉斯矩阵与邻接矩阵的特征值关系。</p>
<hr>
<h3 id="基本定义与符号"><a href="#基本定义与符号" class="headerlink" title="基本定义与符号"></a><strong>基本定义与符号</strong></h3><ol>
<li><p><strong>图的基本矩阵</strong>：</p>
<ul>
<li>邻接矩阵 $$ A $$：元素 $$ A_{ij} $$ 表示顶点 $$ i $$ 和 $$ j $$ 之间的边数。</li>
<li>度矩阵 $$ D $$：对角矩阵，$$ D_{ii} &#x3D; \text{deg}(i) $$。</li>
<li><strong>归一化邻接矩阵</strong>：$$ \mathcal{A} &#x3D; D^{-1&#x2F;2} A D^{-1&#x2F;2} $$。</li>
<li><strong>归一化拉普拉斯矩阵</strong>：$$ \mathcal{L} &#x3D; D^{-1&#x2F;2} L D^{-1&#x2F;2} &#x3D; I - \mathcal{A} $$，其中 $$ L &#x3D; D - A $$ 是未归一化的拉普拉斯矩阵。</li>
</ul>
</li>
<li><p><strong>特征值约定</strong>：</p>
<ul>
<li>$$ \alpha_1 \geq \alpha_2 \geq \cdots \geq \alpha_n $$ 是 $$ \mathcal{A} $$ 的特征值。</li>
<li>$$ \lambda_1 \leq \lambda_2 \leq \cdots \leq \lambda_n $$ 是 $$ \mathcal{L} $$ 的特征值。</li>
<li>由于 $$ \mathcal{L} &#x3D; I - \mathcal{A} $$，有 $$ \lambda_i &#x3D; 1 - \alpha_i $$。</li>
</ul>
</li>
<li><p><strong>Cheeger常数</strong>：</p>
<ul>
<li>图的展开性由Cheeger常数 $$ \phi(G) $$ 度量，定义为：<br>$$\phi(G) &#x3D; \min_{S \subset V} \frac{|\partial S|}{\min(\text{vol}(S), \text{vol}(V \setminus S))},$$<br>其中 $$ \partial S $$ 是边界边集，$$ \text{vol}(S) &#x3D; \sum_{i \in S} \text{deg}(i) $$。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="简单方向（Easy-Direction）：-lambda-2-leq-2-phi-G"><a href="#简单方向（Easy-Direction）：-lambda-2-leq-2-phi-G" class="headerlink" title="简单方向（Easy Direction）：$$ \lambda_2 \leq 2\phi(G) $$"></a><strong>简单方向（Easy Direction）：$$ \lambda_2 \leq 2\phi(G) $$</strong></h3><p><strong>目标</strong>：证明第二小特征值 $$ \lambda_2 $$ 是Cheeger常数的上界，即 $$ \lambda_2 \leq 2\phi(G) $$。</p>
<p><strong>证明步骤</strong>：</p>
<ol>
<li><p><strong>变分刻画</strong>：</p>
<ul>
<li>$$ \lambda_2 $$ 可以表示为如下优化问题的极小值：<br>$$\lambda_2 &#x3D; \min_{x \perp D^{1&#x2F;2} \mathbf{1}} \frac{x^T \mathcal{L} x}{x^T x} &#x3D; \min_{x \perp D^{1&#x2F;2} \mathbf{1}} \frac{\sum_{(i,j) \in E} (x_i - x_j)^2}{\sum_{i \in V} x_i^2 \text{deg}(i)}.$$</li>
</ul>
</li>
<li><p><strong>构造测试向量</strong>：</p>
<ul>
<li>设 $$ S $$ 是使得 $$ \phi(S) &#x3D; \phi(G) $$ 的集合，定义向量 $$ x $$：<br>$$x_i &#x3D; \begin{cases}<br> 1&#x2F;\sqrt{\text{vol}(S)}, &amp; i \in S, \<br> -1&#x2F;\sqrt{\text{vol}(V \setminus S)}, &amp; i \notin S.<br>\end{cases}$$</li>
<li>验证 $$ x \perp D^{1&#x2F;2} \mathbf{1} $$，即 $$ \sum_{i} x_i \sqrt{\text{deg}(i)} &#x3D; 0 $$。</li>
</ul>
</li>
<li><p><strong>计算Rayleigh商</strong>：</p>
<ul>
<li>分子 $$ \sum_{(i,j) \in E} (x_i - x_j)^2 &#x3D; \frac{|\partial S|}{\text{vol}(S)} + \frac{|\partial S|}{\text{vol}(V \setminus S)} $$.</li>
<li>分母 $$ \sum_{i} x_i^2 \text{deg}(i) &#x3D; 2 $$.</li>
<li>因此：<br>$$\frac{x^T \mathcal{L} x}{x^T x} &#x3D; \frac{|\partial S|}{2} \left( \frac{1}{\text{vol}(S)} + \frac{1}{\text{vol}(V \setminus S)} \right) \leq 2\phi(G).$$</li>
</ul>
</li>
<li><p><strong>结论</strong>：</p>
<ul>
<li>由于 $$ \lambda_2 $$ 是所有满足条件的 $$ x $$ 中Rayleigh商的极小值，故 $$ \lambda_2 \leq 2\phi(G) $$。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="困难方向（Hard-Direction）：-phi-G-leq-sqrt-2-lambda-2"><a href="#困难方向（Hard-Direction）：-phi-G-leq-sqrt-2-lambda-2" class="headerlink" title="困难方向（Hard Direction）：$$ \phi(G) \leq \sqrt{2\lambda_2} $$"></a><strong>困难方向（Hard Direction）：$$ \phi(G) \leq \sqrt{2\lambda_2} $$</strong></h3><p><strong>目标</strong>：证明Cheeger常数被第二小特征值控制，即 $$ \phi(G) \leq \sqrt{2\lambda_2} $$。</p>
<p><strong>证明思路</strong>：<br>通过谱划分算法（Spectral Partitioning），利用 $$ \lambda_2 $$ 对应的特征向量构造一个集合 $$ S $$，使得其展开性不超过 $$ \sqrt{2\lambda_2} $$。</p>
<p><strong>证明步骤</strong>：</p>
<ol>
<li><p><strong>特征向量选择</strong>：</p>
<ul>
<li>设 $$ f $$ 是 $$ \mathcal{L} $$ 对应 $$ \lambda_2 $$ 的特征向量，满足 $$ f \perp D^{1&#x2F;2} \mathbf{1} $$。</li>
</ul>
</li>
<li><p><strong>排序与阈值化</strong>：</p>
<ul>
<li>将顶点按 $$ f_i $$ 的值升序排列：$$ f_1 \leq f_2 \leq \cdots \leq f_n $$.</li>
<li>定义阈值 $$ t $$，构造集合 $$ S_t &#x3D; {i | f_i \leq t} $$，寻找使 $$ \phi(S_t) $$ 最小的 $$ t $$。</li>
</ul>
</li>
<li><p><strong>利用中位数技巧</strong>：</p>
<ul>
<li>通过选择合适的中位数阈值 $$ t $$，保证 $$ \text{vol}(S_t) \geq \frac{1}{2}\text{vol}(V) $$ 且边界边数 $$ |\partial S_t| $$ 被控制。</li>
</ul>
</li>
<li><p><strong>估计边界边数</strong>：</p>
<ul>
<li>利用Cauchy-Schwarz不等式和特征向量的性质，有：<br>$$|\partial S_t| \leq \sqrt{2\lambda_2 \cdot \text{vol}(S_t) \cdot \text{vol}(V \setminus S_t)}.$$</li>
<li>结合 $$ \text{vol}(S_t) \geq \frac{1}{2}\text{vol}(V) $$，得到 $$ \phi(S_t) \leq \sqrt{2\lambda_2} $$。</li>
</ul>
</li>
<li><p><strong>结论</strong>：</p>
<ul>
<li>因此存在集合 $$ S $$ 使得 $$ \phi(G) \leq \sqrt{2\lambda_2} $$。</li>
</ul>
</li>
</ol>
<hr>
<h1 id="回到马尔科夫链"><a href="#回到马尔科夫链" class="headerlink" title="回到马尔科夫链"></a>回到马尔科夫链</h1><p>对于有限的连通无向图，随机游走的概率分布 $$ p_t &#x3D; \left( \frac{1}{2}I + \frac{1}{2}AD^{-1} \right)^t p_0 $$ 随时间演化最终收敛到稳态分布 $$ \frac{\vec{d}}{2m} $$，其中 $$ \vec{d} $$ 是度数向量，$$ m $$ 是图的边数。</p>
<hr>
<h3 id="1-转移矩阵的构造与性质"><a href="#1-转移矩阵的构造与性质" class="headerlink" title="1. 转移矩阵的构造与性质"></a><strong>1. 转移矩阵的构造与性质</strong></h3><p><strong>转移矩阵</strong> $$ P $$ 的表达式为：<br>$$P &#x3D; \frac{1}{2}I + \frac{1}{2}AD^{-1}$$</p>
<ul>
<li><strong>物理意义</strong>：这是一个<strong>懒惰随机游走</strong>（Lazy Random Walk）的转移矩阵。每一步有 $$ \frac{1}{2} $$ 的概率停留在当前节点，$$ \frac{1}{2} $$ 的概率按传统无偏随机游走（TURW）的规则转移到邻居节点。</li>
<li><strong>作用</strong>：引入停留概率后，转移矩阵 $$ P $$ 的马尔可夫链变为<strong>非周期</strong>的，从而保证收敛性（传统随机游走可能是周期性的，导致不收敛）。</li>
</ul>
<hr>
<h3 id="2-稳态分布的存在性"><a href="#2-稳态分布的存在性" class="headerlink" title="2. 稳态分布的存在性"></a><strong>2. 稳态分布的存在性</strong></h3><p>对于连通无向图，随机游走的稳态分布 $$ \pi $$ 需满足：<br>$$\pi &#x3D; \pi P$$<br>代入 $$ P $$ 的表达式，展开可得：<br>$$\pi &#x3D; \frac{1}{2}\pi I + \frac{1}{2}\pi AD^{-1}$$<br>由于 $$ \pi I &#x3D; \pi $$，化简后得到：<br>$$\pi &#x3D; \pi AD^{-1}$$<br>这表明稳态分布 $$ \pi $$ 也是传统无偏随机游走（TURW）的稳态分布。根据经典结论，TURW的稳态分布与节点度数成正比：<br>$$\pi_i &#x3D; \frac{d_i}{2m}$$<br>其中 $$ d_i $$ 是节点 $$ i $$ 的度数，$$ m $$ 是图的边数。</p>
<hr>
<h3 id="3-收敛性证明"><a href="#3-收敛性证明" class="headerlink" title="3. 收敛性证明"></a><strong>3. 收敛性证明</strong></h3><p><strong>条件</strong>：图是<strong>连通</strong>且<strong>非周期</strong>的。</p>
<ul>
<li><strong>连通性</strong>：保证马尔可夫链是<strong>不可约</strong>的，即任意状态可达。</li>
<li><strong>非周期性</strong>：通过懒惰随机游走的停留概率实现，避免了周期性震荡。</li>
</ul>
<p><strong>谱分析</strong>：</p>
<ul>
<li>转移矩阵 $$ P $$ 的特征值满足 $$ |\lambda| \leq 1 $$，其中最大特征值为 $$ \lambda_1 &#x3D; 1 $$，对应稳态分布 $$ \frac{\vec{d}}{2m} $$。</li>
<li>其他特征值 $$ \lambda_2, \ldots, \lambda_n $$ 满足 $$ |\lambda_i| &lt; 1 $$，当 $$ t \to \infty $$ 时，它们的贡献衰减为零。</li>
</ul>
<p><strong>初始分布的分解</strong>：<br>将初始分布 $$ p_0 $$ 表示为 $$ P $$ 的特征向量线性组合：<br>$$p_0 &#x3D; c_1 \pi + \sum_{i&#x3D;2}^n c_i v_i$$<br>其中 $$ v_i $$ 是对应特征值 $$ \lambda_i $$ 的特征向量。经过 $$ t $$ 步迭代后：<br>$$p_t &#x3D; P^t p_0 &#x3D; c_1 \pi + \sum_{i&#x3D;2}^n c_i \lambda_i^t v_i$$<br>当 $$ t \to \infty $$ 时，第二项趋近于零，因此 $$ p_t \to \pi &#x3D; \frac{\vec{d}}{2m} $$。</p>
<hr>
<h3 id="定理及证明步骤详解"><a href="#定理及证明步骤详解" class="headerlink" title="定理及证明步骤详解"></a>定理及证明步骤详解</h3><h4 id="定理陈述"><a href="#定理陈述" class="headerlink" title="定理陈述"></a><strong>定理陈述</strong></h4><p>对有限连通无向图的随机游走，其ε-混合时间上界为：<br>$$t_{\text{mix}}(\epsilon) \leq \frac{1}{\lambda} \log\left(\frac{n}{\epsilon}\right),$$<br>其中 $$\lambda &#x3D; \min{1 - \alpha_2, 1 - |\alpha_n|}$$，$$\alpha_2$$ 和 $$\alpha_n$$ 分别是归一化转移矩阵的第二大和最小特征值。</p>
<hr>
<h3 id="证明步骤详解"><a href="#证明步骤详解" class="headerlink" title="证明步骤详解"></a><strong>证明步骤详解</strong></h3><h4 id="1-特征向量分解与转移矩阵展开"><a href="#1-特征向量分解与转移矩阵展开" class="headerlink" title="1. 特征向量分解与转移矩阵展开"></a><strong>1. 特征向量分解与转移矩阵展开</strong></h4><p>假设转移矩阵 $$W$$ 对应的归一化邻接矩阵 $$\mathcal{A}$$ 具有正交正规特征向量基 $${v_1, v_2, \ldots, v_n}$$，对应的特征值为 $$\alpha_1 \geq \alpha_2 \geq \cdots \geq \alpha_n$$。对于初始分布 $$p_0$$，可分解为：<br>$$p_0 &#x3D; c_1 v_1 + c_2 v_2 + \cdots + c_n v_n,$$<br>其中 $$v_1$$ 对应稳态分布 $$\pi$$（即 $$\alpha_1 &#x3D; 1$$）。经过 $$t$$ 步转移后，分布为：<br>$$p_t &#x3D; W^t p_0 &#x3D; c_1 \alpha_1^t v_1 + c_2 \alpha_2^t v_2 + \cdots + c_n \alpha_n^t v_n.$$<br>由于稳态分布 $$\pi &#x3D; c_1 v_1$$，偏差项为：<br>$$p_t - \pi &#x3D; \sum_{i&#x3D;2}^n c_i \alpha_i^t v_i.$$</p>
<p><strong>关键点</strong>：  </p>
<ul>
<li>特征向量分解将随机游走的演化分解为稳态项与衰减项的组合。</li>
<li>稳态对应的特征值 $$\alpha_1 &#x3D; 1$$，非稳态特征值满足 $$|\alpha_i| &lt; 1$$，因此衰减项随 $$t$$ 指数消失。</li>
</ul>
<hr>
<h4 id="2-范数转换：L1-到-L2-范数"><a href="#2-范数转换：L1-到-L2-范数" class="headerlink" title="2. 范数转换：L1 到 L2 范数"></a><strong>2. 范数转换：L1 到 L2 范数</strong></h4><p>通过 <strong>Cauchy-Schwarz 不等式</strong>，将总变差距离（L1 范数）转换为 L2 范数：<br>$$|p_t - \pi|_1 \leq \sqrt{n} |p_t - \pi|_2,$$<br>其中 $$\sqrt{n}$$ 的因子源于向量的维度 $$n$$（即图的顶点数）。<br><strong>推导逻辑</strong>：  </p>
<ul>
<li>L1 范数定义为 $$|x|_1 &#x3D; \sum_i |x_i|$$，L2 范数为 $$|x|_2 &#x3D; \sqrt{\sum_i x_i^2}$$。</li>
<li>由 Cauchy-Schwarz 不等式可得 $$|x|_1 \leq \sqrt{n} |x|_2$$，这是因为每个分量 $$|x_i|$$ 的绝对值之和被 $$\sqrt{n}$$ 和 L2 范数控制。</li>
</ul>
<hr>
<h4 id="3-计算-L2-范数的平方"><a href="#3-计算-L2-范数的平方" class="headerlink" title="3. 计算 L2 范数的平方"></a><strong>3. 计算 L2 范数的平方</strong></h4><p>展开偏差项的 L2 范数平方：<br>$$|p_t - \pi|<em>2^2 &#x3D; \left|\sum</em>{i&#x3D;2}^n c_i \alpha_i^t v_i \right|<em>2^2 &#x3D; \sum</em>{i&#x3D;2}^n c_i^2 \alpha_i^{2t},$$<br>由于特征向量正交且单位化（$$|v_i|_2 &#x3D; 1$$），交叉项消失，仅剩对角项。</p>
<p><strong>关键观察</strong>：  </p>
<ul>
<li>特征值的衰减速率由 $$|\alpha_i|$$ 决定。定义 $$\lambda &#x3D; \min{1 - \alpha_2, 1 - |\alpha_n|}$$，则对所有 $$i \geq 2$$，有 $$|\alpha_i| \leq 1 - \lambda$$。</li>
<li>因此，平方和可进一步上界为：<br>$$\sum_{i&#x3D;2}^n c_i^2 \alpha_i^{2t} \leq (1 - \lambda)^{2t} \sum_{i&#x3D;2}^n c_i^2.$$</li>
</ul>
<hr>
<h4 id="4-初始分布的-L2-范数约束"><a href="#4-初始分布的-L2-范数约束" class="headerlink" title="4. 初始分布的 L2 范数约束"></a><strong>4. 初始分布的 L2 范数约束</strong></h4><p>由于 $$p_0$$ 是概率分布（$$\sum_i p_0(i) &#x3D; 1$$），其 L2 范数满足：<br>$$|p_0|<em>2^2 &#x3D; \sum</em>{i&#x3D;1}^n p_0(i)^2 \leq \sum_{i&#x3D;1}^n p_0(i) &#x3D; 1.$$<br>结合特征分解 $$p_0 &#x3D; \sum_{i&#x3D;1}^n c_i v_i$$，正交性条件给出：<br>$$\sum_{i&#x3D;1}^n c_i^2 &#x3D; |p_0|<em>2^2 \leq 1 \quad \Rightarrow \quad \sum</em>{i&#x3D;2}^n c_i^2 \leq 1.$$<br>因此，偏差的 L2 范数平方满足：<br>$$|p_t - \pi|_2^2 \leq (1 - \lambda)^{2t}.$$</p>
<hr>
<h4 id="5-指数衰减与混合时间推导"><a href="#5-指数衰减与混合时间推导" class="headerlink" title="5. 指数衰减与混合时间推导"></a><strong>5. 指数衰减与混合时间推导</strong></h4><p>结合 L1 范数的上界和指数衰减公式：<br>$$|p_t - \pi|<em>1 \leq \sqrt{n} \cdot (1 - \lambda)^t \leq \sqrt{n} \cdot e^{-\lambda t},$$<br>这里利用了不等式 $$1 - x \leq e^{-x}$$。<br>要求总变差距离小于等于 $$\epsilon$$，即：<br>$$\sqrt{n} e^{-\lambda t} \leq \epsilon \quad \Rightarrow \quad t \geq \frac{1}{\lambda} \log\left(\frac{\sqrt{n}}{\epsilon}\right) &#x3D; \frac{1}{2\lambda} \log\left(\frac{n}{\epsilon^2}\right).$$<br>最终简化得到混合时间上界：<br>$$t</em>{\text{mix}}(\epsilon) \leq \frac{1}{\lambda} \log\left(\frac{n}{\epsilon}\right).$$</p>
<hr>
<h3 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a><strong>补充说明</strong></h3><h4 id="正则图与非正则图的区别"><a href="#正则图与非正则图的区别" class="headerlink" title="正则图与非正则图的区别"></a><strong>正则图与非正则图的区别</strong></h4><ul>
<li><strong>正则图</strong>：若图是 $$d$$-正则的，归一化邻接矩阵为 $$\mathcal{A} &#x3D; \frac{1}{d} A$$，其稳态分布均匀，特征向量基可直接构造，损失因子 $$\sqrt{n}$$ 可优化为常数。</li>
<li><strong>非正则图</strong>：需使用归一化拉普拉斯矩阵 $$\mathcal{L} &#x3D; I - D^{-1&#x2F;2} A D^{-1&#x2F;2}$$ 的特征向量基，此时正交性条件可能引入额外因子 $$\sqrt{n}$$，导致混合时间上界略松。</li>
</ul>
<hr>
<h4 id="谱间隙的意义"><a href="#谱间隙的意义" class="headerlink" title="谱间隙的意义"></a><strong>谱间隙的意义</strong></h4><ul>
<li><strong>谱间隙 $$\lambda$$</strong>：决定了随机游走的收敛速度。当 $$\lambda &#x3D; \Omega(1)$$（常数级别），混合时间为 $$O(\log n)$$，适用于扩展图（如正则图）。</li>
<li><strong>实际应用</strong>：在社交网络或推荐系统中，若图具有强扩展性（大谱间隙），随机游走可在对数步长内均匀采样节点。</li>
</ul>
<hr>
<h2 id="谱图理论中的连通性与谱性质"><a href="#谱图理论中的连通性与谱性质" class="headerlink" title="谱图理论中的连通性与谱性质"></a><strong>谱图理论中的连通性与谱性质</strong></h2><h4 id="1-图的连通性与谱的关系"><a href="#1-图的连通性与谱的关系" class="headerlink" title="1. 图的连通性与谱的关系"></a><strong>1. 图的连通性与谱的关系</strong></h4><ol>
<li><p><strong>第二小特征值（$$\lambda_2$$）与连通性</strong>  </p>
<ul>
<li><strong>定理</strong>：对于图的归一化拉普拉斯矩阵 $$\mathcal{L}$$，其第二小特征值 $$\lambda_2$$ 满足：<br>$$\lambda_2 \text{ 非常小} \iff G \text{ 接近于不连通（存在稀疏割）}.$$</li>
<li><strong>解释</strong>：  <ul>
<li>$$\lambda_2$$ 称为<strong>代数连通度</strong>（Algebraic Connectivity），反映图的“分割难度”。  </li>
<li>若 $$\lambda_2 \approx 0$$，说明存在一个割 $$(S, V \setminus S)$$ 使得边界边数 $$|\partial S|$$ 远小于 $$\min(\text{vol}(S), \text{vol}(V \setminus S))$$，即图几乎可被分成两个弱连接的子图。  </li>
<li><strong>例子</strong>：在“哑铃图”（两个稠密子图通过单边连接）中，$$\lambda_2 \approx 0$$。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>第 $$k$$ 小特征值（$$\lambda_k$$）与多分量连通性</strong>  </p>
<ul>
<li><strong>推广定理</strong>：<br>$$\lambda_k \text{ 非常小} \iff G \text{ 接近于有 } k \text{ 个连通分量（存在 } k \text{ 个稀疏分割）}.$$</li>
<li><strong>解释</strong>：  <ul>
<li>$$\lambda_k$$ 接近零时，图可被划分为 $$k$$ 个几乎不交互的子集，每个子集内部稠密，子集间边稀疏。  </li>
<li><strong>应用</strong>：谱聚类（Spectral Clustering）利用 $$\lambda_k$$ 对应的特征向量将图划分为 $$k$$ 个社区。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h4 id="2-算法与构造中的应用"><a href="#2-算法与构造中的应用" class="headerlink" title="2. 算法与构造中的应用"></a><strong>2. 算法与构造中的应用</strong></h4><ol>
<li><p><strong>谱分割算法</strong>  </p>
<ul>
<li><strong>步骤</strong>：  <ol>
<li>计算拉普拉斯矩阵 $$\mathcal{L}$$ 的前 $$k$$ 个特征向量 $$v_1, v_2, \ldots, v_k$$。  </li>
<li>将顶点嵌入到 $$\mathbb{R}^k$$ 空间，坐标由特征向量分量决定。  </li>
<li>使用 $$k$$-means 等聚类方法划分顶点。</li>
</ol>
</li>
<li><strong>理论依据</strong>：特征向量的分量差异对应图中的稀疏割。</li>
</ul>
</li>
<li><p><strong>扩展图（Expander Graph）的代数构造</strong>  </p>
<ul>
<li><strong>定义</strong>：扩展图是高度连通的稀疏图，满足对所有子集 $$S$$，$$|\partial S| \geq \epsilon |S|$$（常数 $$\epsilon &gt; 0$$）。  </li>
<li><strong>谱性质</strong>：扩展图的谱间隙 $$\lambda_2$$ 远离零（$$\lambda_2 &#x3D; \Omega(1)$$）。  </li>
<li><strong>构造方法</strong>：  <ul>
<li>通过有限域、群论等代数工具显式构造。  </li>
<li>例如：Ramanujan 图的 $$\lambda_2 \geq 1 - 2\sqrt{d-1}&#x2F;d$$（接近最优）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h4 id="3-随机游走混合时间的谱分析"><a href="#3-随机游走混合时间的谱分析" class="headerlink" title="3. 随机游走混合时间的谱分析"></a><strong>3. 随机游走混合时间的谱分析</strong></h4><ol>
<li><p><strong>混合时间与谱间隙</strong>  </p>
<ul>
<li><strong>定理</strong>：懒惰随机游走的 $$\epsilon$$-混合时间满足：<br>$$t_{\text{mix}}(\epsilon) \leq \frac{1}{\lambda} \log\left(\frac{n}{\epsilon}\right), \quad \lambda &#x3D; \min{1 - \alpha_2, 1 - |\alpha_n|},$$<br>其中 $$\alpha_2$$ 是归一化邻接矩阵的第二大特征值。  </li>
<li><strong>关键步骤</strong>：  <ul>
<li>将初始分布 $$p_0$$ 投影到特征向量基，衰减项由 $$|\alpha_i|^t$$ 控制。  </li>
<li>谱间隙 $$\lambda$$ 越大，衰减越快，混合时间越短。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>组合数学与谱间隙的关联</strong>  </p>
<ul>
<li><strong>Cheeger 不等式</strong>：<br>$$\frac{\lambda_2}{2} \leq \phi(G) \leq \sqrt{2\lambda_2},$$<br>其中 $$\phi(G)$$ 是 Cheeger 常数（图的展开性）。  </li>
<li><strong>推论</strong>：  <ul>
<li>高扩展性（$$\phi(G)$$ 大）$$\implies$$ 大谱间隙（$$\lambda_2$$ 大）$$\implies$$ 快速混合（$$t_{\text{mix}}$$ 小）。  </li>
<li>例如：在 $$d$$-正则扩展图中，随机游走可在 $$O(\log n)$$ 步内接近均匀分布。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="总结表格"><a href="#总结表格" class="headerlink" title="总结表格"></a><strong>总结表格</strong></h3><table>
<thead>
<tr>
<th><strong>概念</strong></th>
<th><strong>数学描述</strong></th>
<th><strong>应用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td>代数连通度 ($$\lambda_2$$)</td>
<td>$$\lambda_2 \approx 0 \iff G$$ 有稀疏割</td>
<td>社区检测、图分割</td>
</tr>
<tr>
<td>第 $$k$$ 小特征值 ($$\lambda_k$$)</td>
<td>$$\lambda_k \approx 0 \iff G$$ 有 $$k$$ 个稀疏分割</td>
<td>谱聚类（划分 $$k$$ 个社区）</td>
</tr>
<tr>
<td>扩展图</td>
<td>$$\lambda_2 \geq \epsilon &gt; 0$$</td>
<td>伪随机性构造、纠错码设计</td>
</tr>
<tr>
<td>混合时间</td>
<td>$$t_{\text{mix}} \propto \frac{1}{\lambda} \log n$$</td>
<td>马尔可夫链蒙特卡洛（MCMC）采样</td>
</tr>
</tbody></table>
<hr>
<h3 id="进一步研究方向"><a href="#进一步研究方向" class="headerlink" title="进一步研究方向"></a><strong>进一步研究方向</strong></h3><ol>
<li><strong>高阶 Cheeger 不等式</strong>：研究 $$\lambda_k$$ 与多路分割（Multiway Partition）的关系。  </li>
<li><strong>动态图的谱分析</strong>：如何快速更新特征值&#x2F;向量以适应图结构的动态变化。  </li>
<li><strong>非线性谱方法</strong>：基于图神经网络的连通性分析与聚类。</li>
</ol>
<p>通过谱理论，我们得以将图的组合性质（如连通性）与代数性质（如特征值）深度关联，为算法设计与理论分析提供统一框架。</p>
<p>Thinking… (1s elapsed)中文推导与讲解<br>$$\frac{\lambda_2}{2};\le; \phi(G); \le; \sqrt{2,\lambda_2}$$</p>
<p>下面分三部分说明：  </p>
<ol>
<li>预备概念与符号  </li>
<li>易方向（上界）：$$\lambda_2\le 2\phi(G)$$  </li>
<li>难方向（下界）：$$\phi(G)\le \sqrt{2\lambda_2}$$</li>
</ol>
<hr>
<h2 id="1-预备概念与符号"><a href="#1-预备概念与符号" class="headerlink" title="1. 预备概念与符号"></a>1. 预备概念与符号</h2><ol>
<li><p>图与体积<br>• 图 $$G&#x3D;(V,E)$$ 无向、带权，边权记 $$w_{ij}&#x3D;w_{ji}\ge 0$$。<br>• 顶点度数 $$\deg(i)&#x3D;\sum_j w_{ij}$$。<br>• 体积 $$\operatorname{vol}(S)&#x3D;\sum_{i\in S}\deg(i)$$。</p>
</li>
<li><p>切割边数与扩张率（也称 conductance）<br>• 切割 $$\partial S&#x3D;{(i,j)\in E\mid i\in S,j\notin S}$$。<br>• 扩张率<br>  $$\phi(S)&#x3D;\frac{w(\partial S)}{\min\bigl(\operatorname{vol}(S),\operatorname{vol}(V!\setminus!S)\bigr)},\qquad<br>  \phi(G)&#x3D;\min_{S\subset V}\phi(S).$$</p>
</li>
<li><p>归一化拉普拉斯<br>• 记 $$D&#x3D;\operatorname{diag}(\deg(i))$$，$$A&#x3D;(w_{ij})$$。<br>• 归一化拉普拉斯 $$\mathcal L &#x3D; I - D^{-1&#x2F;2} A D^{-1&#x2F;2}$$。<br>• 其特征值 $$0&#x3D;\lambda_1\le \lambda_2\le\dots\le\lambda_n$$。<br>• 瑞利商<br>  $$\lambda_2&#x3D;\min_{\substack{x\neq 0\x\perp D^{1&#x2F;2}\mathbf 1}}<br>  \frac{x^\top \mathcal L x}{x^\top x},<br>  \qquad<br>  x^\top \mathcal L x&#x3D;\frac12\sum_{(i,j)\in E}w_{ij}\Bigl(\tfrac{x_i}{\sqrt{\deg(i)}}-\tfrac{x_j}{\sqrt{\deg(j)}}\Bigr)^2.$$</p>
</li>
</ol>
<hr>
<h2 id="2-易方向：-lambda-2-le-2-phi-G"><a href="#2-易方向：-lambda-2-le-2-phi-G" class="headerlink" title="2. 易方向：$$\lambda_2\le 2\phi(G)$$"></a>2. 易方向：$$\lambda_2\le 2\phi(G)$$</h2><h3 id="2-1-思路"><a href="#2-1-思路" class="headerlink" title="2.1 思路"></a>2.1 思路</h3><p>要给 $$\lambda_2$$ 找一个<strong>试探向量</strong> $$x$$，把它代入瑞利商即可得到一个上界。<br>最自然的向量是某个切割的指示函数：<br>$$g_i&#x3D;1$$ 若 $$i\in S$$，$$g_i&#x3D;-1$$ 否则。<br>但瑞利商要求 $$x\perp D^{1&#x2F;2}\mathbf1$$。<br>只需把 $$g$$ 左乘 $$D^{-1&#x2F;2}$$ 就能自动满足正交：<br>$$x&#x3D;D^{-1&#x2F;2}g.$$</p>
<h3 id="2-2-计算瑞利商"><a href="#2-2-计算瑞利商" class="headerlink" title="2.2 计算瑞利商"></a>2.2 计算瑞利商</h3><ol>
<li><p>分母<br>$$x^\top x &#x3D; \sum_{i}\frac{g_i^{,2}}{\deg(i)} &#x3D;<br>\sum_{i}\frac{1}{\deg(i)}<br>&#x3D;\sum_{i\in S}\frac{1}{\deg(i)}+\sum_{i\notin S}\frac{1}{\deg(i)},$$<br>这个量不会与边界项混在一起，保持原样即可。</p>
</li>
<li><p>分子（二次型）<br>$$x^\top!\mathcal Lx<br>&#x3D;\frac12!\sum_{(i,j)} w_{ij}\Bigl(<br>\tfrac{g_i}{\sqrt{\deg(i)}}-\tfrac{g_j}{\sqrt{\deg(j)}}\Bigr)^2.$$<br>只有在 $$g_i\neq g_j$$（即边跨越切割）时该项非零，且差值绝对值为<br>$$\frac1{\sqrt{\deg(i)}}+\frac1{\sqrt{\deg(j)}}$$。<br>因此<br>$$x^\top!\mathcal Lx<br>   &#x3D;\frac12\sum_{(i,j)\in\partial S} w_{ij}<br> \Bigl(\tfrac1{\sqrt{\deg(i)}}+\tfrac1{\sqrt{\deg(j)}}\Bigr)^{!2}.$$</p>
</li>
<li><p>估计<br>用基本不等式 $$(a+b)^2\le 2(a^2+b^2)$$：<br>$$\Bigl(\tfrac1{\sqrt{\deg(i)}}+\tfrac1{\sqrt{\deg(j)}}\Bigr)^{2}<br>   \le 2\Bigl(\tfrac1{\deg(i)}+\tfrac1{\deg(j)}\Bigr).$$<br>于是<br>$$x^\top!\mathcal Lx<br>   \le \sum_{(i,j)\in\partial S} w_{ij}<br>   \Bigl(\tfrac1{\deg(i)}+\tfrac1{\deg(j)}\Bigr)<br>   &#x3D;\sum_{i\in S}\frac{w(\partial{i})}{\deg(i)}<br>+\sum_{j\notin S}\frac{w(\partial{j})}{\deg(j)}.$$<br>而<br>$$w(\partial{i})\le\deg(i)$$，故<br>$$x^\top!\mathcal Lx\le |\partial S|.$$</p>
</li>
<li><p>组合分子分母<br>$$\frac{x^\top\mathcal Lx}{x^\top x}<br>\le<br>\frac{|\partial S|}{\min(\operatorname{vol}(S),\operatorname{vol}(V!\setminus!S))}<br>&#x3D;\phi(S);\le;\phi(G).$$<br>再用系数 2 的松弛（去掉上一步的 2 倍常数不等式损失）即可：<br>$$\lambda_2\le 2,\phi(G).$$</p>
</li>
</ol>
<h3 id="2-3-关键改动"><a href="#2-3-关键改动" class="headerlink" title="2.3 关键改动"></a>2.3 关键改动</h3><p>原错误把<br>$$|\partial S|(\frac1{\sqrt{\operatorname{vol}(S)}}+\frac1{\sqrt{\operatorname{vol}(V\setminus S)}})^2$$<br>当成二次型，没有正确考虑每条边两端度数不同。<br>改用 <strong>指示向量 + 逐边展开</strong> 后，完全避免了平均度数假设。</p>
<hr>
<h2 id="3-难方向：-phi-G-le-sqrt-2-lambda-2"><a href="#3-难方向：-phi-G-le-sqrt-2-lambda-2" class="headerlink" title="3. 难方向：$$\phi(G)\le\sqrt{2\lambda_2}$$"></a>3. 难方向：$$\phi(G)\le\sqrt{2\lambda_2}$$</h2><p>思路：利用 $$\lambda_2$$ 的特征向量 $$f$$，把标量值扫阈 (sweep)，总会遇到一个阈值 cut 具有小扩张率。核心工具是离散 <strong>Co-area 公式</strong>。</p>
<h3 id="3-1-特征向量预处理"><a href="#3-1-特征向量预处理" class="headerlink" title="3.1 特征向量预处理"></a>3.1 特征向量预处理</h3><p>取满足<br>$$f\perp D^{1&#x2F;2}\mathbf1$$、$$f^\top f&#x3D;1$$ 的 $$\lambda_2$$ 特征向量。<br>令<br>$$h_i&#x3D;\frac{f_i}{\sqrt{\deg(i)}}\quad(i&#x3D;1,\dots,n).$$<br>按 $$h_i$$ 从小到大排序：<br>$$h_{(1)}\le h_{(2)}\le\dots\le h_{(n)}$$。</p>
<h3 id="3-2-Sweep-cut-定义"><a href="#3-2-Sweep-cut-定义" class="headerlink" title="3.2 Sweep cut 定义"></a>3.2 Sweep cut 定义</h3><p>对每个阈值 $$t\in\mathbb R$$ 定<br>$$S_t&#x3D;{,i\mid h_i\le t\ }$$。<br>当 $$t$$ 连续增大，$$S_t$$ 从空集逐渐扩张到全体顶点。</p>
<h3 id="3-3-离散-Co-area-公式"><a href="#3-3-离散-Co-area-公式" class="headerlink" title="3.3 离散 Co-area 公式"></a>3.3 离散 Co-area 公式</h3><p>$$\int_{-\infty}^{+\infty} w(\partial S_t),dt<br>   &#x3D;\frac12!\sum_{(i,j)\in E}w_{ij}|h_i-h_j|.$$</p>
<p>平方并用 Cauchy–Schwarz：<br>$$\Bigl(\int w(\partial S_t),dt\Bigr)^{2}<br>\le \Bigl(\sum_{(i,j)}w_{ij}(h_i-h_j)^2\Bigr)<br>     \Bigl(\sum_{(i,j)}w_{ij}\Bigr).$$</p>
<p>第一括号就是 $$2\lambda_2$$（由瑞利商），第二括号是 $$\operatorname{vol}(V)$$。<br>于是存在某个 $$t$$ 使<br>$$w(\partial S_t)<br>\le<br>\sqrt{2\lambda_2,\operatorname{vol}(V)};<br> \bigl(\sup_{t}\mu(t)\bigr)^{-1},$$<br>其中 $$\mu(t)&#x3D;\min\bigl(\operatorname{vol}(S_t),\operatorname{vol}(V\setminus S_t)\bigr)$$。</p>
<h3 id="3-4-选取“平衡”阈值"><a href="#3-4-选取“平衡”阈值" class="headerlink" title="3.4 选取“平衡”阈值"></a>3.4 选取“平衡”阈值</h3><p>因为 $$f\perp D^{1&#x2F;2}\mathbf1$$，<br>$$\sum_i\deg(i)h_i&#x3D;0$$。<br>故 $$h_i$$ 的加权中位数使两边体积各至少半数。<br>取此 $$t$$ 便有<br>$$\mu(t)\ge \tfrac12\operatorname{vol}(V)$$。</p>
<p>带回不等式：<br>$$\phi(S_t)&#x3D;\frac{w(\partial S_t)}{\mu(t)}<br>\le<br>\sqrt{2\lambda_2}.$$<br>于是<br>(<br>\phi(G)\le\sqrt{2\lambda_2}.<br>)</p>
<h3 id="3-5-关键修正"><a href="#3-5-关键修正" class="headerlink" title="3.5 关键修正"></a>3.5 关键修正</h3><ol>
<li>明确写出离散 Co-area，而不是“把和看成积分”。  </li>
<li>使用中位数保证体积平衡，而不是模糊地说“总能找到一个好阈值”。  </li>
<li>每一步都保留常数因子，最终得到 $$\sqrt{2}$$ 而非错误的 $$\sqrt{\lambda_2}$$ 或 $$2\sqrt{\lambda_2}$$。</li>
</ol>
<hr>
<h2 id="4-逻辑链条回顾"><a href="#4-逻辑链条回顾" class="headerlink" title="4. 逻辑链条回顾"></a>4. 逻辑链条回顾</h2><ol>
<li>定义所有量（$$\mathcal L,\lambda_2,\phi$$）。  </li>
<li>易方向：<br>• 构造满足正交条件的测试向量。<br>• 逐边展开瑞利商避免度数混淆。<br>• 直接与 $$\phi(G)$$ 比较，得到 $$\lambda_2\le 2\phi(G)$$。  </li>
<li>难方向：<br>• 取特征向量 → 排序 → 阈值分割。<br>• Co-area 公式把“总差额”换成阈值族的“切割量积分”。<br>• Cauchy–Schwarz 找到某个阈值 cut，结合中位数平衡体积。<br>• 得到 $$\phi(G)\le\sqrt{2\lambda_2}$$。</li>
</ol>
<p>至此两向合并，即得 Cheeger 不等式<br>$$\frac{\lambda_2}{2};\le; \phi(G); \le; \sqrt{2,\lambda_2}.$$</p>
<hr>
<h2 id="5-小结与启示"><a href="#5-小结与启示" class="headerlink" title="5. 小结与启示"></a>5. 小结与启示</h2><ul>
<li>左边界说明：若图有窄瓶颈，$$\lambda_2$$ 必然跟着小。  </li>
<li>右边界给出：只要 $$\lambda_2$$ 小，确实能从特征向量里“扫”出小扩张率切割。  </li>
<li>算法视角：用 Fiedler 向量做 sweep cut 就可近似找到良好社区。  </li>
<li>校正点：任何忽略顶点度数或跳过积分—阈值论证的证明，都可能给出错误常数或乃至错误结论。</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/notes.github.io/tags/%E5%85%B6%E4%BB%96/" rel="tag"># 其他</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/notes.github.io/2025/06/23/noteSVD/" rel="prev" title="noteSVD">
      <i class="fa fa-chevron-left"></i> noteSVD
    </a></div>
      <div class="post-nav-item">
    <a href="/notes.github.io/2025/06/23/midterm/" rel="next" title="midterm">
      midterm <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E7%9A%84%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5%E6%9C%80%E5%A4%A7%E7%89%B9%E5%BE%81%E5%80%BC%E4%B8%8A%E4%B8%8B%E7%95%8C%E8%AF%81%E6%98%8E"><span class="nav-number">1.</span> <span class="nav-text">图的邻接矩阵最大特征值上下界证明</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8A%E7%95%8C%E8%AF%81%E6%98%8E%EF%BC%88-alpha-1-leq-Delta"><span class="nav-number">1.1.</span> <span class="nav-text">上界证明（$$ \alpha_1 \leq \Delta $$)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8B%E7%95%8C%E8%AF%81%E6%98%8E%EF%BC%88-d-text-avg-leq-alpha-1"><span class="nav-number">1.2.</span> <span class="nav-text">下界证明（$$ d_{\text{avg}} \leq \alpha_1 $$)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">1.3.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%95%E7%90%86%E8%AF%81%E6%98%8E%E8%AF%A6%E8%A7%A3"><span class="nav-number">2.</span> <span class="nav-text">引理证明详解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%86%E5%9D%97%E7%BB%93%E6%9E%84"><span class="nav-number">2.1.</span> <span class="nav-text">1. 邻接矩阵的分块结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E7%89%B9%E5%BE%81%E5%80%BC%E4%B8%8E%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%9A%84%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB"><span class="nav-number">2.2.</span> <span class="nav-text">2. 特征值与特征向量的对应关系</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E6%9E%84%E9%80%A0-alpha-%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="nav-number">2.3.</span> <span class="nav-text">3. 构造 $$ -\alpha $$ 的特征向量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E9%87%8D%E6%95%B0%E7%9A%84%E7%AD%89%E4%BB%B7%E6%80%A7"><span class="nav-number">2.4.</span> <span class="nav-text">4. 重数的等价性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-%E9%9B%B6%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E7%89%B9%E6%AE%8A%E6%83%85%E5%86%B5"><span class="nav-number">2.5.</span> <span class="nav-text">5. 零特征值的特殊情况</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-1"><span class="nav-number">2.6.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%95%E7%90%86%E8%AF%81%E6%98%8E%EF%BC%9A"><span class="nav-number"></span> <span class="nav-text">引理证明：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5%EF%BC%88Laplacian-Matrix%EF%BC%89%E8%AF%A6%E8%A7%A3"><span class="nav-number">1.</span> <span class="nav-text">拉普拉斯矩阵（Laplacian Matrix）详解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%9F%BA%E6%9C%AC%E5%AE%9A%E4%B9%89"><span class="nav-number">1.1.</span> <span class="nav-text">1. 基本定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E6%AD%A3%E5%88%99%E5%9B%BE%E7%9A%84%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5"><span class="nav-number">1.2.</span> <span class="nav-text">2. 正则图的拉普拉斯矩阵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E4%B8%80%E8%88%AC%E5%9B%BE%E7%9A%84%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5"><span class="nav-number">1.3.</span> <span class="nav-text">3. 一般图的拉普拉斯矩阵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5%E7%9A%84%E8%BE%B9%E5%88%86%E8%A7%A3"><span class="nav-number">1.4.</span> <span class="nav-text">4. 拉普拉斯矩阵的边分解</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-%E5%88%86%E8%A7%A3%E7%9A%84%E6%84%8F%E4%B9%89"><span class="nav-number">1.5.</span> <span class="nav-text">5. 分解的意义</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5-L-G-%E7%9A%84%E6%80%A7%E8%B4%A8%E4%B8%8E%E8%AF%81%E6%98%8E"><span class="nav-number">2.</span> <span class="nav-text">拉普拉斯矩阵 $$ L(G) $$ 的性质与证明</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%AE%9A%E4%B9%89%E5%9B%9E%E9%A1%BE"><span class="nav-number">2.1.</span> <span class="nav-text">1. 定义回顾</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%80%A7%E8%B4%A8-1%EF%BC%9A-mathbf-1-%E6%98%AF-L-G-%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%EF%BC%8C%E5%AF%B9%E5%BA%94%E7%89%B9%E5%BE%81%E5%80%BC-0"><span class="nav-number">3.</span> <span class="nav-text">2. 性质 1：$$ \mathbf{1} $$ 是 $$ L(G) $$ 的特征向量，对应特征值 0</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%80%A7%E8%B4%A8-2%EF%BC%9A-L-G-%E6%98%AF%E5%8D%8A%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%EF%BC%88-L-G-succeq-0-%EF%BC%89"><span class="nav-number">4.</span> <span class="nav-text">3. 性质 2：$$ L(G) $$ 是半正定矩阵（$$ L(G) \succeq 0 $$）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E7%90%86"><span class="nav-number">5.</span> <span class="nav-text">定理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%81%E6%98%8E%EF%BC%88%E2%87%90%EF%BC%89%EF%BC%9A%E4%B8%8D%E8%BF%9E%E9%80%9A%E5%9B%BE%E7%9A%84%E6%83%85%E5%86%B5"><span class="nav-number">6.</span> <span class="nav-text">证明（⇐）：不连通图的情况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%81%E6%98%8E%EF%BC%88%E2%87%92%EF%BC%89%EF%BC%9A%E8%BF%9E%E9%80%9A%E5%9B%BE%E7%9A%84%E6%83%85%E5%86%B5"><span class="nav-number">7.</span> <span class="nav-text">证明（⇒）：连通图的情况</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9A%E7%90%86%E8%AF%81%E6%98%8E"><span class="nav-number"></span> <span class="nav-text">定理证明</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%81%E6%98%8E"><span class="nav-number">0.1.</span> <span class="nav-text">证明</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E6%AD%A5%E9%AA%A4"><span class="nav-number">0.2.</span> <span class="nav-text">关键步骤</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8E%A8%E8%AE%BA"><span class="nav-number">0.3.</span> <span class="nav-text">推论</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Perron-Frobenius%E5%AE%9A%E7%90%86%E7%9A%84%E8%AF%81%E6%98%8E%E6%80%9D%E8%B7%AF%E7%AE%80%E4%BB%8B"><span class="nav-number"></span> <span class="nav-text">Perron-Frobenius定理的证明思路简介</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E6%9C%80%E5%A4%A7%E7%89%B9%E5%BE%81%E5%80%BC-lambda-1-%E7%9A%84%E9%87%8D%E6%95%B0%E4%B8%BA1"><span class="nav-number">0.1.</span> <span class="nav-text">1. 最大特征值 $$ \lambda_1 $$ 的重数为1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E5%AF%B9%E5%BA%94%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E5%85%A8%E4%B8%BA%E6%AD%A3%E4%B8%94%E7%AC%A6%E5%8F%B7%E4%B8%80%E8%87%B4"><span class="nav-number">0.2.</span> <span class="nav-text">2. 对应特征向量全为正且符号一致</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%85%B6%E4%BB%96%E7%89%B9%E5%BE%81%E5%80%BC%E6%BB%A1%E8%B6%B3-lambda-i-lambda-1-2-leq-i-leq-n"><span class="nav-number">0.3.</span> <span class="nav-text">3. 其他特征值满足 $$ |\lambda_i| &lt; \lambda_1 , (2 \leq i \leq n) $$</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cheeger%E4%B8%8D%E7%AD%89%E5%BC%8F%E4%B8%8E%E5%9B%BE%E7%9A%84%E8%BF%9E%E9%80%9A%E6%80%A7%E5%BA%A6%E9%87%8F"><span class="nav-number"></span> <span class="nav-text">Cheeger不等式与图的连通性度量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%9B%BE%E7%9A%84%E8%BF%9E%E9%80%9A%E6%80%A7%E4%B8%8E%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5%E7%89%B9%E5%BE%81%E5%80%BC"><span class="nav-number">0.1.</span> <span class="nav-text">1. 图的连通性与拉普拉斯矩阵特征值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E4%BC%A0%E5%AF%BC%E7%8E%87%EF%BC%88Conductance%EF%BC%89%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="nav-number">0.2.</span> <span class="nav-text">2. 传导率（Conductance）的定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-Cheeger%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="nav-number">0.3.</span> <span class="nav-text">3. Cheeger不等式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E6%89%A9%E5%B1%95%E5%9B%BE%EF%BC%88Expander-Graph%EF%BC%89%E4%B8%8E%E7%A8%80%E7%96%8F%E5%89%B2"><span class="nav-number">0.4.</span> <span class="nav-text">4. 扩展图（Expander Graph）与稀疏割</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cheeger%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="nav-number"></span> <span class="nav-text">Cheeger不等式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E5%AE%9A%E4%B9%89%E4%B8%8E%E7%AC%A6%E5%8F%B7"><span class="nav-number">1.</span> <span class="nav-text">基本定义与符号</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E6%96%B9%E5%90%91%EF%BC%88Easy-Direction%EF%BC%89%EF%BC%9A-lambda-2-leq-2-phi-G"><span class="nav-number">2.</span> <span class="nav-text">简单方向（Easy Direction）：$$ \lambda_2 \leq 2\phi(G) $$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%B0%E9%9A%BE%E6%96%B9%E5%90%91%EF%BC%88Hard-Direction%EF%BC%89%EF%BC%9A-phi-G-leq-sqrt-2-lambda-2"><span class="nav-number">3.</span> <span class="nav-text">困难方向（Hard Direction）：$$ \phi(G) \leq \sqrt{2\lambda_2} $$</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9E%E5%88%B0%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE"><span class="nav-number"></span> <span class="nav-text">回到马尔科夫链</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E8%BD%AC%E7%A7%BB%E7%9F%A9%E9%98%B5%E7%9A%84%E6%9E%84%E9%80%A0%E4%B8%8E%E6%80%A7%E8%B4%A8"><span class="nav-number">1.</span> <span class="nav-text">1. 转移矩阵的构造与性质</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E7%A8%B3%E6%80%81%E5%88%86%E5%B8%83%E7%9A%84%E5%AD%98%E5%9C%A8%E6%80%A7"><span class="nav-number">2.</span> <span class="nav-text">2. 稳态分布的存在性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%94%B6%E6%95%9B%E6%80%A7%E8%AF%81%E6%98%8E"><span class="nav-number">3.</span> <span class="nav-text">3. 收敛性证明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E7%90%86%E5%8F%8A%E8%AF%81%E6%98%8E%E6%AD%A5%E9%AA%A4%E8%AF%A6%E8%A7%A3"><span class="nav-number">4.</span> <span class="nav-text">定理及证明步骤详解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9A%E7%90%86%E9%99%88%E8%BF%B0"><span class="nav-number">4.1.</span> <span class="nav-text">定理陈述</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%81%E6%98%8E%E6%AD%A5%E9%AA%A4%E8%AF%A6%E8%A7%A3"><span class="nav-number">5.</span> <span class="nav-text">证明步骤详解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E5%88%86%E8%A7%A3%E4%B8%8E%E8%BD%AC%E7%A7%BB%E7%9F%A9%E9%98%B5%E5%B1%95%E5%BC%80"><span class="nav-number">5.1.</span> <span class="nav-text">1. 特征向量分解与转移矩阵展开</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E8%8C%83%E6%95%B0%E8%BD%AC%E6%8D%A2%EF%BC%9AL1-%E5%88%B0-L2-%E8%8C%83%E6%95%B0"><span class="nav-number">5.2.</span> <span class="nav-text">2. 范数转换：L1 到 L2 范数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E8%AE%A1%E7%AE%97-L2-%E8%8C%83%E6%95%B0%E7%9A%84%E5%B9%B3%E6%96%B9"><span class="nav-number">5.3.</span> <span class="nav-text">3. 计算 L2 范数的平方</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E5%88%9D%E5%A7%8B%E5%88%86%E5%B8%83%E7%9A%84-L2-%E8%8C%83%E6%95%B0%E7%BA%A6%E6%9D%9F"><span class="nav-number">5.4.</span> <span class="nav-text">4. 初始分布的 L2 范数约束</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-%E6%8C%87%E6%95%B0%E8%A1%B0%E5%87%8F%E4%B8%8E%E6%B7%B7%E5%90%88%E6%97%B6%E9%97%B4%E6%8E%A8%E5%AF%BC"><span class="nav-number">5.5.</span> <span class="nav-text">5. 指数衰减与混合时间推导</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E"><span class="nav-number">6.</span> <span class="nav-text">补充说明</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%9B%BE%E4%B8%8E%E9%9D%9E%E6%AD%A3%E5%88%99%E5%9B%BE%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">6.1.</span> <span class="nav-text">正则图与非正则图的区别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B0%B1%E9%97%B4%E9%9A%99%E7%9A%84%E6%84%8F%E4%B9%89"><span class="nav-number">6.2.</span> <span class="nav-text">谱间隙的意义</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B0%B1%E5%9B%BE%E7%90%86%E8%AE%BA%E4%B8%AD%E7%9A%84%E8%BF%9E%E9%80%9A%E6%80%A7%E4%B8%8E%E8%B0%B1%E6%80%A7%E8%B4%A8"><span class="nav-number"></span> <span class="nav-text">谱图理论中的连通性与谱性质</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%9B%BE%E7%9A%84%E8%BF%9E%E9%80%9A%E6%80%A7%E4%B8%8E%E8%B0%B1%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="nav-number">0.1.</span> <span class="nav-text">1. 图的连通性与谱的关系</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E7%AE%97%E6%B3%95%E4%B8%8E%E6%9E%84%E9%80%A0%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8"><span class="nav-number">0.2.</span> <span class="nav-text">2. 算法与构造中的应用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0%E6%B7%B7%E5%90%88%E6%97%B6%E9%97%B4%E7%9A%84%E8%B0%B1%E5%88%86%E6%9E%90"><span class="nav-number">0.3.</span> <span class="nav-text">3. 随机游走混合时间的谱分析</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93%E8%A1%A8%E6%A0%BC"><span class="nav-number">1.</span> <span class="nav-text">总结表格</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91"><span class="nav-number">2.</span> <span class="nav-text">进一步研究方向</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E9%A2%84%E5%A4%87%E6%A6%82%E5%BF%B5%E4%B8%8E%E7%AC%A6%E5%8F%B7"><span class="nav-number"></span> <span class="nav-text">1. 预备概念与符号</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E6%98%93%E6%96%B9%E5%90%91%EF%BC%9A-lambda-2-le-2-phi-G"><span class="nav-number"></span> <span class="nav-text">2. 易方向：$$\lambda_2\le 2\phi(G)$$</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E6%80%9D%E8%B7%AF"><span class="nav-number">1.</span> <span class="nav-text">2.1 思路</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-%E8%AE%A1%E7%AE%97%E7%91%9E%E5%88%A9%E5%95%86"><span class="nav-number">2.</span> <span class="nav-text">2.2 计算瑞利商</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-%E5%85%B3%E9%94%AE%E6%94%B9%E5%8A%A8"><span class="nav-number">3.</span> <span class="nav-text">2.3 关键改动</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E9%9A%BE%E6%96%B9%E5%90%91%EF%BC%9A-phi-G-le-sqrt-2-lambda-2"><span class="nav-number"></span> <span class="nav-text">3. 难方向：$$\phi(G)\le\sqrt{2\lambda_2}$$</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">1.</span> <span class="nav-text">3.1 特征向量预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-Sweep-cut-%E5%AE%9A%E4%B9%89"><span class="nav-number">2.</span> <span class="nav-text">3.2 Sweep cut 定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-%E7%A6%BB%E6%95%A3-Co-area-%E5%85%AC%E5%BC%8F"><span class="nav-number">3.</span> <span class="nav-text">3.3 离散 Co-area 公式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-%E9%80%89%E5%8F%96%E2%80%9C%E5%B9%B3%E8%A1%A1%E2%80%9D%E9%98%88%E5%80%BC"><span class="nav-number">4.</span> <span class="nav-text">3.4 选取“平衡”阈值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-%E5%85%B3%E9%94%AE%E4%BF%AE%E6%AD%A3"><span class="nav-number">5.</span> <span class="nav-text">3.5 关键修正</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E9%80%BB%E8%BE%91%E9%93%BE%E6%9D%A1%E5%9B%9E%E9%A1%BE"><span class="nav-number"></span> <span class="nav-text">4. 逻辑链条回顾</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E5%B0%8F%E7%BB%93%E4%B8%8E%E5%90%AF%E7%A4%BA"><span class="nav-number"></span> <span class="nav-text">5. 小结与启示</span></a></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Chen Zhan"
      src="/notes.github.io/images/woshicaigou.jpg">
  <p class="site-author-name" itemprop="name">Chen Zhan</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/notes.github.io/archives/">
        
          <span class="site-state-item-count">23</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chen Zhan</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/notes.github.io/lib/anime.min.js"></script>
  <script src="/notes.github.io/lib/velocity/velocity.min.js"></script>
  <script src="/notes.github.io/lib/velocity/velocity.ui.min.js"></script>

<script src="/notes.github.io/js/utils.js"></script>

<script src="/notes.github.io/js/motion.js"></script>


<script src="/notes.github.io/js/schemes/pisces.js"></script>


<script src="/notes.github.io/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
