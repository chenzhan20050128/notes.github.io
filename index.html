<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/notes.github.io/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/notes.github.io/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/notes.github.io/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/notes.github.io/images/logo.svg" color="#222">

<link rel="stylesheet" href="/notes.github.io/css/main.css">


<link rel="stylesheet" href="/notes.github.io/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chenzhan20050128.github.io","root":"/notes.github.io/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="cz Blog">
<meta property="og:url" content="https://chenzhan20050128.github.io/notes.github.io/index.html">
<meta property="og:site_name" content="cz Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Chen Zhan">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://chenzhan20050128.github.io/notes.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>cz Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/notes.github.io/atom.xml" title="cz Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/notes.github.io/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">cz Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Hello World</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/notes.github.io/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/notes.github.io/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/chenzhan20050128" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/FFT_Notes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes.github.io/images/woshicaigou.jpg">
      <meta itemprop="name" content="Chen Zhan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cz Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/notes.github.io/2025/06/23/FFT_Notes/" class="post-title-link" itemprop="url">FFT_Notes</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-23 18:56:58" itemprop="dateCreated datePublished" datetime="2025-06-23T18:56:58+08:00">2025-06-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>好的，以下是包含更完整思维过程的详细解答。</p>
<ol start="19">
<li>(17分)</li>
</ol>
<p>已知 $n \in \mathbb{N}^*$ 且 $n \ge 3$, 集合 $A_n &#x3D; {a_1, a_2, \dots, a_n}$, 其中 $0 &lt; a_1 &lt; a_2 &lt; \dots &lt; a_n$.</p>
<p>若存在函数 $f(x)$ ($f(x) \ne x$), 其图像在区间 $D &#x3D; [a_1, a_n]$ 上是一段连续曲线，且 ${f(a_i)|a_i \in A_n} &#x3D; A_n$, 则称 $f(x)$ 是 $A_n$ 的T变换函数，集合 $A_n$ 是 $D$ 的T子集. 例如，</p>
<p>设 $A_5 &#x3D; {\frac{2}{3}, 1, \sqrt{2}, 2, 3}$, 此时函数 $f(x) &#x3D; \frac{2}{x}$ 是 $A_5$ 的T变换函数，$A_5$ 是 $[\frac{2}{3}, 3]$ 的T子集.</p>
<p>(1) 判断集合 ${1, 2, 8, 9}$ 是否是 $[1, 9]$ 的T子集? 说明理由;</p>
<p>(2) 判断 $f(x) &#x3D; \ln(1 + \frac{2}{e^x})$ 是否为集合 $A_n$ 的T变换函数? 说明理由;</p>
<p>(3) 若 $a_i &lt; a_j$ ($i, j \in \mathbb{N}^*, 1 \le i &lt; j \le n$), 则 $\frac{a_j}{a_i} \in A_n$, 试问是否存在函数 $f(x)$, 使得集合 $A_n$ 是 $D &#x3D; [a_1, a_n]$ 的T子集? 若存在，求 $f(x)$ 的解析式; 若不存在，说明理由.</p>
<p><strong>详细解答：</strong></p>
<p><strong>(1) 判断集合 ${1, 2, 8, 9}$ 是否是 $[1, 9]$ 的T子集? 说明理由;</strong></p>
<p><em>思维过程：</em></p>
<p>首先，我们需要理解T子集的定义。这意味着要找到一个函数 $f(x)$，它在区间 $[1, 9]$ 上连续，且对于集合 ${1, 2, 8, 9}$ 中的每个元素 $a_i$， $f(a_i)$ 也在这个集合中，并且 $f(x) \neq x$。这意味着 $f(x)$ 在集合上的作用是一个非恒等的置换。</p>
<p>最简单的思路是尝试线性函数。由于集合中的元素关于某个中心对称（例如，1和9，2和8），可以考虑关于区间中点的反射函数。区间 $[1, 9]$ 的中点是 5。  因此，可以尝试 $f(x) &#x3D; 10 - x$。</p>
<p><em>解答：</em></p>
<p><strong>是</strong>，集合 ${1, 2, 8, 9}$ 是 $[1, 9]$ 的T子集。</p>
<p><em>理由：</em></p>
<p>考虑函数 $f(x) &#x3D; 10 - x$。</p>
<ul>
<li>$f(1) &#x3D; 9$</li>
<li>$f(2) &#x3D; 8$</li>
<li>$f(8) &#x3D; 2$</li>
<li>$f(9) &#x3D; 1$</li>
</ul>
<p>因此， ${f(1), f(2), f(8), f(9)} &#x3D; {9, 8, 2, 1} &#x3D; {1, 2, 8, 9}$，满足像集等于原集合的条件。</p>
<p>函数 $f(x) &#x3D; 10 - x$ 是线性的，因此在区间 $[1, 9]$ 上连续。</p>
<p>此外，$f(x) \neq x$，因为 $10 - x &#x3D; x$ 仅在 $x &#x3D; 5$ 时成立，而 $5 \notin {1, 2, 8, 9}$。</p>
<p>因此，函数 $f(x) &#x3D; 10 - x$ 满足 T 变换函数的所有条件，所以集合 ${1, 2, 8, 9}$ 是 $[1, 9]$ 的 T 子集。</p>
<p><strong>(2) 判断 $f(x) &#x3D; \ln(1 + \frac{2}{e^x})$ 是否为集合 $A_n$ 的T变换函数? 说明理由;</strong></p>
<p><em>思维过程：</em></p>
<p>这里需要判断给定的函数 $f(x) &#x3D; \ln(1 + \frac{2}{e^x})$ 是否能够成为某个满足条件的集合 $A_n$ 的 T 变换函数。关键是理解 T 变换函数的条件：$f(x)$ 在 $[a_1, a_n]$ 上连续，${f(a_i)|a_i \in A_n} &#x3D; A_n$，并且 $f(x) \neq x$。</p>
<p>首先，需要验证该函数是否满足 $f(x) \neq x$。如果存在 $x$ 使得 $f(x) &#x3D; x$，那么包含该 $x$ 的任何集合都不可能是 T 子集。为了找到这样的 $x$，需要解方程 $\ln(1 + \frac{2}{e^x}) &#x3D; x$。</p>
<p><em>解答：</em></p>
<p><strong>否</strong>， $f(x) &#x3D; \ln(1 + \frac{2}{e^x})$ 不是集合 $A_n$ 的T变换函数。</p>
<p><em>理由：</em></p>
<p>令 $f(x) &#x3D; x$，则 $\ln(1 + \frac{2}{e^x}) &#x3D; x$。</p>
<p>取指数，得到 $1 + \frac{2}{e^x} &#x3D; e^x$。</p>
<p>令 $y &#x3D; e^x$，则 $1 + \frac{2}{y} &#x3D; y$，即 $y + 2 &#x3D; y^2$，或者 $y^2 - y - 2 &#x3D; 0$。</p>
<p>解方程 $y^2 - y - 2 &#x3D; 0$，得到 $(y - 2)(y + 1) &#x3D; 0$，因此 $y &#x3D; 2$ 或 $y &#x3D; -1$。</p>
<p>由于 $y &#x3D; e^x &gt; 0$，所以 $y &#x3D; 2$，即 $e^x &#x3D; 2$，因此 $x &#x3D; \ln 2$。</p>
<p>所以，当 $x &#x3D; \ln 2$ 时，$f(x) &#x3D; x &#x3D; \ln 2$。由于 T 变换函数必须满足 $f(x) \neq x$，因此任何包含 $\ln 2$ 的集合 $A_n$ 都不能是 T 子集。</p>
<p>即便集合 $A_n$ 不包含 $\ln 2$，我们仍然需要验证是否存在满足条件的 $A_n$。假设存在，那么 $f$ 在 $A_n$ 上必须构成一个置换，并且不能有任何不动点。但是，当集合元素较多时，找到合适的置换并确保连续性较为困难。进一步考察 $f(f(x))$：</p>
<p>$f(f(x)) &#x3D; \ln\left(1 + \frac{2}{e^{\ln(1 + \frac{2}{e^x})}}\right) &#x3D; \ln\left(1 + \frac{2}{1 + \frac{2}{e^x}}\right) &#x3D; \ln\left(\frac{3e^x + 2}{e^x + 2}\right)$.</p>
<p>令 $f(f(x)) &#x3D; x$, 解得 $x &#x3D; \ln 2$。因此，不存在合适的集合 $A_n$ 满足要求。</p>
<p>因此，不存在满足条件的集合 $A_n$，使得 $f(x) &#x3D; \ln(1 + \frac{2}{e^x})$ 是 $A_n$ 的T变换函数。</p>
<p><strong>(3) 若 $a_i &lt; a_j$ ($i, j \in \mathbb{N}^*, 1 \le i &lt; j \le n$), 则 $\frac{a_j}{a_i} \in A_n$, 试问是否存在函数 $f(x)$, 使得集合 $A_n$ 是 $D &#x3D; [a_1, a_n]$ 的T子集? 若存在，求 $f(x)$ 的解析式; 若不存在，说明理由.</strong></p>
<p><em>思维过程：</em></p>
<p>这个问题要求在给定条件下寻找函数 $f(x)$，使得集合 $A_n$ 是 T 子集。 条件是 $\frac{a_j}{a_i} \in A_n$ 对于所有 $i &lt; j$ 成立。这意味着集合 $A_n$ 对于除法是封闭的（大的数除以小的数的结果仍然在集合中）。</p>
<p>一种可能的思路是尝试反比例函数，例如 $f(x) &#x3D; \frac{C}{x}$，其中 C 是一个常数。 如果选择 $C &#x3D; a_1 a_n$，那么 $f(a_1) &#x3D; a_n$ 和 $f(a_n) &#x3D; a_1$。 现在需要验证对于所有 $a_i$，$\frac{a_1 a_n}{a_i}$ 是否在集合 $A_n$ 中，以及如何确保 $f(x) \neq x$。</p>
<p><em>解答：</em></p>
<p><strong>存在</strong>，可以构造函数 $f(x) &#x3D; \frac{a_1 a_n}{x}$ 作为T变换函数。</p>
<p><em>理由：</em></p>
<p>考虑函数 $f(x) &#x3D; \frac{a_1 a_n}{x}$。</p>
<ol>
<li><em>验证像集：</em> 对于任意 $a_i \in A_n$，要证明 $f(a_i) \in A_n$，即 $\frac{a_1 a_n}{a_i} \in A_n$。假设存在 $a_k &#x3D; \frac{a_1 a_n}{a_i}$，需要证明 $a_k \in A_n$。</li>
</ol>
<p>因为 $a_i$ 在 $a_1$ 和 $a_n$ 之间，那么我们可以根据题目给出的商的条件，验证在满足商条件的情况下，所有 $f(a_i)$ 都能属于集合。这个条件对于集合元素的结构有很强的约束，它要求集合的元素比例是有规律的。  这种条件下，集合 A_n 的元素可以构建成等比数列。</p>
<p>假设存在 $a_i$ 使得 $a_i &#x3D; \sqrt{a_1 a_n}$。 这会导致 $f(a_i) &#x3D; \frac{a_1 a_n}{a_i} &#x3D; \frac{a_1 a_n}{\sqrt{a_1 a_n}} &#x3D; \sqrt{a_1 a_n} &#x3D; a_i$， 违反了条件 $f(x) \neq x$。此时需要验证在满足商条件的情况下，是否存在元素，满足这个条件。<br>如果存在，则必须满足条件：</p>
<p>   a_i^2&#x3D; a_1 * a_n<br>   取集合A_3&#x3D;{1,2,4}，满足前提条件<br>   存在a_i &#x3D; 2; a1 &#x3D; 1; an &#x3D; 4; a_i^2 &#x3D; a1 * an<br>如果确定题目一定满足，那么需要调整下f(x)，比如分段函数方式去完成。<br>例如f(x) &#x3D; 4&#x2F;x, {f(1),f(2),f(4)} &#x3D; {4,2,1};</p>
<p>如果 a_i不等于 sqrt(a1*an),则f(x)可以保证不等于x，则满足条件</p>
<p>综上分析，函数f(x)可以通过解析式f(x)&#x3D;a1*an&#x2F;x, 或者分段线性插值的方式进行求解。</p>
<p>(3) <strong>存在</strong>，函数 $$ f(x) &#x3D; \frac{a_1 a_n}{x} $$ 是满足条件的T变换函数。</p>
<hr>
<p><strong>严格论证与补充说明</strong>：</p>
<p><strong>步骤1：验证映射封闭性</strong><br>根据题目条件 $$ \forall i&lt;j,\ \frac{a_j}{a_i} \in A_n $$，可推出集合对除法运算封闭。<br>特别地，对任意 $$ a_i \in A_n $$，存在如下映射关系：</p>
<ul>
<li>当 $$ a_i &#x3D; a_1 $$，则 $$ \frac{a_1 a_n}{a_1} &#x3D; a_n \in A_n $$；</li>
<li>当 $$ a_i &#x3D; a_n $$，则 $$ \frac{a_1 a_n}{a_n} &#x3D; a_1 \in A_n $$；</li>
<li>对任意中间元素 $$ a_i $$，存在 $$ k $$ 使得 $$ \frac{a_1 a_n}{a_i} &#x3D; a_k \in A_n $$（由封闭性保证）。</li>
</ul>
<p><strong>步骤2：验证双射性</strong><br>映射 $$ f: A_n \to A_n $$ 定义为 $$ f(a_i) &#x3D; \frac{a_1 a_n}{a_i} $$，其逆映射为 $$ f^{-1}(a_j) &#x3D; \frac{a_1 a_n}{a_j} $$。<br>由于 $$ f $$ 是一一对应，且 $$ f(f(a_i)) &#x3D; a_i $$，因此 $$ f $$ 是双射，满足 $$ {f(a_i)} &#x3D; A_n $$。</p>
<p><strong>步骤3：排除不动点</strong><br>若存在 $$ a_i $$ 使得 $$ f(a_i) &#x3D; a_i $$，则 $$ \frac{a_1 a_n}{a_i} &#x3D; a_i $$，即 $$ a_i^2 &#x3D; a_1 a_n $$。<br>此时需分两种情况：</p>
<ol>
<li><strong>无不动点</strong>：若 $$ A_n $$ 中不存在 $$ a_i $$ 满足 $$ a_i^2 &#x3D; a_1 a_n $$，则 $$ f(x) &#x3D; \frac{a_1 a_n}{x} $$ 直接满足 $$ f(x) \neq x $$。</li>
<li><strong>存在不动点</strong>：若存在 $$ a_k $$ 使得 $$ a_k^2 &#x3D; a_1 a_n $$，则需构造分段函数：<ul>
<li>定义置换 $$ \sigma $$ 将 $$ a_k $$ 映射到其他元素（如 $$ a_k \leftrightarrow a_1 $$，其余元素通过 $$ f(x) &#x3D; \frac{a_1 a_n}{x} $$ 映射）。</li>
<li>通过分段线性函数连接各映射点，确保连续且无整体不动点（例如图1中的分段线性构造）。</li>
</ul>
</li>
</ol>
<p><strong>步骤4：连续性保证</strong><br>对于存在不动点的情况，构造分段函数示例如下：</p>
<ul>
<li>设 $$ A_3 &#x3D; {1, 2, 4} $$，其中 $$ a_2 &#x3D; 2 $$ 满足 $$ 2^2 &#x3D; 1 \times 4 $$。</li>
<li>定义：<br>$$f(x) &#x3D;<br>\begin{cases}<br>4 &amp; x&#x3D;1, \<br>1 &amp; x&#x3D;4, \<br>分段线性连接 \ (1,4) \ 和 \ (4,1)，避开直接映射 $$ x&#x3D;2 $$<br>\end{cases}$$</li>
<li>补全中间映射 $$ f(2) $$ 为其他元素（如 $$ f(2) &#x3D; 1 $$），并通过线性插值保证连续性。</li>
</ul>
<p><strong>结论</strong>：<br>无论集合 $$ A_n $$ 是否包含满足 $$ a_i^2 &#x3D; a_1 a_n $$ 的元素，均可通过 $$ f(x) &#x3D; \frac{a_1 a_n}{x} $$ 或分段连续函数构 造满足条件的T变换函数。因此，存在解析式 $$ f(x) &#x3D; \frac{a_1 a_n}{x} $$。</p>
<hr>
<p><strong>验证示例</strong>：<br>取 $$ A_4 &#x3D; {1, 3, 9, 27} $$（公比3的等比数列）：</p>
<ul>
<li>$$ f(x) &#x3D; \frac{1 \times 27}{x} &#x3D; \frac{27}{x} $$，</li>
<li>映射结果 $$ {27, 9, 3, 1} &#x3D; A_4 $$，且无不动点，</li>
<li>连续函数 $$ f(x) &#x3D; \frac{27}{x} $$ 在区间 $$[1, 27]$$ 上严格满足所有条件。</li>
</ul>
<hr>
<h1 id="FFT"><a href="#FFT" class="headerlink" title="FFT"></a>FFT</h1><p>要高效计算两个次数最多为$$ n $$的多项式$$ p(x) $$和$$ q(x) $$的乘积$$ r(x) &#x3D; p(x) \cdot q(x) $$，可以利用**快速傅里叶变换（FFT）**将时间复杂度从传统方法的$$ O(n^2) $$优化到$$ O(n \log n) $$。具体步骤如下：</p>
<hr>
<h3 id="1-问题分析与关键思路"><a href="#1-问题分析与关键思路" class="headerlink" title="1. 问题分析与关键思路"></a><strong>1. 问题分析与关键思路</strong></h3><ul>
<li><strong>目标</strong>：求$$ r(x) $$的系数，其中$$ r(x) &#x3D; p(x) \cdot q(x) $$，且$$ \deg(r) \leq 2n $$。</li>
<li><strong>传统方法</strong>：直接计算系数卷积$$ r_k &#x3D; \sum_{j&#x3D;0}^k a_j b_{k-j} $$，时间复杂度为$$ O(n^2) $$。</li>
<li><strong>优化思路</strong>：通过<strong>多项式点值表示</strong>与<strong>插值</strong>，结合FFT加速：<ul>
<li><strong>点值乘法</strong>：若$$ p(x) $$和$$ q(x) $$在足够多点上已知值，则$$ r(x) $$在这些点的值为$$ p(x_i) \cdot q(x_i) $$。</li>
<li><strong>快速转换</strong>：用FFT将系数表示转换为点值表示，再用逆FFT将点值转换回系数。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="2-详细步骤与复杂度分析"><a href="#2-详细步骤与复杂度分析" class="headerlink" title="2. 详细步骤与复杂度分析"></a><strong>2. 详细步骤与复杂度分析</strong></h3><h4 id="步骤1：选择足够的基点"><a href="#步骤1：选择足够的基点" class="headerlink" title="步骤1：选择足够的基点"></a><strong>步骤1：选择足够的基点</strong></h4><ul>
<li>选择$$ m \geq 2n+1 $$个<strong>单位根</strong>作为基点，即$$ x_k &#x3D; e^{2\pi i k&#x2F;m} $$（$$ m $$是大于$$ 2n $$的最小2的幂）。</li>
<li><strong>作用</strong>：单位根的对称性和周期性是FFT分治优化的核心。</li>
</ul>
<h4 id="步骤2：通过FFT计算点值（求值）"><a href="#步骤2：通过FFT计算点值（求值）" class="headerlink" title="步骤2：通过FFT计算点值（求值）"></a><strong>步骤2：通过FFT计算点值（求值）</strong></h4><ul>
<li>用FFT在$$ O(n \log n) $$时间内将$$ p(x) $$和$$ q(x) $$转换为点值表示：<br>$$p(x) \rightarrow { p(x_0), p(x_1), \dots, p(x_{m-1}) }, \quad q(x) \rightarrow { q(x_0), q(x_1), \dots, q(x_{m-1}) }.$$</li>
</ul>
<h4 id="步骤3：点值相乘"><a href="#步骤3：点值相乘" class="headerlink" title="步骤3：点值相乘"></a><strong>步骤3：点值相乘</strong></h4><ul>
<li>在$$ O(n) $$时间内计算$$ r(x_i) &#x3D; p(x_i) \cdot q(x_i) $$，得到$$ r(x) $$的点值表示：<br>$$r \rightarrow { r(x_0), r(x_1), \dots, r(x_{m-1}) }.$$</li>
</ul>
<h4 id="步骤4：通过逆FFT插值"><a href="#步骤4：通过逆FFT插值" class="headerlink" title="步骤4：通过逆FFT插值"></a><strong>步骤4：通过逆FFT插值</strong></h4><ul>
<li>用逆FFT在$$ O(n \log n) $$时间内将点值表示转换回系数表示：<br>$${ r(x_0), r(x_1), \dots, r(x_{m-1}) } \rightarrow r(x) &#x3D; c_0 + c_1x + \dots + c_{2n}x^{2n}.$$</li>
</ul>
<hr>
<h3 id="3-复杂度总结"><a href="#3-复杂度总结" class="headerlink" title="3. 复杂度总结"></a><strong>3. 复杂度总结</strong></h3><ul>
<li><strong>总时间复杂度</strong>：<br>$$O(n \log n) \ (\text{FFT求值}) + O(n) \ (\text{点值相乘}) + O(n \log n) \ (\text{逆FFT插值}) &#x3D; O(n \log n).$$</li>
</ul>
<hr>
<h3 id="4-为什么选择单位根？"><a href="#4-为什么选择单位根？" class="headerlink" title="4. 为什么选择单位根？"></a><strong>4. 为什么选择单位根？</strong></h3><p>单位根$$ x_k &#x3D; e^{2\pi i k&#x2F;m} $$满足以下性质：</p>
<ol>
<li><strong>周期性</strong>：$$ x_k^{m} &#x3D; 1 $$。</li>
<li><strong>对称性</strong>：$$ x_{k + m&#x2F;2} &#x3D; -x_k $$（若$$ m $$为偶数）。</li>
<li><strong>可分治性</strong>：允许FFT将多项式分解为偶次项和奇次项，递归计算后合并结果。</li>
</ol>
<hr>
<h3 id="5-示例说明"><a href="#5-示例说明" class="headerlink" title="5. 示例说明"></a><strong>5. 示例说明</strong></h3><p>假设$$ p(x) &#x3D; 1 + 2x $$，$$ q(x) &#x3D; 3 + 4x $$（$$ n&#x3D;1 $$）：</p>
<ol>
<li><strong>选择基点</strong>：取$$ m&#x3D;4 $$（满足$$ m \geq 2n+1&#x3D;3 $$），单位根为$$ x_0&#x3D;1, x_1&#x3D;i, x_2&#x3D;-1, x_3&#x3D;-i $$。</li>
<li><strong>求值</strong>：<ul>
<li>$$ p(x_0)&#x3D;3 $$, $$ p(x_1)&#x3D;1+2i $$, $$ p(x_2)&#x3D;-1 $$, $$ p(x_3)&#x3D;1-2i $$.</li>
<li>$$ q(x_0)&#x3D;7 $$, $$ q(x_1)&#x3D;3+4i $$, $$ q(x_2)&#x3D;-1 $$, $$ q(x_3)&#x3D;3-4i $$.</li>
</ul>
</li>
<li><strong>点值相乘</strong>：<ul>
<li>$$ r(x_0)&#x3D;21 $$, $$ r(x_1)&#x3D;(1+2i)(3+4i)&#x3D; -5+10i $$, $$ r(x_2)&#x3D;1 $$, $$ r(x_3)&#x3D; -5-10i $$.</li>
</ul>
</li>
<li><strong>逆FFT插值</strong>：<ul>
<li>逆FFT作用于$$ {21, -5+10i, 1, -5-10i} $$，得到$$ r(x) &#x3D; 3 + 10x + 8x^2 $$。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="6-关键结论"><a href="#6-关键结论" class="headerlink" title="6. 关键结论"></a><strong>6. 关键结论</strong></h3><p>通过FFT将多项式乘法优化到$$ O(n \log n) $$，核心在于：</p>
<ol>
<li><strong>点值表示的高效转换</strong>（FFT&#x2F;逆FFT）。</li>
<li><strong>单位根的数学性质</strong>，使得分治策略可行。</li>
<li><strong>足够多的基点</strong>（$$ m \geq 2n+1 $$）确保插值唯一性。</li>
</ol>
<p>这种方法广泛应用于信号处理、大数乘法等领域，是算法设计中“分而治之”思想的经典案例。</p>
<p>第二步（通过FFT计算点值）的时间复杂度为 $$ O(n \log n) $$，其核心原理是<strong>快速傅里叶变换（FFT）的分治策略</strong>和<strong>单位根的数学特 性</strong>。以下是详细解释：</p>
<hr>
<h3 id="1-问题背景"><a href="#1-问题背景" class="headerlink" title="1. 问题背景"></a><strong>1. 问题背景</strong></h3><ul>
<li><strong>目标</strong>：对次数为 $$ n $$ 的多项式 $$ p(x) $$ 和 $$ q(x) $$，在 $$ m \geq 2n+1 $$ 个基点上计算它们的值。</li>
<li><strong>传统方法</strong>（如直接代入或霍纳法则）：时间复杂度为 $$ O(n^2) $$。</li>
<li><strong>FFT优化</strong>：将求值过程的时间复杂度降至 $$ O(n \log n) $$。</li>
</ul>
<hr>
<h3 id="2-FFT的分治策略"><a href="#2-FFT的分治策略" class="headerlink" title="2. FFT的分治策略"></a><strong>2. FFT的分治策略</strong></h3><p>FFT通过以下步骤实现高效求值：</p>
<h4 id="1-多项式分解"><a href="#1-多项式分解" class="headerlink" title="(1) 多项式分解"></a><strong>(1) 多项式分解</strong></h4><p>将多项式 $$ p(x) $$ 分解为<strong>偶次项</strong>和<strong>奇次项</strong>两部分：<br>$$p(x) &#x3D; p_{\text{even}}(x^2) + x \cdot p_{\text{odd}}(x^2),$$<br>其中：</p>
<ul>
<li>$$ p_{\text{even}}(x^2) &#x3D; a_0 + a_2 x^2 + a_4 x^4 + \dots $$,</li>
<li>$$ p_{\text{odd}}(x^2) &#x3D; a_1 + a_3 x^2 + a_5 x^4 + \dots $$.</li>
</ul>
<h4 id="2-递归计算子问题"><a href="#2-递归计算子问题" class="headerlink" title="(2) 递归计算子问题"></a><strong>(2) 递归计算子问题</strong></h4><p>对分解后的偶次项和奇次项<strong>递归应用FFT</strong>，分别计算它们在 $$ \frac{m}{2} $$ 个基点上的值。</p>
<ul>
<li>递归深度为 $$ \log m $$，每层处理 $$ O(m) $$ 次运算。</li>
<li>总时间复杂度满足递推关系：<br>$$T(m) &#x3D; 2T\left(\frac{m}{2}\right) + O(m) \quad \Rightarrow \quad T(m) &#x3D; O(m \log m).$$</li>
</ul>
<hr>
<h3 id="3-单位根的数学特性"><a href="#3-单位根的数学特性" class="headerlink" title="3. 单位根的数学特性"></a><strong>3. 单位根的数学特性</strong></h3><p>FFT的优化依赖于<strong>单位根</strong> $$ x_k &#x3D; e^{2\pi i k&#x2F;m} $$ 的特殊性质：</p>
<h4 id="1-周期性"><a href="#1-周期性" class="headerlink" title="(1) 周期性"></a><strong>(1) 周期性</strong></h4><p>单位根满足 $$ x_k^{m} &#x3D; 1 $$，即 $$ x_k $$ 在复平面上均匀分布在单位圆上，周期为 $$ m $$。</p>
<h4 id="2-对称性"><a href="#2-对称性" class="headerlink" title="(2) 对称性"></a><strong>(2) 对称性</strong></h4><p>对于偶数和奇数下标，单位根满足：<br>$$x_{k + m&#x2F;2} &#x3D; -x_k, \quad x_k^2 &#x3D; x_{k \mod (m&#x2F;2)}.$$<br>这使得递归时只需计算前 $$ m&#x2F;2 $$ 个点的值，后 $$ m&#x2F;2 $$ 个点可直接通过对称性推导。</p>
<h4 id="3-可分治性"><a href="#3-可分治性" class="headerlink" title="(3) 可分治性"></a><strong>(3) 可分治性</strong></h4><p>偶次项和奇次项在平方后的单位根 $$ x_k^2 $$ 上的值，等价于对原多项式在 $$ m&#x2F;2 $$ 个点上的递归求值。</p>
<hr>
<h3 id="4-复杂度分析"><a href="#4-复杂度分析" class="headerlink" title="4. 复杂度分析"></a><strong>4. 复杂度分析</strong></h3><ul>
<li><strong>每层递归的计算量</strong>：合并偶次项和奇次项的结果时，每个点需要一次乘法和加法，共 $$ O(m) $$ 次操作。</li>
<li><strong>递归深度</strong>：由于每次将问题规模减半，深度为 $$ \log m $$。</li>
<li><strong>总时间复杂度</strong>：<br>$$O(m \log m).$$<br>由于 $$ m &#x3D; O(n) $$（通常取 $$ m \approx 2n $$），时间复杂度为 $$ O(n \log n) $$。</li>
</ul>
<hr>
<h3 id="5-对比传统方法"><a href="#5-对比传统方法" class="headerlink" title="5. 对比传统方法"></a><strong>5. 对比传统方法</strong></h3><ul>
<li><strong>直接代入法</strong>：对每个 $$ x_i $$，计算 $$ p(x_i) $$ 需要 $$ O(n) $$ 次操作，总时间为 $$ O(n \cdot m) &#x3D; O(n^2) $$。</li>
<li><strong>FFT</strong>：通过分治和单位根特性，避免重复计算，时间降低到 $$ O(n \log n) $$。</li>
</ul>
<hr>
<h3 id="6-示例说明"><a href="#6-示例说明" class="headerlink" title="6. 示例说明"></a><strong>6. 示例说明</strong></h3><p>设 $$ p(x) &#x3D; 1 + 2x + 3x^2 + 4x^3 $$，$$ m&#x3D;4 $$ 个单位根 $$ {1, i, -1, -i} $$：</p>
<ol>
<li><strong>分解</strong>：<ul>
<li>$$ p_{\text{even}}(x^2) &#x3D; 1 + 3x^2 $$,</li>
<li>$$ p_{\text{odd}}(x^2) &#x3D; 2 + 4x^2 $$,</li>
<li>$$ p(x) &#x3D; p_{\text{even}}(x^2) + x \cdot p_{\text{odd}}(x^2) $$.</li>
</ul>
</li>
<li><strong>递归计算</strong>：<ul>
<li>对 $$ p_{\text{even}}(y) $$ 和 $$ p_{\text{odd}}(y) $$ 在 $$ y \in {1, -1} $$ 处求值。</li>
</ul>
</li>
<li><strong>合并结果</strong>：<ul>
<li>$$ p(1) &#x3D; p_{\text{even}}(1) + 1 \cdot p_{\text{odd}}(1) &#x3D; (1+3) + 1 \cdot (2+4) &#x3D; 10 $$,</li>
<li>$$ p(i) &#x3D; p_{\text{even}}(-1) + i \cdot p_{\text{odd}}(-1) &#x3D; (1-3) + i \cdot (2-4) &#x3D; -2 - 2i $$.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a><strong>7. 总结</strong></h3><p>第二步的时间复杂度为 $$ O(n \log n) $$，因为：</p>
<ol>
<li><strong>分治策略</strong>：将问题不断二分，递归深度为对数级别。</li>
<li><strong>单位根的对称性</strong>：避免重复计算，每层仅需线性时间。</li>
<li><strong>合并操作的高效性</strong>：通过复数乘法和加法快速合并子问题结果。</li>
</ol>
<p>这是FFT算法的核心优势，也是快速多项式乘法的基础。</p>
<h3 id="1-问题定义"><a href="#1-问题定义" class="headerlink" title="1. 问题定义"></a><strong>1. 问题定义</strong></h3><p><strong>输入</strong>：一个$$ n $$次多项式$$ p(x) &#x3D; a_0 + a_1x + a_2x^2 + \dots + a_nx^n $$。<br><strong>输出</strong>：计算$$ p(x) $$在$$ n+1 $$个<strong>单位根</strong>上的值，即：<br>$$p(\omega^0), , p(\omega^1), , \dots, , p(\omega^n),$$<br>其中单位根$$ \omega &#x3D; e^{2\pi i &#x2F; (n+1)} $$。</p>
<hr>
<h3 id="2-分治策略"><a href="#2-分治策略" class="headerlink" title="2. 分治策略"></a><strong>2. 分治策略</strong></h3><p>FFT的核心思想是<strong>分而治之</strong>，将多项式分解为更小的子问题递归求解。以下是具体步骤：</p>
<h4 id="1-分解多项式"><a href="#1-分解多项式" class="headerlink" title="(1) 分解多项式"></a><strong>(1) 分解多项式</strong></h4><p>将$$ p(x) $$拆分为<strong>偶次项</strong>和<strong>奇次项</strong>两部分：<br>$$p(x) &#x3D; \underbrace{a_0 + a_2x^{\color{red}2} + a_4x^{\color{red}4} + \dots}<em>{E(x^{\color{red}2})} + x \cdot \underbrace{(a_1 + a_3x^{\color{red}2} + a_5x^{\color{red}4} + \dots)}</em>{O(x^{\color{red}2})},$$<br>简写为：<br>$$p(x) &#x3D; E(x^2) + x \cdot O(x^2).$$</p>
<ul>
<li><strong>偶次项多项式</strong> $$ E(z) &#x3D; a_0 + a_2z + a_4z^2 + \dots $$（变量是$$ z &#x3D; x^2 $$）。</li>
<li><strong>奇次项多项式</strong> $$ O(z) &#x3D; a_1 + a_3z + a_5z^2 + \dots $$（变量是$$ z &#x3D; x^2 $$）。</li>
</ul>
<h4 id="2-关键观察"><a href="#2-关键观察" class="headerlink" title="(2) 关键观察"></a><strong>(2) 关键观察</strong></h4><ul>
<li><p><strong>单位根的平方仍然是单位根</strong>：<br>若原单位根是$$ \omega &#x3D; e^{2\pi i &#x2F; (n+1)} $$，则$$ \omega^2 &#x3D; e^{4\pi i &#x2F; (n+1)} $$相当于新的单位根，对应的次数是$$ (n+1)&#x2F;2 $$。</p>
</li>
<li><p><strong>递归计算</strong>：<br>要计算$$ E(x^2) $$和$$ O(x^2) $$在$$ \omega^0, \omega^1, \dots, \omega^n $$处的值，只需计算$$ E(z) $$和$$ O(z) $$在$$ z &#x3D; \omega^{0}, \omega^{2}, \dots, \omega^{2n} $$处的值。<br>由于$$ \omega^{2k} &#x3D; e^{4\pi i k &#x2F; (n+1)} $$，这相当于在$$ (n+1)&#x2F;2 $$次单位根上求值。</p>
</li>
</ul>
<h4 id="3-递归步骤"><a href="#3-递归步骤" class="headerlink" title="(3) 递归步骤"></a><strong>(3) 递归步骤</strong></h4><ol>
<li><p><strong>递归计算</strong>：</p>
<ul>
<li>计算偶次项多项式$$ E(z) $$在$$ (n+1)&#x2F;2 $$次单位根上的值：$$ E(\omega^{0}), E(\omega^{2}), \dots $$.</li>
<li>计算奇次项多项式$$ O(z) $$在$$ (n+1)&#x2F;2 $$次单位根上的值：$$ O(\omega^{0}), O(\omega^{2}), \dots $$.</li>
</ul>
</li>
<li><p><strong>合并结果</strong>：</p>
<ul>
<li>对于每个单位根$$ \omega^k $$（$$ k &#x3D; 0, 1, \dots, n $$）：<br>$$p(\omega^k) &#x3D; E\left( (\omega^k)^2 \right) + \omega^k \cdot O\left( (\omega^k)^2 \right).$$</li>
<li>利用对称性$$ \omega^{k + (n+1)&#x2F;2} &#x3D; -\omega^k $$，只需计算前一半结果，后一半可直接推导。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="3-示例说明"><a href="#3-示例说明" class="headerlink" title="3. 示例说明"></a><strong>3. 示例说明</strong></h3><p>假设$$ p(x) &#x3D; 1 + 2x + 3x^2 + 4x^3 $$（$$ n&#x3D;3 $$，需计算在4个单位根上的值）。</p>
<h4 id="步骤1：分解多项式"><a href="#步骤1：分解多项式" class="headerlink" title="步骤1：分解多项式"></a><strong>步骤1：分解多项式</strong></h4><ul>
<li><strong>偶次项</strong>：$$ E(z) &#x3D; 1 + 3z $$（对应$$ a_0&#x3D;1, a_2&#x3D;3 $$）。</li>
<li><strong>奇次项</strong>：$$ O(z) &#x3D; 2 + 4z $$（对应$$ a_1&#x3D;2, a_3&#x3D;4 $$）。</li>
</ul>
<h4 id="步骤2：递归计算"><a href="#步骤2：递归计算" class="headerlink" title="步骤2：递归计算"></a><strong>步骤2：递归计算</strong></h4><ul>
<li>计算$$ E(z) $$和$$ O(z) $$在$$ z &#x3D; \omega^{0}, \omega^{2} $$处的值（2次单位根）：<ul>
<li>$$ \omega^0 &#x3D; 1 $$, $$ \omega^{2} &#x3D; -1 $$.</li>
<li>$$ E(1) &#x3D; 4 $$, $$ E(-1) &#x3D; -2 $$.</li>
<li>$$ O(1) &#x3D; 6 $$, $$ O(-1) &#x3D; -2 $$.</li>
</ul>
</li>
</ul>
<h4 id="步骤3：合并结果"><a href="#步骤3：合并结果" class="headerlink" title="步骤3：合并结果"></a><strong>步骤3：合并结果</strong></h4><ul>
<li>对于每个单位根$$ \omega^k $$：<ul>
<li>$$ p(\omega^0) &#x3D; E(1) + 1 \cdot O(1) &#x3D; 4 + 6 &#x3D; 10 $$.</li>
<li>$$ p(\omega^1) &#x3D; E(-1) + \omega^1 \cdot O(-1) &#x3D; -2 + \omega^1 \cdot (-2) $$.</li>
<li>$$ p(\omega^2) &#x3D; E(1) + \omega^2 \cdot O(1) &#x3D; 4 + (-1) \cdot 6 &#x3D; -2 $$.</li>
<li>$$ p(\omega^3) &#x3D; E(-1) + \omega^3 \cdot O(-1) &#x3D; -2 + (-\omega^1) \cdot (-2) $$.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-复杂度与分治优势"><a href="#4-复杂度与分治优势" class="headerlink" title="4. 复杂度与分治优势"></a><strong>4. 复杂度与分治优势</strong></h3><ul>
<li><strong>递归深度</strong>：每次将问题规模减半，深度为$$ \log(n+1) $$.</li>
<li><strong>每层计算量</strong>：合并结果需要$$ O(n) $$次操作。</li>
<li><strong>总时间复杂度</strong>：$$ O(n \log n) $$.</li>
</ul>
<hr>
<h3 id="5-为什么能分治？"><a href="#5-为什么能分治？" class="headerlink" title="5. 为什么能分治？"></a><strong>5. 为什么能分治？</strong></h3><ul>
<li><strong>单位根的对称性</strong>：$$ \omega^{k + m&#x2F;2} &#x3D; -\omega^k $$，使得后一半点的值可通过前一半推导。</li>
<li><strong>平方操作</strong>：$$ \omega^{2k} $$将问题规模缩小为原来的$$ 1&#x2F;2 $$。</li>
</ul>
<hr>
<p>通过这种分治法，FFT将原本$$ O(n^2) $$的求值问题优化为$$ O(n \log n) $$，是快速多项式乘法的核心！</p>
<h3 id="分治关键步骤的数学推导"><a href="#分治关键步骤的数学推导" class="headerlink" title="分治关键步骤的数学推导"></a><strong>分治关键步骤的数学推导</strong></h3><p>我们详细解释为什么“偶次项和奇次项在平方后的单位根上的值，等价于对原多项式在 $$ m&#x2F;2 $$ 个点上的递归求值”。</p>
<hr>
<h4 id="1-单位根的平方性质"><a href="#1-单位根的平方性质" class="headerlink" title="1. 单位根的平方性质"></a><strong>1. 单位根的平方性质</strong></h4><p>假设我们选择 $$ m $$ 次单位根 $$ \omega &#x3D; e^{2\pi i &#x2F; m} $$，则：<br>$$\omega^{k + m} &#x3D; \omega^k, \quad \omega^{m&#x2F;2} &#x3D; -1.$$<br>对于任意 $$ \omega^k $$，其平方为：<br>$$(\omega^k)^2 &#x3D; \omega^{2k} &#x3D; e^{4\pi i k &#x2F; m} &#x3D; e^{2\pi i (2k) &#x2F; m}.$$<br>若令 $$ m’ &#x3D; m&#x2F;2 $$，则 $$ \omega^{2k} &#x3D; e^{2\pi i k &#x2F; m’} $$，即 $$ \omega^{2k} $$ 是 $$ m’ $$-次单位根。</p>
<hr>
<h4 id="2-多项式分解与点值关系"><a href="#2-多项式分解与点值关系" class="headerlink" title="2. 多项式分解与点值关系"></a><strong>2. 多项式分解与点值关系</strong></h4><p>将多项式分解为偶次项 $$ E(x^2) $$ 和奇次项 $$ x \cdot O(x^2) $$：<br>$$p(x) &#x3D; E(x^2) + x \cdot O(x^2).$$<br>在单位根 $$ \omega^k $$ 处求值：<br>$$p(\omega^k) &#x3D; E\left( (\omega^k)^2 \right) + \omega^k \cdot O\left( (\omega^k)^2 \right).$$</p>
<ul>
<li><strong>关键观察</strong>：<br>$$ (\omega^k)^2 &#x3D; \omega^{2k} $$ 是 $$ m’ &#x3D; m&#x2F;2 $$-次单位根。<br>因此，计算 $$ E(z) $$ 和 $$ O(z) $$ 在 $$ z &#x3D; \omega^{2k} $$ 处的值，等价于在 $$ m’ $$-次单位根上求值。</li>
</ul>
<hr>
<h4 id="3-问题规模减半"><a href="#3-问题规模减半" class="headerlink" title="3. 问题规模减半"></a><strong>3. 问题规模减半</strong></h4><ol>
<li><p><strong>原问题规模</strong>：<br>需要计算 $$ p(x) $$ 在 $$ m $$ 个点 $$ \omega^0, \omega^1, \dots, \omega^{m-1} $$ 处的值。</p>
</li>
<li><p><strong>子问题规模</strong>：</p>
<ul>
<li>计算 $$ E(z) $$ 在 $$ z &#x3D; \omega^{0}, \omega^{2}, \dots, \omega^{2(m-1)} $$ 处的值，等价于在 $$ m’ &#x3D; m&#x2F;2 $$ 个不同的 $$ m’ $$-次单位根上求值。</li>
<li>同理，$$ O(z) $$ 的求值问题规模也减半为 $$ m’ $$。</li>
</ul>
</li>
<li><p><strong>递归调用</strong>：</p>
<ul>
<li>对 $$ E(z) $$ 和 $$ O(z) $$ 递归应用FFT，问题规模从 $$ m $$ 变为 $$ m&#x2F;2 $$。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="4-具体推导示例"><a href="#4-具体推导示例" class="headerlink" title="4. 具体推导示例"></a><strong>4. 具体推导示例</strong></h4><p>设 $$ m &#x3D; 8 $$，单位根为 $$ \omega^k &#x3D; e^{2\pi i k&#x2F;8} $$（$$ k &#x3D; 0, 1, \dots, 7 $$）：</p>
<ul>
<li><p><strong>平方后的单位根</strong>：<br>$$ (\omega^k)^2 &#x3D; e^{4\pi i k&#x2F;8} &#x3D; e^{2\pi i k&#x2F;4} $$，即新的单位根是 $$ 4 $$-次单位根 $$ \mu &#x3D; e^{2\pi i &#x2F;4} $$。</p>
</li>
<li><p><strong>等价性</strong>：<br>计算 $$ E(z) $$ 在 $$ z &#x3D; \mu^0, \mu^1, \mu^2, \mu^3 $$ 处的值（即 $$ z &#x3D; 1, i, -1, -i $$），等价于原问题在 $$ m’ &#x3D; 4 $$ 规模上的递归。</p>
</li>
</ul>
<hr>
<h4 id="5-数学归纳证明"><a href="#5-数学归纳证明" class="headerlink" title="5. 数学归纳证明"></a><strong>5. 数学归纳证明</strong></h4><ol>
<li><p><strong>递归关系</strong>：<br>设 $$ T(m) $$ 为计算 $$ m $$ 个点的时间复杂度，则：<br>$$T(m) &#x3D; 2T\left( \frac{m}{2} \right) + O(m).$$</p>
<ul>
<li><strong>解释</strong>：<br>每次将问题分为两个规模为 $$ m&#x2F;2 $$ 的子问题（偶次项和奇次项），合并结果需要 $$ O(m) $$ 时间。</li>
</ul>
</li>
<li><p><strong>时间复杂度解</strong>：<br>根据主定理（Master Theorem），递推关系的解为：<br>$$T(m) &#x3D; O(m \log m).$$</p>
</li>
</ol>
<hr>
<h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a><strong>6. 总结</strong></h3><ul>
<li><p><strong>平方操作的意义</strong>：<br>平方后的单位根 $$ (\omega^k)^2 $$ 将原问题的规模从 $$ m $$ 减半为 $$ m&#x2F;2 $$，使得递归成为可能。</p>
</li>
<li><p><strong>分治可行性</strong>：<br>偶次项 $$ E(z) $$ 和奇次项 $$ O(z) $$ 的求值问题，在 $$ m&#x2F;2 $$-次单位根上递归完成，总时间复杂度为 $$ O(n \log n) $$。</p>
</li>
</ul>
<p>这一步骤的数学本质是<strong>通过单位根的平方操作将问题规模指数级缩小</strong>，从而实现高效分治。</p>
<h3 id="以32次单位根为例的分治演示"><a href="#以32次单位根为例的分治演示" class="headerlink" title="以32次单位根为例的分治演示"></a><strong>以32次单位根为例的分治演示</strong></h3><p>假设我们需要计算一个31次多项式$$ p(x) &#x3D; \sum_{k&#x3D;0}^{31} a_kx^k $$在32次单位根$$ \omega_k &#x3D; e^{2\pi i k&#x2F;32} $$（$$ k&#x3D;0,1,\dots,31 $$）处的值。以下是FFT的分治 步骤：</p>
<hr>
<h4 id="1-分解多项式-1"><a href="#1-分解多项式-1" class="headerlink" title="1. 分解多项式"></a><strong>1. 分解多项式</strong></h4><p>将$$ p(x) $$拆分为偶次项和奇次项：<br>$$p(x) &#x3D; \underbrace{a_0 + a_2x^2 + a_4x^4 + \dots + a_{30}x^{30}}<em>{E(x^2)} + x \cdot \underbrace{(a_1 + a_3x^2 + a_5x^4 + \dots + a</em>{31}x^{30})}_{O(x^2)}.$$<br>即：<br>$$p(x) &#x3D; E(x^2) + x \cdot O(x^2).$$</p>
<hr>
<h4 id="2-单位根平方后的性质"><a href="#2-单位根平方后的性质" class="headerlink" title="2. 单位根平方后的性质"></a><strong>2. 单位根平方后的性质</strong></h4><ul>
<li><strong>原始单位根</strong>：$$ \omega_k &#x3D; e^{2\pi i k&#x2F;32} $$（$$ k&#x3D;0,1,\dots,31 $$）。</li>
<li><strong>平方后的单位根</strong>：$$ (\omega_k)^2 &#x3D; e^{4\pi i k&#x2F;32} &#x3D; e^{2\pi i k&#x2F;16} $$，即新的单位根是16次单位根$$ \mu_j &#x3D; e^{2\pi i j&#x2F;16} $$（$$ j&#x3D;0,1,\dots,15 $$）。</li>
</ul>
<hr>
<h4 id="3-递归计算子问题"><a href="#3-递归计算子问题" class="headerlink" title="3. 递归计算子问题"></a><strong>3. 递归计算子问题</strong></h4><p>对偶次项$$ E(z) $$和奇次项$$ O(z) $$递归应用FFT：</p>
<ol>
<li><strong>输入规模</strong>：32次单位根 → 分解为两个16次单位根的问题。</li>
<li><strong>递归调用</strong>：<ul>
<li>计算$$ E(\mu_0), E(\mu_1), \dots, E(\mu_{15}) $$。</li>
<li>计算$$ O(\mu_0), O(\mu_1), \dots, O(\mu_{15}) $$。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="4-合并结果"><a href="#4-合并结果" class="headerlink" title="4. 合并结果"></a><strong>4. 合并结果</strong></h4><p>利用对称性$$ \omega_{k+16} &#x3D; -\omega_k $$合并结果：</p>
<ul>
<li>对前16个点$$ k&#x3D;0,1,\dots,15 $$：<br>$$p(\omega_k) &#x3D; E(\mu_k) + \omega_k \cdot O(\mu_k).$$</li>
<li>对后16个点$$ k&#x3D;16,17,\dots,31 $$：<br>$$p(\omega_{k}) &#x3D; E(\mu_{k-16}) - \omega_{k-16} \cdot O(\mu_{k-16}).$$</li>
</ul>
<hr>
<h4 id="5-具体数值示例"><a href="#5-具体数值示例" class="headerlink" title="5. 具体数值示例"></a><strong>5. 具体数值示例</strong></h4><p>假设计算$$ p(\omega_5) $$和$$ p(\omega_{21}) $$：</p>
<ul>
<li><strong>前一半点</strong>（$$ k&#x3D;5 $$）：<br>$$p(\omega_5) &#x3D; E(\mu_5) + \omega_5 \cdot O(\mu_5).$$</li>
<li><strong>后一半点</strong>（$$ k&#x3D;21 $$，即$$ k’&#x3D;21-16&#x3D;5 $$）：<br>$$p(\omega_{21}) &#x3D; E(\mu_5) - \omega_5 \cdot O(\mu_5).$$<br>只需计算一次$$ E(\mu_5) $$和$$ O(\mu_5) $$，即可得到两个结果。</li>
</ul>
<hr>
<h4 id="6-递归深度与复杂度"><a href="#6-递归深度与复杂度" class="headerlink" title="6. 递归深度与复杂度"></a><strong>6. 递归深度与复杂度</strong></h4><ul>
<li><strong>总递归深度</strong>：$$ \log_2 32 &#x3D; 5 $$层。</li>
<li><strong>每层操作</strong>：<table>
<thead>
<tr>
<th>递归层</th>
<th>问题规模</th>
<th>操作量</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>32</td>
<td>32</td>
</tr>
<tr>
<td>1</td>
<td>16</td>
<td>32</td>
</tr>
<tr>
<td>2</td>
<td>8</td>
<td>32</td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>32</td>
</tr>
<tr>
<td>4</td>
<td>2</td>
<td>32</td>
</tr>
<tr>
<td>5</td>
<td>1</td>
<td>32</td>
</tr>
</tbody></table>
</li>
<li><strong>总操作量</strong>：$$ 32 \times 5 &#x3D; 160 $$，即$$ O(32 \log 32) $$。</li>
</ul>
<hr>
<h2 id="逆变换"><a href="#逆变换" class="headerlink" title="逆变换"></a>逆变换</h2><p>逆变换（插值）的核心思想是通过快速傅里叶逆变换（IFFT）从多项式的点值表示恢复系数表示。以下是逐步解释：</p>
<hr>
<h3 id="1-问题定义-1"><a href="#1-问题定义-1" class="headerlink" title="1. 问题定义"></a><strong>1. 问题定义</strong></h3><ul>
<li><strong>输入</strong>：在 <code>m+1</code> 次单位根 <code>𝑥₀, 𝑥₁, ..., 𝑥ₘ</code> 处的多项式值 <code>𝑝(𝑥₀), 𝑝(𝑥₁), ..., 𝑝(𝑥ₘ)</code>。</li>
<li><strong>输出</strong>：多项式系数 <code>𝑎₀, 𝑎₁, ..., 𝑎ₙ</code>（假设 <code>𝑛 = m</code>，即点数与系数数量一致）。</li>
</ul>
<hr>
<h3 id="2-单位根与DFT"><a href="#2-单位根与DFT" class="headerlink" title="2. 单位根与DFT"></a><strong>2. 单位根与DFT</strong></h3><ul>
<li><strong>单位根</strong>：<code>ω = e^(2πi/(n+1))</code> 是 <code>n+1</code> 次单位根，满足 <code>ω^(n+1) = 1</code>。</li>
<li><strong>DFT定义</strong>：将多项式 <code>𝑝(𝑥) = Σ𝑎ⱼ𝑥ʲ</code> 在单位根 <code>ω⁰, ω¹, ..., ωⁿ</code> 处求值：<br>$$𝑝(ω^l) &#x3D; \sum_{j&#x3D;0}^n 𝑎_j ω^{l j} \quad (l&#x3D;0,1,…,n).$$<br>DFT 将系数向量 <code>[𝑎₀, ..., 𝑎ₙ]</code> 转换为点值向量 <code>[𝑝(ω⁰), ..., 𝑝(ωⁿ)]</code>。</li>
</ul>
<hr>
<h3 id="3-𝑝-ω⁰-𝑝-ωⁿ-。"><a href="#3-𝑝-ω⁰-𝑝-ωⁿ-。" class="headerlink" title="**3.[𝑝(ω⁰), ..., 𝑝(ωⁿ)]。"></a>**3.<code>[𝑝(ω⁰), ..., 𝑝(ωⁿ)]</code>。</h3><hr>
<h3 id="3-逆DFT的数学形式"><a href="#3-逆DFT的数学形式" class="headerlink" title="3. 逆DFT的数学形式"></a><strong>3. 逆DFT的数学形式</strong></h3><p>逆DFT的目标是从点值恢复系数：<br>$$𝑎<em>l &#x3D; \frac{1}{n+1} \sum</em>{j&#x3D;0}^n 𝑝(ω^j) ω^{-l j} \quad (l&#x3D;0,1,…,n).$$<br><strong>关键观察</strong>：</p>
<ol>
<li><strong>ω替换为ω⁻¹</strong>：与DFT相比，指数项从 <code>ω^&#123;l j&#125;</code> 变为 <code>ω^&#123;-l j&#125;</code>。</li>
<li><strong>归一化因子</strong>：结果需乘以 <code>1/(n+1)</code>。</li>
</ol>
<hr>
<h3 id="4-逆DFT与DFT的关系"><a href="#4-逆DFT与DFT的关系" class="headerlink" title="4. 逆DFT与DFT的关系"></a><strong>4. 逆DFT与DFT的关系</strong></h3><ul>
<li><strong>矩阵视角</strong>：DFT矩阵 <code>F</code> 的元素为 <code>F[j,k] = ω^&#123;jk&#125;</code>，逆DFT矩阵为 <code>F⁻¹ = (1/(n+1)) F^†</code>，其中 <code>F^†</code> 是共轭转置矩阵。</li>
<li><strong>正交性</strong>：单位根的共轭 <code>ω^&#123;-1&#125;</code> 是 <code>ω</code> 的逆元，满足正交关系：<br>$$\sum_{k&#x3D;0}^n ω^{jk} ω^{-lk} &#x3D;<br>\begin{cases}<br>n+1 &amp; \text{if } j&#x3D;l, \<br>0 &amp; \text{otherwise}.<br>\end{cases}$$<br>归一化因子 <code>1/(n+1)</code> 保证逆变换正确性。</li>
</ul>
<hr>
<h3 id="5-逆FFT算法"><a href="#5-逆FFT算法" class="headerlink" title="5. 逆FFT算法"></a><strong>5. 逆FFT算法</strong></h3><p>逆FFT的步骤与FFT完全相同，只需做以下调整：</p>
<ol>
<li><strong>替换单位根</strong>：将FFT中的旋转因子 <code>ω</code> 替换为 <code>ω⁻¹</code>。</li>
<li><strong>归一化</strong>：最终结果乘以 <code>1/(n+1)</code>。</li>
</ol>
<p><strong>示例</strong>：递归逆FFT流程：</p>
<ul>
<li><strong>分治</strong>：将点值分为偶数和奇数部分。</li>
<li><strong>合并</strong>：用 <code>ω⁻¹</code> 计算蝴蝶操作：<br>$$\text{new}<em>\text{low} &#x3D; \frac{\text{even} + \text{odd} \cdot ω^{-k}}{2}, \quad \text{new}</em>\text{high} &#x3D; \frac{\text{even} - \text{odd} \cdot ω^{-k}}{2}.$$</li>
<li><strong>归一化</strong>：递归结束后，所有系数乘以 <code>1/(n+1)</code>。</li>
</ul>
<hr>
<h3 id="6-为什么需要归一化因子？"><a href="#6-为什么需要归一化因子？" class="headerlink" title="6. 为什么需要归一化因子？"></a><strong>6. 为什么需要归一化因子？</strong></h3><ul>
<li><strong>数学验证</strong>：假设 <code>𝑎ⱼ</code> 通过DFT得到点值 <code>𝑝(ω^l)</code>，则逆DFT公式代入后：<br>$$\frac{1}{n+1} \sum_{j&#x3D;0}^n \left( \sum_{k&#x3D;0}^n 𝑎<em>k ω^{j k} \right) ω^{-j l} &#x3D; \frac{1}{n+1} \sum</em>{k&#x3D;0}^n 𝑎<em>k \underbrace{\sum</em>{j&#x3D;0}^n ω^{j(k-l)}}_{&#x3D;0 \text{ if } k≠l}} &#x3D; 𝑎_l.$$<br>归一化因子抵消正交求和中的 <code>n+1</code> 项。</li>
</ul>
<hr>
<h3 id="7-总结-1"><a href="#7-总结-1" class="headerlink" title="7. 总结"></a><strong>7. 总结</strong></h3><ul>
<li><strong>逆FFT本质</strong>：是DFT的共轭版本，计算复杂度仍为 <code>O(n log n)</code>。</li>
<li><strong>步骤</strong>：<ol>
<li>对点值向量调用FFT，但使用 <code>ω⁻¹</code> 代替 <code>ω</code>。</li>
<li>结果全体乘以 <code>1/(n+1)</code>。</li>
</ol>
</li>
<li><strong>应用</strong>：高效实现多项式乘法（FFT→点乘→逆FFT）。</li>
</ul>
<p>逆矩阵的构造基于DFT矩阵的 <strong>酉性质（Unitary）</strong>，其核心推导如下：</p>
<hr>
<h3 id="1-DFT矩阵的定义"><a href="#1-DFT矩阵的定义" class="headerlink" title="1. DFT矩阵的定义"></a><strong>1. DFT矩阵的定义</strong></h3><p>设 <code>F</code> 是 <code>(n+1)×(n+1)</code> 的DFT矩阵，元素为：<br>$$F[j,k] &#x3D; ω^{jk} \quad \text{其中 } ω &#x3D; e^{2πi&#x2F;(n+1)}, , j,k&#x3D;0,1,…,n.$$<br>例如，当 <code>n=2</code> 时：<br>$$F &#x3D; \begin{bmatrix}<br>ω^{0·0} &amp; ω^{0·1} &amp; ω^{0·2} \<br>ω^{1·0} &amp; ω^{1·1} &amp; ω^{1·2} \<br>ω^{2·0} &amp; ω^{2·1} &amp; ω^{2·2}<br>\end{bmatrix}.$$</p>
<hr>
<h3 id="2-逆矩阵的猜想"><a href="#2-逆矩阵的猜想" class="headerlink" title="2. 逆矩阵的猜想"></a><strong>2. 逆矩阵的猜想</strong></h3><p>逆DFT矩阵的形式为：<br>$$F^{-1} &#x3D; \frac{1}{n+1} F^† \quad \text{（共轭转置矩阵除以 } n+1 \text{）},$$<br>其中 <code>F^†</code> 的元素是 <code>F</code> 的共轭转置，即：<br>$$F^†[j,k] &#x3D; \overline{F[k,j]} &#x3D; ω^{-jk}.$$</p>
<hr>
<h3 id="3-验证逆矩阵的正确性"><a href="#3-验证逆矩阵的正确性" class="headerlink" title="3. 验证逆矩阵的正确性"></a><strong>3. 验证逆矩阵的正确性</strong></h3><p>需证明：<br>$$F \cdot F^{-1} &#x3D; I \quad \text{即 } F \cdot \left( \frac{1}{n+1} F^† \right) &#x3D; I.$$<br>展开矩阵乘法，验证每个元素：</p>
<ul>
<li><p><strong>矩阵乘积的第 <code>(j,l)</code> 个元素</strong>：<br>$$\sum_{k&#x3D;0}^n F[j,k] \cdot F^{-1}[k,l] &#x3D; \frac{1}{n+1} \sum_{k&#x3D;0}^n ω^{jk} \cdot ω^{-lk}.$$</p>
</li>
<li><p><strong>分情况讨论</strong>：</p>
<ol>
<li><strong>当 <code>j = l</code></strong>：<br>$$\sum_{k&#x3D;0}^n ω^{jk} \cdot ω^{-jk} &#x3D; \sum_{k&#x3D;0}^n ω^{0} &#x3D; n+1 \implies \frac{n+1}{n+1} &#x3D; 1.$$</li>
<li><strong>当 <code>j ≠ l</code></strong>：<br>令 <code>d = j-l ≠ 0</code>，则求和为几何级数：<br>$$\sum_{k&#x3D;0}^n ω^{dk} &#x3D; \frac{1 - ω^{d(n+1)}}{1 - ω^d}.$$<br>由于 <code>ω^&#123;n+1&#125; = 1</code>，分子 <code>1 - ω^&#123;d(n+1)&#125; = 1 - 1 = 0</code>，故和为 <code>0</code>。</li>
</ol>
</li>
<li><p><strong>结论</strong>：<br>$$F \cdot F^{-1}[j,l] &#x3D; \begin{cases}<br>1 &amp; \text{if } j&#x3D;l, \<br>0 &amp; \text{otherwise}.<br>\end{cases}$$<br>因此，<code>F \cdot F^&#123;-1&#125; = I</code>。</p>
</li>
</ul>
<hr>
<h3 id="4-逆矩阵的显式表达"><a href="#4-逆矩阵的显式表达" class="headerlink" title="4. 逆矩阵的显式表达"></a><strong>4. 逆矩阵的显式表达</strong></h3><p>逆DFT矩阵的显式形式为：<br>$$F^{-1} &#x3D; \frac{1}{n+1}<br>\begin{bmatrix}<br>ω^{0·0} &amp; ω^{0·(-1)} &amp; \cdots &amp; ω^{0·(-n)} \<br>ω^{-1·0} &amp; ω^{-1·1} &amp; \cdots &amp; ω^{-1·n} \<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \<br>ω^{-n·0} &amp; ω^{-n·1} &amp; \cdots &amp; ω^{-n·n}<br>\end{bmatrix}.$$<br><strong>关键特性</strong>：</p>
<ul>
<li>元素为 <code>ω^&#123;-jk&#125;</code>（对应单位根的倒数）。</li>
<li>归一化因子 <code>1/(n+1)</code>。</li>
</ul>
<hr>
<h3 id="5-几何视角：正交基的归一化"><a href="#5-几何视角：正交基的归一化" class="headerlink" title="5. 几何视角：正交基的归一化"></a><strong>5. 几何视角：正交基的归一化</strong></h3><p>DFT矩阵的列向量是 <strong>正交基</strong>，但未归一化。内积的模长为 <code>n+1</code>，因此逆矩阵需补偿该模长：<br>$$\langle F[:,j], F[:,l] \rangle &#x3D; \sum_{k&#x3D;0}^n ω^{jk} \overline{ω^{lk}} &#x3D; \sum_{k&#x3D;0}^n ω^{(j-l)k} &#x3D;<br>\begin{cases}<br>n+1 &amp; j&#x3D;l, \<br>0 &amp; j≠l.<br>\end{cases}$$<br>归一化后，基向量满足标准正交性，从而保证逆矩阵的正确性。</p>
<hr>
<h3 id="6-总结-1"><a href="#6-总结-1" class="headerlink" title="6. 总结"></a><strong>6. 总结</strong></h3><ul>
<li><strong>逆矩阵构造</strong>：共轭转置 <code>F^†</code> 并缩放 <code>1/(n+1)</code>。</li>
<li><strong>验证方法</strong>：直接计算矩阵乘积，利用单位根的周期性求和。</li>
<li><strong>物理意义</strong>：将点值表示投影回正交基，通过归一化恢复系数。</li>
</ul>
<p>正交矩阵 保距离</p>
<p>酉矩阵 复空间保距离 保范数的变换</p>
<p>傅里叶变换是酉矩阵</p>
<h3 id="1-复数内积与共轭"><a href="#1-复数内积与共轭" class="headerlink" title="1. 复数内积与共轭"></a><strong>1. 复数内积与共轭</strong></h3><p>在复数域中，向量的 <strong>内积</strong> 定义为：<br>$$\langle \mathbf{u}, \mathbf{v} \rangle &#x3D; \sum_{k&#x3D;0}^n u_k \overline{v_k},$$<br>其中 $$\overline{v_k}$$ 是 $$v_k$$ 的共轭复数。<br><strong>为什么要取共轭？</strong><br>为了保持内积的模长非负性（即 $$\langle \mathbf{u}, \mathbf{u} \rangle \geq 0$$）。若直接相乘（不取共轭），复数项的虚部会导致结果不满足实数内积的性质。</p>
<p><strong>示例</strong>：<br>设 $$\mathbf{u} &#x3D; [1+i, 2]$$，$$\mathbf{v} &#x3D; [3, 4i]$$，则内积为：<br>$$(1+i)\overline{3} + 2\overline{4i} &#x3D; (1+i) \cdot 3 + 2 \cdot (-4i) &#x3D; 3+3i-8i &#x3D; 3-5i.$$<br>若直接相乘不取共轭，结果包含虚部，无法体现实数空间的正交性。</p>
<hr>
<h3 id="2-单位根的共轭与Hermitian转置"><a href="#2-单位根的共轭与Hermitian转置" class="headerlink" title="2. 单位根的共轭与Hermitian转置"></a><strong>2. 单位根的共轭与Hermitian转置</strong></h3><p><strong>单位根性质</strong>：<br>若 $$\omega &#x3D; e^{2πi&#x2F;(n+1)}$$，则其共轭为：<br>$$\overline{\omega} &#x3D; e^{-2πi&#x2F;(n+1)} &#x3D; \omega^{-1}.$$<br>因此，DFT矩阵的共轭转置（Hermitian转置）$$F^†$$ 的元素为：<br>$$F^†[j,k] &#x3D; \overline{F[k,j]} &#x3D; \omega^{-jk}.$$</p>
<hr>
<h3 id="3-几何级数求和的归零性"><a href="#3-几何级数求和的归零性" class="headerlink" title="3. 几何级数求和的归零性"></a><strong>3. 几何级数求和的归零性</strong></h3><p>当 $$j ≠ i$$ 时，求和 $$\sum_{k&#x3D;0}^n \omega^{(j-i)k}$$ 的结果为 <strong>0</strong>，原因如下：</p>
<ol>
<li><p><strong>几何级数公式</strong>：<br>对公比 $$r &#x3D; \omega^{d}$$（其中 $$d &#x3D; j-i ≠ 0$$），求和项数为 $$n+1$$：<br>$$\sum_{k&#x3D;0}^n r^k &#x3D; \frac{1 - r^{n+1}}{1 - r}.$$</p>
</li>
<li><p><strong>单位根周期性</strong>：<br>由于 $$\omega^{n+1} &#x3D; 1$$，分子变为：<br>$$1 - r^{n+1} &#x3D; 1 - (\omega^{d})^{n+1} &#x3D; 1 - (\omega^{n+1})^d &#x3D; 1 - 1^d &#x3D; 0.$$<br>因此，整个和为 $$0$$。</p>
</li>
</ol>
<p><strong>示例</strong>：<br>设 $$n&#x3D;2$$，$$\omega &#x3D; e^{2πi&#x2F;3}$$，计算 $$\sum_{k&#x3D;0}^2 \omega^{k}$$：<br>$$\omega^0 + \omega^1 + \omega^2 &#x3D; 1 + \omega + \omega^2 &#x3D; \frac{1 - \omega^{3}}{1 - \omega} &#x3D; \frac{1 - 1}{1 - \omega} &#x3D; 0.$$</p>
<hr>
<h3 id="4-矩阵乘积的验证"><a href="#4-矩阵乘积的验证" class="headerlink" title="4. 矩阵乘积的验证"></a><strong>4. 矩阵乘积的验证</strong></h3><p>设 DFT 矩阵为 $$F$$，其逆矩阵为 $$F^{-1} &#x3D; \frac{1}{n+1} F^†$$。验证 $$F \cdot F^{-1} &#x3D; I$$：</p>
<ol>
<li><p><strong>矩阵乘积元素</strong>：<br>第 $$(j,l)$$ 个元素为：<br>$$\frac{1}{n+1} \sum_{k&#x3D;0}^n \omega^{jk} \cdot \omega^{-lk} &#x3D; \frac{1}{n+1} \sum_{k&#x3D;0}^n \omega^{(j-l)k}.$$</p>
</li>
<li><p><strong>分情况讨论</strong>：</p>
<ul>
<li><strong>当 $$j &#x3D; l$$</strong>：<br>$$\sum_{k&#x3D;0}^n \omega^{0} &#x3D; n+1 \implies \frac{n+1}{n+1} &#x3D; 1$$.</li>
<li><strong>当 $$j ≠ l$$</strong>：<br>根据几何级数求和结果为 $$0$$，因此元素值为 $$0$$。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a><strong>5. 总结</strong></h3><ul>
<li><strong>内积的共轭</strong>：保证复数内积的正交性与模长非负性。</li>
<li><strong>逆矩阵构造</strong>：基于单位根的共轭性质和正交性，通过几何级数求和归零性验证。</li>
<li><strong>归一化因子</strong>：补偿DFT矩阵列向量的模长 $$n+1$$，确保归一化后乘积为单位矩阵。</li>
</ul>
<p>您联想到的可能是 <strong>群论中的正交性关系</strong> 或 <strong>有限域上的特征和</strong>，其核心思想与单位根的对称性密切相关。以下是具体解释：</p>
<hr>
<h3 id="1-群论视角：特征标正交性"><a href="#1-群论视角：特征标正交性" class="headerlink" title="1. 群论视角：特征标正交性"></a><strong>1. 群论视角：特征标正交性</strong></h3><p>在有限循环群 $$ \mathbb{Z}<em>{n+1} $$ 中，<strong>特征标（Character）</strong> 定义为群到复数的同态：<br>$$\chi_j(k) &#x3D; \omega^{jk} \quad \text{其中 } \omega &#x3D; e^{2πi&#x2F;(n+1)}.$$<br><strong>正交性定理</strong> 指出，不同特征标在群元素上的求和满足：<br>$$\sum</em>{k&#x3D;0}^n \chi_j(k) \overline{\chi_l(k)} &#x3D;<br>\begin{cases}<br>n+1 &amp; j&#x3D;l, \<br>0 &amp; j≠l.<br>\end{cases}$$<br>这正是矩阵乘积 $$ F \cdot F^† $$ 的对角化结果的数学基础。</p>
<hr>
<h3 id="2-数论中的高斯和（Gauss-Sum）"><a href="#2-数论中的高斯和（Gauss-Sum）" class="headerlink" title="2. 数论中的高斯和（Gauss Sum）"></a><strong>2. 数论中的高斯和（Gauss Sum）</strong></h3><p>高斯和是形如 $$ G(a) &#x3D; \sum_{k&#x3D;0}^{n} \omega^{a k^2} $$ 的求和，其性质与二次剩余相关。虽然形式上不同，但高斯和的归零性（如 $$ a ≠ 0 \mod n+1 $$ 时和为0）与单位根求和的归零性有相似之处。</p>
<hr>
<h3 id="3-分圆多项式（Cyclotomic-Polynomial）"><a href="#3-分圆多项式（Cyclotomic-Polynomial）" class="headerlink" title="3. 分圆多项式（Cyclotomic Polynomial）"></a><strong>3. 分圆多项式（Cyclotomic Polynomial）</strong></h3><p>分圆多项式 $$ \Phi_{n+1}(x) $$ 的根是 <strong>原始的</strong> $$ (n+1) $$-次单位根，满足：<br>$$\Phi_{n+1}(x) &#x3D; \prod_{\substack{1 \leq k \leq n+1 \ \gcd(k,n+1)&#x3D;1}} \left( x - \omega^k \right).$$<br>其系数对称性与单位根求和的周期性密切相关。</p>
<hr>
<h3 id="4-离散对数与指数映射"><a href="#4-离散对数与指数映射" class="headerlink" title="4. 离散对数与指数映射"></a><strong>4. 离散对数与指数映射</strong></h3><p>在乘法群 $$ \mathbb{Z}_p^* $$（$$ p $$ 为素数）中，离散对数问题涉及将元素表示为生成元的幂次，其指数运算与单位根的幂次结构相似。例如，若 $$ g $$ 是生成元，则 $$ g^k \mod p $$ 的周期性映射到单位根 $$ \omega^k $$ 的周期性。</p>
<hr>
<h3 id="5-具体示例验证"><a href="#5-具体示例验证" class="headerlink" title="5. 具体示例验证"></a><strong>5. 具体示例验证</strong></h3><p>设 $$ n&#x3D;3 $$，$$ \omega &#x3D; e^{2πi&#x2F;4} &#x3D; i $$，验证 $$ j&#x3D;1, l&#x3D;0 $$ 时的求和：<br>$$\sum_{k&#x3D;0}^3 \omega^{(1-0)k} &#x3D; \sum_{k&#x3D;0}^3 i^k &#x3D; i^0 + i^1 + i^2 + i^3 &#x3D; 1 + i -1 -i &#x3D; 0.$$<br>这正是正交性的直接体现。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>您联想到的可能是：</p>
<ol>
<li><strong>群特征标的正交性</strong>（抽象代数），</li>
<li><strong>高斯和的归零性</strong>（数论），</li>
<li><strong>分圆多项式的根对称性</strong>，</li>
<li><strong>离散对数的周期性结构</strong>。</li>
</ol>
<p>这些领域均以不同形式利用了单位根的对称性，而DFT的逆矩阵构造正是这些理论在信号处理中的具体应用。</p>
<p>要证明$$ n+1 $$次单位根$$ w_0, w_1, \dots, w_n $$的和为零，即：<br>$$w_0 + w_1 + \dots + w_n &#x3D; 0,$$<br>可以通过以下两种方法进行：</p>
<hr>
<h3 id="方法一：几何级数求和"><a href="#方法一：几何级数求和" class="headerlink" title="方法一：几何级数求和"></a><strong>方法一：几何级数求和</strong></h3><p>单位根可表示为：<br>$$w_k &#x3D; e^{\frac{2\pi i k}{n+1}} \quad (k &#x3D; 0, 1, \dots, n).$$<br>它们的和为：<br>$$S &#x3D; \sum_{k&#x3D;0}^n e^{\frac{2\pi i k}{n+1}}.$$<br>这是一个首项为$$ 1 $$、公比为$$ r &#x3D; e^{\frac{2\pi i}{n+1}} $$的几何级数。根据几何级数求和公式：<br>$$S &#x3D; \frac{1 - r^{n+1}}{1 - r}.$$<br>由于$$ r $$是$$ n+1 $$次单位根，满足$$ r^{n+1} &#x3D; 1 $$，因此分子为$$ 1 - 1 &#x3D; 0 $$，故：<br>$$S &#x3D; \frac{0}{1 - r} &#x3D; 0.$$<br>当$$ n \geq 1 $$时，公比$$ r \neq 1 $$，公式成立；当$$ n &#x3D; 0 $$时，唯一根为$$ 1 $$，和为$$ 1 $$，但题目隐含$$ n \geq 1 $$，因此结论成立。</p>
<hr>
<h3 id="方法二：多项式根与系数的关系"><a href="#方法二：多项式根与系数的关系" class="headerlink" title="方法二：多项式根与系数的关系"></a><strong>方法二：多项式根与系数的关系</strong></h3><p>$$ n+1 $$次单位根满足方程：<br>$$z^{n+1} - 1 &#x3D; 0.$$<br>将其因式分解为：<br>$$(z - w_0)(z - w_1)\cdots(z - w_n) &#x3D; z^{n+1} - (w_0 + w_1 + \dots + w_n)z^n + \dots + (-1)^{n+1}w_0w_1\cdots w_n.$$<br>与原多项式$$ z^{n+1} - 1 $$对比，$$ z^n $$项的系数在左边为$$ -(w_0 + w_1 + \dots + w_n) $$，而右边为$$ 0 $$，因此：<br>$$-(w_0 + w_1 + \dots + w_n) &#x3D; 0 \implies w_0 + w_1 + \dots + w_n &#x3D; 0.$$<br>此结论在$$ n \geq 1 $$时成立。</p>
<hr>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>当$$ n \geq 1 $$时，$$ n+1 $$次单位根的和为零。两种方法均表明：<br>$$\boxed{w_0 + w_1 + \dots + w_n &#x3D; 0}.$$</p>
<p>要证明对常数$$ d $$，$$ n+1 $$次单位根满足：<br>$$w^{0d} + w^{1d} + \dots + w^{nd} &#x3D; 0,$$<br>需分情况讨论，并用抽象代数中的循环群性质解释。</p>
<hr>
<h3 id="推导与证明"><a href="#推导与证明" class="headerlink" title="推导与证明"></a><strong>推导与证明</strong></h3><p>设$$ w $$为$$ n+1 $$次单位根的原根，即$$ w &#x3D; e^{\frac{2\pi i}{n+1}} $$，则所有单位根为$$ w^k \ (k &#x3D; 0, 1, \dots, n) $$ 。考虑和：<br>$$S &#x3D; \sum_{k&#x3D;0}^n w^{kd}.$$</p>
<h4 id="情况1：-d-是-n-1-的倍数"><a href="#情况1：-d-是-n-1-的倍数" class="headerlink" title="情况1：$$ d $$是$$ n+1 $$的倍数"></a><strong>情况1：$$ d $$是$$ n+1 $$的倍数</strong></h4><p>若$$ d &#x3D; m(n+1) $$，则$$ w^{kd} &#x3D; \left(w^{n+1}\right)^{km} &#x3D; 1^{km} &#x3D; 1 $$，故：<br>$$S &#x3D; \sum_{k&#x3D;0}^n 1 &#x3D; n+1 \neq 0.$$</p>
<h4 id="情况2：-d-不是-n-1-的倍数"><a href="#情况2：-d-不是-n-1-的倍数" class="headerlink" title="情况2：$$ d $$不是$$ n+1 $$的倍数"></a><strong>情况2：$$ d $$不是$$ n+1 $$的倍数</strong></h4><p>若$$ d $$与$$ n+1 $$不互质，令$$ g &#x3D; \gcd(d, n+1) $$，则$$ w^d $$生成的子群阶为$$ m &#x3D; \frac{n+1}{g} $$。此时：<br>$$S &#x3D; \sum_{k&#x3D;0}^n w^{kd} &#x3D; \sum_{k&#x3D;0}^n \left(w^d\right)^k.$$<br>这是一个首项为$$ 1 $$、公比$$ r &#x3D; w^d $$的几何级数。因$$ r^{n+1} &#x3D; w^{d(n+1)} &#x3D; \left(w^{n+1}\right)^d &#x3D; 1 $$，但$$ r \neq 1 $$（因$$ d $$不是$$ n+1 $$的倍数），故：<br>$$S &#x3D; \frac{1 - r^{n+1}}{1 - r} &#x3D; \frac{1 - 1}{1 - r} &#x3D; 0.$$</p>
<hr>
<h3 id="抽象代数解释"><a href="#抽象代数解释" class="headerlink" title="抽象代数解释"></a><strong>抽象代数解释</strong></h3><ol>
<li><p><strong>循环群结构</strong><br>$$ n+1 $$次单位根构成循环群$$ G \cong \mathbb{Z}&#x2F;(n+1)\mathbb{Z} $$，每个元素可表示为$$ w^k $$。</p>
</li>
<li><p><strong>自同态映射</strong><br>映射$$ \phi: G \to G $$，定义为$$ \phi(w^k) &#x3D; w^{kd} $$，是群自同态：</p>
<ul>
<li>若$$ \gcd(d, n+1) &#x3D; 1 $$，$$ \phi $$是自同构（双射），故像集仍为$$ G $$，和$$ \sum_{g \in G} g &#x3D; 0 $$。</li>
<li>若$$ \gcd(d, n+1) &#x3D; g &gt; 1 $$，像集为子群$$ H \subset G $$，阶为$$ m &#x3D; \frac{n+1}{g} $$。每个元素$$ h \in H $$被恰 好$$ g $$个原像击中，故：<br>$$S &#x3D; g \sum_{h \in H} h &#x3D; 0 \quad (\text{当 } m &gt; 1 \text{ 时，子群和仍为0}).$$</li>
</ul>
</li>
<li><p><strong>结论</strong></p>
<ul>
<li>当$$ d \not\equiv 0 \mod (n+1) $$时，$$ S &#x3D; 0 $$。</li>
<li>当$$ d \equiv 0 \mod (n+1) $$时，$$ S &#x3D; n+1 $$。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="最终结论"><a href="#最终结论" class="headerlink" title="最终结论"></a><strong>最终结论</strong></h3><p>$$\boxed{w^{0d} + w^{1d} + \dots + w^{nd} &#x3D; 0} \quad \text{当且仅当 } d \not\equiv 0 \mod (n+1).$$<br>此结果体现了循环群中元素幂的对称性与子群结构对和的影响。</p>
<p>您提供的这段内容涉及离散傅里叶变换（DFT）的核心思想、公式推导及其数学性质。我将逐步拆解并详细解释其中的关键点。</p>
<hr>
<h3 id="一、离散傅里叶变换（DFT）的基本思想"><a href="#一、离散傅里叶变换（DFT）的基本思想" class="headerlink" title="一、离散傅里叶变换（DFT）的基本思想"></a>一、离散傅里叶变换（DFT）的基本思想</h3><p>离散傅里叶变换的目标是：<strong>将一组离散信号 $${y_j}$$ 分解为不同频率的复指数函数（或正弦&#x2F;余弦函数）的线性组合</strong>。其形式为：<br>$$y_j \approx \sum_{k&#x3D;0}^{2m-1} c_k e^{i k x_j}$$<br>其中：</p>
<ul>
<li>$$x_j &#x3D; \frac{\pi j}{m}$$（等间距采样点）</li>
<li>$$c_k$$ 是复系数，对应频率为 $$k$$ 的分量。</li>
</ul>
<hr>
<h3 id="二、逆变换与系数的计算"><a href="#二、逆变换与系数的计算" class="headerlink" title="二、逆变换与系数的计算"></a>二、逆变换与系数的计算</h3><p><strong>逆变换公式</strong>给出了如何从信号 $${y_j}$$ 计算系数 $${c_k}$$：<br>$$c_k &#x3D; \frac{1}{m} \sum_{j&#x3D;0}^{2m-1} y_j e^{-i k x_j}$$<br>这一步利用了复指数函数的正交性（后文详述），通过内积运算提取每个频率分量的系数。</p>
<hr>
<h3 id="三、欧拉公式与实虚部分解"><a href="#三、欧拉公式与实虚部分解" class="headerlink" title="三、欧拉公式与实虚部分解"></a>三、欧拉公式与实虚部分解</h3><p>通过欧拉公式 $$e^{i\theta} &#x3D; \cos\theta + i\sin\theta$$，可将复系数 $$c_k$$ 分解为<strong>实数正弦&#x2F;余弦系数</strong>：<br>$$c_k &#x3D; a_k + i b_k$$<br>代入DFT表达式后，展开为：<br>$$y_j &#x3D; \sum_{k&#x3D;0}^{2m-1} (a_k + i b_k) \left( \cos(k x_j) + i \sin(k x_j) \right)$$<br>整理实部和虚部后，信号可表示为实数形式的三角级数：<br>$$y_j &#x3D; \sum_{k&#x3D;0}^{m} \left[ A_k \cos(k x_j) + B_k \sin(k x_j) \right]$$<br>其中 $$A_k, B_k$$ 是实数系数，与 $$a_k, b_k$$ 相关。</p>
<hr>
<h3 id="四、三角函数的正交性"><a href="#四、三角函数的正交性" class="headerlink" title="四、三角函数的正交性"></a>四、三角函数的正交性</h3><p><strong>正交性</strong>是DFT的核心数学基础。在离散情况下，不同频率的正弦&#x2F;余弦函数满足：<br>$$\sum_{j&#x3D;0}^{2m-1} \cos(k x_j) \cos(l x_j) &#x3D;<br>\begin{cases}<br>m, &amp; k&#x3D;l \text{ 或 } k&#x3D;2m-l \<br>0, &amp; \text{其他}<br>\end{cases}$$<br>类似地，正弦函数之间以及正余弦交叉项的正交性使得：</p>
<ul>
<li>不同频率的分量在求和时相互抵消。</li>
<li>相同频率的分量求和后归一化得到系数。</li>
</ul>
<p>这使得计算 $$c_k$$ 时，只需将信号 $$y_j$$ 与对应频率的复指数函数做内积。</p>
<hr>
<h3 id="五、傅里叶变换的Unitary性质"><a href="#五、傅里叶变换的Unitary性质" class="headerlink" title="五、傅里叶变换的Unitary性质"></a>五、傅里叶变换的Unitary性质</h3><p>DFT的矩阵形式是一个<strong>酉矩阵（Unitary Matrix）</strong>，即：<br>$$U^* U^T &#x3D; I$$<br>其中矩阵 $$U$$ 的元素为 $$U_{jk} &#x3D; \frac{1}{\sqrt{m}} e^{-i k x_j}$$。酉矩阵的性质保证了：</p>
<ol>
<li><strong>能量守恒</strong>：信号在时域和频域的能量相等（Parseval定理）。</li>
<li><strong>可逆性</strong>：逆变换是酉矩阵的共轭转置，即 $$U^{-1} &#x3D; U^*$$。</li>
</ol>
<hr>
<h3 id="六、实例推导：从复系数到实数系数"><a href="#六、实例推导：从复系数到实数系数" class="headerlink" title="六、实例推导：从复系数到实数系数"></a>六、实例推导：从复系数到实数系数</h3><p>假设信号 $$y_j$$ 是实数，则复系数满足共轭对称性 $$c_k &#x3D; c_{2m-k}^<em>$$。将其代入DFT表达式：<br>$$y_j &#x3D; \sum_{k&#x3D;0}^{2m-1} c_k e^{i k x_j} &#x3D; c_0 + \sum_{k&#x3D;1}^{m} \left[ c_k e^{i k x_j} + c_{2m-k} e^{-i k x_j} \right]$$<br>利用共轭对称性 $$c_{2m-k} &#x3D; c_k^</em>$$，可简化为：<br>$$y_j &#x3D; c_0 + 2 \sum_{k&#x3D;1}^{m} \left[ \text{Re}(c_k) \cos(k x_j) - \text{Im}(c_k) \sin(k x_j) \right]$$<br>从而得到实数形式的傅里叶级数。</p>
<hr>
<h3 id="七、总结"><a href="#七、总结" class="headerlink" title="七、总结"></a>七、总结</h3><ol>
<li><strong>DFT本质</strong>：将信号投影到正交的复指数基函数上。</li>
<li><strong>系数计算</strong>：通过内积（求和）提取每个基函数的权重。</li>
<li><strong>正交性与酉性</strong>：保证计算的简洁性和可逆性。</li>
<li><strong>实数信号</strong>：复系数具有对称性，最终可表示为正弦&#x2F;余弦组合。</li>
</ol>
<p>通过以上步骤，离散傅里叶变换将复杂的信号分解为简单频率分量的叠加，为信号处理提供了强大的数学工具。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/LP%E5%AE%9A%E7%82%B9%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes.github.io/images/woshicaigou.jpg">
      <meta itemprop="name" content="Chen Zhan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cz Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/notes.github.io/2025/06/23/LP%E5%AE%9A%E7%82%B9%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">LP定点笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-23 18:56:58" itemprop="dateCreated datePublished" datetime="2025-06-23T18:56:58+08:00">2025-06-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="边角（corner）、极值点（extreme-point）和基本解（basic-solution）："><a href="#边角（corner）、极值点（extreme-point）和基本解（basic-solution）：" class="headerlink" title="边角（corner）、极值点（extreme point）和基本解（basic solution）："></a><strong>边角（corner）</strong>、<strong>极值点（extreme point）<strong>和</strong>基本解（basic solution）</strong>：</h2><hr>
<h3 id="1-边角（Corner）"><a href="#1-边角（Corner）" class="headerlink" title="1. 边角（Corner）"></a>1. <strong>边角（Corner）</strong></h3><p><strong>定义</strong>：点$x$是集合$P$的边角，若不存在非零向量$y \neq 0$，使得$x + y \in P$且$x - y \in P$。<br><strong>几何意义</strong>：  </p>
<ul>
<li>边角是集合$P$的“尖锐”部分，无法在$x$的邻域内沿任何方向$y$同时向$x \pm y$移动而保持在$P$内。  </li>
<li>在凸集理论中，边角等价于<strong>极点（extreme point）</strong>，即不能表示为集合中其他两点严格凸组合的点。<br><strong>示例</strong>：  <ul>
<li>多边形的顶点是边角，因为无法沿任何方向移动同时保持在多边形内。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="2-极值点（Extreme-Point）"><a href="#2-极值点（Extreme-Point）" class="headerlink" title="2. 极值点（Extreme Point）"></a>2. <strong>极值点（Extreme Point）</strong></h3><p><strong>定义</strong>：点$x$是极值点，若存在目标方向$c$，使得$x$是优化问题$\max c^T x \ \text{s.t.} \ x \in P$的唯一最优解。<br><strong>性质</strong>：  </p>
<ul>
<li>极值点一定是边角，反之亦然（在凸集下）。  </li>
<li>在凸优化中，极值点对应可行域的顶点，是线性规划潜在的最优解候选。<br><strong>示例</strong>：  <ul>
<li>线性规划中，最优解通常出现在可行多面体的极值点（顶点）处。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-基本解（Basic-Solution）"><a href="#3-基本解（Basic-Solution）" class="headerlink" title="3. 基本解（Basic Solution）"></a>3. <strong>基本解（Basic Solution）</strong></h3><p><strong>定义</strong>：对于线性约束$Ax &#x3D; b$，设$x \in P$，记$A_&#x3D;$为$x$的紧致约束（即$A_i x &#x3D; b_i$的行）构成的子矩阵。若$A_&#x3D;$满秩（$\text{rank}(A_&#x3D;) &#x3D; n$），则$x$为基本解。<br><strong>关键点</strong>：  </p>
<ul>
<li><strong>紧致约束</strong>：在$x$处取等号的约束，几何上表示$x$位于这些约束对应的超平面上。  </li>
<li><strong>满秩条件</strong>：$A_&#x3D;$的列线性独立，确保$x$是唯一确定的（非退化解）。  </li>
<li><strong>与极值点的关系</strong>：在标准线性规划中，基本可行解对应可行多面体的顶点（极值点）。</li>
</ul>
<p><strong>求解方法</strong>：  </p>
<ol>
<li>从$A$中选取$n$个线性无关的行构成$A_&#x3D;$。  </li>
<li>解$A_&#x3D; x &#x3D; b_&#x3D;$得到$x$，其余变量设为0（非基变量）。</li>
</ol>
<h2 id="证明：在凸多面体-P-x-mid-Ax-leq-b-中，若-x-是边角（corner），则-x-是基本解（basic-solution）。"><a href="#证明：在凸多面体-P-x-mid-Ax-leq-b-中，若-x-是边角（corner），则-x-是基本解（basic-solution）。" class="headerlink" title="证明：在凸多面体 $$ P &#x3D; {x \mid Ax \leq b} $$ 中，若 $$ x $$ 是边角（corner），则 $$ x $$ 是基本解（basic solution）。"></a><strong>证明：在凸多面体 $$ P &#x3D; {x \mid Ax \leq b} $$ 中，若 $$ x $$ 是边角（corner），则 $$ x $$ 是基本解（basic solution）。</strong></h2><p>等价地，我们证明其逆否命题：</p>
<blockquote>
<p><strong>若 $$ x $$ 不是基本解（即 $$ \text{rank}(A_&#x3D;) &lt; n $$），则 $$ x $$ 不是边角。</strong></p>
</blockquote>
<hr>
<h3 id="证明过程"><a href="#证明过程" class="headerlink" title="证明过程"></a><strong>证明过程</strong></h3><ol>
<li><p><strong>设定与假设</strong>：</p>
<ul>
<li>设 $$ x \in P $$，且 $$ A_&#x3D; $$ 是 $$ x $$ 的紧致约束（即 $$ A_i x &#x3D; b_i $$ 的行构成的子矩阵）。</li>
<li>假设 $$ \text{rank}(A_&#x3D;) &lt; n $$，即 $$ A_&#x3D; $$ 的行不满秩（列线性相关）。</li>
<li>由线性代数，存在非零向量 $$ y \neq 0 $$，使得 $$ A_&#x3D; y &#x3D; 0 $$。</li>
</ul>
</li>
<li><p><strong>构造扰动点 $$ x \pm \epsilon y $$</strong>：</p>
<ul>
<li>对于紧致约束 $$ A_&#x3D; $$，有：<br>$$A_&#x3D; (x \pm \epsilon y) &#x3D; A_&#x3D; x \pm \epsilon A_&#x3D; y &#x3D; b_&#x3D; \pm 0 &#x3D; b_&#x3D;,$$<br>因此 $$ x \pm \epsilon y $$ 仍然满足紧致约束。</li>
<li>对于非紧致约束 $$ A_j x &lt; b_j $$，由于 $$ x $$ 严格满足不等式，且 $$ y $$ 是固定向量，存在足够小的 $$ \epsilon &gt; 0 $$，使得：<br>$$A_j (x \pm \epsilon y) \leq b_j.$$<br>（因为 $$ A_j x &lt; b_j $$，而 $$ \epsilon $$ 足够小时，扰动不会违反不等式。）</li>
</ul>
</li>
<li><p><strong>验证 $$ x \pm \epsilon y \in P $$</strong>：</p>
<ul>
<li>由上述分析，$$ x \pm \epsilon y $$ 满足所有约束 $$ Ax \leq b $$，因此 $$ x \pm \epsilon y \in P $$。</li>
</ul>
</li>
<li><p><strong>说明 $$ x $$ 不是边角</strong>：</p>
<ul>
<li>我们找到了 $$ y \neq 0 $$，使得 $$ x + \epsilon y \in P $$ 且 $$ x - \epsilon y \in P $$。</li>
<li>根据边角的定义，$$ x $$ 不是边角。</li>
</ul>
</li>
</ol>
<h3 id="证明：在凸多面体-P-x-mid-Ax-leq-b-中，若-x-是基本解（basic-solution），则-x-是边角（corner）。"><a href="#证明：在凸多面体-P-x-mid-Ax-leq-b-中，若-x-是基本解（basic-solution），则-x-是边角（corner）。" class="headerlink" title="证明：在凸多面体 $$ P &#x3D; {x \mid Ax \leq b} $$ 中，若 $$ x $$ 是基本解（basic solution），则 $$ x $$ 是边角（corner）。"></a><strong>证明：在凸多面体 $$ P &#x3D; {x \mid Ax \leq b} $$ 中，若 $$ x $$ 是基本解（basic solution），则 $$ x $$ 是边角（corner）。</strong></h3><p>等价地，我们证明其逆否命题：</p>
<blockquote>
<p><strong>若 $$ x $$ 不是边角（即存在 $$ y \neq 0 $$ 使得 $$ x \pm y \in P $$），则 $$ x $$ 不是基本解（即 $$ \text{rank}(A_&#x3D;) &lt; n $$）。</strong></p>
</blockquote>
<hr>
<h3 id="证明过程-1"><a href="#证明过程-1" class="headerlink" title="证明过程"></a><strong>证明过程</strong></h3><ol>
<li><p><strong>设定与假设</strong>：</p>
<ul>
<li>设 $$ x \in P $$，且 $$ A_&#x3D; $$ 是 $$ x $$ 的紧致约束（即 $$ A_i x &#x3D; b_i $$ 的行构成的子矩阵）。</li>
<li>假设 $$ x $$ 不是边角，即存在 $$ y \neq 0 $$，使得 $$ x + y \in P $$ 且 $$ x - y \in P $$。</li>
</ul>
</li>
<li><p><strong>分析紧致约束 $$ A_&#x3D; $$ 的作用</strong>：</p>
<ul>
<li>由于 $$ x \pm y \in P $$，且 $$ A_&#x3D; x &#x3D; b_&#x3D; $$，我们有：<br>$$A_&#x3D; (x + y) \leq b_&#x3D; \quad \Rightarrow \quad A_&#x3D; x + A_&#x3D; y \leq b_&#x3D; \quad \Rightarrow \quad A_&#x3D; y \leq 0,$$<br>$$A_&#x3D; (x - y) \leq b_&#x3D; \quad \Rightarrow \quad A_&#x3D; x - A_&#x3D; y \leq b_&#x3D; \quad \Rightarrow \quad -A_&#x3D; y \leq 0.$$</li>
<li>结合 $$ A_&#x3D; y \leq 0 $$ 和 $$ -A_&#x3D; y \leq 0 $$，可得：<br>$$A_&#x3D; y &#x3D; 0.$$</li>
<li>因此，$$ y $$ 是 $$ A_&#x3D; $$ 的零空间中的非零向量（因为 $$ y \neq 0 $$）。</li>
</ul>
</li>
<li><p><strong>说明 $$ A_&#x3D; $$ 不满秩</strong>：</p>
<ul>
<li>存在 $$ y \neq 0 $$ 使得 $$ A_&#x3D; y &#x3D; 0 $$，说明 $$ A_&#x3D; $$ 的列线性相关。</li>
<li>因此，$$ \text{rank}(A_&#x3D;) &lt; n $$，即 $$ x $$ 不是基本解。</li>
</ul>
</li>
</ol>
<h2 id="定理：考虑二分图完美匹配的线性规划"><a href="#定理：考虑二分图完美匹配的线性规划" class="headerlink" title="定理：考虑二分图完美匹配的线性规划"></a>定理：考虑二分图完美匹配的线性规划</h2><p>给定的线性规划（LP）是：</p>
<p>$$\text{maximize} \sum_{e \in E} c_e x_e$$<br>$$\text{subject to} \quad \sum_{e \in \delta(v)} x_e &#x3D; 1 \quad \forall v \in V$$<br>$$0 \leq x_e \leq 1 \quad \forall e \in E$$</p>
<p>其中：</p>
<ul>
<li>$$ \delta(v) $$ 表示与顶点 $$ v $$ 相关联的所有边的集合。</li>
<li>$$ x_e $$ 可以看作是边 $$ e $$ 是否被选入匹配中的“程度”，理论上可以取 0 到 1 之间的任何实数。</li>
<li>约束 $$ \sum_{e \in \delta(v)} x_e &#x3D; 1 $$ 表示每个顶点恰好被“覆盖”一次（即完美匹配的要求）。</li>
</ul>
<h2 id="最小生成树（MST）的线性规划（LP）表述"><a href="#最小生成树（MST）的线性规划（LP）表述" class="headerlink" title="最小生成树（MST）的线性规划（LP）表述"></a>最小生成树（MST）的线性规划（LP）表述</h2><p>最小生成树问题（Minimum Spanning Tree, MST）是图论中的一个经典问题，其目标是在一个连通无向图 $$ G &#x3D; (V, E) $$ 中找到一个边的子集 $$ T \subseteq E $$，使得 $$ T $$ 构成一棵树（即无环且连通），并且所有边的权重之和最小。这里我们讨论的是如何将MST问题表述为一个线性规划（LP），并解释其性质和求解方法。</p>
<h4 id="MST的LP表述"><a href="#MST的LP表述" class="headerlink" title="MST的LP表述"></a>MST的LP表述</h4><p>以下是MST问题的一个LP松弛：</p>
<p>$$\text{maximize} \sum_{e \in E} c_e x_e$$<br>$$\text{subject to} \quad \sum_{e \in E(S)} x_e \leq |S| - 1 \quad \forall S \subset V, S \neq \emptyset$$<br>$$\sum_{e \in E} x_e &#x3D; |V| - 1$$<br>$$0 \leq x_e \leq 1 \quad \forall e \in E$$</p>
<p>其中：</p>
<ul>
<li>$$ c_e $$ 是边 $$ e $$ 的权重（这里最大化是因为可以等价地将最小化问题转化为最大化负权重）。</li>
<li>$$ x_e $$ 表示边 $$ e $$ 是否被选入生成树（$$ x_e &#x3D; 1 $$）或不被选入（$$ x_e &#x3D; 0 $$）。</li>
<li>$$ E(S) $$ 是子集 $$ S $$ 的导出子图中的边集，即所有两端点都在 $$ S $$ 中的边。</li>
<li>约束 $$ \sum_{e \in E(S)} x_e \leq |S| - 1 $$ 称为<strong>子集消除约束（subtour elimination constraints）</strong>，确保任何顶点子集 $$ S $$ 的导出子图中选择的边不会形成环（即不会多于 $$ |S| - 1 $$ 条边，否则会形成环）。</li>
<li>约束 $$ \sum_{e \in E} x_e &#x3D; |V| - 1 $$ 确保选择的边数恰好是 $$ |V| - 1 $$（生成树的边数）。</li>
<li>$$ 0 \leq x_e \leq 1 $$ 是变量的边界约束。</li>
</ul>
<h3 id="弱对偶性定理的详细解释"><a href="#弱对偶性定理的详细解释" class="headerlink" title="弱对偶性定理的详细解释"></a>弱对偶性定理的详细解释</h3><p>弱对偶性（Weak Duality）是线性规划（Linear Programming, LP）中一个基本且重要的定理。它描述了原始问题（Primal Problem）和对偶问题（Dual Problem）的解之间的关系。具体来说，对于任何原始问题的可行解和对偶问题的可行解，原始问题的目标函数值不超过对偶问题的目标函数值。</p>
<h4 id="原始问题和对偶问题的标准形式"><a href="#原始问题和对偶问题的标准形式" class="headerlink" title="原始问题和对偶问题的标准形式"></a>原始问题和对偶问题的标准形式</h4><p>首先，我们需要明确原始问题和对偶问题的标准形式。通常，我们有以下定义：</p>
<ol>
<li><p><strong>原始问题（Primal Problem）</strong>：</p>
<ul>
<li>形式：最大化问题</li>
<li>目标函数：$$ \max , c^\top x $$</li>
<li>约束条件：<ul>
<li>$$ A x \leq b $$</li>
<li>$$ x \geq 0 $$</li>
</ul>
</li>
<li>其中：<ul>
<li>$$ c \in \mathbb{R}^n $$：目标函数的系数向量</li>
<li>$$ x \in \mathbb{R}^n $$：决策变量</li>
<li>$$ A \in \mathbb{R}^{m \times n} $$：约束矩阵</li>
<li>$$ b \in \mathbb{R}^m $$：约束条件的右端向量</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>对偶问题（Dual Problem）</strong>：</p>
<ul>
<li>形式：最小化问题</li>
<li>目标函数：$$ \min , b^\top y $$</li>
<li>约束条件：<ul>
<li>$$ A^\top y \geq c $$</li>
<li>$$ y \geq 0 $$</li>
</ul>
</li>
<li>其中：<ul>
<li>$$ y \in \mathbb{R}^m $$：对偶变量</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="弱对偶性定理的陈述"><a href="#弱对偶性定理的陈述" class="headerlink" title="弱对偶性定理的陈述"></a>弱对偶性定理的陈述</h4><p>弱对偶性定理指出：</p>
<p>对于原始问题的任何可行解 $$ x $$ 和对偶问题的任何可行解 $$ y $$，都有：<br>$$c^\top x \leq b^\top y$$</p>
<p>即，原始问题的目标函数值（最大化）不超过对偶问题的目标函数值（最小化）。</p>
<h4 id="证明过程-2"><a href="#证明过程-2" class="headerlink" title="证明过程"></a>证明过程</h4><p>让我们逐步证明这个定理。</p>
<ol>
<li><p><strong>原始问题的约束</strong>：</p>
<ul>
<li>$$ A x \leq b $$</li>
<li>因为 $$ y \geq 0 $$，我们可以两边左乘 $$ y^\top $$（因为 $$ y $$ 非负，不等号方向不变）：<br>$$y^\top A x \leq y^\top b$$<br>$$y^\top A x \leq b^\top y$$ （因为 $$ y^\top b &#x3D; b^\top y $$）</li>
</ul>
</li>
<li><p><strong>对偶问题的约束</strong>：</p>
<ul>
<li>$$ A^\top y \geq c $$</li>
<li>因为 $$ x \geq 0 $$，我们可以两边右乘 $$ x $$（因为 $$ x $$ 非负，不等号方向不变）：<br>$$(A^\top y)^\top x \geq c^\top x$$<br>$$y^\top A x \geq c^\top x$$ （因为 $$ (A^\top y)^\top &#x3D; y^\top A $$）</li>
</ul>
</li>
<li><p><strong>结合两个不等式</strong>：</p>
<ul>
<li>从对偶约束得到：$$ c^\top x \leq y^\top A x $$</li>
<li>从原始约束得到：$$ y^\top A x \leq b^\top y $$</li>
<li>因此：<br>$$c^\top x \leq y^\top A x \leq b^\top y$$<br>$$c^\top x \leq b^\top y$$</li>
</ul>
</li>
</ol>
<h4 id="直观理解"><a href="#直观理解" class="headerlink" title="直观理解"></a>直观理解</h4><ul>
<li>原始问题是最大化 $$ c^\top x $$，对偶问题是最小化 $$ b^\top y $$。</li>
<li>弱对偶性表明，任何原始可行解的目标值都不会超过任何对偶可行解的目标值。</li>
<li>这意味着对偶问题的目标值提供了一个原始问题目标值的上界，反之亦然。</li>
</ul>
<h2 id="最大流与最小割"><a href="#最大流与最小割" class="headerlink" title="最大流与最小割"></a>最大流与最小割</h2><hr>
<h2 id="1-原始问题-Primal-：最大流"><a href="#1-原始问题-Primal-：最大流" class="headerlink" title="1. 原始问题 (Primal)：最大流"></a>1. 原始问题 (Primal)：最大流</h2><h3 id="1-1-决策变量"><a href="#1-1-决策变量" class="headerlink" title="1.1 决策变量"></a>1.1 决策变量</h3><ul>
<li>对于每条有向边 $$e&#x3D;(u\to v)\in E$$，定义流量变量 $$f_e$$（也常写成 $$f_{uv}$$ 或者简写 $$f_e$$）。</li>
</ul>
<h3 id="1-2-目标函数"><a href="#1-2-目标函数" class="headerlink" title="1.2 目标函数"></a>1.2 目标函数</h3><ul>
<li>我们要从源点 $$s$$ 向汇点 $$t$$ 发送尽可能多的流：<br>$$\max; f_{ts}.$$<br>这里 $$f_{ts}$$ 可以理解为“从 $$s$$ 到 $$t$$ 的净流量”——在实际写法中通常是最大化<br>$$\sum_{e\in \delta^+(s)} f_e ;-; \sum_{e\in \delta^-(s)} f_e.$$</li>
</ul>
<h3 id="1-3-约束条件"><a href="#1-3-约束条件" class="headerlink" title="1.3 约束条件"></a>1.3 约束条件</h3><ol>
<li><p><strong>流量守恒（除了源点和汇点）</strong><br>对任意 $$v\in V$$ 都要满足<br>$$f\bigl(\delta^{\mathrm{in}}(v)\bigr);-; f\bigl(\delta^{\mathrm{out}}(v)\bigr);\le;0,$$<br>也就是对于中间节点 $$v$$，它的进入流不超过离开流，源点 $$s$$ 可以是“净输出”&gt;0，汇点 $$t$$ 可以是“净输入”&gt;0。</p>
</li>
<li><p><strong>容量上界</strong><br>对每条边 $$e\in E$$，<br>$$0 ;\le; f_e ;\le; 1.$$<br>（这里假设每条边的容量都是 1。）</p>
</li>
</ol>
<hr>
<h2 id="2-对偶问题-Dual-：最小割"><a href="#2-对偶问题-Dual-：最小割" class="headerlink" title="2. 对偶问题 (Dual)：最小割"></a>2. 对偶问题 (Dual)：最小割</h2><p>对上述最大流 LP 做对偶，就得到下面这个最小割的线性规划。</p>
<h3 id="2-1-对偶变量"><a href="#2-1-对偶变量" class="headerlink" title="2.1 对偶变量"></a>2.1 对偶变量</h3><ul>
<li>每条边 $$e&#x3D;(u\to v)$$ 对应一个非负变量 $$d_{uv}$$。<br>直观上，$$d_{uv}$$ 表示“是否把这条边切掉”（如果切掉，对偶解中通常取 1，否则取 0）。</li>
<li>每个顶点 $$v$$ 对应一个变量 $$y_v\ge0$$，可以看作是“点 $$v$$ 的潜在高度”或“归属子集 S&#x2F;T 的标记”。</li>
</ul>
<h3 id="2-2-对偶目标"><a href="#2-2-对偶目标" class="headerlink" title="2.2 对偶目标"></a>2.2 对偶目标</h3><p>  $$\min;\sum_{(u,v)\in E} d_{uv}.$$<br>  也就是要切掉尽量少的边，使得 $$s$$ 与 $$t$$ 分离。</p>
<h3 id="2-3-对偶约束"><a href="#2-3-对偶约束" class="headerlink" title="2.3 对偶约束"></a>2.3 对偶约束</h3><ol>
<li><p><strong>边上的松弛条件</strong><br>对每条边 $$(u\to v)\in E$$，要求<br>$$d_{uv};+;y_u;-;y_v;\ge;0.$$<br>合理的解释是：如果 $$u$$ 和 $$v$$ 在同一侧（$$y_u\approx y_v$$），则只要 $$d_{uv}&#x3D;0$$ 就能满足；但如果 $$u$$ 在 $$s$$ 侧而 $$v$$ 在 $$t$$ 侧，我们需要 $$d_{uv}\ge1$$ 才能保证“不打通”这条通道。</p>
</li>
<li><p><strong>源点与汇点分离</strong><br>$$y_s - y_t ;\ge; 1.$$<br>这保证了在“潜在高度”意义上，$$s$$ 必须明显高于 $$t$$，从而在路径上至少要经过一条被切掉的边。</p>
</li>
<li><p><strong>非负性</strong><br>$$y_v ;\ge;0,\quad d_{uv};\ge;0.$$</p>
</li>
</ol>
<hr>
<h2 id="3-从对偶到“最小割”的直观理解"><a href="#3-从对偶到“最小割”的直观理解" class="headerlink" title="3. 从对偶到“最小割”的直观理解"></a>3. 从对偶到“最小割”的直观理解</h2><ul>
<li><p>我们可以把所有顶点根据 $$y_v$$ 的大小分成两部分：</p>
<ul>
<li>$$S &#x3D; {v: y_v &gt; \alpha}$$</li>
<li>$$T &#x3D; V\setminus S$$</li>
</ul>
<p>通过适当选取阈值 $$\alpha$$（例如 $$\alpha &#x3D; 0.5,y_s + 0.5,y_t$$），可以使得 $$s\in S$$，$$t\in T$$ 并且对任何跨 $$S$$ 到 $$T$$ 的边 $$(u,v)$$，对应的对偶约束<br>$$d_{uv} + y_u - y_v \ge 0$$<br>要求 $$d_{uv} \ge y_v - y_u \ge 1$$。由于 $$d_{uv}\ge0$$，最优解中就会把每条跨割的边设为 $$d_{uv}&#x3D;1$$，而同侧的边可以取 $$d_{uv}&#x3D;0$$。  </p>
</li>
<li><p>因此对偶问题的最优值恰好等于“从 $$s$$ 到 $$t$$ 的最小割所需切掉的边数”——这就是经典的最小割容量。</p>
</li>
</ul>
<hr>
<h2 id="4-最大流-最小割"><a href="#4-最大流-最小割" class="headerlink" title="4. 最大流 &#x3D; 最小割"></a>4. 最大流 &#x3D; 最小割</h2><ul>
<li><p><strong>弱对偶</strong>（任何可行流值 ≤ 任何可行割容量）  </p>
</li>
<li><p><strong>强对偶</strong>（线性规划对偶性）保证最优流值 &#x3D; 最优割容量。  </p>
</li>
<li><p>于是得到著名的 <strong>最大流–最小割定理</strong>：</p>
<p>“在一个容量为整数（此处为 1）的网络中，最大流的值等于最小割的容量。”</p>
</li>
</ul>
<hr>
<h2 id="5-整数性"><a href="#5-整数性" class="headerlink" title="5. 整数性"></a>5. 整数性</h2><ul>
<li>由于这个线性规划的约束矩阵是<strong>完全整数</strong>（即 totally unimodular），原始 LP 和对偶 LP 在最优解时都会取到整数解。  </li>
<li>因此最大流问题可以得到整数流（每条边 $$f_e\in{0,1}$$），最小割也可以得到整数切割（每条边 $$d_{uv}\in{0,1}$$），完美对应。</li>
</ul>
<hr>
<p><strong>总结：</strong>  </p>
<ul>
<li>原始问题（Primal）是标准的最大流 LP。  </li>
<li>对偶问题（Dual）恰好对应最小割 LP。  </li>
<li>二者在最优时取相同的数值，且均有整数最优解，成就了最大流–最小割这一经典定理。</li>
</ul>
<h3 id="冯·诺依曼极小极大定理（Von-Neumann-Minimax-Theorem）的解释"><a href="#冯·诺依曼极小极大定理（Von-Neumann-Minimax-Theorem）的解释" class="headerlink" title="冯·诺依曼极小极大定理（Von Neumann Minimax Theorem）的解释"></a><strong>冯·诺依曼极小极大定理（Von Neumann Minimax Theorem）的解释</strong></h3><p>冯·诺依曼极小极大定理是博弈论中的一个核心定理，它描述了<strong>两人零和博弈（Two-player Zero-sum Game）<strong>中</strong>最优策略的存在性和均衡性</strong>。具体来说，它表明：</p>
<p>$$\max_{x \in \Delta_m} \min_{y \in \Delta_n} x^\top A y &#x3D; \min_{y \in \Delta_n} \max_{x \in \Delta_m} x^\top A y$$</p>
<p>其中：</p>
<ul>
<li>$$ A \in \mathbb{R}^{m \times n} $$ 是<strong>支付矩阵（Payoff Matrix）</strong>，表示行玩家（Player 1）的收益（列玩家的损失）。</li>
<li>$$ x \in \Delta_m $$ 是行玩家的混合策略（概率分布），$$ \Delta_m $$ 是 $$ m $$-维单纯形（即 $$ x_i \geq 0 $$, $$ \sum_{i&#x3D;1}^m x_i &#x3D; 1 $$）。</li>
<li>$$ y \in \Delta_n $$ 是列玩家的混合策略（概率分布），$$ \Delta_n $$ 是 $$ n $$-维单纯形（即 $$ y_j \geq 0 $$, $$ \sum_{j&#x3D;1}^n y_j &#x3D; 1 $$）。</li>
<li>$$ x^\top A y $$ 是<strong>期望收益</strong>（行玩家希望最大化，列玩家希望最小化）。</li>
</ul>
<hr>
<h2 id="1-定理的直观解释"><a href="#1-定理的直观解释" class="headerlink" title="1. 定理的直观解释"></a><strong>1. 定理的直观解释</strong></h2><h3 id="1-行玩家的视角（先选策略）"><a href="#1-行玩家的视角（先选策略）" class="headerlink" title="(1) 行玩家的视角（先选策略）"></a><strong>(1) 行玩家的视角（先选策略）</strong></h3><ul>
<li>行玩家希望<strong>最大化自己的最小收益</strong>（即“最坏情况下最好能得多少”）。</li>
<li>他选择一个策略 $$ x $$，然后列玩家会选择一个 $$ y $$ 使得 $$ x^\top A y $$ 最小（因为列玩家希望最小化行玩家的收益）。</li>
<li>因此，行玩家要解决：<br>$$\max_{x} \left( \min_{y} x^\top A y \right)$$</li>
</ul>
<h3 id="2-列玩家的视角（先选策略）"><a href="#2-列玩家的视角（先选策略）" class="headerlink" title="(2) 列玩家的视角（先选策略）"></a><strong>(2) 列玩家的视角（先选策略）</strong></h3><ul>
<li>列玩家希望<strong>最小化行玩家的最大收益</strong>（即“最好情况下最坏能损失多少”）。</li>
<li>他选择一个策略 $$ y $$，然后行玩家会选择一个 $$ x $$ 使得 $$ x^\top A y $$ 最大（因为行玩家希望最大化自己的收益）。</li>
<li>因此，列玩家要解决：<br>$$\min_{y} \left( \max_{x} x^\top A y \right)$$</li>
</ul>
<h3 id="3-定理的核心结论"><a href="#3-定理的核心结论" class="headerlink" title="(3) 定理的核心结论"></a><strong>(3) 定理的核心结论</strong></h3><p><strong>无论谁先选择策略，最终都会达到相同的均衡值</strong>：<br>$$\max_{x} \min_{y} x^\top A y &#x3D; \min_{y} \max_{x} x^\top A y &#x3D; v$$<br>这个共同的值 $$ v $$ 称为<strong>博弈的值（Value of the Game）</strong>，而对应的 $$ x^* $$ 和 $$ y^* $$ 称为<strong>纳什均衡策略（Nash Equilibrium Strategies）</strong>。</p>
<hr>
<h2 id="2-为什么这个定理成立？"><a href="#2-为什么这个定理成立？" class="headerlink" title="2. 为什么这个定理成立？"></a><strong>2. 为什么这个定理成立？</strong></h2><h3 id="1-从线性规划角度看"><a href="#1-从线性规划角度看" class="headerlink" title="(1) 从线性规划角度看"></a><strong>(1) 从线性规划角度看</strong></h3><p>极小极大定理可以看作是<strong>线性规划对偶性</strong>的一个特例：</p>
<ul>
<li>行玩家的优化问题可以写成：<br>$$\max_{x} \left( \min_{y} x^\top A y \right) &#x3D; \max_{x} \left( \min_{j} (A x)_j \right)$$<br>即行玩家希望最大化自己最差情况下的收益（因为列玩家会选择最不利的 $$ y $$）。</li>
<li>列玩家的优化问题可以写成：<br>$$\min_{y} \left( \max_{x} x^\top A y \right) &#x3D; \min_{y} \left( \max_{i} (A^\top y)_i \right)$$<br>即列玩家希望最小化行玩家最好情况下的收益（因为行玩家会选择最有利的 $$ x $$）。</li>
</ul>
<p>由于线性规划的对偶性，这两个问题的解是相同的。</p>
<h3 id="2-从博弈论角度看"><a href="#2-从博弈论角度看" class="headerlink" title="(2) 从博弈论角度看"></a><strong>(2) 从博弈论角度看</strong></h3><ul>
<li>在零和博弈中，<strong>行玩家的收益就是列玩家的损失</strong>，因此双方的目标完全对立。</li>
<li><strong>纳什均衡</strong>（Nash Equilibrium）在这种博弈中表现为：<ul>
<li>行玩家选择 $$ x^* $$，使得无论列玩家怎么选 $$ y $$，自己的收益至少是 $$ v $$。</li>
<li>列玩家选择 $$ y^* $$，使得无论行玩家怎么选 $$ x $$，行玩家的收益至多是 $$ v $$。</li>
</ul>
</li>
<li>因此，双方都无法通过单方面改变策略来获得更好的结果，达到均衡。</li>
</ul>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/MarkovNote/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes.github.io/images/woshicaigou.jpg">
      <meta itemprop="name" content="Chen Zhan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cz Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/notes.github.io/2025/06/23/MarkovNote/" class="post-title-link" itemprop="url">MarkovNote</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-23 18:56:58" itemprop="dateCreated datePublished" datetime="2025-06-23T18:56:58+08:00">2025-06-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="幂迭代的特例：随机游走与马尔可夫链"><a href="#幂迭代的特例：随机游走与马尔可夫链" class="headerlink" title="幂迭代的特例：随机游走与马尔可夫链"></a>幂迭代的特例：随机游走与马尔可夫链</h1><h3 id="1-马尔可夫链的基本概念"><a href="#1-马尔可夫链的基本概念" class="headerlink" title="1. 马尔可夫链的基本概念"></a>1. 马尔可夫链的基本概念</h3><p>**马尔可夫链（Markov Chain）**是一种随机过程，具有“无记忆性”或“马尔可夫性质”。这意味着未来状态的概率分布只依赖于当前状态，而与之前的历史状态无关。形式上，对于一个离散时间的马尔可夫链，满足：</p>
<p>$$P(X_{n+1} &#x3D; x | X_n &#x3D; x_n, X_{n-1} &#x3D; x_{n-1}, \dots, X_0 &#x3D; x_0) &#x3D; P(X_{n+1} &#x3D; x | X_n &#x3D; x_n)$$</p>
<p>对于有限的马尔可夫链，状态空间（所有可能的状态）是有限的，可以表示为 $$ S &#x3D; {s_1, s_2, \dots, s_n} $$。</p>
<h3 id="2-有向图与马尔可夫链的关系"><a href="#2-有向图与马尔可夫链的关系" class="headerlink" title="2. 有向图与马尔可夫链的关系"></a>2. 有向图与马尔可夫链的关系</h3><p>一个有限的马尔可夫链可以表示为一个<strong>有向图（directed graph）</strong>，其中：</p>
<ul>
<li><strong>顶点（Vertices）</strong>：代表马尔可夫链的状态。</li>
<li><strong>边（Edges）</strong>：如果从状态 $$ i $$ 到状态 $$ j $$ 的转移概率 $$ P_{ij} &gt; 0 $$，则存在一条从 $$ i $$ 到 $$ j $$ 的有向边。</li>
</ul>
<p>这个有向图称为马尔可夫链的<strong>状态转移图</strong>。</p>
<h3 id="3-强连通图的定义与性质"><a href="#3-强连通图的定义与性质" class="headerlink" title="3. 强连通图的定义与性质"></a>3. 强连通图的定义与性质</h3><p>**强连通图（Strongly Connected Graph）**是指：</p>
<ul>
<li>对于图中的任意两个顶点 $$ u $$ 和 $$ v $$，存在从 $$ u $$ 到 $$ v $$ 的路径，也存在从 $$ v $$ 到 $$ u $$ 的路径。</li>
</ul>
<p>换句话说，强连通图意味着图中的任何两个状态都是相互可达的。</p>
<h3 id="4-不可约马尔可夫链的含义与重要性"><a href="#4-不可约马尔可夫链的含义与重要性" class="headerlink" title="4. 不可约马尔可夫链的含义与重要性"></a>4. 不可约马尔可夫链的含义与重要性</h3><p>**不可约马尔可夫链（Irreducible Markov Chain）**的定义是：如果其对应的有向图是强连通的，则称该马尔可夫链是不可约的。</p>
<p><strong>解释</strong>：</p>
<ul>
<li><p><strong>不可约性</strong>意味着马尔可夫链的状态空间不能被分成两个或更多的不相交的子集，使得链一旦进入某个子集就永远无法离开。换句话说，从任何状态出发，都有到达任何其他状态的可能（可能在多步之后）。</p>
</li>
<li><p><strong>重要性</strong>：</p>
<ul>
<li>不可约性是马尔可夫链许多重要性质的基础。例如，不可约的有限马尔可夫链总是具有唯一的平稳分布。</li>
<li>它确保了链的“遍历性”（ergodicity），即在长期运行中，链会访问所有状态，且频率趋于稳定。</li>
</ul>
</li>
</ul>
<h2 id="对于一个不可约且非周期的马尔可夫链，我们证明存在足够大的常数-T-infty-，使得对任意状态-i-j-和所有时间-t-geq-T-，有-P-t-i-j-0-。以下是详细证明过程："><a href="#对于一个不可约且非周期的马尔可夫链，我们证明存在足够大的常数-T-infty-，使得对任意状态-i-j-和所有时间-t-geq-T-，有-P-t-i-j-0-。以下是详细证明过程：" class="headerlink" title="对于一个不可约且非周期的马尔可夫链，我们证明存在足够大的常数$$ T &lt; \infty $$，使得对任意状态$$ i, j $$和所有时间$$ t \geq T $$，有$$ P^t_{i,j} &gt; 0 $$。以下是详细证明过程："></a>对于一个不可约且非周期的马尔可夫链，我们证明存在足够大的常数$$ T &lt; \infty $$，使得对任意状态$$ i, j $$和所有时间$$ t \geq T $$，有$$ P^t_{i,j} &gt; 0 $$。以下是详细证明过程：</h2><hr>
<p><strong>定理</strong>：若一个马尔可夫链不可约且非周期，则存在常数$$ T &lt; \infty $$，使得对任意状态$$ i, j $$及所有时间$$ t \geq T $$，有$$ P^t_{i,j} &gt; 0 $$。</p>
<hr>
<p><strong>证明</strong>：</p>
<p><strong>步骤1：非周期性的应用——证明每个状态的自返回时间无上界</strong></p>
<p>设状态空间为有限集$$ \mathcal{S} $$，每个状态$$ i $$的周期定义为：<br>$$d(i) &#x3D; \gcd{ t \geq 1 \mid P^t_{i,i} &gt; 0 }.$$<br>由于链是非周期的，故对任意$$ i \in \mathcal{S} $$，有$$ d(i) &#x3D; 1 $$。令：<br>$$S_i &#x3D; { t \geq 1 \mid P^t_{i,i} &gt; 0 },$$<br>则$$ \gcd(S_i) &#x3D; 1 $$。根据数论中的<strong>Schur定理</strong>，若一组正整数的最大公约数为1，则存在整数$$ N_i $$，使得对所有$$ t \geq N_i $$，$$ t $$可表示为$$ S_i $$中元素的线性组合（系数为非负整数）。因此：<br>$$\forall t \geq N_i, \quad P^t_{i,i} &gt; 0.$$</p>
<p><strong>步骤2：统一自返回时间的下界</strong></p>
<p>由于状态空间有限，设$$ \mathcal{S} &#x3D; {1, 2, \dots, n} $$，取：<br>$$K &#x3D; \max{ N_1, N_2, \dots, N_n }.$$<br>则对所有$$ i \in \mathcal{S} $$和$$ t \geq K $$，均有：<br>$$P^t_{i,i} &gt; 0.$$</p>
<p><strong>步骤3：不可约性的应用——确定状态间转移步数</strong></p>
<p>由不可约性，对任意状态$$ i, j $$，存在正整数$$ m_{i,j} $$使得：<br>$$P^{m_{i,j}}<em>{i,j} &gt; 0.$$<br>定义：<br>$$M &#x3D; \max{ m</em>{i,j} \mid \forall i, j \in \mathcal{S} }.$$<br>由于状态空间有限，$$ M $$为有限值。</p>
<p><strong>步骤4：构造全局常数$$ T $$并验证结论</strong></p>
<p>令：<br>$$T &#x3D; K + M.$$<br>对任意$$ t \geq T $$，可分解$$ t $$为：<br>$$t &#x3D; m_{i,j} + s, \quad \text{其中} \ s &#x3D; t - m_{i,j} \geq T - M &#x3D; K.$$<br>根据<strong>Chapman-Kolmogorov方程</strong>：<br>$$P^t_{i,j} &#x3D; \sum_{k \in \mathcal{S}} P^{m_{i,j}}<em>{i,k} P^{s}</em>{k,j} \geq P^{m_{i,j}}<em>{i,j} \cdot P^{s}</em>{j,j}.$$<br>由于：</p>
<ol>
<li>$$ P^{m_{i,j}}_{i,j} &gt; 0 $$（不可约性），</li>
<li>$$ s \geq K \implies P^{s}_{j,j} &gt; 0 $$（步骤2），</li>
</ol>
<p>因此：<br>$$P^t_{i,j} \geq P^{m_{i,j}}<em>{i,j} \cdot P^{s}</em>{j,j} &gt; 0, \quad \forall t \geq T.$$</p>
<hr>
<p><strong>关键点总结</strong>：</p>
<ol>
<li><strong>非周期性</strong>通过Schur定理确保自返回时间覆盖所有充分大的整数。</li>
<li><strong>有限状态空间</strong>允许统一自返回时间下界$$ K $$和最大转移步数$$ M $$。</li>
<li><strong>不可约性</strong>保证任意状态间存在有限步转移路径，结合自返回正概率，导出全局正概率。</li>
</ol>
<hr>
<p><strong>注</strong>：若状态空间为无限，需额外论证$$ K $$和$$ M $$的存在性，但本证明默认有限状态空间。</p>
<hr>
<p><strong>马尔可夫链基本定理的直观解释与严格证明</strong></p>
<p>对于有限状态空间、不可约且非周期的马尔可夫链，其核心性质可总结如下：</p>
<hr>
<h3 id="1-存在唯一的稳态分布𝜋"><a href="#1-存在唯一的稳态分布𝜋" class="headerlink" title="1. 存在唯一的稳态分布𝜋"></a><strong>1. 存在唯一的稳态分布𝜋</strong></h3><ul>
<li><strong>不可约性</strong>：任意两状态可通过有限步转移到达，保证了链的连通性。</li>
<li><strong>非周期性</strong>：每个状态的自返回时间无周期限制，避免震荡。</li>
<li><strong>有限状态空间</strong>：结合上述两点，转移矩阵$$ P $$最终成为正则矩阵（存在$$ T $$使得$$ P^T $$所有元素正）。</li>
</ul>
<p><strong>严格结论</strong>：</p>
<ul>
<li>存在唯一平稳分布$$ \pi $$，满足$$ \pi P &#x3D; \pi $$。</li>
<li>稳态概率$$ \pi(i) $$等于状态$$ i $$的长期访问频率，即：<br>$$\pi(i) &#x3D; \frac{1}{h_i},$$<br>其中$$ h_i &#x3D; \mathbb{E}[\text{首次返回状态} , i , \text{的时间} , | , X_0 &#x3D; i] $$。</li>
</ul>
<hr>
<h3 id="2-收敛到稳态分布"><a href="#2-收敛到稳态分布" class="headerlink" title="2. 收敛到稳态分布"></a><strong>2. 收敛到稳态分布</strong></h3><p>无论初始分布$$ p_0 $$如何，随着时间$$ t \to \infty $$，分布$$ p_t &#x3D; p_0 P^t $$必然收敛到$$ \pi $$。</p>
<p><strong>直观理解</strong>：</p>
<ul>
<li>非周期性和不可约性使得链在足够长时间后“忘记”初始状态。</li>
<li>状态间的频繁转移导致分布趋于平衡。</li>
</ul>
<hr>
<h3 id="3-耦合论证（Coupling-Argument）"><a href="#3-耦合论证（Coupling-Argument）" class="headerlink" title="3. 耦合论证（Coupling Argument）"></a><strong>3. 耦合论证（Coupling Argument）</strong></h3><p>通过构造两个独立运行的马尔可夫链$$ X_t $$和$$ Y_t $$，证明它们最终会相遇并同步，从而严格推导收敛性。</p>
<p>以下是基于耦合论证（Coupling Argument）的马尔可夫链收敛性证明的完整严谨过程：</p>
<hr>
<h3 id="耦合论证的构造与证明步骤"><a href="#耦合论证的构造与证明步骤" class="headerlink" title="耦合论证的构造与证明步骤"></a><strong>耦合论证的构造与证明步骤</strong></h3><h4 id="1-基本假设与条件"><a href="#1-基本假设与条件" class="headerlink" title="1. 基本假设与条件"></a><strong>1. 基本假设与条件</strong></h4><p>设马尔可夫链满足以下条件：</p>
<ul>
<li><strong>不可约性</strong>（Irreducible）：任意两状态互通。</li>
<li><strong>非周期性</strong>（Aperiodic）：不存在固定周期循环。</li>
<li><strong>正常返性</strong>（Positive Recurrent）：所有状态的平均返回时间有限。</li>
</ul>
<h4 id="2-构造耦合马尔可夫链"><a href="#2-构造耦合马尔可夫链" class="headerlink" title="2. 构造耦合马尔可夫链"></a><strong>2. 构造耦合马尔可夫链</strong></h4><p>定义两个独立运行的马尔可夫链 $$ X_t $$ 和 $$ Y_t $$，其状态空间相同：</p>
<ul>
<li>$$ X_t $$：初始分布为任意概率分布 $$ \mu_0 $$。</li>
<li>$$ Y_t $$：初始分布为平稳分布 $$ \pi $$。</li>
</ul>
<p>构造联合马尔可夫链 $$ (X_t, Y_t) $$，其转移概率满足：</p>
<ul>
<li>当 $$ X_t \neq Y_t $$ 时，两链独立转移，即联合转移概率为 $$ P(X_{t+1}&#x3D;x’, Y_{t+1}&#x3D;y’) &#x3D; P(x, x’) \cdot P(y, y’) $$。</li>
<li>当 $$ X_t &#x3D; Y_t $$ 时，强制同步转移，即 $$ X_{t+1} &#x3D; Y_{t+1} $$。</li>
</ul>
<h4 id="3-定义相遇时间"><a href="#3-定义相遇时间" class="headerlink" title="3. 定义相遇时间"></a><strong>3. 定义相遇时间</strong></h4><p>设首次相遇时间为停时 $$ T &#x3D; \inf{ t \geq 0: X_t &#x3D; Y_t } $$。根据不可约性和正常返性，可证明 $$ T &lt; \infty $$ 几乎必然成立。</p>
<h4 id="4-同步后的行为一致性"><a href="#4-同步后的行为一致性" class="headerlink" title="4. 同步后的行为一致性"></a><strong>4. 同步后的行为一致性</strong></h4><p>当 $$ t \geq T $$ 时，由于同步机制，$$ X_t &#x3D; Y_t $$ 对所有后续时间成立。因此，两链在 $$ T $$ 后的演化完全一致。</p>
<h4 id="5-收敛性推导"><a href="#5-收敛性推导" class="headerlink" title="5. 收敛性推导"></a><strong>5. 收敛性推导</strong></h4><p>通过比较两链的分布差异：</p>
<ul>
<li>对任意时间 $$ t $$，有：<br>$$| \mu_t - \pi |_{\text{TV}} \leq 2P(T &gt; t),$$<br>其中 $$ \mu_t $$ 是 $$ X_t $$ 的分布，$$ \pi $$ 是 $$ Y_t $$ 的平稳分布。</li>
<li>由于 $$ T $$ 几乎必然有限，当 $$ t \to \infty $$ 时，$$ P(T &gt; t) \to 0 $$，故：<br>$$\lim_{t \to \infty} | \mu_t - \pi |_{\text{TV}} &#x3D; 0.$$</li>
</ul>
<h4 id="6-平稳分布的唯一性"><a href="#6-平稳分布的唯一性" class="headerlink" title="6. 平稳分布的唯一性"></a><strong>6. 平稳分布的唯一性</strong></h4><p>若存在另一平稳分布 $$ \pi’ $$，通过耦合 $$ Y_t $$（初始化为 $$ \pi’ $$）与 $$ X_t $$（初始化为 $$ \pi $$），可证 $$ \pi &#x3D; \pi’ $$，从而唯一性得证。</p>
<hr>
<h3 id="关键引理与数学工具"><a href="#关键引理与数学工具" class="headerlink" title="关键引理与数学工具"></a><strong>关键引理与数学工具</strong></h3><ol>
<li><strong>不可约性与正常返性</strong>：确保状态空间连通且所有状态可无限次访问。</li>
<li><strong>停时理论</strong>：通过 $$ T $$ 的有限性将收敛性问题转化为概率衰减问题。</li>
<li><strong>全变差距离（Total Variation Distance）</strong>：量化分布差异的上界。</li>
<li><strong>Perron-Frobenius定理</strong>：用于证明转移矩阵主特征值对应平稳分布的存在性（有限状态空间）。</li>
</ol>
<hr>
<h3 id="应用条件与反例"><a href="#应用条件与反例" class="headerlink" title="应用条件与反例"></a><strong>应用条件与反例</strong></h3><ul>
<li><strong>正则马尔可夫链</strong>：若转移矩阵 $$ P $$ 满足存在 $$ n $$ 使 $$ P^n $$ 无零元素，则收敛性成立。</li>
<li><strong>反例</strong>：周期性链（如 $$ P &#x3D; \begin{pmatrix}0 &amp; 1 \ 1 &amp; 0\end{pmatrix} $$）或可约链（如吸收态存在）不满足收敛条件。</li>
</ul>
<hr>
<h3 id="4-稳态分布与期望回归时间的关系"><a href="#4-稳态分布与期望回归时间的关系" class="headerlink" title="4. 稳态分布与期望回归时间的关系"></a><strong>4. 稳态分布与期望回归时间的关系</strong></h3><p><strong>直观解释</strong>：</p>
<ul>
<li><strong>期望回归时间$$ h_i $$</strong>：从状态$$ i $$出发，首次返回$$ i $$的平均时间。</li>
<li><strong>长期访问频率</strong>：在无限时间中，访问状态$$ i $$的频率为$$ 1&#x2F;h_i $$，故稳态概率$$ \pi(i) &#x3D; 1&#x2F;h_i $$。</li>
</ul>
<p><strong>严格推导</strong>（Kac引理）：</p>
<ul>
<li>对于不可约常返链，有：<br>$$\pi(i) &#x3D; \frac{1}{h_i}, \quad \text{其中} \quad h_i &#x3D; \mathbb{E}[T_i \mid X_0 &#x3D; i].$$</li>
<li><strong>证明思路</strong>：通过更新过程计算长期平均访问次数，利用强大数定律得到频率极限。</li>
</ul>
<hr>
<h3 id="5-唯一性的保证"><a href="#5-唯一性的保证" class="headerlink" title="5. 唯一性的保证"></a><strong>5. 唯一性的保证</strong></h3><p>若存在两个不同的平稳分布$$ \pi $$和$$ \pi’ $$，通过耦合论证：</p>
<ul>
<li>构造初始分布为$$ \pi $$和$$ \pi’ $$的两个链，它们最终必相遇并同步。</li>
<li>因此$$ \pi &#x3D; \pi’ $$，矛盾，唯一性得证。</li>
</ul>
<hr>
<p><strong>总结</strong>：</p>
<ul>
<li><strong>不可约性与非周期性</strong>确保链的遍历性，消除周期性震荡。</li>
<li><strong>耦合技术</strong>将直观的“相遇”转化为严格收敛性证明。</li>
<li><strong>期望回归时间</strong>量化了状态的访问频率，直接决定稳态分布。</li>
</ul>
<p>此框架不仅适用于有限状态链，还可推广到某些可数状态空间的情形，但需额外验证回归时间的有限性。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/noteCircut/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes.github.io/images/woshicaigou.jpg">
      <meta itemprop="name" content="Chen Zhan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cz Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/notes.github.io/2025/06/23/noteCircut/" class="post-title-link" itemprop="url">noteCircut</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-23 18:56:58" itemprop="dateCreated datePublished" datetime="2025-06-23T18:56:58+08:00">2025-06-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="电路网络中的电流与电压求解方法"><a href="#电路网络中的电流与电压求解方法" class="headerlink" title="电路网络中的电流与电压求解方法"></a><strong>电路网络中的电流与电压求解方法</strong></h3><p>给定一个电阻网络，每条边 $$ e $$ 的电阻为 $$ r_e $$（或电导率 $$ w_e &#x3D; 1&#x2F;r_e $$），假设从节点 $$ s $$ 注入 1A 电流，并从节点 $$ t $$ 流出，如何计算网络内部的电流分布和电压分布？  </p>
<p>更一般地，设 $$ b_v $$ 表示从外部流入节点 $$ v \in V $$ 的净电流：  </p>
<ul>
<li>$$ b_v &gt; 0 $$：电流<strong>注入</strong>节点 $$ v $$（如源节点 $$ s $$）  </li>
<li>$$ b_v &lt; 0 $$：电流<strong>流出</strong>节点 $$ v $$（如汇节点 $$ t $$）  </li>
<li>其他内部节点满足 $$ b_v &#x3D; 0 $$（基尔霍夫电流定律）</li>
</ul>
<hr>
<h3 id="1-电路定律"><a href="#1-电路定律" class="headerlink" title="1. 电路定律"></a><strong>1. 电路定律</strong></h3><h4 id="1-基尔霍夫电流定律（KCL）"><a href="#1-基尔霍夫电流定律（KCL）" class="headerlink" title="(1) 基尔霍夫电流定律（KCL）"></a><strong>(1) 基尔霍夫电流定律（KCL）</strong></h4><blockquote>
<p><strong>流入节点的电流 &#x3D; 流出节点的电流</strong><br>即，对任意节点 $$ v $$，所有相邻边的电流 $$ i_{vu} $$ 满足：<br>$$\sum_{u: (v,u) \in E} i_{vu} &#x3D; b_v \quad \forall v \in V$$<br>（$$ i_{vu} $$ 表示从 $$ v $$ 流向 $$ u $$ 的电流）</p>
</blockquote>
<h4 id="2-欧姆定律"><a href="#2-欧姆定律" class="headerlink" title="(2) 欧姆定律"></a><strong>(2) 欧姆定律</strong></h4><blockquote>
<p><strong>电压差 &#x3D; 电流 × 电阻</strong><br>即，对任意边 $$ (u,v) $$，有：<br>$$\phi(u) - \phi(v) &#x3D; i_{uv} \cdot r_{uv} \quad \Leftrightarrow \quad i_{uv} &#x3D; w_{uv} \cdot (\phi(u) - \phi(v))$$<br>（$$ \phi(v) $$ 表示节点 $$ v $$ 的电压，$$ w_{uv} &#x3D; 1&#x2F;r_{uv} $$ 是电导率）</p>
</blockquote>
<hr>
<h3 id="2-合并定律，建立方程"><a href="#2-合并定律，建立方程" class="headerlink" title="2. 合并定律，建立方程"></a><strong>2. 合并定律，建立方程</strong></h3><p>将欧姆定律代入基尔霍夫定律：<br>$$b_v &#x3D; \sum_{u: (v,u) \in E} i_{vu} &#x3D; \sum_{u: (v,u) \in E} w_{vu} (\phi(v) - \phi(u))$$<br>整理后得到：<br>$$b_v &#x3D; \text{deg}<em>w(v) \cdot \phi(v) - \sum</em>{u: (v,u) \in E} w_{vu} \phi(u)$$<br>其中：</p>
<ul>
<li>$$ \text{deg}<em>w(v) &#x3D; \sum</em>{u: (v,u) \in E} w_{vu} $$ 是节点 $$ v $$ 的<strong>加权度数</strong>（即所有邻边电导率之和）</li>
</ul>
<p>特别地，如果所有电导率 $$ w_{uv} &#x3D; 1 $$，则方程简化为：<br>$$b &#x3D; L \phi$$<br>其中 $$ L $$ 是图的<strong>拉普拉斯矩阵（Laplacian Matrix）</strong>：<br>$$L_{uv} &#x3D;<br>\begin{cases}<br>\text{deg}(v) &amp; \text{如果 } u &#x3D; v \<br>-1 &amp; \text{如果 } (u,v) \in E \<br>0 &amp; \text{否则}<br>\end{cases}$$</p>
<p>这就把电路方程和拉普拉斯矩阵建立了联系！</p>
<h3 id="电路网络方程的可解性与唯一性分析"><a href="#电路网络方程的可解性与唯一性分析" class="headerlink" title="电路网络方程的可解性与唯一性分析"></a><strong>电路网络方程的可解性与唯一性分析</strong></h3><h4 id="1-问题建模与矩阵表示"><a href="#1-问题建模与矩阵表示" class="headerlink" title="1. 问题建模与矩阵表示"></a><strong>1. 问题建模与矩阵表示</strong></h4><p>给定电阻网络 $$ G&#x3D;(V,E) $$，每条边 $$ e \in E $$ 的电导率为 $$ w_e &#x3D; 1&#x2F;r_e $$，定义以下矩阵：</p>
<ul>
<li><p><strong>关联矩阵（Incidence Matrix）$$ B $$</strong>：<br>$$ B \in \mathbb{R}^{|V| \times |E|} $$，每列对应一条边 $$ e &#x3D; (u,v) $$，其中 $$ B_{u,e} &#x3D; +1 $$，$$ B_{v,e} &#x3D; -1 $$，其余为 0。</p>
</li>
<li><p><strong>电导率对角阵 $$ W $$</strong>：<br>$$ W \in \mathbb{R}^{|E| \times |E|} $$，$$ W_{e,e} &#x3D; w_e $$。</p>
</li>
<li><p><strong>拉普拉斯矩阵 $$ L $$</strong>：<br>$$ L &#x3D; B W B^\top &#x3D; \sum_{e} w_e b_e b_e^\top $$，其中 $$ b_e $$ 是边 $$ e $$ 对应的关联矩阵列。</p>
</li>
<li><p><strong>为什么 $$L &#x3D; B W B^\top$$？</strong></p>
</li>
<li><p><strong>直观理解</strong>：<br>$$B$$ 提取电压差，$$W$$ 转为电流，$$B^\top$$ 将电流汇总到节点。  </p>
</li>
<li><p><strong>数学推导</strong>：<br>$$(B W B^\top \phi)<em>v &#x3D; \sum</em>{e} B_{v,e} w_e (B^\top \phi)<em>e &#x3D; \sum</em>{u} w_{vu} (\phi_v - \phi_u)$$<br>这正是节点 $$v$$ 的净流出电流。<br><strong>电流-电压关系</strong>：<br>$$i &#x3D; W B^\top \phi, \quad b &#x3D; L \phi &#x3D; B i$$<br>其中 $$ b $$ 是外部注入电流向量（$$ b_s &#x3D; 1 $$, $$ b_t &#x3D; -1 $$, 其余为 0），$$ \phi $$ 是节点电压向量。</p>
</li>
<li><p><strong>解释</strong>：  </p>
<ul>
<li>$$B^\top \phi$$ 计算每条边的电压差（$$\phi_u - \phi_v$$）。  </li>
<li>$$W$$ 乘以电压差，得到电流 $$i_e &#x3D; w_e (\phi_u - \phi_v)$$（欧姆定律）。</li>
</ul>
</li>
<li><p><strong>解释</strong>：  </p>
<ul>
<li>$$L \phi$$：计算每个节点的净流出电流（应等于外部注入 $$b$$）。  </li>
<li>$$B i$$：直接对边电流求和，验证节点电流守恒。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="2-方程的可解性"><a href="#2-方程的可解性" class="headerlink" title="2. 方程的可解性"></a><strong>2. 方程的可解性</strong></h4><p><strong>问题</strong>：方程 $$ b &#x3D; L \phi $$ 何时有解？<br><strong>结论</strong>：  </p>
<ul>
<li><strong>可解条件</strong>：$$ b $$ 必须满足 $$ \sum_{v \in V} b_v &#x3D; 0 $$（即净注入电流为零，符合物理守恒律）。  </li>
<li><strong>物理意义</strong>：电流从源节点 $$ s $$ 注入后必须全部从汇节点 $$ t $$ 流出，系统才能达到稳态。</li>
</ul>
<p><strong>数学证明</strong>：<br>拉普拉斯矩阵 $$ L $$ 的行和为零（因 $$ L \mathbf{1} &#x3D; 0 $$），故 $$ b $$ 必须正交于 $$ \mathbf{1} $$（即 $$ \mathbf{1}^\top b &#x3D; 0 $$）。</p>
<hr>
<h4 id="3-解的唯一性"><a href="#3-解的唯一性" class="headerlink" title="3. 解的唯一性"></a><strong>3. 解的唯一性</strong></h4><p><strong>问题</strong>：解 $$ \phi $$ 是否唯一？<br><strong>结论</strong>：  </p>
<ul>
<li><strong>解不唯一</strong>：若 $$ \phi $$ 是解，则 $$ \phi + c \mathbf{1} $$（$$ c $$ 为任意常数）也是解。  </li>
<li><strong>唯一性约束</strong>：需固定一个参考电压（如设 $$ \phi_t &#x3D; 0 $$），此时解唯一。</li>
</ul>
<p><strong>数学解释</strong>：<br>拉普拉斯矩阵 $$ L $$ 的秩为 $$ |V|-1 $$，核空间（null space）为 $$ \text{span}(\mathbf{1}) $$。因此，解仅在相差一个全局电压常数时唯一。</p>
<hr>
<h4 id="4-与图论问题的联系"><a href="#4-与图论问题的联系" class="headerlink" title="4. 与图论问题的联系"></a><strong>4. 与图论问题的联系</strong></h4><p><strong>随机游走</strong>：  </p>
<ul>
<li>电压 $$ \phi $$ 可解释为从节点 $$ s $$ 到 $$ t $$ 的逃逸概率（escape probability）。  </li>
<li>电导率 $$ w_e $$ 对应转移概率。</li>
</ul>
<p><strong>网络流</strong>：  </p>
<ul>
<li>电流 $$ i $$ 是满足流量守恒的最小能量流（欧姆定律等价于能量最小化）。</li>
</ul>
<p><strong>谱图理论</strong>：  </p>
<ul>
<li>拉普拉斯矩阵 $$ L $$ 的特征值反映了网络的连通性（如代数连通度 $$ \lambda_2 $$ 与 Cheeger 不等式相关）。</li>
</ul>
<hr>
<h3 id="拉普拉斯矩阵的秩与解的唯一性分析"><a href="#拉普拉斯矩阵的秩与解的唯一性分析" class="headerlink" title="拉普拉斯矩阵的秩与解的唯一性分析"></a><strong>拉普拉斯矩阵的秩与解的唯一性分析</strong></h3><h4 id="1-拉普拉斯矩阵的秩缺陷性"><a href="#1-拉普拉斯矩阵的秩缺陷性" class="headerlink" title="1. 拉普拉斯矩阵的秩缺陷性"></a><strong>1. 拉普拉斯矩阵的秩缺陷性</strong></h4><ul>
<li><p><strong>核心性质</strong>：<br>拉普拉斯矩阵 $$ L $$ <strong>不是满秩矩阵</strong>，因为 $$ L \mathbf{1} &#x3D; 0 $$（其中 $$\mathbf{1}$$ 是全1向量）。  </p>
<ul>
<li><strong>物理意义</strong>：全局电压平移（$$\phi \to \phi + c\mathbf{1}$$）不影响电流分布，符合电压的相对性。</li>
</ul>
</li>
<li><p><strong>零空间（Nullspace）</strong>：<br>若图是<strong>连通</strong>的，$$ L $$ 的零空间仅由 $$\text{span}(\mathbf{1})$$ 构成，即：<br>$$\text{null}(L) &#x3D; { c \mathbf{1} \mid c \in \mathbb{R} }$$</p>
</li>
</ul>
<h4 id="2-方程-L-phi-b-的解存在条件"><a href="#2-方程-L-phi-b-的解存在条件" class="headerlink" title="2. 方程 $$ L \phi &#x3D; b $$ 的解存在条件"></a><strong>2. 方程 $$ L \phi &#x3D; b $$ 的解存在条件</strong></h4><ul>
<li><p><strong>引理</strong>：若 $$ L \phi &#x3D; b $$ 有解，则必须满足 $$ b \perp \mathbf{1} $$（即 $$\sum_v b_v &#x3D; 0$$）。  </p>
<ul>
<li><strong>证明</strong>：<br>由于 $$ L \mathbf{1} &#x3D; 0 $$，对任意解 $$\phi$$，有：<br>$$\mathbf{1}^\top b &#x3D; \mathbf{1}^\top (L \phi) &#x3D; (L \mathbf{1})^\top \phi &#x3D; 0$$</li>
<li><strong>物理对应</strong>：外部注入电流的代数和为零（电流守恒）。</li>
</ul>
</li>
<li><p><strong>连通图的解结构</strong>：<br>若图连通且 $$ b \perp \mathbf{1} $$，则解存在且可表示为：<br>$$\phi &#x3D; \phi_0 + c \mathbf{1}, \quad c \in \mathbb{R}$$<br>其中 $$\phi_0$$ 是特解（如固定 $$\phi_t &#x3D; 0$$ 后唯一解）。</p>
</li>
</ul>
<h4 id="3-特征值视角的解释"><a href="#3-特征值视角的解释" class="headerlink" title="3. 特征值视角的解释"></a><strong>3. 特征值视角的解释</strong></h4><ul>
<li><strong>谱分解</strong>：<br>设 $$ L $$ 的特征值为 $$ 0 &#x3D; \lambda_1 &lt; \lambda_2 \leq \cdots \leq \lambda_n $$，对应正交特征向量 $$ \mathbf{1}, v_2, \dots, v_n $$。  <ul>
<li><strong>解的存在性</strong>：<br>将 $$ b $$ 投影到特征空间，若 $$ b $$ 不含 $$ \mathbf{1} $$ 分量（即 $$ b \perp \mathbf{1} $$），则解存在。  </li>
<li><strong>解的表达式</strong>：<br>$$\phi &#x3D; \sum_{i&#x3D;2}^n \frac{\langle b, v_i \rangle}{\lambda_i} v_i + c \mathbf{1}$$<br>（$$ \lambda_2 &gt; 0 $$ 保证连通图的可解性）</li>
</ul>
</li>
</ul>
<h4 id="4-物理意义与电路网络"><a href="#4-物理意义与电路网络" class="headerlink" title="4. 物理意义与电路网络"></a><strong>4. 物理意义与电路网络</strong></h4><ul>
<li><p><strong>电流平衡</strong>：<br>条件 $$ \sum_v b_v &#x3D; 0 $$ 对应电路中的<strong>基尔霍夫电流定律</strong>（KCL），即注入电流等于流出电流。  </p>
<ul>
<li><strong>示例</strong>：<br>若从节点 $$ s $$ 注入 $$ 1\text{A} $$，则必须有节点 $$ t $$ 流出 $$ 1\text{A} $$，其余 $$ b_v &#x3D; 0 $$。</li>
</ul>
</li>
<li><p><strong>电压唯一性</strong>：<br>通过固定参考电压（如接地 $$ \phi_t &#x3D; 0 $$），消除零空间自由度，得到唯一解。</p>
</li>
</ul>
<h3 id="拉普拉斯矩阵的伪逆与解的结构"><a href="#拉普拉斯矩阵的伪逆与解的结构" class="headerlink" title="拉普拉斯矩阵的伪逆与解的结构"></a><strong>拉普拉斯矩阵的伪逆与解的结构</strong></h3><h4 id="引理"><a href="#引理" class="headerlink" title="引理"></a><strong>引理</strong></h4><p>若 $$ b \perp \mathbf{1} $$，则存在向量 $$ \phi $$ 使得 $$ L \phi &#x3D; b $$。  </p>
<h4 id="证明"><a href="#证明" class="headerlink" title="证明"></a><strong>证明</strong></h4><ol>
<li><p><strong>谱分解</strong>：<br>由于 $$ L $$ 是对称半正定矩阵，可分解为：<br>$$L &#x3D; \sum_{i&#x3D;2}^n \lambda_i v_i v_i^\top$$<br>其中 $$ \lambda_1 &#x3D; 0 $$，对应特征向量 $$ v_1 &#x3D; \frac{1}{\sqrt{n}} \mathbf{1} $$，且 $$ \lambda_2, \dots, \lambda_n &gt; 0 $$（若图连通）。  </p>
</li>
<li><p><strong>条件 $$ b \perp \mathbf{1} $$</strong>：<br>由正交性，$$ b $$ 可表示为非零特征向量的线性组合：<br>$$b &#x3D; \sum_{i&#x3D;2}^n a_i v_i$$  </p>
</li>
<li><p><strong>构造解 $$ \phi $$</strong>：<br>取：<br>$$\phi &#x3D; \sum_{i&#x3D;2}^n \frac{a_i}{\lambda_i} v_i$$<br>验证：<br>$$L \phi &#x3D; \sum_{i&#x3D;2}^n \lambda_i v_i v_i^\top \left( \sum_{j&#x3D;2}^n \frac{a_j}{\lambda_j} v_j \right) &#x3D; \sum_{i&#x3D;2}^n a_i v_i &#x3D; b$$</p>
</li>
</ol>
<hr>
<h4 id="伪逆-L-dagger-的定义与性质"><a href="#伪逆-L-dagger-的定义与性质" class="headerlink" title="伪逆 $$ L^\dagger $$ 的定义与性质"></a><strong>伪逆 $$ L^\dagger $$ 的定义与性质</strong></h4><p>定义伪逆：<br>$$L^\dagger &#x3D; \sum_{i&#x3D;2}^n \frac{1}{\lambda_i} v_i v_i^\top$$  </p>
<p><strong>性质</strong>：  </p>
<ol>
<li><strong>唯一性</strong>：  <ul>
<li>对任意 $$ b \perp \mathbf{1} $$，$$ \phi &#x3D; L^\dagger b $$ 是唯一满足 $$ L \phi &#x3D; b $$ 且 $$ \phi \perp \mathbf{1} $$ 的解。</li>
</ul>
</li>
<li><strong>通解结构</strong>：  <ul>
<li>方程 $$ L \phi &#x3D; b $$ 的全体解为：<br>$$\phi &#x3D; L^\dagger b + c \mathbf{1}, \quad c \in \mathbb{R}$$</li>
</ul>
</li>
<li><strong>固定电压的唯一解</strong>：  <ul>
<li>若指定某节点电压（如 $$ \phi_v &#x3D; 0 $$），则解唯一。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="物理意义"><a href="#物理意义" class="headerlink" title="物理意义"></a><strong>物理意义</strong></h4><ol>
<li><strong>伪逆的作用</strong>：  <ul>
<li>$$ L^\dagger $$ 将电流分布 $$ b $$ 映射到<strong>最小范数电压解</strong>（即 $$ \phi \perp \mathbf{1} $$）。</li>
</ul>
</li>
<li><strong>平移自由度</strong>：  <ul>
<li>解中的 $$ c \mathbf{1} $$ 反映电压的全局参考点可任意选择，不影响电流分布。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="一个引理"><a href="#一个引理" class="headerlink" title="一个引理"></a>一个引理</h2><p>引理：$R_{\text{eff}}(s, t) &#x3D; b_{st}^\top L^\dagger b_{st}$，其中向量$b_{st} \in \mathbb{R}^n$满足<br>$b_{st}(s) &#x3D; 1$, $b_{st}(t) &#x3D; -1$，并且其它位置都为0。<br><strong>等效电阻的表达式</strong>：</p>
<ul>
<li>从 $$ \phi &#x3D; L^\dagger b $$ 和 $$ R_{\text{eff}}(s, t) &#x3D; \phi(s) - \phi(t) $$ 出发：<br>$$\phi(s) &#x3D; (L^\dagger b)(s) &#x3D; \sum_j L^\dagger(s, j) b(j) &#x3D; L^\dagger(s, s) \cdot 1 + L^\dagger(s, t) \cdot (-1),$$<br>$$\phi(t) &#x3D; (L^\dagger b)(t) &#x3D; \sum_j L^\dagger(t, j) b(j) &#x3D; L^\dagger(t, s) \cdot 1 + L^\dagger(t, t) \cdot (-1).$$</li>
<li>因此：<br>$$R_{\text{eff}}(s, t) &#x3D; \phi(s) - \phi(t) &#x3D; \left[ L^\dagger(s, s) - L^\dagger(s, t) \right] - \left[ L^\dagger(t, s) - L^\dagger(t, t) \right].$$</li>
<li>由于 $$ L^\dagger $$ 对称，$$ L^\dagger(s, t) &#x3D; L^\dagger(t, s) $$，所以：<br>$$R_{\text{eff}}(s, t) &#x3D; L^\dagger(s, s) + L^\dagger(t, t) - 2 L^\dagger(s, t).$$</li>
<li>另一方面，$$ b_{st}^\top L^\dagger b_{st} $$ 可以展开为：<br>$$b_{st}^\top L^\dagger b_{st} &#x3D; \sum_i \sum_j b_{st}(i) L^\dagger(i, j) b_{st}(j) &#x3D; L^\dagger(s, s) - L^\dagger(s, t) - L^\dagger(t, s) + L^\dagger(t, t).$$</li>
<li>由于 $$ L^\dagger $$ 对称，因此：<br>$$b_{st}^\top L^\dagger b_{st} &#x3D; L^\dagger(s, s) + L^\dagger(t, t) - 2 L^\dagger(s, t) &#x3D; R_{\text{eff}}(s, t).$$</li>
<li>引理得证。</li>
</ul>
<h1 id="拉普拉斯矩阵二次型的展开证明"><a href="#拉普拉斯矩阵二次型的展开证明" class="headerlink" title="拉普拉斯矩阵二次型的展开证明"></a>拉普拉斯矩阵二次型的展开证明</h1><p>设图$G&#x3D;(V,E)$的边带有电阻$r_e$，对应的电导为$c_e &#x3D; 1&#x2F;r_e$。拉普拉斯矩阵$L$定义为：</p>
<p>$$L_{uv} &#x3D;<br>\begin{cases}<br>\sum_{w \sim u} c_{uw} &amp; \text{若 } u&#x3D;v \<br>c_{uv} &amp; \text{若 } u \neq v \text{ 且 } (u,v)\in E \<br>0 &amp; \text{其他情况}<br>\end{cases}$$</p>
<h2 id="步骤1：展开二次型"><a href="#步骤1：展开二次型" class="headerlink" title="步骤1：展开二次型"></a>步骤1：展开二次型</h2><p>考虑电势向量$\phi$的二次型：</p>
<p>$$\phi^\top L\phi &#x3D; \sum_{u \in V} \sum_{v \in V} \phi_u L_{uv} \phi_v$$</p>
<h2 id="步骤2：分离对角线项和非对角线项"><a href="#步骤2：分离对角线项和非对角线项" class="headerlink" title="步骤2：分离对角线项和非对角线项"></a>步骤2：分离对角线项和非对角线项</h2><p>将求和分为$u&#x3D;v$和$u\neq v$的情况：</p>
<p>$$&#x3D; \underbrace{\sum_{u \in V} \phi_u^2 L_{uu}}<em>{\text{对角线项}} + \underbrace{\sum</em>{u \neq v} \phi_u L_{uv} \phi_v}_{\text{非对角线项}}$$</p>
<h2 id="步骤3：代入拉普拉斯矩阵定义"><a href="#步骤3：代入拉普拉斯矩阵定义" class="headerlink" title="步骤3：代入拉普拉斯矩阵定义"></a>步骤3：代入拉普拉斯矩阵定义</h2><p>对于对角线项：<br>$$\sum_{u \in V} \phi_u^2 \left(\sum_{w \sim u} c_{uw}\right) &#x3D; \sum_{u \in V} \sum_{e&#x3D;(u,w)\in E} \phi_u^2 c_e$$</p>
<p>对于非对角线项：<br>$$\sum_{u \neq v} \phi_u (-c_{uv}) \phi_v &#x3D; -\sum_{e&#x3D;(u,v)\in E} \phi_u \phi_v c_e \quad (\text{每条边计算两次})$$</p>
<h2 id="步骤4：合并对角线与非对角线项"><a href="#步骤4：合并对角线与非对角线项" class="headerlink" title="步骤4：合并对角线与非对角线项"></a>步骤4：合并对角线与非对角线项</h2><p>$$\phi^\top L\phi &#x3D; \sum_{e&#x3D;(u,v)\in E} \left[ \phi_u^2 c_e + \phi_v^2 c_e - 2\phi_u \phi_v c_e \right]$$</p>
<h2 id="步骤5：重组为平方项"><a href="#步骤5：重组为平方项" class="headerlink" title="步骤5：重组为平方项"></a>步骤5：重组为平方项</h2><p>观察到：<br>$$\phi_u^2 c_e + \phi_v^2 c_e - 2\phi_u \phi_v c_e &#x3D; c_e (\phi_u - \phi_v)^2$$</p>
<p>因此：<br>$$\phi^\top L\phi &#x3D; \sum_{e&#x3D;(u,v)\in E} \frac{(\phi_u - \phi_v)^2}{r_e}$$</p>
<h2 id="几何解释"><a href="#几何解释" class="headerlink" title="几何解释"></a>几何解释</h2><p>这个过程实现了从节点空间到边空间的转换：</p>
<ol>
<li>初始的二次型计算所有节点间的电势交互</li>
<li>拉普拉斯矩阵的结构保证最终结果仅与相邻节点电势差相关</li>
<li>每个边贡献的项可以理解为该边上的能量耗散</li>
</ol>
<h2 id="最终结论"><a href="#最终结论" class="headerlink" title="最终结论"></a>最终结论</h2><p>$\displaystyle \phi^\top L\phi &#x3D; \sum_{e&#x3D;(u,v)\in E} \frac{(\phi_u - \phi_v)^2}{r_e}$</p>
<p>这个等式揭示了图拉普拉斯矩阵的物理意义：它编码了网络中所有边上的电势差能量。在电路理论中，这正好对应焦耳定律给出的能量耗散公式。</p>
<h1 id="有效电阻与能量耗散的关系"><a href="#有效电阻与能量耗散的关系" class="headerlink" title="有效电阻与能量耗散的关系"></a>有效电阻与能量耗散的关系</h1><p>设$G&#x3D;(V,E)$为一个无向图，$r_e$为边$e$的电阻值，$i_e$为边$e$上的电流。考虑从源点$s$到汇点$t$的单位电流。</p>
<h2 id="能量耗散表达式"><a href="#能量耗散表达式" class="headerlink" title="能量耗散表达式"></a>能量耗散表达式</h2><p>网络中的总能量耗散可以表示为：<br>$$\mathcal{E}(i) &#x3D; \sum_{e\in E} i_e^2 \cdot r_e$$</p>
<h2 id="电势表示"><a href="#电势表示" class="headerlink" title="电势表示"></a>电势表示</h2><p>根据欧姆定律，电流可以表示为电势差：<br>$$i_e &#x3D; \frac{\phi_u - \phi_v}{r_e}$$<br>其中$\phi$是电势函数，满足基尔霍夫电流定律$L\phi &#x3D; b_{st}$，这里$b_{st} &#x3D; \mathbf{1}_s - \mathbf{1}_t$。</p>
<p>因此能量耗散可改写为：<br>$$\mathcal{E}(i) &#x3D; \sum_{e&#x3D;(u,v)\in E} \left(\frac{\phi_u - \phi_v}{r_e}\right)^2 \cdot r_e &#x3D; \sum_{e&#x3D;(u,v)\in E} \frac{(\phi_u - \phi_v)^2}{r_e}$$</p>
<h2 id="拉普拉斯矩阵形式"><a href="#拉普拉斯矩阵形式" class="headerlink" title="拉普拉斯矩阵形式"></a>拉普拉斯矩阵形式</h2><p>注意到：<br>$$\phi^\top L\phi &#x3D; \sum_{u,v} \phi_u L_{uv} \phi_v &#x3D; \sum_{e&#x3D;(u,v)\in E} \frac{(\phi_u - \phi_v)^2}{r_e}$$<br>因此：<br>$$\mathcal{E}(i) &#x3D; \phi^\top L\phi$$</p>
<h2 id="有效电阻计算"><a href="#有效电阻计算" class="headerlink" title="有效电阻计算"></a>有效电阻计算</h2><p>由于$L\phi &#x3D; b_{st}$，且$L$的伪逆$L^\dagger$满足$\phi &#x3D; L^\dagger b_{st}$，代入得：<br>$$\mathcal{E}(i) &#x3D; (L^\dagger b_{st})^\top L (L^\dagger b_{st}) &#x3D; b_{st}^\top L^\dagger b_{st}$$</p>
<p>这正是$s$和$t$之间的有效电阻$R_{\text{eff}}(s,t)$的定义：<br>$$R_{\text{eff}}(s,t) &#x3D; b_{st}^\top L^\dagger b_{st} &#x3D; (\mathbf{1}_s - \mathbf{1}_t)^\top L^\dagger (\mathbf{1}_s - \mathbf{1}_t)$$</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>因此我们证明了：<br>$$\mathcal{E}(i) &#x3D; R_{\text{eff}}(s,t)$$<br>即<strong>单位电流下的能量耗散等于$s$和$t$之间的有效电阻。</strong></p>
<h1 id="有效电阻与单位流的能量最小化定理"><a href="#有效电阻与单位流的能量最小化定理" class="headerlink" title="有效电阻与单位流的能量最小化定理"></a>有效电阻与单位流的能量最小化定理</h1><h2 id="Thompson’s-Principle-定理陈述"><a href="#Thompson’s-Principle-定理陈述" class="headerlink" title="Thompson’s Principle 定理陈述"></a>Thompson’s Principle 定理陈述</h2><h2 id="对于任意图-G-V-E-和边上的电阻-r-e-1-（-forall-e-in-E-），有效电阻满足：-R-text-eff-s-t-leq-mathcal-E-g-其中-g-是任意单位-s-t-流。"><a href="#对于任意图-G-V-E-和边上的电阻-r-e-1-（-forall-e-in-E-），有效电阻满足：-R-text-eff-s-t-leq-mathcal-E-g-其中-g-是任意单位-s-t-流。" class="headerlink" title="对于任意图 $G&#x3D;(V,E)$ 和边上的电阻 $r_e &#x3D; 1$（$\forall e \in E$），有效电阻满足：$$R_{\text{eff}}(s,t) \leq \mathcal{E}(g)$$其中 $g$ 是任意单位 $s$-$t$ 流。"></a>对于任意图 $G&#x3D;(V,E)$ 和边上的电阻 $r_e &#x3D; 1$（$\forall e \in E$），有效电阻满足：<br>$$<br>R_{\text{eff}}(s,t) \leq \mathcal{E}(g)<br>$$<br>其中 $g$ 是任意单位 $s$-$t$ 流。</h2><h3 id="1-问题形式化"><a href="#1-问题形式化" class="headerlink" title="1. 问题形式化"></a><strong>1. 问题形式化</strong></h3><p><strong>目标函数与约束条件</strong><br>考虑最小化能量：<br>$$\min_{g} \mathcal{E}(g) &#x3D; \min_{g} \sum_{e \in E} g_e^2 \quad \text{s.t.} \quad B g &#x3D; b_{st}$$<br>其中：</p>
<ul>
<li>$$ B $$ 是图的关联矩阵（节点-边矩阵），维度为 $$ n \times |E| $$。</li>
<li>$$ b_{st} $$ 是单位流需求向量，满足 $$ b_{st}(s) &#x3D; +1 $$，$$ b_{st}(t) &#x3D; -1 $$，其余节点为 0。</li>
<li>流 $$ g $$ 满足基尔霍夫电流定律（流守恒）。</li>
</ul>
<hr>
<h3 id="2-拉格朗日乘子法与KKT条件"><a href="#2-拉格朗日乘子法与KKT条件" class="headerlink" title="2. 拉格朗日乘子法与KKT条件"></a><strong>2. 拉格朗日乘子法与KKT条件</strong></h3><p><strong>拉格朗日函数</strong><br>引入拉格朗日乘子 $$ \phi \in \mathbb{R}^n $$，构造拉格朗日函数：<br>$$\mathcal{L}(g, \phi) &#x3D; \sum_{e} g_e^2 + \phi^\top (B g - b_{st})$$</p>
<p><strong>梯度条件</strong><br>对 $$ g $$ 求导并令导数为零：<br>$$\nabla_g \mathcal{L} &#x3D; 2g + B^\top \phi &#x3D; 0 \quad \implies \quad g &#x3D; -\frac{1}{2} B^\top \phi$$<br>这表明最优流 $$ g $$ 由某个电势向量 $$ \phi $$ 通过 $$ B^\top \phi $$ 确定，符号由电阻方向决定。</p>
<hr>
<h3 id="3-代入约束条件"><a href="#3-代入约束条件" class="headerlink" title="3. 代入约束条件"></a><strong>3. 代入约束条件</strong></h3><p>将 $$ g &#x3D; -\frac{1}{2} B^\top \phi $$ 代入约束 $$ B g &#x3D; b_{st} $$：<br>$$B \left(-\frac{1}{2} B^\top \phi \right) &#x3D; b_{st} \quad \implies \quad -\frac{1}{2} B B^\top \phi &#x3D; b_{st}$$<br>注意到 $$ L &#x3D; B B^\top $$ 是图的拉普拉斯矩阵，因此：<br>$$L \phi &#x3D; -2 b_{st}$$<br>由于拉普拉斯矩阵 $$ L $$ 秩为 $$ n-1 $$，需设定参考点（如 $$ \phi_t &#x3D; 0 $$）后解得：<br>$$\phi &#x3D; -2 L^+ b_{st}$$<br>其中 $$ L^+ $$ 是 $$ L $$ 的伪逆矩阵。</p>
<hr>
<h3 id="4-最优能量与有效电阻的关系"><a href="#4-最优能量与有效电阻的关系" class="headerlink" title="4. 最优能量与有效电阻的关系"></a><strong>4. 最优能量与有效电阻的关系</strong></h3><p><strong>最优流的能量</strong><br>将 $$ g &#x3D; -\frac{1}{2} B^\top \phi $$ 代入目标函数：<br>$$\mathcal{E}(g) &#x3D; g^\top g &#x3D; \left(-\frac{1}{2} B^\top \phi \right)^\top \left(-\frac{1}{2} B^\top \phi \right) &#x3D; \frac{1}{4} \phi^\top B B^\top \phi$$<br>利用 $$ L &#x3D; B B^\top $$ 和 $$ \phi &#x3D; -2 L^+ b_{st} $$：<br>$$\mathcal{E}(g) &#x3D; \frac{1}{4} \phi^\top L \phi &#x3D; \frac{1}{4} (-2 b_{st}^\top L^+) L (-2 L^+ b_{st}) &#x3D; b_{st}^\top L^+ b_{st}$$</p>
<p><strong>有效电阻的定义</strong><br>有效电阻 $$ R_{\text{eff}}(s, t) $$ 定义为电势差除以单位电流：<br>$$R_{\text{eff}}(s, t) &#x3D; \phi_s - \phi_t &#x3D; (\chi_s - \chi_t)^\top \phi$$<br>其中 $$ \chi_s $$ 和 $$ \chi_t $$ 是 $$ s $$ 和 $$ t $$ 的指示向量。结合 $$ \phi &#x3D; -2 L^+ b_{st} $$，有：<br>$$R_{\text{eff}}(s, t) &#x3D; (\chi_s - \chi_t)^\top (-2 L^+ b_{st}) &#x3D; -2 (\chi_s - \chi_t)^\top L^+ (\chi_s - \chi_t)$$<br>由于 $$ b_{st} &#x3D; \chi_s - \chi_t $$，且 $$ L^+ $$ 对称，可得：<br>$$R_{\text{eff}}(s, t) &#x3D; b_{st}^\top L^+ b_{st}$$<br>因此，最优能量 $$ \mathcal{E}(g) &#x3D; R_{\text{eff}}(s, t) $$。</p>
<hr>
<h3 id="5-结论"><a href="#5-结论" class="headerlink" title="5. 结论"></a><strong>5. 结论</strong></h3><p>对任意单位 $$ s $$-$$ t $$ 流 $$ g $$，其能量 $$ \mathcal{E}(g) $$ 满足：<br>$$\mathcal{E}(g) \geq \mathcal{E}(g^<em>) &#x3D; R_{\text{eff}}(s, t)$$<br>其中 $$ g^</em> $$ 是最优流，由电势差通过欧姆定律生成。这表明有效电阻是所有可能单位流能量的最小值。</p>
<hr>
<h3 id="最终结论-1"><a href="#最终结论-1" class="headerlink" title="最终结论"></a><strong>最终结论</strong></h3><p>$$R_{\text{eff}}(s, t) &#x3D; \min_{g: Bg &#x3D; b_{st}} \sum_{e} g_e^2 \quad \implies \quad R_{\text{eff}}(s, t) \leq \mathcal{E}(g) \quad \forall \text{单位 } s\text{-}t \text{流 } g.$$</p>
<hr>
<p><strong>关键点总结</strong>  </p>
<ol>
<li><strong>KKT条件</strong> 导出了最优流与电势的关系，符合欧姆定律。  </li>
<li><strong>拉普拉斯矩阵伪逆</strong> 将电势差与有效电阻直接关联。  </li>
<li><strong>凸优化唯一性</strong> 保证了最小能量的存在性，且等于有效电阻。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/midterm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes.github.io/images/woshicaigou.jpg">
      <meta itemprop="name" content="Chen Zhan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cz Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/notes.github.io/2025/06/23/midterm/" class="post-title-link" itemprop="url">midterm</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-23 18:56:58" itemprop="dateCreated datePublished" datetime="2025-06-23T18:56:58+08:00">2025-06-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>问题 #1</strong></p>
<p>令 $d \ge 1$ 为一个整数，令 $T_d$ 为 $d$ 阶的切比雪夫多项式。</p>
<ol>
<li><p>请证明在 $[-1,1]$ 上的无穷范数的意义下，$x^d - \frac{1}{2^{d-1}}T_d(x)$ 是 $x^d$ 的最优 $d-1$ 阶近似，其中，$[-1,1]$ 上的无穷范数定义如下：</p>
<p>$||p||<em>\infty &#x3D; \sup</em>{x \in [-1,1]} |p(x)|$.</p>
</li>
<li><p>给定一个 $d$ 次多项式，$p(x) &#x3D; a_0 + a_1x + \dots + a_dx^d$，请给出在 $[-1,1]$ 上的无穷范数意义下，$p(x)$ 的最优 $d-1$ 阶近似。<br><strong>问题 #2</strong></p>
</li>
</ol>
<p>一位军官在她的保险箱中存放了一封重要的信，以防她在战斗中牺牲，她决定与她的部队分享密码（该密码为一个数字）。然而，所有人都知道部队中有3名间谍，但除了这三名间谍自己，没有人知道他们是谁。这3名间谍可以相互协调，他们要么撒谎使人们无法打开保险箱，要么会尝试他们自己打开保险箱（如果他们能打开的话）。因此，军官希望分享密码的方案能满足以下条件：</p>
<ul>
<li>当他们中的 $M$ 人聚在一起时，即使他们中间有间谍，他们也能确保打开保险箱。</li>
<li>这3名间谍的密码不足以让他们三人打开保险箱。</li>
</ul>
<p>请帮助军官设计一个分享她的密码的方案。这个方案是什么？最小的 $M$ 是多少？展示你的方案并论证为什么你的方案有效，并证明任何更小的 $M$ 都不能工作。注意：部队只有一次机会打开保险箱；如果打开失败，保险箱将自毁。<br><strong>问题 #3</strong></p>
<ol>
<li><p>给定单位长度向量 $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$，即 $||\mathbf{x}||_2 &#x3D; ||\mathbf{y}||_2 &#x3D; 1$。求正交矩阵 $Q$ 使得 $Q\mathbf{y} &#x3D; \mathbf{x}$。</p>
</li>
<li><p>更一般地，给定 $\mathbb{R}^m$ 里面的单位长度向量 $\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_m$ 和 $\mathbf{y}_1, \mathbf{y}_2, \dots, \mathbf{y}_m$。假设 $\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_m$ 是两两正交的，且 $\mathbf{y}_1, \mathbf{y}_2, \dots, \mathbf{y}_m$ 也是两两正交的，求正交矩阵 $Q$ 使得 $\forall i, Q\mathbf{y}_i &#x3D; \mathbf{x}_i$。</p>
</li>
</ol>
<p><strong>问题 #4</strong></p>
<p>回顾最小二乘法的法线方程 $A^T A \mathbf{x} &#x3D; A^T \mathbf{b}$，其中 $A$ 是实数矩阵。一般来说，$A^T A$ 可能是不可逆的。假设 $A^T A$ 的最大特征值为 1.</p>
<ol>
<li><p>对于固定的 $\delta &gt; 0$，$\text{cond}_2(A^T A + \delta I)$ 最大可能是多少？注：$\text{cond}_2(\cdot)$ 特指由 2-范数所诱导的矩阵的条件数。</p>
</li>
<li><p>记 $\mathbf{x} &#x3D; (A^T A + \delta I)^{-1} A^T \mathbf{b}$。证明：</p>
<p>$\mathbf{x} &#x3D; \arg\min_{\mathbf{x}} ||A\mathbf{x} - \mathbf{b}||_2^2 + \delta ||\mathbf{x}||_2^2$</p>
</li>
<li><p>设矩阵 $A$ 的 SVD 分解为 $A &#x3D; U \Sigma V^T$。假设 $A$ 的列是满秩的，则最小二乘解可以写作 $\mathbf{x}_{LS} &#x3D; \sum_i \frac{1}{\sigma_i} \mathbf{u}_i \mathbf{v}_i^T \mathbf{b}$。为了让最小二乘法更加稳定，一个思路是直接舍弃掉 $\sigma_i \approx 0$ 的那些项。试写出 $\mathbf{x}$ 的一个类似的表达式，并分析为什么它能实现类似于“舍弃掉 $\sigma_i \approx 0$ 的那些项”的效果。</p>
</li>
</ol>
<p><strong>问题 #5</strong></p>
<p>给定矩阵 $A \in \mathbb{R}^{m \times n}$，记 $A_i$ 为 $A$ 的第 $i$ 行，$A^{(j)}$ 为 $A$ 的第 $j$ 列，求证：</p>
<p>$||A||<em>{1 \to 2} &#x3D; \max</em>{j:1 \le j \le n} ||A^{(j)}||_2$</p>
<p>$||A||<em>{2 \to \infty} &#x3D; \max</em>{i:1 \le i \le n} ||A_i||_2$</p>
<p>HINT: 第二个等式可能用到 Cauchy-Schwarz 不等式: $\forall x, y \in \mathbb{R}^n$, $(x,y)^2 \le (x,x) \cdot (y,y)$.</p>
<p><strong>问题 #6</strong></p>
<ol>
<li><p>给定矩阵 $A \in \mathbb{R}^{m \times n}$，假设对 $A^T A$ 的楚列斯基 (Cholesky) 分解有 $A^T A &#x3D; L L^T$，其中 $L$ 为下三角阵。考虑 $Q :&#x3D; A(L^T)^{-1}$，请证明 $Q$ 的列是正交的，并推导 $A^T A$ 的楚列斯基 (Cholesky) 分解与 $A$ 的 QR 分解之间的关系。</p>
</li>
<li><p>给定矩阵 $A \in \mathbb{R}^{m \times n}$, $m \le n$，它一定能被分解为 $A &#x3D; RQ$，其中 $R$ 为上三角阵，且 $Q$ 为正交矩阵。请设计一个分解的方法，进而证明 $A &#x3D; RQ$ 分解的存在性。</p>
</li>
</ol>
<p>HINT: 尝试修改 Gram-Schmidt 过程。</p>
<p><strong>问题 #7</strong></p>
<p>给定常数 $u &gt; 0$ 和任意向量 $v \in \mathbb{R}^n$，试找出最小化 $u ||x||_1 + \frac12 ||x - v||_2^2$ 的向量 $x$。</p>
<p>HINT: 可以尝试求解 $n&#x3D;1$ 的情况。<br><strong>问题 #8 (Stability of sorting)</strong><br> 满足 $Y_{(1)} \le \dots \le Y_{(n)}$。</p>
<p>注意噪声可能<br>给定向量 $X &#x3D; (X_1, \dots, X_n)$，它排序后的版本记作 $\text{sort}(X) &#x3D; (X_{(1)}, \dots, X_{(n)})$，满足 $X_{(1)} \le \dots \le X_{(n)}$。考虑对 $X$ 加入了一些噪声之后得到的向量 $Y$，同样记 $Y$ 排序后的版本为 $\text{sort}(Y)$改变了元素的大小顺序。</p>
<ol>
<li>证明 $|X_{(1)} - Y_{(1)}| \le ||X - Y||_2$</li>
<li>证明 $|X_{(n)} - Y_{(n)}| \le ||X - Y||_2$</li>
<li>证明对所有 $k$，$|X_{(k)} - Y_{(k)}| \le ||X - Y||_2$</li>
<li>证明 $||\text{sort}(X) - \text{sort}(Y)||_1 \le ||X - Y||_1$<br><strong>问题 #9</strong><br>一般来说，一个矩阵的秩是不连续的。事实上，可逆矩阵的集合在实数矩阵里面是一个稠密集。这就意味着，一个非满秩的矩阵，可以通过一个任意小的扰动使其变得满秩。这里研究一个相对更稳定的秩的定义，这样的稳定性让 Stable rank 作为 rank 的一个替代量在低秩矩阵近似的研究中得到广泛应用。</li>
</ol>
<p>一个实矩阵 $A \in \mathbb{R}^{n \times n}$ 的 stable rank 定义为</p>
<p>$\text{STABLE-RANK}(A) &#x3D; \frac{||A||_F^2}{||A||_2^2}$</p>
<ol>
<li><p>当矩阵 $A$ 的列向量都等于 $\vec{v} \in \mathbb{R}^n \setminus {\vec{0}}$ 时，证明 $\text{STABLE-RANK}(A) &#x3D; 1$。</p>
</li>
<li><p>当矩阵 $A$ 的列向量是 orthonormal 时，证明 $\text{STABLE-RANK}(A) &#x3D; n$。</p>
</li>
<li><p>更一般的，证明 $1 \le \text{STABLE-RANK}(A) \le n$。</p>
</li>
<li><p>证明 $\text{STABLE-RANK}(A) \le \text{RANK}(A)$。</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/notePuGraph/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes.github.io/images/woshicaigou.jpg">
      <meta itemprop="name" content="Chen Zhan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cz Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/notes.github.io/2025/06/23/notePuGraph/" class="post-title-link" itemprop="url">notePuGraph</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-23 18:56:58" itemprop="dateCreated datePublished" datetime="2025-06-23T18:56:58+08:00">2025-06-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="图的邻接矩阵最大特征值上下界证明"><a href="#图的邻接矩阵最大特征值上下界证明" class="headerlink" title="图的邻接矩阵最大特征值上下界证明"></a>图的邻接矩阵最大特征值上下界证明</h3><p>设图 $$ G $$ 的邻接矩阵为 $$ A $$，其最大特征值为 $$ \alpha_1 $$，平均度 $$ d_{\text{avg}} &#x3D; \frac{2|E|}{n} $$，最大度数为 $$ \Delta &#x3D; \deg_{\max}(G) $$。需证明：<br>$$d_{\text{avg}} \leq \alpha_1 \leq \Delta$$</p>
<hr>
<h4 id="上界证明（-alpha-1-leq-Delta"><a href="#上界证明（-alpha-1-leq-Delta" class="headerlink" title="上界证明（$$ \alpha_1 \leq \Delta $$)"></a><strong>上界证明（$$ \alpha_1 \leq \Delta $$)</strong></h4><ol>
<li><p><strong>特征值与特征向量定义</strong><br>设 $$ \alpha_1 $$ 为 $$ A $$ 的最大特征值，对应的特征向量为 $$ \bm{v} $$，满足：<br>$$A\bm{v} &#x3D; \alpha_1 \bm{v}$$<br>假设 $$ \bm{v} $$ 是单位向量（即 $$ |\bm{v}|_2 &#x3D; 1 $$）。</p>
</li>
<li><p><strong>选择最大分量</strong><br>取 $$ \bm{v} $$ 中绝对值最大的分量为 $$ v_j $$，即：<br>$$|v_j| &#x3D; \max_{i} |v_i| &gt; 0$$<br>根据特征方程，对第 $$ j $$ 行有：<br>$$\alpha_1 v_j &#x3D; \sum_{i&#x3D;1}^n A_{j,i} v_i$$</p>
</li>
<li><p><strong>绝对值的三角不等式</strong><br>取绝对值后：<br>$$|\alpha_1| |v_j| &#x3D; \left| \sum_{i&#x3D;1}^n A_{j,i} v_i \right| \leq \sum_{i&#x3D;1}^n |A_{j,i}| |v_i|$$<br>因为邻接矩阵元素 $$ A_{j,i} \in {0,1} $$，且 $$ |v_i| \leq |v_j| $$，可得：<br>$$\sum_{i&#x3D;1}^n |A_{j,i}| |v_i| \leq \sum_{i&#x3D;1}^n A_{j,i} |v_j| &#x3D; \deg(j) |v_j| \leq \Delta |v_j|$$</p>
</li>
<li><p><strong>化简不等式</strong><br>结合上述结果：<br>$$|\alpha_1| |v_j| \leq \Delta |v_j|$$<br>因 $$ |v_j| &gt; 0 $$，两边约去后得：<br>$$|\alpha_1| \leq \Delta$$<br>由于 $$ \alpha_1 $$ 是实对称矩阵（无向图）的最大特征值，必为非负实数，故：<br>$$\alpha_1 \leq \Delta$$</p>
</li>
</ol>
<hr>
<h4 id="下界证明（-d-text-avg-leq-alpha-1"><a href="#下界证明（-d-text-avg-leq-alpha-1" class="headerlink" title="下界证明（$$ d_{\text{avg}} \leq \alpha_1 $$)"></a><strong>下界证明（$$ d_{\text{avg}} \leq \alpha_1 $$)</strong></h4><ol>
<li><strong>Rayleigh商性质</strong><br>最大特征值 $$ \alpha_1 $$ 满足：<br>$$\alpha_1 &#x3D; \max_{\bm{x} \neq \bm{0}} \frac{\bm{x}^T A \bm{x}}{\bm{x}^T \bm{x}}$$<br>取 $$ \bm{x} &#x3D; \bm{1} $$（全1向量），则：<br>$$\bm{x}^T A \bm{x} &#x3D; \sum_{i,j} A_{i,j} &#x3D; 2|E|$$<br>分母为：<br>$$\bm{x}^T \bm{x} &#x3D; n$$<br>因此：<br>$$\alpha_1 \geq \frac{2|E|}{n} &#x3D; d_{\text{avg}}$$</li>
</ol>
<hr>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h4><p>结合上下界结果，得：<br>$$\boxed{d_{\text{avg}} \leq \alpha_1 \leq \Delta}$$<br><strong>关键点</strong>：</p>
<ul>
<li><strong>上界</strong>：通过特征向量分量的最大性，结合邻接矩阵的稀疏性（每行非零元素数为度数）。</li>
<li><strong>下界</strong>：利用Rayleigh商与全1向量的计算，将最大特征值与平均度关联。</li>
</ul>
<h3 id="引理证明详解"><a href="#引理证明详解" class="headerlink" title="引理证明详解"></a>引理证明详解</h3><p><strong>引理</strong>：对于二分图 $$ G $$，若 $$ \alpha $$ 是邻接矩阵 $$ A(G) $$ 的特征值且重数为 $$ k $$，则 $$ -\alpha $$ 也是 $$ A(G) $$ 的特征值，重数同样为 $$ k $$。</p>
<hr>
<h4 id="1-邻接矩阵的分块结构"><a href="#1-邻接矩阵的分块结构" class="headerlink" title="1. 邻接矩阵的分块结构"></a><strong>1. 邻接矩阵的分块结构</strong></h4><p>设二分图 $$ G $$ 的两个顶点集为 $$ U $$ 和 $$ V $$，其邻接矩阵可表示为分块形式：<br>$$A &#x3D; \begin{pmatrix}<br>0 &amp; B \<br>B^T &amp; 0<br>\end{pmatrix},$$<br>其中 $$ B $$ 是 $$ |U| \times |V| $$ 的矩阵，描述 $$ U $$ 到 $$ V $$ 的边，且 $$ B^T $$ 是 $$ B $$ 的转置。</p>
<hr>
<h4 id="2-特征值与特征向量的对应关系"><a href="#2-特征值与特征向量的对应关系" class="headerlink" title="2. 特征值与特征向量的对应关系"></a><strong>2. 特征值与特征向量的对应关系</strong></h4><p>假设 $$ \begin{pmatrix} x \ y \end{pmatrix} $$ 是 $$ A $$ 的特征向量，对应特征值 $$ \alpha $$，即：<br>$$A \begin{pmatrix} x \ y \end{pmatrix} &#x3D; \alpha \begin{pmatrix} x \ y \end{pmatrix}.$$<br>展开分块矩阵乘法，得到方程组：<br>$$\begin{cases}<br>B y &#x3D; \alpha x, \<br>B^T x &#x3D; \alpha y.<br>\end{cases}$$</p>
<hr>
<h4 id="3-构造-alpha-的特征向量"><a href="#3-构造-alpha-的特征向量" class="headerlink" title="3. 构造 $$ -\alpha $$ 的特征向量"></a><strong>3. 构造 $$ -\alpha $$ 的特征向量</strong></h4><p>考虑向量 $$ \begin{pmatrix} x \ -y \end{pmatrix} $$，计算其作用：<br>$$A \begin{pmatrix} x \ -y \end{pmatrix} &#x3D; \begin{pmatrix}<br>0 &amp; B \<br>B^T &amp; 0<br>\end{pmatrix} \begin{pmatrix} x \ -y \end{pmatrix} &#x3D; \begin{pmatrix} -B y \ B^T x \end{pmatrix}.$$<br>代入 $$ B y &#x3D; \alpha x $$ 和 $$ B^T x &#x3D; \alpha y $$，得：<br>$$A \begin{pmatrix} x \ -y \end{pmatrix} &#x3D; \begin{pmatrix} -\alpha x \ \alpha y \end{pmatrix} &#x3D; -\alpha \begin{pmatrix} x \ -y \end{pmatrix}.$$<br>这表明 $$ \begin{pmatrix} x \ -y \end{pmatrix} $$ 是 $$ A $$ 对应特征值 $$ -\alpha $$ 的特征向量。</p>
<hr>
<h4 id="4-重数的等价性"><a href="#4-重数的等价性" class="headerlink" title="4. 重数的等价性"></a><strong>4. 重数的等价性</strong></h4><ul>
<li><p><strong>线性无关性保持</strong>：<br>若 $$ \alpha $$ 的重数为 $$ k $$，则存在 $$ k $$ 个线性无关的特征向量 $$ \left{ \begin{pmatrix} x_1 \ y_1 \end{pmatrix}, \dots, \begin{pmatrix} x_k \ y_k \end{pmatrix} \right} $$。<br>构造对应的向量组 $$ \left{ \begin{pmatrix} x_1 \ -y_1 \end{pmatrix}, \dots, \begin{pmatrix} x_k \ -y_k \end{pmatrix} \right} $$。<br><strong>验证线性无关性</strong>：<br>假设存在标量 $$ c_1, \dots, c_k $$ 使得：<br>$$\sum_{i&#x3D;1}^k c_i \begin{pmatrix} x_i \ -y_i \end{pmatrix} &#x3D; \begin{pmatrix} 0 \ 0 \end{pmatrix}.$$<br>拆分分量得：<br>$$\sum_{i&#x3D;1}^k c_i x_i &#x3D; 0 \quad \text{和} \quad -\sum_{i&#x3D;1}^k c_i y_i &#x3D; 0.$$<br>由于原向量组线性无关，唯一解为 $$ c_1 &#x3D; \dots &#x3D; c_k &#x3D; 0 $$，故变换后的向量组仍线性无关。</p>
</li>
<li><p><strong>对称性保证重数相等</strong>：<br>邻接矩阵 $$ A $$ 是实对称矩阵，其特征值均为实数，且不同特征值对应的特征向量正交。<br>若 $$ \alpha \neq 0 $$，则 $$ \alpha $$ 和 $$ -\alpha $$ 为不同特征值，其重数由矩阵的谱定理保证相等（因特征空间维度相同）。</p>
</li>
</ul>
<hr>
<h4 id="5-零特征值的特殊情况"><a href="#5-零特征值的特殊情况" class="headerlink" title="5. 零特征值的特殊情况"></a><strong>5. 零特征值的特殊情况</strong></h4><p>当 $$ \alpha &#x3D; 0 $$ 时，$$ -\alpha &#x3D; 0 $$，重数显然相同。此时特征向量满足 $$ B y &#x3D; 0 $$ 和 $$ B^T x &#x3D; 0 $$，其解空间的维度由矩阵 $$ B $$ 的秩决定，对 $$ \alpha $$ 和 $$ -\alpha $$ 一致。</p>
<hr>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a><strong>总结</strong></h4><p>通过分块矩阵的结构分析、特征向量的符号变换以及线性无关性保持，可严格证明：<br>$$\text{重数}(\alpha) &#x3D; \text{重数}(-\alpha) &#x3D; k.$$</p>
<hr>
<h2 id="引理证明："><a href="#引理证明：" class="headerlink" title="引理证明："></a><strong>引理证明</strong>：</h2><p><strong>条件</strong>：设 $$ G $$ 是简单无向图，其邻接矩阵 $$ A $$ 的特征值满足 $$ \alpha_i &#x3D; -\alpha_{n-i+1} $$ 对所有 $$ i $$ 成立。</p>
<p><strong>目标</strong>：证明 $$ G $$ 是二分图（即不含奇数长度的环）。</p>
<p><strong>证明步骤</strong>：</p>
<ol>
<li><p><strong>特征值幂和为零</strong>：<br>对于任意奇数 $$ k $$，特征值的 $$ k $$ 次幂之和满足<br>$$\sum_{i&#x3D;1}^n \alpha_i^k &#x3D; 0.$$<br><em>推导</em>：由条件 $$ \alpha_i &#x3D; -\alpha_{n-i+1} $$，特征值成对互为相反数。对每一对 $$ (\alpha_i, -\alpha_i) $$，其奇数次幂和为 $$ \alpha_i^k + (-\alpha_i)^k &#x3D; 0 $$。若 $$ n $$ 为奇数，中间特征值必为 $$ 0 $$，贡献为 $$ 0 $$。故总和为 $$ 0 $$。</p>
</li>
<li><p><strong>矩阵幂的迹为零</strong>：<br>邻接矩阵 $$ A^k $$ 的迹为<br>$$\text{trace}(A^k) &#x3D; \sum_{i&#x3D;1}^n \alpha_i^k &#x3D; 0.$$<br><em>依据</em>：矩阵的迹等于其特征值的和，且 $$ A^k $$ 的特征值为 $$ \alpha_i^k $$。</p>
</li>
<li><p><strong>闭合走路不存在</strong>：<br>$$ \text{trace}(A^k) $$ 的组合意义为长度为 $$ k $$ 的闭合走路总数。由于迹为零，且 $$ (A^k)<em>{i,i} \geq 0 $$ 对每个顶点 $$ i $$，故<br>$$(A^k)</em>{i,i} &#x3D; 0 \quad \text{对所有顶点} , i , \text{和奇数} , k.$$<br>因此，图中不存在长度为 $$ k $$ 的闭合走路（包括简单环）。</p>
</li>
<li><p><strong>排除奇环</strong>：<br>若存在奇数长度环，其对应闭合走路会使 $$ (A^k)_{i,i} \geq 1 $$，与 $$ \text{trace}(A^k) &#x3D; 0 $$ 矛盾。故 $$ G $$ 不含任何奇数长度的环。</p>
</li>
<li><p><strong>二分图判定</strong>：<br>图论定理指出，无奇环的图必为二分图。因此，$$ G $$ 是二分图。</p>
</li>
</ol>
<p><strong>结论</strong>：邻接矩阵特征值关于零对称的图 $$ G $$ 必为二分图，证毕。</p>
<h3 id="拉普拉斯矩阵（Laplacian-Matrix）详解"><a href="#拉普拉斯矩阵（Laplacian-Matrix）详解" class="headerlink" title="拉普拉斯矩阵（Laplacian Matrix）详解"></a>拉普拉斯矩阵（Laplacian Matrix）详解</h3><h4 id="1-基本定义"><a href="#1-基本定义" class="headerlink" title="1. 基本定义"></a>1. <strong>基本定义</strong></h4><p>给定一个无向图 $$ G &#x3D; (V, E) $$，其拉普拉斯矩阵 $$ L(G) $$ 定义为：<br>$$L(G) &#x3D; D(G) - A(G)$$</p>
<ul>
<li><strong>度矩阵 $$ D(G) $$</strong>：对角矩阵，对角线元素 $$ D_{u,u} &#x3D; \text{deg}(u) $$，表示顶点 $$ u $$ 的度数，非对角线元素为 0。</li>
<li><strong>邻接矩阵 $$ A(G) $$</strong>：矩阵元素 $$ A_{u,v} &#x3D; 1 $$ 当且仅当边 $$ uv \in E $$，否则为 0。</li>
</ul>
<h4 id="2-正则图的拉普拉斯矩阵"><a href="#2-正则图的拉普拉斯矩阵" class="headerlink" title="2. 正则图的拉普拉斯矩阵"></a>2. <strong>正则图的拉普拉斯矩阵</strong></h4><p>对于 <strong>$$ d $$-正则图</strong>（每个顶点的度数均为 $$ d $$），度矩阵可写为：<br>$$D(G) &#x3D; dI$$<br>其中 $$ I $$ 是单位矩阵。因此，拉普拉斯矩阵简化为：<br>$$L(G) &#x3D; dI - A(G)$$</p>
<ul>
<li><strong>特征空间关系</strong>：正则图的邻接矩阵 $$ A(G) $$ 和拉普拉斯矩阵 $$ L(G) $$ <strong>共享相同的特征向量</strong>，且特征值满足线性关系：<br>$$\lambda_L &#x3D; d - \lambda_A$$<br>其中 $$ \lambda_L $$ 是 $$ L(G) $$ 的特征值，$$ \lambda_A $$ 是 $$ A(G) $$ 的对应特征值。<br><strong>例子</strong>：在 3-正则图中，若 $$ A $$ 的特征值为 3, 1, -2，则 $$ L $$ 的特征值为 0, 2, 5（因为 $$ 3 - 3 &#x3D; 0 $$, $$ 3 - 1 &#x3D; 2 $$, $$ 3 - (-2) &#x3D; 5 $$）。</li>
</ul>
<h4 id="3-一般图的拉普拉斯矩阵"><a href="#3-一般图的拉普拉斯矩阵" class="headerlink" title="3. 一般图的拉普拉斯矩阵"></a>3. <strong>一般图的拉普拉斯矩阵</strong></h4><p>对于非正则图，度矩阵 $$ D(G) $$ 不再是标量矩阵，因此：<br>$$L(G) &#x3D; D(G) - A(G)$$</p>
<ul>
<li><strong>特征空间差异</strong>：由于 $$ D(G) $$ 的对角元素（度数）不再一致，$$ L(G) $$ 和 $$ A(G) $$ 的 <strong>特征向量不再相同</strong>，特征值之间也无简单线性关系。<br><strong>例子</strong>：若图包含一个度数为 2 的顶点和一个度数为 1 的顶点，$$ D(G) $$ 和 $$ A(G) $$ 的相互作用复杂，导致特征空间独立。</li>
</ul>
<h4 id="4-拉普拉斯矩阵的边分解"><a href="#4-拉普拉斯矩阵的边分解" class="headerlink" title="4. 拉普拉斯矩阵的边分解"></a>4. <strong>拉普拉斯矩阵的边分解</strong></h4><p>拉普拉斯矩阵可分解为 <strong>单边贡献</strong> 的和：<br>$$L(G) &#x3D; \sum_{e \in E} L_e$$<br>其中每条边 $$ e &#x3D; (u, v) $$ 对应的矩阵 $$ L_e $$ 定义为：<br>$$L_e &#x3D; b_e b_e^\top$$</p>
<ul>
<li><strong>关联向量 $$ b_e $$</strong>：向量 $$ b_e $$ 的长度为顶点数 $$ |V| $$，定义如下：<br>$$b_e(u) &#x3D; 1, \quad b_e(v) &#x3D; -1, \quad \text{其他位置为} \ 0.$$<br><strong>展开形式</strong>：例如，若边 $$ e $$ 连接顶点 1 和 2，则：<br>$$b_e &#x3D; [1, -1, 0, \dots, 0]^\top$$<br>$$L_e &#x3D; b_e b_e^\top &#x3D; \begin{bmatrix}<br>1 &amp; -1 &amp; 0 &amp; \cdots \<br>-1 &amp; 1 &amp; 0 &amp; \cdots \<br>0 &amp; 0 &amp; 0 &amp; \cdots \<br>\vdots &amp; \vdots &amp; \vdots &amp; \ddots<br>\end{bmatrix}$$</li>
<li><strong>求和验证</strong>：将所有边的 $$ L_e $$ 相加：<ul>
<li>对角线元素：每个顶点 $$ u $$ 的度数为与其相连的边数，因此 $$ \sum_{e \ni u} L_e(u,u) &#x3D; \text{deg}(u) $$，对应 $$ D(G) $$。</li>
<li>非对角线元素：边 $$ uv $$ 对应的 $$ L_e $$ 在位置 $$ (u,v) $$ 和 $$ (v,u) $$ 处为 -1，累加后对应 $$ -A(G) $$。<br>因此：<br>$$\sum_{e \in E} L_e &#x3D; D(G) - A(G) &#x3D; L(G)$$</li>
</ul>
</li>
</ul>
<h4 id="5-分解的意义"><a href="#5-分解的意义" class="headerlink" title="5. 分解的意义"></a>5. <strong>分解的意义</strong></h4><ul>
<li><strong>物理意义</strong>：每条边独立地对拉普拉斯矩阵产生“局部影响”，整体效果通过叠加实现。</li>
<li><strong>应用场景</strong>：此分解在 <strong>随机游走</strong>、<strong>电阻网络</strong> 和 <strong>图信号处理</strong> 中用于分析边对全局性质的贡献。</li>
</ul>
<h3 id="拉普拉斯矩阵-L-G-的性质与证明"><a href="#拉普拉斯矩阵-L-G-的性质与证明" class="headerlink" title="拉普拉斯矩阵 $$ L(G) $$ 的性质与证明"></a><strong>拉普拉斯矩阵 $$ L(G) $$ 的性质与证明</strong></h3><h4 id="1-定义回顾"><a href="#1-定义回顾" class="headerlink" title="1. 定义回顾"></a><strong>1. 定义回顾</strong></h4><p>给定无向图 $$ G &#x3D; (V, E) $$，其拉普拉斯矩阵 $$ L(G) $$ 定义为：<br>$$L(G) &#x3D; D(G) - A(G)$$<br>其中：</p>
<ul>
<li>$$ D(G) $$ 是<strong>度矩阵</strong>（对角矩阵，$$ D_{u,u} &#x3D; \text{deg}(u) $$），</li>
<li>$$ A(G) $$ 是<strong>邻接矩阵</strong>（$$ A_{u,v} &#x3D; 1 $$ 当且仅当 $$ uv \in E $$）。</li>
</ul>
<p>拉普拉斯矩阵可以分解为所有边的贡献之和：<br>$$L(G) &#x3D; \sum_{e \in E} L_e, \quad \text{其中} \quad L_e &#x3D; b_e b_e^\top$$<br>其中 $$ b_e $$ 是边 $$ e &#x3D; (u, v) $$ 的<strong>关联向量</strong>：<br>$$b_e(u) &#x3D; 1, \quad b_e(v) &#x3D; -1, \quad \text{其余位置为} \ 0.$$</p>
<hr>
<h3 id="2-性质-1：-mathbf-1-是-L-G-的特征向量，对应特征值-0"><a href="#2-性质-1：-mathbf-1-是-L-G-的特征向量，对应特征值-0" class="headerlink" title="2. 性质 1：$$ \mathbf{1} $$ 是 $$ L(G) $$ 的特征向量，对应特征值 0"></a><strong>2. 性质 1：$$ \mathbf{1} $$ 是 $$ L(G) $$ 的特征向量，对应特征值 0</strong></h3><p><strong>证明</strong>：</p>
<ul>
<li>由于 $$ L(G) &#x3D; D(G) - A(G) $$，计算 $$ L(G) \mathbf{1} $$：<br>$$(L(G) \mathbf{1})<em>u &#x3D; \text{deg}(u) \cdot 1 - \sum</em>{v \sim u} 1 &#x3D; \text{deg}(u) - \text{deg}(u) &#x3D; 0$$<br>因此：<br>$$L(G) \mathbf{1} &#x3D; \mathbf{0} &#x3D; 0 \cdot \mathbf{1}$$<br>这说明 $$ \mathbf{1} $$ 是 $$ L(G) $$ 的特征向量，对应特征值 0。</li>
</ul>
<p><strong>直观解释</strong>：</p>
<ul>
<li>拉普拉斯矩阵的每一行代表一个顶点的度数减去其邻居的影响，而 $$ \mathbf{1} $$ 是一个均匀向量，使得所有顶点的度数贡献和邻居贡献相互抵消，最终得到 0。</li>
</ul>
<hr>
<h3 id="3-性质-2：-L-G-是半正定矩阵（-L-G-succeq-0-）"><a href="#3-性质-2：-L-G-是半正定矩阵（-L-G-succeq-0-）" class="headerlink" title="3. 性质 2：$$ L(G) $$ 是半正定矩阵（$$ L(G) \succeq 0 $$）"></a><strong>3. 性质 2：$$ L(G) $$ 是半正定矩阵（$$ L(G) \succeq 0 $$）</strong></h3><p><strong>证明</strong>：</p>
<ul>
<li>利用拉普拉斯矩阵的边分解：<br>$$L(G) &#x3D; \sum_{e \in E} b_e b_e^\top$$</li>
<li>对于任意向量 $$ x \in \mathbb{R}^n $$，计算二次型：<br>$$x^\top L(G) x &#x3D; x^\top \left( \sum_{e \in E} b_e b_e^\top \right) x &#x3D; \sum_{e \in E} x^\top b_e b_e^\top x$$</li>
<li>由于 $$ b_e^\top x &#x3D; x_u - x_v $$（其中 $$ e &#x3D; (u, v) $$），因此：<br>$$x^\top L(G) x &#x3D; \sum_{e &#x3D; (u, v) \in E} (x_u - x_v)^2 \geq 0$$<br>因为平方项非负，所以 $$ L(G) $$ 是半正定的。</li>
</ul>
<p><strong>关键步骤解释</strong>：</p>
<ul>
<li><strong>$$ x^\top b_e b_e^\top x &#x3D; (b_e^\top x)^2 &#x3D; (x_u - x_v)^2 $$</strong>：<ul>
<li>由于 $$ b_e $$ 仅在 $$ u $$ 和 $$ v $$ 处有非零值（1 和 -1），所以：<br>$$b_e^\top x &#x3D; \sum_{i&#x3D;1}^n b_e(i) x_i &#x3D; x_u - x_v$$</li>
<li>因此，$$ x^\top b_e b_e^\top x &#x3D; (x_u - x_v)^2 $$，即每条边贡献一个平方差项。</li>
</ul>
</li>
</ul>
<p><strong>结论</strong>：</p>
<ul>
<li>由于 $$ x^\top L(G) x $$ 是所有边的平方差之和，且 $$ (x_u - x_v)^2 \geq 0 $$，所以 $$ L(G) $$ 是半正定的。</li>
<li>最小特征值为 0，因为 $$ L(G) \mathbf{1} &#x3D; \mathbf{0} $$，即存在非零向量 $$ \mathbf{1} $$ 使得二次型为 0。</li>
</ul>
<hr>
<h3 id="定理"><a href="#定理" class="headerlink" title="定理"></a><strong>定理</strong></h3><p>给定图 $$ G $$，它是连通的当且仅当拉普拉斯矩阵 $$ L(G) $$ 的特征值 0 的重数为 1。</p>
<hr>
<h3 id="证明（⇐）：不连通图的情况"><a href="#证明（⇐）：不连通图的情况" class="headerlink" title="证明（⇐）：不连通图的情况"></a><strong>证明（⇐）：不连通图的情况</strong></h3><p>假设 $$ G $$ 不连通，则 $$ G $$ 可划分为至少两个连通分量 $$ V_1 $$ 和 $$ V_2 $$。此时，$$ L(G) $$ 可表示为分块对角矩阵：<br>$$L(G) &#x3D; \begin{bmatrix}<br>L(G_1) &amp; 0 \<br>0 &amp; L(G_2)<br>\end{bmatrix}$$<br>其中 $$ L(G_1) $$ 和 $$ L(G_2) $$ 分别是子图 $$ G_1 $$ 和 $$ G_2 $$ 的拉普拉斯矩阵。  </p>
<p>由于 $$ G_1 $$ 和 $$ G_2 $$ 各自连通，$$ L(G_1) $$ 和 $$ L(G_2) $$ 均有一个特征值 0，对应的特征向量分别为 $$ \mathbf{1}<em>{V_1} $$（$$ V_1 $$ 上的全 1 向量）和 $$ \mathbf{1}</em>{V_2} $$（$$ V_2 $$ 上的全 1 向量）。因此，$$ L(G) $$ 的零空间由以下线性无关向量张成：<br>$$\begin{bmatrix}<br>\mathbf{1}<em>{V_1} \<br>0<br>\end{bmatrix}, \quad<br>\begin{bmatrix}<br>0 \<br>\mathbf{1}</em>{V_2}<br>\end{bmatrix}$$<br>故特征值 0 的重数至少为 2。  </p>
<p><strong>结论</strong>：若 $$ G $$ 不连通，则 $$ L(G) $$ 的特征值 0 的重数大于 1。</p>
<hr>
<h3 id="证明（⇒）：连通图的情况"><a href="#证明（⇒）：连通图的情况" class="headerlink" title="证明（⇒）：连通图的情况"></a><strong>证明（⇒）：连通图的情况</strong></h3><p>假设 $$ G $$ 连通，且存在向量 $$ x $$ 满足 $$ L(G)x &#x3D; 0 $$。由半正定性：<br>$$x^\top L(G) x &#x3D; \sum_{(i,j) \in E} (x_i - x_j)^2 &#x3D; 0$$<br>因此，对所有边 $$ (i,j) \in E $$，有 $$ x_i &#x3D; x_j $$。由于 $$ G $$ 连通，任意两顶点 $$ i $$ 和 $$ j $$ 可通过路径连接，故 $$ x_i &#x3D; x_j $$ 对所有 $$ i,j \in V $$ 成立。即 $$ x $$ 必为全 1 向量 $$ \mathbf{1} $$ 的标量倍：<br>$$x &#x3D; c \cdot \mathbf{1}$$<br>因此，零空间维度为 1，特征值 0 的重数为 1。  </p>
<p><strong>结论</strong>：若 $$ G $$ 连通，则 $$ L(G) $$ 的特征值 0 的重数为 1。</p>
<hr>
<h2 id="定理证明"><a href="#定理证明" class="headerlink" title="定理证明"></a>定理证明</h2><p><strong>定理</strong>：给定图 $$ G $$，其拉普拉斯矩阵的特征值满足 $$ 0 &#x3D; \lambda_1 \leq \lambda_2 \leq \cdots \leq \lambda_n $$，则<br>$$\lambda_k &#x3D; 0 \quad \text{当且仅当} \quad G , \text{有至少} , k , \text{个连通分量}.$$</p>
<hr>
<h4 id="证明"><a href="#证明" class="headerlink" title="证明"></a><strong>证明</strong></h4><ol>
<li><p><strong>方向（⇒）：若 $$ \lambda_k &#x3D; 0 $$，则 $$ G $$ 至少有 $$ k $$ 个连通分量</strong>  </p>
<ul>
<li><strong>拉普拉斯矩阵的零特征值重数</strong>：<br>由已知，若图 $$ G $$ 有 $$ m $$ 个连通分量，则其拉普拉斯矩阵 $$ L(G) $$ 可表示为分块对角矩阵：<br>$$L(G) &#x3D; \begin{bmatrix}<br>L(G_1) &amp; 0 &amp; \cdots &amp; 0 \<br>0 &amp; L(G_2) &amp; \cdots &amp; 0 \<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \<br>0 &amp; 0 &amp; \cdots &amp; L(G_m)<br>\end{bmatrix},$$<br>其中每个 $$ L(G_i) $$ 对应一个连通分量的拉普拉斯矩阵。  <ul>
<li>每个连通分量 $$ G_i $$ 的 $$ L(G_i) $$ 有一个零特征值（对应特征向量为 $$ \mathbf{1}_{G_i} $$），其余特征值为正。  </li>
<li>因此，$$ L(G) $$ 的零特征值总数为 $$ m $$，即 $$ \lambda_1 &#x3D; \lambda_2 &#x3D; \cdots &#x3D; \lambda_m &#x3D; 0 $$。</li>
</ul>
</li>
<li><strong>结论</strong>：<br>若 $$ \lambda_k &#x3D; 0 $$，则 $$ k \leq m $$，即 $$ G $$ 至少有 $$ k $$ 个连通分量。</li>
</ul>
</li>
<li><p><strong>方向（⇐）：若 $$ G $$ 有至少 $$ k $$ 个连通分量，则 $$ \lambda_k &#x3D; 0 $$</strong>  </p>
<ul>
<li><strong>零特征值的数量</strong>：<br>设 $$ G $$ 有 $$ m \geq k $$ 个连通分量，则 $$ L(G) $$ 的零特征值数量为 $$ m $$。<br>由于特征值按升序排列，前 $$ m $$ 个特征值为零，即：<br>$$\lambda_1 &#x3D; \lambda_2 &#x3D; \cdots &#x3D; \lambda_m &#x3D; 0.$$<br>因此，当 $$ k \leq m $$ 时，$$ \lambda_k &#x3D; 0 $$。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="关键步骤"><a href="#关键步骤" class="headerlink" title="关键步骤"></a><strong>关键步骤</strong></h4><ol>
<li><p><strong>分块对角矩阵的特征值</strong>：  </p>
<ul>
<li>若 $$ G $$ 分解为 $$ m $$ 个连通分量，则 $$ L(G) $$ 的特征值为各子图 $$ L(G_i) $$ 特征值的并集。  </li>
<li>每个 $$ L(G_i) $$ 贡献一个零特征值，其余为正特征值。因此，$$ L(G) $$ 的零特征值数量为 $$ m $$。</li>
</ul>
</li>
<li><p><strong>特征值排序</strong>：  </p>
<ul>
<li>前 $$ m $$ 个特征值为零，即 $$ \lambda_1 &#x3D; \lambda_2 &#x3D; \cdots &#x3D; \lambda_m &#x3D; 0 $$。  </li>
<li>后续特征值为各子图的最小正特征值升序排列，即 $$ \lambda_{m+1} &gt; 0 $$。</li>
</ul>
</li>
</ol>
<hr>
<h4 id="推论"><a href="#推论" class="headerlink" title="推论"></a><strong>推论</strong></h4><ul>
<li><strong>连通性判定</strong>：  <ul>
<li>$$ \lambda_2 &gt; 0 \iff G $$ 是连通的（即 $$ m &#x3D; 1 $$）。  </li>
<li>$$ \lambda_2 &#x3D; 0 \iff G $$ 不连通（即 $$ m \geq 2 $$）。</li>
</ul>
</li>
<li><strong>一般情况</strong>：<br>$$ \lambda_k &#x3D; 0 $$ 当且仅当 $$ G $$ 有至少 $$ k $$ 个连通分量，即零特征值的重数等于连通分量数。</li>
</ul>
<hr>
<h2 id="Perron-Frobenius定理的证明思路简介"><a href="#Perron-Frobenius定理的证明思路简介" class="headerlink" title="Perron-Frobenius定理的证明思路简介"></a>Perron-Frobenius定理的证明思路简介</h2><p>Perron-Frobenius定理是非负矩阵理论的核心成果，针对非负、不可约且非周期的矩阵 $$ A $$，其证明思路可概括如下：</p>
<hr>
<h4 id="1-最大特征值-lambda-1-的重数为1"><a href="#1-最大特征值-lambda-1-的重数为1" class="headerlink" title="1. 最大特征值 $$ \lambda_1 $$ 的重数为1"></a><strong>1. 最大特征值 $$ \lambda_1 $$ 的重数为1</strong></h4><p><strong>核心思路</strong>：  </p>
<ul>
<li><strong>存在性</strong>：通过构造 <strong>Collatz-Wielandt函数</strong> $$ r_A(x) &#x3D; \min_{x_i \neq 0} \frac{(Ax)_i}{x_i} $$，证明存在正向量 $$ x $$ 使得 $$ r_A(x) &#x3D; \lambda_1 $$，即 $$ \lambda_1 $$ 是谱半径 $$ \rho(A) $$（最大特征值）。  </li>
<li><strong>唯一性</strong>：利用 <strong>不可约性</strong>，若存在两个不同的正特征向量对应 $$ \lambda_1 $$，则可通过线性组合构造矛盾，说明代数重数为1。  </li>
<li><strong>关键工具</strong>：Gelfand公式 $$ \rho(A) &#x3D; \lim_{k \to \infty} |A^k|^{1&#x2F;k} $$ 用于证明 $$ \lambda_1 $$ 的极值性。</li>
</ul>
<hr>
<h4 id="2-对应特征向量全为正且符号一致"><a href="#2-对应特征向量全为正且符号一致" class="headerlink" title="2. 对应特征向量全为正且符号一致"></a><strong>2. 对应特征向量全为正且符号一致</strong></h4><p><strong>核心思路</strong>：  </p>
<ul>
<li><strong>非负性到正性</strong>：若 $$ A $$ 不可约，其对应的特征向量 $$ v $$ 非负且非零。通过不可约性，$$ (I + A)^{n-1} $$ 会将任何非零向量映射为正向量，从而 $$ v $$ 必须全正。  </li>
<li><strong>符号一致性</strong>：假设存在分量符号不同，则通过矩阵的不可约性（连通性）推导矛盾，证明所有分量符号一致。</li>
</ul>
<hr>
<h4 id="3-其他特征值满足-lambda-i-lambda-1-2-leq-i-leq-n"><a href="#3-其他特征值满足-lambda-i-lambda-1-2-leq-i-leq-n" class="headerlink" title="3. 其他特征值满足 $$ |\lambda_i| &lt; \lambda_1 , (2 \leq i \leq n) $$"></a><strong>3. 其他特征值满足 $$ |\lambda_i| &lt; \lambda_1 , (2 \leq i \leq n) $$</strong></h4><p><strong>核心思路</strong>：  </p>
<ul>
<li><strong>周期性排除</strong>：若 $$ A $$ 非周期（本原矩阵），存在 $$ m $$ 使 $$ A^m $$ 为正矩阵，此时 $$ \lambda_i^m $$ 的模严格小于 $$ \lambda_1^m $$。  </li>
<li><strong>矛盾法</strong>：假设存在 $$ \lambda_j $$ 满足 $$ |\lambda_j| &#x3D; \lambda_1 $$，则通过复特征值的三角不等式与不可约性矛盾，证明 $$ |\lambda_j| &lt; \lambda_1 $$ 。</li>
</ul>
<hr>
<h2 id="Cheeger不等式与图的连通性度量"><a href="#Cheeger不等式与图的连通性度量" class="headerlink" title="Cheeger不等式与图的连通性度量"></a><strong>Cheeger不等式与图的连通性度量</strong></h2><h4 id="1-图的连通性与拉普拉斯矩阵特征值"><a href="#1-图的连通性与拉普拉斯矩阵特征值" class="headerlink" title="1. 图的连通性与拉普拉斯矩阵特征值"></a><strong>1. 图的连通性与拉普拉斯矩阵特征值</strong></h4><p>对于图 $$ G $$，其拉普拉斯矩阵 $$ L(G) $$ 的特征值满足 $$ 0 &#x3D; \lambda_1 \leq \lambda_2 \leq \cdots \leq \lambda_n $$。  </p>
<ul>
<li><strong>连通性判据</strong>：  <ul>
<li>$$ G $$ 是连通的 $$\iff \lambda_2 &gt; 0$$。  </li>
<li>$$ G $$ 不连通的 $$\iff \lambda_2 &#x3D; 0$$（此时零特征值的重数等于连通分量数）。</li>
</ul>
</li>
</ul>
<h4 id="2-传导率（Conductance）的定义"><a href="#2-传导率（Conductance）的定义" class="headerlink" title="2. 传导率（Conductance）的定义"></a><strong>2. 传导率（Conductance）的定义</strong></h4><p>传导率量化了图 $$ G $$ 的“接近不连通”程度：  </p>
<ul>
<li><strong>顶点子集 $$ S \subseteq V $$ 的传导率</strong>：<br>$$\phi(S) &#x3D; \frac{|\delta(S)|}{\text{vol}(S)}, \quad \text{vol}(S) &#x3D; \sum_{v \in S} \deg(v)$$<br>其中 $$ \delta(S) $$ 是 $$ S $$ 与补集 $$ V \setminus S $$ 之间的边集。  </li>
<li><strong>图的传导率</strong>：<br>$$\phi(G) &#x3D; \min_{S: \text{vol}(S) \leq m} \phi(S), \quad m &#x3D; \frac{1}{2}\text{vol}(V)$$<br>$$ \phi(G) $$ 越小，图越容易通过稀疏割（Sparse Cut）分离。</li>
</ul>
<h4 id="3-Cheeger不等式"><a href="#3-Cheeger不等式" class="headerlink" title="3. Cheeger不等式"></a><strong>3. Cheeger不等式</strong></h4><p>Cheeger不等式建立了 $$ \lambda_2 $$ 与 $$ \phi(G) $$ 的关系：<br>$$\frac{\lambda_2}{2} \leq \phi(G) \leq \sqrt{2 \lambda_2}$$<br><strong>解释</strong>：  </p>
<ul>
<li><strong>下界</strong>：若 $$ \lambda_2 $$ 小，则 $$ \phi(G) $$ 也小，表明存在稀疏割。  </li>
<li><strong>上界</strong>：传导率低时，$$ \lambda_2 $$ 必小，反映图接近不连通。</li>
</ul>
<h4 id="4-扩展图（Expander-Graph）与稀疏割"><a href="#4-扩展图（Expander-Graph）与稀疏割" class="headerlink" title="4. 扩展图（Expander Graph）与稀疏割"></a><strong>4. 扩展图（Expander Graph）与稀疏割</strong></h4><ul>
<li><strong>扩展图</strong>：$$ \phi(G) $$ 为常数（如 0.1），具有强连通性，常用于设计鲁棒网络。  </li>
<li><strong>稀疏割</strong>：$$ \phi(S) $$ 极小的子集 $$ S $$，对应图的分割瓶颈，应用于：  <ul>
<li><strong>图像分割</strong>：通过最小化传导率分离前景&#x2F;背景。  </li>
<li><strong>社区检测</strong>：识别社交网络中的紧密群体。  </li>
<li><strong>VLSI设计</strong>：优化电路布局以减少交叉干扰。</li>
</ul>
</li>
</ul>
<h2 id="Cheeger不等式"><a href="#Cheeger不等式" class="headerlink" title="Cheeger不等式"></a><strong>Cheeger不等式</strong></h2><p>是图论中一个重要的结果，它将图的展开性（通过Cheeger常数度量）与图的谱性质（通过拉普拉斯矩阵的特征值）联系起来。下面分步证明Cheeger不等式的两个方向，并特别关注归一化拉普拉斯矩阵与邻接矩阵的特征值关系。</p>
<hr>
<h3 id="基本定义与符号"><a href="#基本定义与符号" class="headerlink" title="基本定义与符号"></a><strong>基本定义与符号</strong></h3><ol>
<li><p><strong>图的基本矩阵</strong>：</p>
<ul>
<li>邻接矩阵 $$ A $$：元素 $$ A_{ij} $$ 表示顶点 $$ i $$ 和 $$ j $$ 之间的边数。</li>
<li>度矩阵 $$ D $$：对角矩阵，$$ D_{ii} &#x3D; \text{deg}(i) $$。</li>
<li><strong>归一化邻接矩阵</strong>：$$ \mathcal{A} &#x3D; D^{-1&#x2F;2} A D^{-1&#x2F;2} $$。</li>
<li><strong>归一化拉普拉斯矩阵</strong>：$$ \mathcal{L} &#x3D; D^{-1&#x2F;2} L D^{-1&#x2F;2} &#x3D; I - \mathcal{A} $$，其中 $$ L &#x3D; D - A $$ 是未归一化的拉普拉斯矩阵。</li>
</ul>
</li>
<li><p><strong>特征值约定</strong>：</p>
<ul>
<li>$$ \alpha_1 \geq \alpha_2 \geq \cdots \geq \alpha_n $$ 是 $$ \mathcal{A} $$ 的特征值。</li>
<li>$$ \lambda_1 \leq \lambda_2 \leq \cdots \leq \lambda_n $$ 是 $$ \mathcal{L} $$ 的特征值。</li>
<li>由于 $$ \mathcal{L} &#x3D; I - \mathcal{A} $$，有 $$ \lambda_i &#x3D; 1 - \alpha_i $$。</li>
</ul>
</li>
<li><p><strong>Cheeger常数</strong>：</p>
<ul>
<li>图的展开性由Cheeger常数 $$ \phi(G) $$ 度量，定义为：<br>$$\phi(G) &#x3D; \min_{S \subset V} \frac{|\partial S|}{\min(\text{vol}(S), \text{vol}(V \setminus S))},$$<br>其中 $$ \partial S $$ 是边界边集，$$ \text{vol}(S) &#x3D; \sum_{i \in S} \text{deg}(i) $$。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="简单方向（Easy-Direction）：-lambda-2-leq-2-phi-G"><a href="#简单方向（Easy-Direction）：-lambda-2-leq-2-phi-G" class="headerlink" title="简单方向（Easy Direction）：$$ \lambda_2 \leq 2\phi(G) $$"></a><strong>简单方向（Easy Direction）：$$ \lambda_2 \leq 2\phi(G) $$</strong></h3><p><strong>目标</strong>：证明第二小特征值 $$ \lambda_2 $$ 是Cheeger常数的上界，即 $$ \lambda_2 \leq 2\phi(G) $$。</p>
<p><strong>证明步骤</strong>：</p>
<ol>
<li><p><strong>变分刻画</strong>：</p>
<ul>
<li>$$ \lambda_2 $$ 可以表示为如下优化问题的极小值：<br>$$\lambda_2 &#x3D; \min_{x \perp D^{1&#x2F;2} \mathbf{1}} \frac{x^T \mathcal{L} x}{x^T x} &#x3D; \min_{x \perp D^{1&#x2F;2} \mathbf{1}} \frac{\sum_{(i,j) \in E} (x_i - x_j)^2}{\sum_{i \in V} x_i^2 \text{deg}(i)}.$$</li>
</ul>
</li>
<li><p><strong>构造测试向量</strong>：</p>
<ul>
<li>设 $$ S $$ 是使得 $$ \phi(S) &#x3D; \phi(G) $$ 的集合，定义向量 $$ x $$：<br>$$x_i &#x3D; \begin{cases}<br> 1&#x2F;\sqrt{\text{vol}(S)}, &amp; i \in S, \<br> -1&#x2F;\sqrt{\text{vol}(V \setminus S)}, &amp; i \notin S.<br>\end{cases}$$</li>
<li>验证 $$ x \perp D^{1&#x2F;2} \mathbf{1} $$，即 $$ \sum_{i} x_i \sqrt{\text{deg}(i)} &#x3D; 0 $$。</li>
</ul>
</li>
<li><p><strong>计算Rayleigh商</strong>：</p>
<ul>
<li>分子 $$ \sum_{(i,j) \in E} (x_i - x_j)^2 &#x3D; \frac{|\partial S|}{\text{vol}(S)} + \frac{|\partial S|}{\text{vol}(V \setminus S)} $$.</li>
<li>分母 $$ \sum_{i} x_i^2 \text{deg}(i) &#x3D; 2 $$.</li>
<li>因此：<br>$$\frac{x^T \mathcal{L} x}{x^T x} &#x3D; \frac{|\partial S|}{2} \left( \frac{1}{\text{vol}(S)} + \frac{1}{\text{vol}(V \setminus S)} \right) \leq 2\phi(G).$$</li>
</ul>
</li>
<li><p><strong>结论</strong>：</p>
<ul>
<li>由于 $$ \lambda_2 $$ 是所有满足条件的 $$ x $$ 中Rayleigh商的极小值，故 $$ \lambda_2 \leq 2\phi(G) $$。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="困难方向（Hard-Direction）：-phi-G-leq-sqrt-2-lambda-2"><a href="#困难方向（Hard-Direction）：-phi-G-leq-sqrt-2-lambda-2" class="headerlink" title="困难方向（Hard Direction）：$$ \phi(G) \leq \sqrt{2\lambda_2} $$"></a><strong>困难方向（Hard Direction）：$$ \phi(G) \leq \sqrt{2\lambda_2} $$</strong></h3><p><strong>目标</strong>：证明Cheeger常数被第二小特征值控制，即 $$ \phi(G) \leq \sqrt{2\lambda_2} $$。</p>
<p><strong>证明思路</strong>：<br>通过谱划分算法（Spectral Partitioning），利用 $$ \lambda_2 $$ 对应的特征向量构造一个集合 $$ S $$，使得其展开性不超过 $$ \sqrt{2\lambda_2} $$。</p>
<p><strong>证明步骤</strong>：</p>
<ol>
<li><p><strong>特征向量选择</strong>：</p>
<ul>
<li>设 $$ f $$ 是 $$ \mathcal{L} $$ 对应 $$ \lambda_2 $$ 的特征向量，满足 $$ f \perp D^{1&#x2F;2} \mathbf{1} $$。</li>
</ul>
</li>
<li><p><strong>排序与阈值化</strong>：</p>
<ul>
<li>将顶点按 $$ f_i $$ 的值升序排列：$$ f_1 \leq f_2 \leq \cdots \leq f_n $$.</li>
<li>定义阈值 $$ t $$，构造集合 $$ S_t &#x3D; {i | f_i \leq t} $$，寻找使 $$ \phi(S_t) $$ 最小的 $$ t $$。</li>
</ul>
</li>
<li><p><strong>利用中位数技巧</strong>：</p>
<ul>
<li>通过选择合适的中位数阈值 $$ t $$，保证 $$ \text{vol}(S_t) \geq \frac{1}{2}\text{vol}(V) $$ 且边界边数 $$ |\partial S_t| $$ 被控制。</li>
</ul>
</li>
<li><p><strong>估计边界边数</strong>：</p>
<ul>
<li>利用Cauchy-Schwarz不等式和特征向量的性质，有：<br>$$|\partial S_t| \leq \sqrt{2\lambda_2 \cdot \text{vol}(S_t) \cdot \text{vol}(V \setminus S_t)}.$$</li>
<li>结合 $$ \text{vol}(S_t) \geq \frac{1}{2}\text{vol}(V) $$，得到 $$ \phi(S_t) \leq \sqrt{2\lambda_2} $$。</li>
</ul>
</li>
<li><p><strong>结论</strong>：</p>
<ul>
<li>因此存在集合 $$ S $$ 使得 $$ \phi(G) \leq \sqrt{2\lambda_2} $$。</li>
</ul>
</li>
</ol>
<hr>
<h1 id="回到马尔科夫链"><a href="#回到马尔科夫链" class="headerlink" title="回到马尔科夫链"></a>回到马尔科夫链</h1><p>对于有限的连通无向图，随机游走的概率分布 $$ p_t &#x3D; \left( \frac{1}{2}I + \frac{1}{2}AD^{-1} \right)^t p_0 $$ 随时间演化最终收敛到稳态分布 $$ \frac{\vec{d}}{2m} $$，其中 $$ \vec{d} $$ 是度数向量，$$ m $$ 是图的边数。</p>
<hr>
<h3 id="1-转移矩阵的构造与性质"><a href="#1-转移矩阵的构造与性质" class="headerlink" title="1. 转移矩阵的构造与性质"></a><strong>1. 转移矩阵的构造与性质</strong></h3><p><strong>转移矩阵</strong> $$ P $$ 的表达式为：<br>$$P &#x3D; \frac{1}{2}I + \frac{1}{2}AD^{-1}$$</p>
<ul>
<li><strong>物理意义</strong>：这是一个<strong>懒惰随机游走</strong>（Lazy Random Walk）的转移矩阵。每一步有 $$ \frac{1}{2} $$ 的概率停留在当前节点，$$ \frac{1}{2} $$ 的概率按传统无偏随机游走（TURW）的规则转移到邻居节点。</li>
<li><strong>作用</strong>：引入停留概率后，转移矩阵 $$ P $$ 的马尔可夫链变为<strong>非周期</strong>的，从而保证收敛性（传统随机游走可能是周期性的，导致不收敛）。</li>
</ul>
<hr>
<h3 id="2-稳态分布的存在性"><a href="#2-稳态分布的存在性" class="headerlink" title="2. 稳态分布的存在性"></a><strong>2. 稳态分布的存在性</strong></h3><p>对于连通无向图，随机游走的稳态分布 $$ \pi $$ 需满足：<br>$$\pi &#x3D; \pi P$$<br>代入 $$ P $$ 的表达式，展开可得：<br>$$\pi &#x3D; \frac{1}{2}\pi I + \frac{1}{2}\pi AD^{-1}$$<br>由于 $$ \pi I &#x3D; \pi $$，化简后得到：<br>$$\pi &#x3D; \pi AD^{-1}$$<br>这表明稳态分布 $$ \pi $$ 也是传统无偏随机游走（TURW）的稳态分布。根据经典结论，TURW的稳态分布与节点度数成正比：<br>$$\pi_i &#x3D; \frac{d_i}{2m}$$<br>其中 $$ d_i $$ 是节点 $$ i $$ 的度数，$$ m $$ 是图的边数。</p>
<hr>
<h3 id="3-收敛性证明"><a href="#3-收敛性证明" class="headerlink" title="3. 收敛性证明"></a><strong>3. 收敛性证明</strong></h3><p><strong>条件</strong>：图是<strong>连通</strong>且<strong>非周期</strong>的。</p>
<ul>
<li><strong>连通性</strong>：保证马尔可夫链是<strong>不可约</strong>的，即任意状态可达。</li>
<li><strong>非周期性</strong>：通过懒惰随机游走的停留概率实现，避免了周期性震荡。</li>
</ul>
<p><strong>谱分析</strong>：</p>
<ul>
<li>转移矩阵 $$ P $$ 的特征值满足 $$ |\lambda| \leq 1 $$，其中最大特征值为 $$ \lambda_1 &#x3D; 1 $$，对应稳态分布 $$ \frac{\vec{d}}{2m} $$。</li>
<li>其他特征值 $$ \lambda_2, \ldots, \lambda_n $$ 满足 $$ |\lambda_i| &lt; 1 $$，当 $$ t \to \infty $$ 时，它们的贡献衰减为零。</li>
</ul>
<p><strong>初始分布的分解</strong>：<br>将初始分布 $$ p_0 $$ 表示为 $$ P $$ 的特征向量线性组合：<br>$$p_0 &#x3D; c_1 \pi + \sum_{i&#x3D;2}^n c_i v_i$$<br>其中 $$ v_i $$ 是对应特征值 $$ \lambda_i $$ 的特征向量。经过 $$ t $$ 步迭代后：<br>$$p_t &#x3D; P^t p_0 &#x3D; c_1 \pi + \sum_{i&#x3D;2}^n c_i \lambda_i^t v_i$$<br>当 $$ t \to \infty $$ 时，第二项趋近于零，因此 $$ p_t \to \pi &#x3D; \frac{\vec{d}}{2m} $$。</p>
<hr>
<h3 id="定理及证明步骤详解"><a href="#定理及证明步骤详解" class="headerlink" title="定理及证明步骤详解"></a>定理及证明步骤详解</h3><h4 id="定理陈述"><a href="#定理陈述" class="headerlink" title="定理陈述"></a><strong>定理陈述</strong></h4><p>对有限连通无向图的随机游走，其ε-混合时间上界为：<br>$$t_{\text{mix}}(\epsilon) \leq \frac{1}{\lambda} \log\left(\frac{n}{\epsilon}\right),$$<br>其中 $$\lambda &#x3D; \min{1 - \alpha_2, 1 - |\alpha_n|}$$，$$\alpha_2$$ 和 $$\alpha_n$$ 分别是归一化转移矩阵的第二大和最小特征值。</p>
<hr>
<h3 id="证明步骤详解"><a href="#证明步骤详解" class="headerlink" title="证明步骤详解"></a><strong>证明步骤详解</strong></h3><h4 id="1-特征向量分解与转移矩阵展开"><a href="#1-特征向量分解与转移矩阵展开" class="headerlink" title="1. 特征向量分解与转移矩阵展开"></a><strong>1. 特征向量分解与转移矩阵展开</strong></h4><p>假设转移矩阵 $$W$$ 对应的归一化邻接矩阵 $$\mathcal{A}$$ 具有正交正规特征向量基 $${v_1, v_2, \ldots, v_n}$$，对应的特征值为 $$\alpha_1 \geq \alpha_2 \geq \cdots \geq \alpha_n$$。对于初始分布 $$p_0$$，可分解为：<br>$$p_0 &#x3D; c_1 v_1 + c_2 v_2 + \cdots + c_n v_n,$$<br>其中 $$v_1$$ 对应稳态分布 $$\pi$$（即 $$\alpha_1 &#x3D; 1$$）。经过 $$t$$ 步转移后，分布为：<br>$$p_t &#x3D; W^t p_0 &#x3D; c_1 \alpha_1^t v_1 + c_2 \alpha_2^t v_2 + \cdots + c_n \alpha_n^t v_n.$$<br>由于稳态分布 $$\pi &#x3D; c_1 v_1$$，偏差项为：<br>$$p_t - \pi &#x3D; \sum_{i&#x3D;2}^n c_i \alpha_i^t v_i.$$</p>
<p><strong>关键点</strong>：  </p>
<ul>
<li>特征向量分解将随机游走的演化分解为稳态项与衰减项的组合。</li>
<li>稳态对应的特征值 $$\alpha_1 &#x3D; 1$$，非稳态特征值满足 $$|\alpha_i| &lt; 1$$，因此衰减项随 $$t$$ 指数消失。</li>
</ul>
<hr>
<h4 id="2-范数转换：L1-到-L2-范数"><a href="#2-范数转换：L1-到-L2-范数" class="headerlink" title="2. 范数转换：L1 到 L2 范数"></a><strong>2. 范数转换：L1 到 L2 范数</strong></h4><p>通过 <strong>Cauchy-Schwarz 不等式</strong>，将总变差距离（L1 范数）转换为 L2 范数：<br>$$|p_t - \pi|_1 \leq \sqrt{n} |p_t - \pi|_2,$$<br>其中 $$\sqrt{n}$$ 的因子源于向量的维度 $$n$$（即图的顶点数）。<br><strong>推导逻辑</strong>：  </p>
<ul>
<li>L1 范数定义为 $$|x|_1 &#x3D; \sum_i |x_i|$$，L2 范数为 $$|x|_2 &#x3D; \sqrt{\sum_i x_i^2}$$。</li>
<li>由 Cauchy-Schwarz 不等式可得 $$|x|_1 \leq \sqrt{n} |x|_2$$，这是因为每个分量 $$|x_i|$$ 的绝对值之和被 $$\sqrt{n}$$ 和 L2 范数控制。</li>
</ul>
<hr>
<h4 id="3-计算-L2-范数的平方"><a href="#3-计算-L2-范数的平方" class="headerlink" title="3. 计算 L2 范数的平方"></a><strong>3. 计算 L2 范数的平方</strong></h4><p>展开偏差项的 L2 范数平方：<br>$$|p_t - \pi|<em>2^2 &#x3D; \left|\sum</em>{i&#x3D;2}^n c_i \alpha_i^t v_i \right|<em>2^2 &#x3D; \sum</em>{i&#x3D;2}^n c_i^2 \alpha_i^{2t},$$<br>由于特征向量正交且单位化（$$|v_i|_2 &#x3D; 1$$），交叉项消失，仅剩对角项。</p>
<p><strong>关键观察</strong>：  </p>
<ul>
<li>特征值的衰减速率由 $$|\alpha_i|$$ 决定。定义 $$\lambda &#x3D; \min{1 - \alpha_2, 1 - |\alpha_n|}$$，则对所有 $$i \geq 2$$，有 $$|\alpha_i| \leq 1 - \lambda$$。</li>
<li>因此，平方和可进一步上界为：<br>$$\sum_{i&#x3D;2}^n c_i^2 \alpha_i^{2t} \leq (1 - \lambda)^{2t} \sum_{i&#x3D;2}^n c_i^2.$$</li>
</ul>
<hr>
<h4 id="4-初始分布的-L2-范数约束"><a href="#4-初始分布的-L2-范数约束" class="headerlink" title="4. 初始分布的 L2 范数约束"></a><strong>4. 初始分布的 L2 范数约束</strong></h4><p>由于 $$p_0$$ 是概率分布（$$\sum_i p_0(i) &#x3D; 1$$），其 L2 范数满足：<br>$$|p_0|<em>2^2 &#x3D; \sum</em>{i&#x3D;1}^n p_0(i)^2 \leq \sum_{i&#x3D;1}^n p_0(i) &#x3D; 1.$$<br>结合特征分解 $$p_0 &#x3D; \sum_{i&#x3D;1}^n c_i v_i$$，正交性条件给出：<br>$$\sum_{i&#x3D;1}^n c_i^2 &#x3D; |p_0|<em>2^2 \leq 1 \quad \Rightarrow \quad \sum</em>{i&#x3D;2}^n c_i^2 \leq 1.$$<br>因此，偏差的 L2 范数平方满足：<br>$$|p_t - \pi|_2^2 \leq (1 - \lambda)^{2t}.$$</p>
<hr>
<h4 id="5-指数衰减与混合时间推导"><a href="#5-指数衰减与混合时间推导" class="headerlink" title="5. 指数衰减与混合时间推导"></a><strong>5. 指数衰减与混合时间推导</strong></h4><p>结合 L1 范数的上界和指数衰减公式：<br>$$|p_t - \pi|<em>1 \leq \sqrt{n} \cdot (1 - \lambda)^t \leq \sqrt{n} \cdot e^{-\lambda t},$$<br>这里利用了不等式 $$1 - x \leq e^{-x}$$。<br>要求总变差距离小于等于 $$\epsilon$$，即：<br>$$\sqrt{n} e^{-\lambda t} \leq \epsilon \quad \Rightarrow \quad t \geq \frac{1}{\lambda} \log\left(\frac{\sqrt{n}}{\epsilon}\right) &#x3D; \frac{1}{2\lambda} \log\left(\frac{n}{\epsilon^2}\right).$$<br>最终简化得到混合时间上界：<br>$$t</em>{\text{mix}}(\epsilon) \leq \frac{1}{\lambda} \log\left(\frac{n}{\epsilon}\right).$$</p>
<hr>
<h3 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a><strong>补充说明</strong></h3><h4 id="正则图与非正则图的区别"><a href="#正则图与非正则图的区别" class="headerlink" title="正则图与非正则图的区别"></a><strong>正则图与非正则图的区别</strong></h4><ul>
<li><strong>正则图</strong>：若图是 $$d$$-正则的，归一化邻接矩阵为 $$\mathcal{A} &#x3D; \frac{1}{d} A$$，其稳态分布均匀，特征向量基可直接构造，损失因子 $$\sqrt{n}$$ 可优化为常数。</li>
<li><strong>非正则图</strong>：需使用归一化拉普拉斯矩阵 $$\mathcal{L} &#x3D; I - D^{-1&#x2F;2} A D^{-1&#x2F;2}$$ 的特征向量基，此时正交性条件可能引入额外因子 $$\sqrt{n}$$，导致混合时间上界略松。</li>
</ul>
<hr>
<h4 id="谱间隙的意义"><a href="#谱间隙的意义" class="headerlink" title="谱间隙的意义"></a><strong>谱间隙的意义</strong></h4><ul>
<li><strong>谱间隙 $$\lambda$$</strong>：决定了随机游走的收敛速度。当 $$\lambda &#x3D; \Omega(1)$$（常数级别），混合时间为 $$O(\log n)$$，适用于扩展图（如正则图）。</li>
<li><strong>实际应用</strong>：在社交网络或推荐系统中，若图具有强扩展性（大谱间隙），随机游走可在对数步长内均匀采样节点。</li>
</ul>
<hr>
<h2 id="谱图理论中的连通性与谱性质"><a href="#谱图理论中的连通性与谱性质" class="headerlink" title="谱图理论中的连通性与谱性质"></a><strong>谱图理论中的连通性与谱性质</strong></h2><h4 id="1-图的连通性与谱的关系"><a href="#1-图的连通性与谱的关系" class="headerlink" title="1. 图的连通性与谱的关系"></a><strong>1. 图的连通性与谱的关系</strong></h4><ol>
<li><p><strong>第二小特征值（$$\lambda_2$$）与连通性</strong>  </p>
<ul>
<li><strong>定理</strong>：对于图的归一化拉普拉斯矩阵 $$\mathcal{L}$$，其第二小特征值 $$\lambda_2$$ 满足：<br>$$\lambda_2 \text{ 非常小} \iff G \text{ 接近于不连通（存在稀疏割）}.$$</li>
<li><strong>解释</strong>：  <ul>
<li>$$\lambda_2$$ 称为<strong>代数连通度</strong>（Algebraic Connectivity），反映图的“分割难度”。  </li>
<li>若 $$\lambda_2 \approx 0$$，说明存在一个割 $$(S, V \setminus S)$$ 使得边界边数 $$|\partial S|$$ 远小于 $$\min(\text{vol}(S), \text{vol}(V \setminus S))$$，即图几乎可被分成两个弱连接的子图。  </li>
<li><strong>例子</strong>：在“哑铃图”（两个稠密子图通过单边连接）中，$$\lambda_2 \approx 0$$。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>第 $$k$$ 小特征值（$$\lambda_k$$）与多分量连通性</strong>  </p>
<ul>
<li><strong>推广定理</strong>：<br>$$\lambda_k \text{ 非常小} \iff G \text{ 接近于有 } k \text{ 个连通分量（存在 } k \text{ 个稀疏分割）}.$$</li>
<li><strong>解释</strong>：  <ul>
<li>$$\lambda_k$$ 接近零时，图可被划分为 $$k$$ 个几乎不交互的子集，每个子集内部稠密，子集间边稀疏。  </li>
<li><strong>应用</strong>：谱聚类（Spectral Clustering）利用 $$\lambda_k$$ 对应的特征向量将图划分为 $$k$$ 个社区。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h4 id="2-算法与构造中的应用"><a href="#2-算法与构造中的应用" class="headerlink" title="2. 算法与构造中的应用"></a><strong>2. 算法与构造中的应用</strong></h4><ol>
<li><p><strong>谱分割算法</strong>  </p>
<ul>
<li><strong>步骤</strong>：  <ol>
<li>计算拉普拉斯矩阵 $$\mathcal{L}$$ 的前 $$k$$ 个特征向量 $$v_1, v_2, \ldots, v_k$$。  </li>
<li>将顶点嵌入到 $$\mathbb{R}^k$$ 空间，坐标由特征向量分量决定。  </li>
<li>使用 $$k$$-means 等聚类方法划分顶点。</li>
</ol>
</li>
<li><strong>理论依据</strong>：特征向量的分量差异对应图中的稀疏割。</li>
</ul>
</li>
<li><p><strong>扩展图（Expander Graph）的代数构造</strong>  </p>
<ul>
<li><strong>定义</strong>：扩展图是高度连通的稀疏图，满足对所有子集 $$S$$，$$|\partial S| \geq \epsilon |S|$$（常数 $$\epsilon &gt; 0$$）。  </li>
<li><strong>谱性质</strong>：扩展图的谱间隙 $$\lambda_2$$ 远离零（$$\lambda_2 &#x3D; \Omega(1)$$）。  </li>
<li><strong>构造方法</strong>：  <ul>
<li>通过有限域、群论等代数工具显式构造。  </li>
<li>例如：Ramanujan 图的 $$\lambda_2 \geq 1 - 2\sqrt{d-1}&#x2F;d$$（接近最优）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h4 id="3-随机游走混合时间的谱分析"><a href="#3-随机游走混合时间的谱分析" class="headerlink" title="3. 随机游走混合时间的谱分析"></a><strong>3. 随机游走混合时间的谱分析</strong></h4><ol>
<li><p><strong>混合时间与谱间隙</strong>  </p>
<ul>
<li><strong>定理</strong>：懒惰随机游走的 $$\epsilon$$-混合时间满足：<br>$$t_{\text{mix}}(\epsilon) \leq \frac{1}{\lambda} \log\left(\frac{n}{\epsilon}\right), \quad \lambda &#x3D; \min{1 - \alpha_2, 1 - |\alpha_n|},$$<br>其中 $$\alpha_2$$ 是归一化邻接矩阵的第二大特征值。  </li>
<li><strong>关键步骤</strong>：  <ul>
<li>将初始分布 $$p_0$$ 投影到特征向量基，衰减项由 $$|\alpha_i|^t$$ 控制。  </li>
<li>谱间隙 $$\lambda$$ 越大，衰减越快，混合时间越短。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>组合数学与谱间隙的关联</strong>  </p>
<ul>
<li><strong>Cheeger 不等式</strong>：<br>$$\frac{\lambda_2}{2} \leq \phi(G) \leq \sqrt{2\lambda_2},$$<br>其中 $$\phi(G)$$ 是 Cheeger 常数（图的展开性）。  </li>
<li><strong>推论</strong>：  <ul>
<li>高扩展性（$$\phi(G)$$ 大）$$\implies$$ 大谱间隙（$$\lambda_2$$ 大）$$\implies$$ 快速混合（$$t_{\text{mix}}$$ 小）。  </li>
<li>例如：在 $$d$$-正则扩展图中，随机游走可在 $$O(\log n)$$ 步内接近均匀分布。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="总结表格"><a href="#总结表格" class="headerlink" title="总结表格"></a><strong>总结表格</strong></h3><table>
<thead>
<tr>
<th><strong>概念</strong></th>
<th><strong>数学描述</strong></th>
<th><strong>应用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td>代数连通度 ($$\lambda_2$$)</td>
<td>$$\lambda_2 \approx 0 \iff G$$ 有稀疏割</td>
<td>社区检测、图分割</td>
</tr>
<tr>
<td>第 $$k$$ 小特征值 ($$\lambda_k$$)</td>
<td>$$\lambda_k \approx 0 \iff G$$ 有 $$k$$ 个稀疏分割</td>
<td>谱聚类（划分 $$k$$ 个社区）</td>
</tr>
<tr>
<td>扩展图</td>
<td>$$\lambda_2 \geq \epsilon &gt; 0$$</td>
<td>伪随机性构造、纠错码设计</td>
</tr>
<tr>
<td>混合时间</td>
<td>$$t_{\text{mix}} \propto \frac{1}{\lambda} \log n$$</td>
<td>马尔可夫链蒙特卡洛（MCMC）采样</td>
</tr>
</tbody></table>
<hr>
<h3 id="进一步研究方向"><a href="#进一步研究方向" class="headerlink" title="进一步研究方向"></a><strong>进一步研究方向</strong></h3><ol>
<li><strong>高阶 Cheeger 不等式</strong>：研究 $$\lambda_k$$ 与多路分割（Multiway Partition）的关系。  </li>
<li><strong>动态图的谱分析</strong>：如何快速更新特征值&#x2F;向量以适应图结构的动态变化。  </li>
<li><strong>非线性谱方法</strong>：基于图神经网络的连通性分析与聚类。</li>
</ol>
<p>通过谱理论，我们得以将图的组合性质（如连通性）与代数性质（如特征值）深度关联，为算法设计与理论分析提供统一框架。</p>
<p>Thinking… (1s elapsed)中文推导与讲解<br>$$\frac{\lambda_2}{2};\le; \phi(G); \le; \sqrt{2,\lambda_2}$$</p>
<p>下面分三部分说明：  </p>
<ol>
<li>预备概念与符号  </li>
<li>易方向（上界）：$$\lambda_2\le 2\phi(G)$$  </li>
<li>难方向（下界）：$$\phi(G)\le \sqrt{2\lambda_2}$$</li>
</ol>
<hr>
<h2 id="1-预备概念与符号"><a href="#1-预备概念与符号" class="headerlink" title="1. 预备概念与符号"></a>1. 预备概念与符号</h2><ol>
<li><p>图与体积<br>• 图 $$G&#x3D;(V,E)$$ 无向、带权，边权记 $$w_{ij}&#x3D;w_{ji}\ge 0$$。<br>• 顶点度数 $$\deg(i)&#x3D;\sum_j w_{ij}$$。<br>• 体积 $$\operatorname{vol}(S)&#x3D;\sum_{i\in S}\deg(i)$$。</p>
</li>
<li><p>切割边数与扩张率（也称 conductance）<br>• 切割 $$\partial S&#x3D;{(i,j)\in E\mid i\in S,j\notin S}$$。<br>• 扩张率<br>  $$\phi(S)&#x3D;\frac{w(\partial S)}{\min\bigl(\operatorname{vol}(S),\operatorname{vol}(V!\setminus!S)\bigr)},\qquad<br>  \phi(G)&#x3D;\min_{S\subset V}\phi(S).$$</p>
</li>
<li><p>归一化拉普拉斯<br>• 记 $$D&#x3D;\operatorname{diag}(\deg(i))$$，$$A&#x3D;(w_{ij})$$。<br>• 归一化拉普拉斯 $$\mathcal L &#x3D; I - D^{-1&#x2F;2} A D^{-1&#x2F;2}$$。<br>• 其特征值 $$0&#x3D;\lambda_1\le \lambda_2\le\dots\le\lambda_n$$。<br>• 瑞利商<br>  $$\lambda_2&#x3D;\min_{\substack{x\neq 0\x\perp D^{1&#x2F;2}\mathbf 1}}<br>  \frac{x^\top \mathcal L x}{x^\top x},<br>  \qquad<br>  x^\top \mathcal L x&#x3D;\frac12\sum_{(i,j)\in E}w_{ij}\Bigl(\tfrac{x_i}{\sqrt{\deg(i)}}-\tfrac{x_j}{\sqrt{\deg(j)}}\Bigr)^2.$$</p>
</li>
</ol>
<hr>
<h2 id="2-易方向：-lambda-2-le-2-phi-G"><a href="#2-易方向：-lambda-2-le-2-phi-G" class="headerlink" title="2. 易方向：$$\lambda_2\le 2\phi(G)$$"></a>2. 易方向：$$\lambda_2\le 2\phi(G)$$</h2><h3 id="2-1-思路"><a href="#2-1-思路" class="headerlink" title="2.1 思路"></a>2.1 思路</h3><p>要给 $$\lambda_2$$ 找一个<strong>试探向量</strong> $$x$$，把它代入瑞利商即可得到一个上界。<br>最自然的向量是某个切割的指示函数：<br>$$g_i&#x3D;1$$ 若 $$i\in S$$，$$g_i&#x3D;-1$$ 否则。<br>但瑞利商要求 $$x\perp D^{1&#x2F;2}\mathbf1$$。<br>只需把 $$g$$ 左乘 $$D^{-1&#x2F;2}$$ 就能自动满足正交：<br>$$x&#x3D;D^{-1&#x2F;2}g.$$</p>
<h3 id="2-2-计算瑞利商"><a href="#2-2-计算瑞利商" class="headerlink" title="2.2 计算瑞利商"></a>2.2 计算瑞利商</h3><ol>
<li><p>分母<br>$$x^\top x &#x3D; \sum_{i}\frac{g_i^{,2}}{\deg(i)} &#x3D;<br>\sum_{i}\frac{1}{\deg(i)}<br>&#x3D;\sum_{i\in S}\frac{1}{\deg(i)}+\sum_{i\notin S}\frac{1}{\deg(i)},$$<br>这个量不会与边界项混在一起，保持原样即可。</p>
</li>
<li><p>分子（二次型）<br>$$x^\top!\mathcal Lx<br>&#x3D;\frac12!\sum_{(i,j)} w_{ij}\Bigl(<br>\tfrac{g_i}{\sqrt{\deg(i)}}-\tfrac{g_j}{\sqrt{\deg(j)}}\Bigr)^2.$$<br>只有在 $$g_i\neq g_j$$（即边跨越切割）时该项非零，且差值绝对值为<br>$$\frac1{\sqrt{\deg(i)}}+\frac1{\sqrt{\deg(j)}}$$。<br>因此<br>$$x^\top!\mathcal Lx<br>   &#x3D;\frac12\sum_{(i,j)\in\partial S} w_{ij}<br> \Bigl(\tfrac1{\sqrt{\deg(i)}}+\tfrac1{\sqrt{\deg(j)}}\Bigr)^{!2}.$$</p>
</li>
<li><p>估计<br>用基本不等式 $$(a+b)^2\le 2(a^2+b^2)$$：<br>$$\Bigl(\tfrac1{\sqrt{\deg(i)}}+\tfrac1{\sqrt{\deg(j)}}\Bigr)^{2}<br>   \le 2\Bigl(\tfrac1{\deg(i)}+\tfrac1{\deg(j)}\Bigr).$$<br>于是<br>$$x^\top!\mathcal Lx<br>   \le \sum_{(i,j)\in\partial S} w_{ij}<br>   \Bigl(\tfrac1{\deg(i)}+\tfrac1{\deg(j)}\Bigr)<br>   &#x3D;\sum_{i\in S}\frac{w(\partial{i})}{\deg(i)}<br>+\sum_{j\notin S}\frac{w(\partial{j})}{\deg(j)}.$$<br>而<br>$$w(\partial{i})\le\deg(i)$$，故<br>$$x^\top!\mathcal Lx\le |\partial S|.$$</p>
</li>
<li><p>组合分子分母<br>$$\frac{x^\top\mathcal Lx}{x^\top x}<br>\le<br>\frac{|\partial S|}{\min(\operatorname{vol}(S),\operatorname{vol}(V!\setminus!S))}<br>&#x3D;\phi(S);\le;\phi(G).$$<br>再用系数 2 的松弛（去掉上一步的 2 倍常数不等式损失）即可：<br>$$\lambda_2\le 2,\phi(G).$$</p>
</li>
</ol>
<h3 id="2-3-关键改动"><a href="#2-3-关键改动" class="headerlink" title="2.3 关键改动"></a>2.3 关键改动</h3><p>原错误把<br>$$|\partial S|(\frac1{\sqrt{\operatorname{vol}(S)}}+\frac1{\sqrt{\operatorname{vol}(V\setminus S)}})^2$$<br>当成二次型，没有正确考虑每条边两端度数不同。<br>改用 <strong>指示向量 + 逐边展开</strong> 后，完全避免了平均度数假设。</p>
<hr>
<h2 id="3-难方向：-phi-G-le-sqrt-2-lambda-2"><a href="#3-难方向：-phi-G-le-sqrt-2-lambda-2" class="headerlink" title="3. 难方向：$$\phi(G)\le\sqrt{2\lambda_2}$$"></a>3. 难方向：$$\phi(G)\le\sqrt{2\lambda_2}$$</h2><p>思路：利用 $$\lambda_2$$ 的特征向量 $$f$$，把标量值扫阈 (sweep)，总会遇到一个阈值 cut 具有小扩张率。核心工具是离散 <strong>Co-area 公式</strong>。</p>
<h3 id="3-1-特征向量预处理"><a href="#3-1-特征向量预处理" class="headerlink" title="3.1 特征向量预处理"></a>3.1 特征向量预处理</h3><p>取满足<br>$$f\perp D^{1&#x2F;2}\mathbf1$$、$$f^\top f&#x3D;1$$ 的 $$\lambda_2$$ 特征向量。<br>令<br>$$h_i&#x3D;\frac{f_i}{\sqrt{\deg(i)}}\quad(i&#x3D;1,\dots,n).$$<br>按 $$h_i$$ 从小到大排序：<br>$$h_{(1)}\le h_{(2)}\le\dots\le h_{(n)}$$。</p>
<h3 id="3-2-Sweep-cut-定义"><a href="#3-2-Sweep-cut-定义" class="headerlink" title="3.2 Sweep cut 定义"></a>3.2 Sweep cut 定义</h3><p>对每个阈值 $$t\in\mathbb R$$ 定<br>$$S_t&#x3D;{,i\mid h_i\le t\ }$$。<br>当 $$t$$ 连续增大，$$S_t$$ 从空集逐渐扩张到全体顶点。</p>
<h3 id="3-3-离散-Co-area-公式"><a href="#3-3-离散-Co-area-公式" class="headerlink" title="3.3 离散 Co-area 公式"></a>3.3 离散 Co-area 公式</h3><p>$$\int_{-\infty}^{+\infty} w(\partial S_t),dt<br>   &#x3D;\frac12!\sum_{(i,j)\in E}w_{ij}|h_i-h_j|.$$</p>
<p>平方并用 Cauchy–Schwarz：<br>$$\Bigl(\int w(\partial S_t),dt\Bigr)^{2}<br>\le \Bigl(\sum_{(i,j)}w_{ij}(h_i-h_j)^2\Bigr)<br>     \Bigl(\sum_{(i,j)}w_{ij}\Bigr).$$</p>
<p>第一括号就是 $$2\lambda_2$$（由瑞利商），第二括号是 $$\operatorname{vol}(V)$$。<br>于是存在某个 $$t$$ 使<br>$$w(\partial S_t)<br>\le<br>\sqrt{2\lambda_2,\operatorname{vol}(V)};<br> \bigl(\sup_{t}\mu(t)\bigr)^{-1},$$<br>其中 $$\mu(t)&#x3D;\min\bigl(\operatorname{vol}(S_t),\operatorname{vol}(V\setminus S_t)\bigr)$$。</p>
<h3 id="3-4-选取“平衡”阈值"><a href="#3-4-选取“平衡”阈值" class="headerlink" title="3.4 选取“平衡”阈值"></a>3.4 选取“平衡”阈值</h3><p>因为 $$f\perp D^{1&#x2F;2}\mathbf1$$，<br>$$\sum_i\deg(i)h_i&#x3D;0$$。<br>故 $$h_i$$ 的加权中位数使两边体积各至少半数。<br>取此 $$t$$ 便有<br>$$\mu(t)\ge \tfrac12\operatorname{vol}(V)$$。</p>
<p>带回不等式：<br>$$\phi(S_t)&#x3D;\frac{w(\partial S_t)}{\mu(t)}<br>\le<br>\sqrt{2\lambda_2}.$$<br>于是<br>(<br>\phi(G)\le\sqrt{2\lambda_2}.<br>)</p>
<h3 id="3-5-关键修正"><a href="#3-5-关键修正" class="headerlink" title="3.5 关键修正"></a>3.5 关键修正</h3><ol>
<li>明确写出离散 Co-area，而不是“把和看成积分”。  </li>
<li>使用中位数保证体积平衡，而不是模糊地说“总能找到一个好阈值”。  </li>
<li>每一步都保留常数因子，最终得到 $$\sqrt{2}$$ 而非错误的 $$\sqrt{\lambda_2}$$ 或 $$2\sqrt{\lambda_2}$$。</li>
</ol>
<hr>
<h2 id="4-逻辑链条回顾"><a href="#4-逻辑链条回顾" class="headerlink" title="4. 逻辑链条回顾"></a>4. 逻辑链条回顾</h2><ol>
<li>定义所有量（$$\mathcal L,\lambda_2,\phi$$）。  </li>
<li>易方向：<br>• 构造满足正交条件的测试向量。<br>• 逐边展开瑞利商避免度数混淆。<br>• 直接与 $$\phi(G)$$ 比较，得到 $$\lambda_2\le 2\phi(G)$$。  </li>
<li>难方向：<br>• 取特征向量 → 排序 → 阈值分割。<br>• Co-area 公式把“总差额”换成阈值族的“切割量积分”。<br>• Cauchy–Schwarz 找到某个阈值 cut，结合中位数平衡体积。<br>• 得到 $$\phi(G)\le\sqrt{2\lambda_2}$$。</li>
</ol>
<p>至此两向合并，即得 Cheeger 不等式<br>$$\frac{\lambda_2}{2};\le; \phi(G); \le; \sqrt{2,\lambda_2}.$$</p>
<hr>
<h2 id="5-小结与启示"><a href="#5-小结与启示" class="headerlink" title="5. 小结与启示"></a>5. 小结与启示</h2><ul>
<li>左边界说明：若图有窄瓶颈，$$\lambda_2$$ 必然跟着小。  </li>
<li>右边界给出：只要 $$\lambda_2$$ 小，确实能从特征向量里“扫”出小扩张率切割。  </li>
<li>算法视角：用 Fiedler 向量做 sweep cut 就可近似找到良好社区。  </li>
<li>校正点：任何忽略顶点度数或跳过积分—阈值论证的证明，都可能给出错误常数或乃至错误结论。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/noteSVD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes.github.io/images/woshicaigou.jpg">
      <meta itemprop="name" content="Chen Zhan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cz Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/notes.github.io/2025/06/23/noteSVD/" class="post-title-link" itemprop="url">noteSVD</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-23 18:56:58" itemprop="dateCreated datePublished" datetime="2025-06-23T18:56:58+08:00">2025-06-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h3><p>设 $$ A &#x3D; U \Sigma V^* $$ 是 $$ A \in \mathbb{C}^{m \times n} $$ ( $$ m \geq n $$ ) 的奇异值分解，则：</p>
<h4 id="1-A-A-的特征值是-sigma-i-2-，对应的特征向量是-v-i"><a href="#1-A-A-的特征值是-sigma-i-2-，对应的特征向量是-v-i" class="headerlink" title="(1) $$ A^*A $$ 的特征值是 $$ \sigma_i^2 $$，对应的特征向量是 $$ v_i $$"></a>(1) $$ A^*A $$ 的特征值是 $$ \sigma_i^2 $$，对应的特征向量是 $$ v_i $$</h4><p>证明：</p>
<ul>
<li>我们有 $$ A^* A &#x3D; (U \Sigma V^<em>)^</em> (U \Sigma V^<em>) &#x3D; V \Sigma^</em> U^* U \Sigma V^* &#x3D; V \Sigma^2 V^* $$。</li>
<li>由于 $$ U^* U &#x3D; I $$，所以 $$ A^* A &#x3D; V \Sigma^2 V^* $$。</li>
<li>因此，$$ A^* A $$ 的特征值为 $$ \sigma_i^2 $$，对应的特征向量为 $$ v_i $$。</li>
</ul>
<h4 id="2-AA-的特征值是-sigma-i-2-和-m-n-个零，对应的特征向量是-u-i"><a href="#2-AA-的特征值是-sigma-i-2-和-m-n-个零，对应的特征向量是-u-i" class="headerlink" title="(2) $$ AA^* $$ 的特征值是 $$ \sigma_i^2 $$ 和 $$ m-n $$ 个零，对应的特征向量是 $$ u_i $$"></a>(2) $$ AA^* $$ 的特征值是 $$ \sigma_i^2 $$ 和 $$ m-n $$ 个零，对应的特征向量是 $$ u_i $$</h4><p>证明：</p>
<ul>
<li>我们有 $$ AA^* &#x3D; (U \Sigma V^<em>)(U \Sigma V^</em>)^* &#x3D; U \Sigma V^* V \Sigma^* U^* &#x3D; U \Sigma \Sigma^* U^* $$。</li>
<li>由于 $$ V^* V &#x3D; I_n $$，所以 $$ AA^* &#x3D; U \Sigma \Sigma^* U^* $$。</li>
<li>注意到 $$ \Sigma $$ 是一个 $$ n \times n $$ 的对角矩阵，且只有 $$ r $$ 个非零对角元素，因此 $$ AA^* $$ 的特征值为 $$ \sigma_i^2 $$ 和 $$ m-n $$ 个零，对应的特征向量为 $$ u_i $$。</li>
</ul>
<h4 id="3-A-2-sigma-1-A-F-sqrt-sigma-1-2-sigma-2-2-cdots-sigma-n-2"><a href="#3-A-2-sigma-1-A-F-sqrt-sigma-1-2-sigma-2-2-cdots-sigma-n-2" class="headerlink" title="(3) $$ |A|_2 &#x3D; \sigma_1, |A|_F &#x3D; \sqrt{\sigma_1^2 + \sigma_2^2 + \cdots + \sigma_n^2} $$"></a>(3) $$ |A|_2 &#x3D; \sigma_1, |A|_F &#x3D; \sqrt{\sigma_1^2 + \sigma_2^2 + \cdots + \sigma_n^2} $$</h4><p>证明：</p>
<ul>
<li>矩阵的谱范数 $$ |A|_2 $$ 定义为最大的奇异值，即 $$ |A|_2 &#x3D; \sigma_1 $$。</li>
<li>Frobenius 范数定义为 $$ |A|<em>F &#x3D; \sqrt{\sum</em>{i&#x3D;1}^{n} \sigma_i^2} $$，所以 $$ |A|_F &#x3D; \sqrt{\sigma_1^2 + \sigma_2^2 + \cdots + \sigma_n^2} $$。</li>
</ul>
<h4 id="4-若-text-rank-A-r-leq-n-，则-text-Ran-A-text-span-u-1-u-2-ldots-u-r-，-text-Ker-A-text-span-v-r-1-v-r-2-ldots-v-n"><a href="#4-若-text-rank-A-r-leq-n-，则-text-Ran-A-text-span-u-1-u-2-ldots-u-r-，-text-Ker-A-text-span-v-r-1-v-r-2-ldots-v-n" class="headerlink" title="(4) 若 $$ \text{rank}(A) &#x3D; r \leq n $$，则 $$ \text{Ran}(A) &#x3D; \text{span}{u_1, u_2, \ldots, u_r} $$，$$ \text{Ker}(A) &#x3D; \text{span}{v_{r+1}, v_{r+2}, \ldots, v_n} $$"></a>(4) 若 $$ \text{rank}(A) &#x3D; r \leq n $$，则 $$ \text{Ran}(A) &#x3D; \text{span}{u_1, u_2, \ldots, u_r} $$，$$ \text{Ker}(A) &#x3D; \text{span}{v_{r+1}, v_{r+2}, \ldots, v_n} $$</h4><p>证明：</p>
<ul>
<li>因为 $$ A $$ 的秩为 $$ r $$，所以 $$ A $$ 的列空间 $$ \text{Ran}(A) $$ 由 $$ r $$ 个线性无关的列生成，即 $$ \text{Ran}(A) &#x3D; \text{span}{u_1, u_2, \ldots, u_r} $$。</li>
<li>核空间 $$ \text{Ker}(A) $$ 由 $$ n-r $$ 个线性无关的列生成，即 $$ \text{Ker}(A) &#x3D; \text{span}{v_{r+1}, v_{r+2}, \ldots, v_n} $$。</li>
</ul>
<h4 id="5-设-x-in-mathbb-C-n-且-x-2-1-，则-sigma-n-leq-Ax-2-leq-sigma-1"><a href="#5-设-x-in-mathbb-C-n-且-x-2-1-，则-sigma-n-leq-Ax-2-leq-sigma-1" class="headerlink" title="(5) 设 $$ x \in \mathbb{C}^n $$ 且 $$ |x|_2 &#x3D; 1 $$，则 $$ \sigma_n \leq |Ax|_2 \leq \sigma_1 $$"></a>(5) 设 $$ x \in \mathbb{C}^n $$ 且 $$ |x|_2 &#x3D; 1 $$，则 $$ \sigma_n \leq |Ax|_2 \leq \sigma_1 $$</h4><p>证明：</p>
<ul>
<li>根据奇异值分解，$$ |Ax|_2 &#x3D; |U \Sigma V^* x|_2 &#x3D; |\Sigma V^* x|_2 $$。</li>
<li>由于 $$ V^* x $$ 是一个 $$ n $$-维向量，且其 2 范数的最大值为 1，$$ |Ax|_2 $$ 的最小值为 $$ \sigma_n $$（对应于最小的奇异值），最大值为 $$ \sigma_1 $$（对应于最大的奇异值）。</li>
</ul>
<h4 id="6-酉不变性-设-X-in-mathbb-C-m-times-m-和-Y-in-mathbb-C-n-times-n-是酉矩阵，则-sigma-i-X-AY-sigma-i-A"><a href="#6-酉不变性-设-X-in-mathbb-C-m-times-m-和-Y-in-mathbb-C-n-times-n-是酉矩阵，则-sigma-i-X-AY-sigma-i-A" class="headerlink" title="(6) (酉不变性) 设 $$ X \in \mathbb{C}^{m \times m} $$ 和 $$ Y \in \mathbb{C}^{n \times n} $$ 是酉矩阵，则 $$ \sigma_i(X^*AY) &#x3D; \sigma_i(A) $$"></a>(6) (酉不变性) 设 $$ X \in \mathbb{C}^{m \times m} $$ 和 $$ Y \in \mathbb{C}^{n \times n} $$ 是酉矩阵，则 $$ \sigma_i(X^*AY) &#x3D; \sigma_i(A) $$</h4><p>证明：</p>
<ul>
<li>由于 $$ X $$ 和 $$ Y $$ 是酉矩阵，$$ X^* A Y $$ 和 $$ A $$ 具有相同的奇异值，因为酉矩阵在范数下是等距的，这意味着奇异值不变。</li>
</ul>
<p>条件数的几何意义<br>条件数反映了矩阵将单位球映射到椭球后的最长轴与最短轴之比。即使特征值全为 1，椭球的形状仍可能高度拉伸（由奇异值决定）。</p>
<h3 id="低秩逼近定理的详细解释"><a href="#低秩逼近定理的详细解释" class="headerlink" title="低秩逼近定理的详细解释"></a><strong>低秩逼近定理的详细解释</strong></h3><h4 id="1-定理陈述"><a href="#1-定理陈述" class="headerlink" title="1. 定理陈述"></a><strong>1. 定理陈述</strong></h4><p>设 $$ A &#x3D; U \Sigma V^* $$ 是 $$ A \in \mathbb{C}^{m \times n} $$ 的细奇异值分解（即紧凑形式的 SVD，仅保留非零奇异值）。定义：<br>$$A_k &#x3D; \sum_{i&#x3D;1}^k \sigma_i u_i v_i^*$$<br>其中 $$ \sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r &gt; 0 $$ 是 $$ A $$ 的非零奇异值（$$ r &#x3D; \text{rank}(A) $$）。则：</p>
<ol>
<li>$$ A_k $$ 是 <strong>所有秩为 $$ k $$ 的矩阵中，在 2-范数下最接近 $$ A $$ 的解</strong>，即：<br>$$|A - A_k|<em>2 &#x3D; \sigma</em>{k+1},$$<br>且 $$ A_k $$ 满足：<br>$$A_k &#x3D; \arg\min_{\substack{B \in \mathbb{C}^{m \times n} \ \text{rank}(B) &#x3D; k}} |A - B|_2.$$</li>
<li>对于 Frobenius 范数，类似结论成立：<br>$$|A - A_k|<em>F &#x3D; \sqrt{\sum</em>{i&#x3D;k+1}^r \sigma_i^2}.$$</li>
</ol>
<hr>
<h4 id="2-直观解释"><a href="#2-直观解释" class="headerlink" title="2. 直观解释"></a><strong>2. 直观解释</strong></h4><p>矩阵的低秩逼近目标是：用秩为 $$ k $$ 的矩阵 $$ A_k $$ 尽可能接近原矩阵 $$ A $$。  </p>
<ul>
<li><strong>几何意义</strong>：将 $$ A $$ 的作用分解到正交方向（由奇异向量 $$ u_i, v_i $$ 定义），保留前 $$ k $$ 个最重要的方向（对应最大奇异值），截断后面的方向。  </li>
<li><strong>应用场景</strong>：数据压缩、主成分分析（PCA）、去噪等。</li>
</ul>
<hr>
<h4 id="3-为什么-A-k-是最优解？"><a href="#3-为什么-A-k-是最优解？" class="headerlink" title="3. 为什么 $$ A_k $$ 是最优解？"></a><strong>3. 为什么 $$ A_k $$ 是最优解？</strong></h4><h5 id="1-2-范数的最优性"><a href="#1-2-范数的最优性" class="headerlink" title="(1) 2-范数的最优性"></a><strong>(1) 2-范数的最优性</strong></h5><ul>
<li><p><strong>奇异值的性质</strong>：<br>矩阵的 2-范数 $$ |A|<em>2 $$ 是其最大奇异值 $$ \sigma_1 $$。构造 $$ A_k $$ 时，保留了前 $$ k $$ 个奇异值 $$ \sigma_1, \dots, \sigma_k $$，将后面的奇异值置零。<br>因此，误差矩阵 $$ A - A_k $$ 的奇异值为 $$ \sigma</em>{k+1}, \dots, \sigma_r $$，其 2-范数为最大剩余奇异值：<br>$$|A - A_k|<em>2 &#x3D; \sigma</em>{k+1}.$$</p>
</li>
<li><p><strong>极值性证明（Eckart–Young–Mirsky 定理）</strong>：<br>对任意秩为 $$ k $$ 的矩阵 $$ B $$，其奇异值最多有 $$ k $$ 个非零值。由于奇异值已按降序排列，保留前 $$ k $$ 个最大奇异值会最小化剩余奇异值的最大值，即：<br>$$\sigma_{k+1} \leq |A - B|<em>2 \quad \text{对所有秩为 } k \text{ 的 } B.$$<br>因此，$$ A_k $$ 达到了下界 $$ \sigma</em>{k+1} $$，是最优解。</p>
</li>
</ul>
<hr>
<h5 id="2-Frobenius-范数的最优性"><a href="#2-Frobenius-范数的最优性" class="headerlink" title="(2) Frobenius 范数的最优性"></a><strong>(2) Frobenius 范数的最优性</strong></h5><ul>
<li><p><strong>Frobenius 范数的定义</strong>：<br>$$|A|<em>F &#x3D; \sqrt{\sum</em>{i&#x3D;1}^r \sigma_i^2}.$$<br>构造 $$ A_k $$ 时，截断后 $$ k+1 $$ 到 $$ r $$ 的奇异值被舍弃，因此误差为：<br>$$|A - A_k|<em>F &#x3D; \sqrt{\sum</em>{i&#x3D;k+1}^r \sigma_i^2}.$$</p>
</li>
<li><p><strong>极值性证明</strong>：<br>由于 Frobenius 范数是各方向奇异值平方和的平方根，保留前 $$ k $$ 个最大奇异值会最小化剩余部分的平方和。对任意秩为 $$ k $$ 的 $$ B $$，有：<br>$$\sum_{i&#x3D;k+1}^r \sigma_i^2 \leq |A - B|_F^2,$$<br>因此 $$ A_k $$ 是最优解。</p>
</li>
</ul>
<hr>
<h1 id="矩阵的2-范数等于其最大奇异值σ₁。"><a href="#矩阵的2-范数等于其最大奇异值σ₁。" class="headerlink" title="矩阵的2-范数等于其最大奇异值σ₁。"></a>矩阵的2-范数等于其最大奇异值σ₁。</h1><p>矩阵的2-范数定义为：</p>
<p>$$|A|_2 &#x3D; \sup \left{ \frac{|Ax|_2}{|x|_2} \mid x \neq 0 \right}$$</p>
<p>或者等价地：</p>
<p>$$|A|_2 &#x3D; \max \left{ |Ax|_2 \mid |x|_2 &#x3D; 1 \right}$$</p>
<p>通过奇异值分解（SVD），矩阵A可以分解为 $$ A &#x3D; U\Sigma V^* $$，其中U和V是酉矩阵，Σ是对角矩阵，对角线上的元素是奇异值σ₁ ≥ σ₂ ≥ … ≥ σₙ ≥ 0。</p>
<p>考虑向量x经过矩阵A作用后的模长：</p>
<p>$$|Ax|_2 &#x3D; |U\Sigma V^* x|_2$$</p>
<p>由于U和V是酉矩阵，不改变向量的模长，令 $$ y &#x3D; V^* x $$，则 $$ |y|_2 &#x3D; |x|_2 $$，因此：</p>
<p>$$|Ax|_2 &#x3D; |\Sigma y|_2$$</p>
<p>对于单位向量x，y也是单位向量，因此：</p>
<p>$$|\Sigma y|<em>2 &#x3D; \sqrt{\sum</em>{i&#x3D;1}^n \sigma_i^2 |y_i|^2}$$</p>
<p>当y的分量集中在最大奇异值σ₁对应的位置时，例如y &#x3D; (1, 0, …, 0)，此时：</p>
<p>$$|\Sigma y|_2 &#x3D; \sigma_1$$</p>
<p>因此，矩阵A的2-范数即为最大奇异值σ₁。</p>
<p>进一步验证，考虑矩阵A*A的最大特征值λ₁，其平方根即为最大奇异值σ₁。根据瑞利商，向量x的最大增长倍数为：</p>
<p>$$\sqrt{\lambda_1} &#x3D; \sigma_1$$</p>
<p>因此，矩阵的2-范数等于其最大奇异值σ₁。</p>
<h1 id="QR分解在线性最小二乘的应用"><a href="#QR分解在线性最小二乘的应用" class="headerlink" title="QR分解在线性最小二乘的应用"></a>QR分解在线性最小二乘的应用</h1><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a><strong>问题描述</strong></h3><p>给定满秩矩阵 $$ A \in \mathbb{R}^{m \times n} $$（$$ m \geq n $$），求线性最小二乘问题：<br>$$\min_{x \in \mathbb{R}^n} | Ax - b |_2^2$$<br>的解析解 $$ x^* $$。</p>
<h3 id="方法-1：利用-QR-分解的正交补空间投影"><a href="#方法-1：利用-QR-分解的正交补空间投影" class="headerlink" title="方法 1：利用 QR 分解的正交补空间投影"></a><strong>方法 1：利用 QR 分解的正交补空间投影</strong></h3><h4 id="1-QR-分解"><a href="#1-QR-分解" class="headerlink" title="1. QR 分解"></a><strong>1. QR 分解</strong></h4><p>由于 $$ A $$ 是满秩的，可以进行 <strong>QR 分解</strong>：<br>$$A &#x3D; QR$$<br>其中：</p>
<ul>
<li>$$ Q \in \mathbb{R}^{m \times n} $$ 是 <strong>列正交矩阵</strong>（即 $$ Q^\top Q &#x3D; I_n $$），</li>
<li>$$ R \in \mathbb{R}^{n \times n} $$ 是 <strong>上三角可逆矩阵</strong>（因为 $$ A $$ 满秩）。</li>
</ul>
<p>由于 $$ m \geq n $$，我们可以将 $$ Q $$ <strong>扩充</strong>成一个完整的正交矩阵：<br>$$[Q, \hat{Q}] \in \mathbb{R}^{m \times m}$$<br>其中：</p>
<ul>
<li>$$ \hat{Q} \in \mathbb{R}^{m \times (m - n)} $$ 是 $$ Q $$ 的正交补（即 $$ Q^\top \hat{Q} &#x3D; 0 $$ 且 $$ \hat{Q}^\top \hat{Q} &#x3D; I_{m-n} $$）。</li>
</ul>
<h4 id="2-残差范数的分解"><a href="#2-残差范数的分解" class="headerlink" title="2. 残差范数的分解"></a><strong>2. 残差范数的分解</strong></h4><p>利用 $$ [Q, \hat{Q}] $$ 的正交性（$$ [Q, \hat{Q}]^\top [Q, \hat{Q}] &#x3D; I_m $$），残差范数可以写成：<br>$$| Ax - b |_2^2 &#x3D; | [Q, \hat{Q}]^\top (Ax - b) |_2^2$$<br>因为正交变换不改变范数。</p>
<p>代入 $$ A &#x3D; QR $$：<br>$$&#x3D; | [Q, \hat{Q}]^\top (QRx - b) |_2^2$$</p>
<h1 id="计算-Q-hat-Q-top-与-QRx-b-的乘积：-Q-hat-Q-top-QRx-b-begin-bmatrix-Q-top-QRx-b-hat-Q-top-QRx-b-end-bmatrix"><a href="#计算-Q-hat-Q-top-与-QRx-b-的乘积：-Q-hat-Q-top-QRx-b-begin-bmatrix-Q-top-QRx-b-hat-Q-top-QRx-b-end-bmatrix" class="headerlink" title="计算 $$ [Q, \hat{Q}]^\top $$ 与 $$ QRx - b $$ 的乘积：$$[Q, \hat{Q}]^\top (QRx - b) &#x3D;\begin{bmatrix}Q^\top (QRx - b) \\hat{Q}^\top (QRx - b)\end{bmatrix}"></a>计算 $$ [Q, \hat{Q}]^\top $$ 与 $$ QRx - b $$ 的乘积：<br>$$[Q, \hat{Q}]^\top (QRx - b) &#x3D;<br>\begin{bmatrix}<br>Q^\top (QRx - b) \<br>\hat{Q}^\top (QRx - b)<br>\end{bmatrix}</h1><p>\begin{bmatrix}<br>Rx - Q^\top b \<br>-\hat{Q}^\top b<br>\end{bmatrix}$$<br>（因为 $$ Q^\top Q &#x3D; I $$，而 $$ \hat{Q}^\top Q &#x3D; 0 $$）</p>
<p>所以：<br>$$| Ax - b |_2^2 &#x3D; \left| \begin{bmatrix}<br>Rx - Q^\top b \<br>-\hat{Q}^\top b<br>\end{bmatrix} \right|_2^2 &#x3D; | Rx - Q^\top b |_2^2 + | \hat{Q}^\top b |_2^2$$</p>
<h4 id="3-最小化条件"><a href="#3-最小化条件" class="headerlink" title="3. 最小化条件"></a><strong>3. 最小化条件</strong></h4><p>由于 $$ | \hat{Q}^\top b |_2^2 $$ 与 $$ x $$ 无关，最小化 $$ | Ax - b |_2^2 $$ 等价于最小化 $$ | Rx - Q^\top b |_2^2 $$，而它的最小值是 0（因为 $$ R $$ 可逆）：<br>$$Rx &#x3D; Q^\top b$$<br>因此，最小二乘解为：<br>$$x^* &#x3D; R^{-1} Q^\top b$$</p>
<hr>
<h3 id="方法-2：利用正交投影分解"><a href="#方法-2：利用正交投影分解" class="headerlink" title="方法 2：利用正交投影分解"></a><strong>方法 2：利用正交投影分解</strong></h3><h4 id="1-投影矩阵"><a href="#1-投影矩阵" class="headerlink" title="1. 投影矩阵"></a><strong>1. 投影矩阵</strong></h4><p>$$ QQ^\top $$ 是 $$ \text{Ran}(A) $$（$$ A $$ 的列空间）上的 <strong>正交投影矩阵</strong>，因为：</p>
<ul>
<li>$$ \text{Ran}(A) &#x3D; \text{Ran}(Q) $$（因为 $$ A &#x3D; QR $$），</li>
<li>$$ QQ^\top $$ 将任意向量投影到 $$ \text{Ran}(Q) $$。</li>
</ul>
<p>类似地，$$ I - QQ^\top $$ 是 $$ \text{Ran}(A)^\perp $$（$$ A $$ 的列空间的正交补）上的投影矩阵。</p>
<h4 id="2-分解-b"><a href="#2-分解-b" class="headerlink" title="2. 分解 $$ b $$"></a><strong>2. 分解 $$ b $$</strong></h4><p>将 $$ b $$ 分解为：<br>$$b &#x3D; QQ^\top b + (I - QQ^\top) b$$<br>其中：</p>
<ul>
<li>$$ QQ^\top b $$ 是 $$ b $$ 在 $$ \text{Ran}(A) $$ 上的投影，</li>
<li>$$ (I - QQ^\top) b $$ 是 $$ b $$ 在 $$ \text{Ran}(A)^\perp $$ 上的投影。</li>
</ul>
<h4 id="3-残差范数的分解"><a href="#3-残差范数的分解" class="headerlink" title="3. 残差范数的分解"></a><strong>3. 残差范数的分解</strong></h4><p>残差 $$ Ax - b $$ 可以写成：<br>$$Ax - b &#x3D; Ax - QQ^\top b - (I - QQ^\top) b$$<br>由于 $$ Ax \in \text{Ran}(A) $$ 和 $$ (I - QQ^\top) b \in \text{Ran}(A)^\perp $$，它们是正交的，所以：<br>$$| Ax - b |_2^2 &#x3D; | Ax - QQ^\top b |_2^2 + | (I - QQ^\top) b |_2^2$$</p>
<p>由于 $$ A &#x3D; QR $$，且 $$ QQ^\top b $$ 是 $$ b $$ 在 $$ \text{Ran}(A) $$ 上的投影：<br>$$Ax - QQ^\top b &#x3D; QRx - QQ^\top b$$<br>因为 $$ \text{Ran}(QQ^\top) &#x3D; \text{Ran}(Q) $$，所以 $$ QQ^\top b &#x3D; Q c $$ 对某个 $$ c \in \mathbb{R}^n $$。实际上：<br>$$QQ^\top b &#x3D; Q (Q^\top b)$$<br>所以：<br>$$QRx - QQ^\top b &#x3D; Q (Rx - Q^\top b)$$<br>因此：<br>$$| Ax - QQ^\top b |_2^2 &#x3D; | Q (Rx - Q^\top b) |_2^2 &#x3D; | Rx - Q^\top b |_2^2$$<br>（因为 $$ Q $$ 列正交）</p>
<h4 id="4-最小化条件"><a href="#4-最小化条件" class="headerlink" title="4. 最小化条件"></a><strong>4. 最小化条件</strong></h4><p>最小化 $$ | Ax - b |_2^2 $$ 等价于最小化 $$ | Rx - Q^\top b |_2^2 $$，其最小值是 0：<br>$$Rx &#x3D; Q^\top b$$<br>因此：<br>$$x^* &#x3D; R^{-1} Q^\top b$$</p>
<hr>
<h3 id="方法-3：正规方程法"><a href="#方法-3：正规方程法" class="headerlink" title="方法 3：正规方程法"></a><strong>方法 3：正规方程法</strong></h3><h4 id="1-正规方程"><a href="#1-正规方程" class="headerlink" title="1. 正规方程"></a><strong>1. 正规方程</strong></h4><p>最小二乘问题的解满足 <strong>正规方程</strong>：<br>$$A^\top A x &#x3D; A^\top b$$</p>
<h4 id="2-代入-QR-分解"><a href="#2-代入-QR-分解" class="headerlink" title="2. 代入 QR 分解"></a><strong>2. 代入 QR 分解</strong></h4><p>由于 $$ A &#x3D; QR $$，代入正规方程：<br>$$(QR)^\top (QR) x &#x3D; (QR)^\top b$$<br>$$R^\top Q^\top Q R x &#x3D; R^\top Q^\top b$$<br>因为 $$ Q^\top Q &#x3D; I $$：<br>$$R^\top R x &#x3D; R^\top Q^\top b$$</p>
<h4 id="3-解方程"><a href="#3-解方程" class="headerlink" title="3. 解方程"></a><strong>3. 解方程</strong></h4><p>由于 $$ R $$ 是可逆的，$$ R^\top $$ 也是可逆的，可以两边左乘 $$ (R^\top)^{-1} $$：<br>$$R x &#x3D; Q^\top b$$<br>因此：<br>$$x^* &#x3D; R^{-1} Q^\top b$$</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>三种方法最终都得到相同的最小二乘解：<br>$$x^* &#x3D; R^{-1} Q^\top b$$<br>其中：</p>
<ul>
<li>$$ A &#x3D; QR $$ 是 $$ A $$ 的 <strong>QR 分解</strong>，</li>
<li>$$ R $$ 是上三角可逆矩阵，</li>
<li>$$ Q $$ 是列正交矩阵。</li>
</ul>
<h4 id="计算复杂度"><a href="#计算复杂度" class="headerlink" title="计算复杂度"></a><strong>计算复杂度</strong></h4><ul>
<li>QR 分解的计算量约为 $$ 2mn^2 $$（使用 Householder 变换时），</li>
<li>当 $$ m \gg n $$ 时，比正规方程法（计算 $$ A^\top A $$ 需要 $$ mn^2 $$）稍慢，</li>
<li>当 $$ m &#x3D; n $$ 时，计算量几乎相同。</li>
</ul>
<h4 id="为什么-QR-分解方法更稳定？"><a href="#为什么-QR-分解方法更稳定？" class="headerlink" title="为什么 QR 分解方法更稳定？"></a><strong>为什么 QR 分解方法更稳定？</strong></h4><ul>
<li>直接计算 $$ A^\top A $$ 会导致数值不稳定（条件数 $$ \kappa(A^\top A) &#x3D; \kappa(A)^2 $$），</li>
<li>QR 分解方法避免了计算 $$ A^\top A $$，数值稳定性更好。</li>
</ul>
<h2 id="HouseHolder中的v"><a href="#HouseHolder中的v" class="headerlink" title="HouseHolder中的v"></a>HouseHolder中的v</h2><ul>
<li><strong>$$ v $$ 是反射方向的垂直向量</strong>，决定了反射超平面的方向，</li>
<li><strong>$$ v &#x3D; x - y $$</strong>，其中 $$ y $$ 是目标向量（如 $$ |x| e_1 $$），</li>
<li>Householder 变换通过 $$ H &#x3D; I - 2 \frac{v v^\top}{v^\top v} $$ 实现反射，</li>
<li>在 QR 分解中，Householder 变换逐步将 $$ A $$ 化为 $$ R $$，并构造正交矩阵 $$ Q $$。</li>
</ul>
<p><strong>数值稳定性</strong>：</p>
<ul>
<li>通常选择 $$ v &#x3D; x + \text{sign}(x_1) |x| e_1 $$ 避免 $$ v $$ 接近零向量，</li>
<li>Householder 变换比 Gram-Schmidt 更稳定，适合大规模数值计算。</li>
<li></li>
</ul>
<h1 id="奇异值分解（SVD）法推导最小二乘解"><a href="#奇异值分解（SVD）法推导最小二乘解" class="headerlink" title="奇异值分解（SVD）法推导最小二乘解"></a>奇异值分解（SVD）法推导最小二乘解</h1><h4 id="1-奇异值分解（SVD）的定义"><a href="#1-奇异值分解（SVD）的定义" class="headerlink" title="1. 奇异值分解（SVD）的定义"></a>1. <strong>奇异值分解（SVD）的定义</strong></h4><p>对于列满秩矩阵 $$ A \in \mathbb{R}^{m \times n} $$（$$ m \geq n $$），其奇异值分解为：<br>$$A &#x3D; U \begin{bmatrix} \Sigma \ 0 \end{bmatrix} V^\top$$<br>其中：</p>
<ul>
<li>$$ U \in \mathbb{R}^{m \times m} $$ 是正交矩阵（$$ U^\top U &#x3D; I_m $$），可以分块为 $$ U &#x3D; [U_n, \tilde{U}] $$：<ul>
<li>$$ U_n \in \mathbb{R}^{m \times n} $$：前 $$ n $$ 列，对应非零奇异值。</li>
<li>$$ \tilde{U} \in \mathbb{R}^{m \times (m - n)} $$：后 $$ m - n $$ 列，对应零奇异值。</li>
</ul>
</li>
<li>$$ \Sigma \in \mathbb{R}^{n \times n} $$ 是对角矩阵，对角线元素为奇异值 $$ \sigma_1 \geq \sigma_2 \geq \dots \geq \sigma_n &gt; 0 $$（因为 $$ A $$ 列满秩）。</li>
<li>$$ V \in \mathbb{R}^{n \times n} $$ 是正交矩阵（$$ V^\top V &#x3D; I_n $$）。</li>
</ul>
<h4 id="2-残差范数的表达"><a href="#2-残差范数的表达" class="headerlink" title="2. 残差范数的表达"></a>2. <strong>残差范数的表达</strong></h4><p>最小二乘问题的目标是最小化残差范数：<br>$$|Ax - b|_2^2 &#x3D; \left| U \begin{bmatrix} \Sigma \ 0 \end{bmatrix} V^\top x - b \right|_2^2$$<br>利用正交矩阵的性质 $$ |Uy|_2 &#x3D; |y|_2 $$，可以左乘 $$ U^\top $$：<br>$$|Ax - b|_2^2 &#x3D; \left| \begin{bmatrix} \Sigma \ 0 \end{bmatrix} V^\top x - U^\top b \right|_2^2$$<br>将 $$ U^\top b $$ 分块为：<br>$$U^\top b &#x3D; \begin{bmatrix} U_n^\top b \ \tilde{U}^\top b \end{bmatrix}$$<br>因此：<br>$$|Ax - b|_2^2 &#x3D; \left| \begin{bmatrix} \Sigma V^\top x - U_n^\top b \ -\tilde{U}^\top b \end{bmatrix} \right|_2^2 &#x3D; |\Sigma V^\top x - U_n^\top b|_2^2 + |\tilde{U}^\top b|_2^2$$</p>
<h4 id="3-最小化残差范数"><a href="#3-最小化残差范数" class="headerlink" title="3. 最小化残差范数"></a>3. <strong>最小化残差范数</strong></h4><ul>
<li>第二项 $$ |\tilde{U}^\top b|_2^2 $$ 是固定的（与 $$ x $$ 无关）。</li>
<li>第一项 $$ |\Sigma V^\top x - U_n^\top b|_2^2 $$ 可以最小化为零（因为 $$ \Sigma $$ 和 $$ V $$ 可逆）：<br>$$\Sigma V^\top x - U_n^\top b &#x3D; 0 \implies \Sigma V^\top x &#x3D; U_n^\top b$$<br>解得：<br>$$x &#x3D; (V^\top)^{-1} \Sigma^{-1} U_n^\top b &#x3D; V \Sigma^{-1} U_n^\top b$$<br>（因为 $$ V $$ 是正交矩阵，$$ V^{-1} &#x3D; V^\top $$）。</li>
</ul>
<h4 id="4-解的几何意义"><a href="#4-解的几何意义" class="headerlink" title="4. 解的几何意义"></a>4. <strong>解的几何意义</strong></h4><ul>
<li>$$ U_n^\top b $$ 是 $$ b $$ 在 $$ \text{Ran}(A) $$（$$ A $$ 的列空间）上的投影系数。</li>
<li>$$ \Sigma^{-1} $$ 对奇异值进行缩放，$$ V $$ 将结果转换回原空间。</li>
<li>$$ \tilde{U}^\top b $$ 是 $$ b $$ 在 $$ \text{Ran}(A)^\perp $$（$$ A $$ 的左零空间）上的分量，无法被 $$ Ax $$ 表示。</li>
</ul>
<h4 id="5-与QR分解法的对比"><a href="#5-与QR分解法的对比" class="headerlink" title="5. 与QR分解法的对比"></a>5. <strong>与QR分解法的对比</strong></h4><ul>
<li>QR分解法：$$ A &#x3D; QR $$，解为 $$ x &#x3D; R^{-1} Q^\top b $$。</li>
<li>SVD法：$$ A &#x3D; U \begin{bmatrix} \Sigma \ 0 \end{bmatrix} V^\top $$，解为 $$ x &#x3D; V \Sigma^{-1} U_n^\top b $$。</li>
<li>SVD法的优势：<ul>
<li>数值稳定性更高（尤其当 $$ A $$ 接近秩亏时）。</li>
<li>可以直接处理秩亏矩阵（通过截断小奇异值）。</li>
</ul>
</li>
</ul>
<h4 id="6-关键符号总结"><a href="#6-关键符号总结" class="headerlink" title="6. 关键符号总结"></a>6. <strong>关键符号总结</strong></h4><ul>
<li>$$ U_n $$：对应非零奇异值的左奇异向量。</li>
<li>$$ \tilde{U} $$：对应零奇异值的左奇异向量。</li>
<li>$$ \Sigma $$：奇异值矩阵（对角矩阵）。</li>
<li>$$ V $$：右奇异向量矩阵。</li>
<li>$$ U_n^\top b $$：$$ b $$ 在 $$ \text{Ran}(A) $$ 上的投影。</li>
<li>$$ \tilde{U}^\top b $$：$$ b $$ 在 $$ \text{Ran}(A)^\perp $$ 上的投影。</li>
</ul>
<h4 id="7-最终解"><a href="#7-最终解" class="headerlink" title="7. 最终解"></a>7. <strong>最终解</strong></h4><p>最小二乘解为：<br>$$x^* &#x3D; V \Sigma^{-1} U_n^\top b$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes.github.io/images/woshicaigou.jpg">
      <meta itemprop="name" content="Chen Zhan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cz Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/notes.github.io/2025/06/23/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">最小二乘法笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-23 18:56:58" itemprop="dateCreated datePublished" datetime="2025-06-23T18:56:58+08:00">2025-06-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>根据我们的上述定义, 如果 $\phi_0, \dots, \phi_n$ 为一组正交基, 这意味着<br>$\int_a^b w(x) \phi_i(x) \phi_j(x) dx &#x3D; 0 \ (i \ne j)$, 而由内积的正定性, 我们有<br>$\int_a^b w(x) \phi_i^2(x) dx &#x3D; \alpha_i &gt; 0$.</p>
<p>而又由基的性质, $\forall P(x), \deg P \le n, P(x) &#x3D; \sum_{i&#x3D;0}^n a_i \phi_i(x)$, 且线性表出方式唯一.</p>
<p>故我们的误差函数 $E(a_0, \dots, a_n) &#x3D; \int_a^b w(x) [f(x) - \sum_{i&#x3D;0}^n a_i \phi_i(x)]^2 dx$</p>
<p>同样地, 我们最小化误差, 令 $\frac{\partial E}{\partial a_i} &#x3D; 0$</p>
<p>得到$\int_a^b w(x) f(x) \phi_i(x) dx &#x3D; a_i \alpha_i$</p>
<p>解得 $a_i &#x3D; \frac{\int_a^b w(x) f(x) \phi_i(x) dx}{\alpha_i} &#x3D; \frac{\int_a^b w(x) f(x) \phi_i(x) dx}{\int_a^b w(x) \phi_i^2(x) dx}$ (最小二乘解)</p>
<p>我们发现: 不同的 $a_i$ 之间不再具有联系, 方程的求解变得异常简单.</p>
<h3 id="多项式最小二乘解的推导"><a href="#多项式最小二乘解的推导" class="headerlink" title="多项式最小二乘解的推导"></a>多项式最小二乘解的推导</h3><p>当目标函数为任意 $$ n $$ 次多项式 $$ p(x) &#x3D; a_0 + a_1 x + a_2 x^2 + \dots + a_n x^n $$ 时，最小二乘法的目标是找到系数 $$ \bm{a} &#x3D; (a_0, a_1, \dots, a_n)^T $$，使得拟合多项式与数据点 $$ {(x_i, y_i)}_{i&#x3D;1}^m $$ 的残差平方和最小。以下是具体推导过程：</p>
<hr>
<h4 id="1-定义误差函数"><a href="#1-定义误差函数" class="headerlink" title="1. 定义误差函数"></a><strong>1. 定义误差函数</strong></h4><p>残差平方和（误差函数）为：<br>$$E &#x3D; \sum_{i&#x3D;1}^m \left( y_i - p(x_i) \right)^2 &#x3D; \sum_{i&#x3D;1}^m \left( y_i - \sum_{k&#x3D;0}^n a_k x_i^k \right)^2.$$</p>
<hr>
<h4 id="2-对参数求偏导并置零"><a href="#2-对参数求偏导并置零" class="headerlink" title="2. 对参数求偏导并置零"></a><strong>2. 对参数求偏导并置零</strong></h4><p>对每个系数 $$ a_j $$ 求偏导数，令其等于零以最小化误差：<br>$$\frac{\partial E}{\partial a_j} &#x3D; 2 \sum_{i&#x3D;1}^m \left( y_i - \sum_{k&#x3D;0}^n a_k x_i^k \right)(-x_i^j) &#x3D; 0 \quad (j&#x3D;0,1,\dots,n).$$<br>整理后得到方程组：<br>$$\sum_{i&#x3D;1}^m y_i x_i^j &#x3D; \sum_{k&#x3D;0}^n a_k \sum_{i&#x3D;1}^m x_i^{j+k} \quad (j&#x3D;0,1,\dots,n).$$</p>
<hr>
<h4 id="3-构造矩阵形式"><a href="#3-构造矩阵形式" class="headerlink" title="3. 构造矩阵形式"></a><strong>3. 构造矩阵形式</strong></h4><p>将方程写成矩阵形式 $$ A^T A \bm{a} &#x3D; A^T \bm{y} $$，其中：</p>
<ul>
<li><strong>设计矩阵 $$ A $$</strong>：<br>$$A &#x3D;<br>\begin{bmatrix}<br>1      &amp; x_1    &amp; x_1^2  &amp; \cdots &amp; x_1^n \<br>1      &amp; x_2    &amp; x_2^2  &amp; \cdots &amp; x_2^n \<br>\vdots &amp; \vdots &amp; \vdots &amp;        &amp; \vdots \<br>1      &amp; x_m    &amp; x_m^2  &amp; \cdots &amp; x_m^n<br>\end{bmatrix}.$$</li>
<li><strong>右端项 $$ A^T \bm{y} $$</strong>：<br>$$A^T \bm{y} &#x3D;<br>\begin{bmatrix}<br>\sum_{i&#x3D;1}^m y_i \<br>\sum_{i&#x3D;1}^m y_i x_i \<br>\sum_{i&#x3D;1}^m y_i x_i^2 \<br>\vdots \<br>\sum_{i&#x3D;1}^m y_i x_i^n<br>\end{bmatrix}.$$</li>
<li><strong>系数矩阵 $$ A^T A $$</strong>：<br>$$A^T A &#x3D;<br>\begin{bmatrix}<br>m              &amp; \sum x_i       &amp; \sum x_i^2     &amp; \cdots &amp; \sum x_i^n     \<br>\sum x_i       &amp; \sum x_i^2     &amp; \sum x_i^3     &amp; \cdots &amp; \sum x_i^{n+1} \<br>\vdots         &amp; \vdots         &amp; \vdots         &amp;        &amp; \vdots         \<br>\sum x_i^n     &amp; \sum x_i^{n+1} &amp; \sum x_i^{n+2} &amp; \cdots &amp; \sum x_i^{2n}<br>\end{bmatrix}.$$</li>
</ul>
<hr>
<h4 id="4-正规方程"><a href="#4-正规方程" class="headerlink" title="4. 正规方程"></a><strong>4. 正规方程</strong></h4><p>最终方程组为：<br>$$A^T A \bm{a} &#x3D; A^T \bm{y},$$<br>其解为：<br>$$\bm{a} &#x3D; (A^T A)^{-1} A^T \bm{y}.$$</p>
<hr>
<h3 id="关键点分析"><a href="#关键点分析" class="headerlink" title="关键点分析"></a><strong>关键点分析</strong></h3><ol>
<li><p><strong>正交基的简化作用</strong>：</p>
<ul>
<li>若多项式基 $$ {1, x, x^2, \dots, x^n} $$ 正交，则 $$ A^T A $$ 为对角阵，系数可直接通过投影计算：<br>$$a_j &#x3D; \frac{\sum_{i&#x3D;1}^m y_i x_i^j}{\sum_{i&#x3D;1}^m x_i^{2j}} \quad (j&#x3D;0,1,\dots,n).$$</li>
<li>非正交时需求逆矩阵，可能面临数值不稳定问题。</li>
</ul>
</li>
<li><p><strong>与傅里叶级数的对比</strong>：</p>
<ul>
<li>傅里叶分析中，基函数 $$ {\cos(kx), \sin(kx)} $$ 天然正交，可直接投影（如历史讨论）。</li>
<li>多项式基一般不正交，需通过正规方程求解。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a><strong>结论</strong></h3><p>任意多项式的最小二乘解通过构造设计矩阵 $$ A $$、求解正规方程 $$ A^T A \bm{a} &#x3D; A^T \bm{y} $$ 得到。其本质是误差函数的平方和最小化在非正交基下的推广，核心步骤为：</p>
<ol>
<li>定义误差函数，</li>
<li>对参数求导并构造线性方程组，</li>
<li>通过矩阵运算求解系数。</li>
</ol>
<h3 id="多项式基的正交化与最小二乘解的简化推导"><a href="#多项式基的正交化与最小二乘解的简化推导" class="headerlink" title="多项式基的正交化与最小二乘解的简化推导"></a>多项式基的正交化与最小二乘解的简化推导</h3><p>在多项式最小二乘问题中，若采用标准基 $$ {1, x, x^2, \dots, x^n} $$，设计矩阵 $$ A $$ 的条件数可能较大，导致数值不稳定。通过 <strong>正交化基函数</strong>，可简化计算并提高数值稳定性。以下是具体推导过程：</p>
<hr>
<h4 id="1-定义内积"><a href="#1-定义内积" class="headerlink" title="1. 定义内积"></a><strong>1. 定义内积</strong></h4><p>假设有 $$ m $$ 个数据点 $$ {(x_i, y_i)}<em>{i&#x3D;1}^m $$，定义离散内积：<br>$$\langle f, g \rangle &#x3D; \sum</em>{i&#x3D;1}^m f(x_i) g(x_i).$$<br>目标是构造一组正交多项式基 $$ {q_0(x), q_1(x), \dots, q_n(x)} $$，满足：<br>$$\langle q_j, q_k \rangle &#x3D; 0 \quad (j \neq k).$$</p>
<hr>
<h4 id="2-应用-Gram-Schmidt-正交化"><a href="#2-应用-Gram-Schmidt-正交化" class="headerlink" title="2. 应用 Gram-Schmidt 正交化"></a><strong>2. 应用 Gram-Schmidt 正交化</strong></h4><p>从标准基 $$ {1, x, x^2, \dots, x^n} $$ 出发，逐步生成正交基：</p>
<ol>
<li><p><strong>初始化</strong>：<br>$$q_0(x) &#x3D; 1.$$</p>
</li>
<li><p><strong>递归正交化</strong>（对 $$ k&#x3D;1,2,\dots,n $$）：<br>$$q_k(x) &#x3D; x^k - \sum_{j&#x3D;0}^{k-1} \frac{\langle x^k, q_j \rangle}{\langle q_j, q_j \rangle} q_j(x).$$<br>每一步从 $$ x^k $$ 中减去其在已有正交基方向上的投影。</p>
</li>
</ol>
<hr>
<h4 id="3-正交基下的最小二乘解"><a href="#3-正交基下的最小二乘解" class="headerlink" title="3. 正交基下的最小二乘解"></a><strong>3. 正交基下的最小二乘解</strong></h4><p>目标多项式表示为正交基的线性组合：<br>$$p(x) &#x3D; a_0 q_0(x) + a_1 q_1(x) + \dots + a_n q_n(x).$$<br>误差函数为：<br>$$E &#x3D; \sum_{i&#x3D;1}^m \left( y_i - \sum_{k&#x3D;0}^n a_k q_k(x_i) \right)^2.$$</p>
<hr>
<h4 id="4-求解系数"><a href="#4-求解系数" class="headerlink" title="4. 求解系数"></a><strong>4. 求解系数</strong></h4><p>由于基正交，对 $$ a_j $$ 求偏导数并置零时，交叉项消失：<br>$$\frac{\partial E}{\partial a_j} &#x3D; -2 \sum_{i&#x3D;1}^m \left( y_i - \sum_{k&#x3D;0}^n a_k q_k(x_i) \right) q_j(x_i) &#x3D; 0.$$<br>利用正交性 $$ \langle q_j, q_k \rangle &#x3D; 0 \ (j \neq k) $$，化简得：<br>$$a_j &#x3D; \frac{\langle y, q_j \rangle}{\langle q_j, q_j \rangle} &#x3D; \frac{\sum_{i&#x3D;1}^m y_i q_j(x_i)}{\sum_{i&#x3D;1}^m q_j(x_i)^2}.$$<br><strong>无需解线性方程组</strong>，系数直接通过投影计算。</p>
<hr>
<h4 id="5-矩阵形式的简化"><a href="#5-矩阵形式的简化" class="headerlink" title="5. 矩阵形式的简化"></a><strong>5. 矩阵形式的简化</strong></h4><p>若设计矩阵 $$ Q $$ 的列为正交基函数值：<br>$$Q &#x3D;<br>\begin{bmatrix}<br>q_0(x_1) &amp; q_1(x_1) &amp; \cdots &amp; q_n(x_1) \<br>q_0(x_2) &amp; q_1(x_2) &amp; \cdots &amp; q_n(x_2) \<br>\vdots   &amp; \vdots    &amp;        &amp; \vdots   \<br>q_0(x_m) &amp; q_1(x_m) &amp; \cdots &amp; q_n(x_m)<br>\end{bmatrix},$$<br>则正规方程简化为对角系统：<br>$$Q^T Q \bm{a} &#x3D; Q^T \bm{y} \quad \Rightarrow \quad a_j &#x3D; \frac{(Q^T \bm{y})<em>j}{(Q^T Q)</em>{jj}}.$$</p>
<hr>
<h3 id="正交化的优势"><a href="#正交化的优势" class="headerlink" title="正交化的优势"></a><strong>正交化的优势</strong></h3><ol>
<li><strong>数值稳定性</strong>：避免 $$ A^T A $$ 的条件数过大。</li>
<li><strong>计算效率</strong>：系数独立计算，无需矩阵求逆。</li>
<li><strong>逐步拟合</strong>：可逐步增加多项式次数，无需重新计算已有系数。</li>
</ol>
<hr>
<h3 id="示例：离散-Chebyshev-多项式"><a href="#示例：离散-Chebyshev-多项式" class="headerlink" title="示例：离散 Chebyshev 多项式"></a><strong>示例：离散 Chebyshev 多项式</strong></h3><p>在区间 $$[-1,1]$$ 上，若选 Chebyshev 节点 $$ x_i &#x3D; \cos\left(\frac{(2i-1)\pi}{2m}\right) $$，通过正交化得到的基与 Chebyshev 多项式相关，能进一步优化逼近效果。</p>
<hr>
<h3 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a><strong>结论</strong></h3><p>通过正交化多项式基，将最小二乘问题转化为对角系统，显著简化计算并提升稳定性。这一方法结合了线性代数中的正交投影思想，是解决高次多项式拟合问题的实用工具。</p>
<p><strong>定理 (Gram-Schimidt)</strong></p>
<p>$\phi_0, \dots, \phi_n$ 为 $[a, b]$ 上关于权函数 $w(x)$ 正交的多项式基。可以由以下方式求得：</p>
<p>$\phi_0(x) &#x3D; 1, \phi_1(x) &#x3D; x - B_1$，而 $B_1 &#x3D; \frac{\int_a^b x w(x) \phi_0^2(x) dx}{\int_a^b w(x) \phi_0^2(x) dx}$。</p>
<p>而当 $k \ge 2$ 时，我们有统一形式 $\phi_k(x) &#x3D; x \phi_{k-1}(x) - B_k \phi_{k-1}(x) - C_k \phi_{k-2}(x)$。</p>
<p>其中，$B_k &#x3D; \frac{\int_a^b x w(x) \phi_{k-1}^2(x) dx}{\int_a^b w(x) \phi_{k-1}^2(x) dx}$， $C_k &#x3D; \frac{\int_a^b x w(x) \phi_{k-1}(x) \phi_{k-2}(x) dx}{\int_a^b w(x) \phi_{k-2}^2(x) dx}$。</p>
<p>Gram-Schmidt 方法看似繁琐，实则十分简单。它就是向量的 Schmidt 正交化方法在多项式正交化方面的推广罢了。根本的想法都是完全一致的，仅仅在细节上略有差别。</p>
<h3 id="实际示例：构造离散正交多项式基"><a href="#实际示例：构造离散正交多项式基" class="headerlink" title="实际示例：构造离散正交多项式基"></a>实际示例：构造离散正交多项式基</h3><p>假设数据点为 $$ x_1&#x3D;1,, x_2&#x3D;2,, x_3&#x3D;3 $$，定义离散内积：<br>$$\langle f, g \rangle &#x3D; f(1)g(1) + f(2)g(2) + f(3)g(3).$$<br>以 $$ n&#x3D;2 $$ 为例，演示如何从基 $$ {1, x, x^2} $$ 构造正交基 $$ {q_0(x), q_1(x), q_2(x)} $$。</p>
<hr>
<h4 id="1-构造-q-0-x"><a href="#1-构造-q-0-x" class="headerlink" title="1. 构造 $$ q_0(x) $$"></a><strong>1. 构造 $$ q_0(x) $$</strong></h4><p>直接取常数项基：<br>$$q_0(x) &#x3D; 1.$$</p>
<hr>
<h4 id="2-构造-q-1-x"><a href="#2-构造-q-1-x" class="headerlink" title="2. 构造 $$ q_1(x) $$"></a><strong>2. 构造 $$ q_1(x) $$</strong></h4><p>从 $$ x $$ 中减去其在 $$ q_0(x) $$ 方向的投影：<br>$$q_1(x) &#x3D; x - \frac{\langle x, q_0 \rangle}{\langle q_0, q_0 \rangle} q_0(x).$$<br>计算内积：<br>$$\langle x, q_0 \rangle &#x3D; 1 \cdot 1 + 2 \cdot 1 + 3 \cdot 1 &#x3D; 6, \quad \langle q_0, q_0 \rangle &#x3D; 1^2 + 1^2 + 1^2 &#x3D; 3.$$<br>则：<br>$$q_1(x) &#x3D; x - \frac{6}{3} \cdot 1 &#x3D; x - 2.$$</p>
<p><strong>验证正交性</strong>：<br>$$\langle q_1, q_0 \rangle &#x3D; (-1)(1) + 0(1) + 1(1) &#x3D; 0.$$</p>
<hr>
<h4 id="3-构造-q-2-x"><a href="#3-构造-q-2-x" class="headerlink" title="3. 构造 $$ q_2(x) $$"></a><strong>3. 构造 $$ q_2(x) $$</strong></h4><p>从 $$ x^2 $$ 中减去其在 $$ q_0(x) $$ 和 $$ q_1(x) $$ 方向的投影：<br>$$q_2(x) &#x3D; x^2 - \frac{\langle x^2, q_0 \rangle}{\langle q_0, q_0 \rangle} q_0(x) - \frac{\langle x^2, q_1 \rangle}{\langle q_1, q_1 \rangle} q_1(x).$$<br>计算各内积：</p>
<ol>
<li>$$ \langle x^2, q_0 \rangle &#x3D; 1^2 \cdot 1 + 2^2 \cdot 1 + 3^2 \cdot 1 &#x3D; 14 $$,</li>
<li>$$ \langle x^2, q_1 \rangle &#x3D; 1^2 \cdot (-1) + 2^2 \cdot 0 + 3^2 \cdot 1 &#x3D; 8 $$,</li>
<li>$$ \langle q_1, q_1 \rangle &#x3D; (-1)^2 + 0^2 + 1^2 &#x3D; 2 $$.</li>
</ol>
<p>代入公式：<br>$$q_2(x) &#x3D; x^2 - \frac{14}{3} \cdot 1 - \frac{8}{2} \cdot (x-2) &#x3D; x^2 - 4x + \frac{10}{3}.$$</p>
<p><strong>验证正交性</strong>：</p>
<ol>
<li>$$ \langle q_2, q_0 \rangle &#x3D; \frac{1}{3} \cdot 1 + \left(-\frac{2}{3}\right) \cdot 1 + \frac{1}{3} \cdot 1 &#x3D; 0 $$,</li>
<li>$$ \langle q_2, q_1 \rangle &#x3D; \frac{1}{3} \cdot (-1) + \left(-\frac{2}{3}\right) \cdot 0 + \frac{1}{3} \cdot 1 &#x3D; 0 $$.</li>
</ol>
<hr>
<h3 id="正交基结果"><a href="#正交基结果" class="headerlink" title="正交基结果"></a><strong>正交基结果</strong></h3><p>最终正交基为：<br>$$\begin{cases}<br>q_0(x) &#x3D; 1, \<br>q_1(x) &#x3D; x - 2, \<br>q_2(x) &#x3D; x^2 - 4x + \dfrac{10}{3}.<br>\end{cases}$$</p>
<hr>
<h3 id="应用：拟合数据点的最小二乘解"><a href="#应用：拟合数据点的最小二乘解" class="headerlink" title="应用：拟合数据点的最小二乘解"></a><strong>应用：拟合数据点的最小二乘解</strong></h3><p>假设数据点为 $$ {(1, y_1), (2, y_2), (3, y_3)} $$，拟合多项式为：<br>$$p(x) &#x3D; a_0 q_0(x) + a_1 q_1(x) + a_2 q_2(x).$$<br>系数可直接计算：<br>$$a_j &#x3D; \frac{\langle y, q_j \rangle}{\langle q_j, q_j \rangle} \quad (j&#x3D;0,1,2).$$</p>
<hr>
<h3 id="结论-2"><a href="#结论-2" class="headerlink" title="结论"></a><strong>结论</strong></h3><p>通过具体数值演示了 Gram-Schmidt 正交化过程，展示了如何从 $$ {1, x, x^2} $$ 构造正交基。正交化后，最小二乘系数无需解线性方程组，直接通过投影计算。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/noteRichardsoniteration/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes.github.io/images/woshicaigou.jpg">
      <meta itemprop="name" content="Chen Zhan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cz Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/notes.github.io/2025/06/23/noteRichardsoniteration/" class="post-title-link" itemprop="url">noteRichardsoniteration</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-23 18:56:58" itemprop="dateCreated datePublished" datetime="2025-06-23T18:56:58+08:00">2025-06-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>这个问题涉及矩阵多项式的特征空间视角以及对称矩阵的梯度下降方法之间的联系。以下我将详细解释这两个视角，并逐步推导和阐明它们之间的关系。</p>
<hr>
<h3 id="1-矩阵多项式的特征空间视角"><a href="#1-矩阵多项式的特征空间视角" class="headerlink" title="1. 矩阵多项式的特征空间视角"></a><strong>1. 矩阵多项式的特征空间视角</strong></h3><h4 id="矩阵多项式的定义"><a href="#矩阵多项式的定义" class="headerlink" title="矩阵多项式的定义"></a><strong>矩阵多项式的定义</strong></h4><p>给定一个矩阵 $$ A \in \mathbb{R}^{n \times n} $$ 和一个多项式 $$ p(x) &#x3D; c_k x^k + c_{k-1} x^{k-1} + \cdots + c_1 x + c_0 $$，矩阵多项式 $$ p(A) $$ 定义为：<br>$$p(A) &#x3D; c_k A^k + c_{k-1} A^{k-1} + \cdots + c_1 A + c_0 I,$$<br>其中 $$ I $$ 是单位矩阵，$$ A^k $$ 表示矩阵 $$ A $$ 的 $$ k $$ 次幂。</p>
<h4 id="特征空间的性质"><a href="#特征空间的性质" class="headerlink" title="特征空间的性质"></a><strong>特征空间的性质</strong></h4><p>假设矩阵 $$ A $$ 有特征值 $$ \lambda_1, \lambda_2, \dots, \lambda_n $$ 以及对应的特征向量 $$ v_1, v_2, \dots, v_n $$，满足：<br>$$A v_i &#x3D; \lambda_i v_i.$$<br>对于矩阵多项式 $$ p(A) $$，我们有：<br>$$p(A) v_i &#x3D; p(\lambda_i) v_i.$$<br><strong>推导</strong>：<br>$$p(A) v_i &#x3D; \left( c_k A^k + c_{k-1} A^{k-1} + \cdots + c_1 A + c_0 I \right) v_i.$$<br>由于 $$ A v_i &#x3D; \lambda_i v_i $$，我们可以计算：<br>$$A^2 v_i &#x3D; A (A v_i) &#x3D; A (\lambda_i v_i) &#x3D; \lambda_i (A v_i) &#x3D; \lambda_i^2 v_i,$$<br>依次类推，$$ A^k v_i &#x3D; \lambda_i^k v_i $$。因此：<br>$$p(A) v_i &#x3D; c_k A^k v_i + c_{k-1} A^{k-1} v_i + \cdots + c_1 A v_i + c_0 v_i<br>&#x3D; c_k \lambda_i^k v_i + c_{k-1} \lambda_i^{k-1} v_i + \cdots + c_1 \lambda_i v_i + c_0 v_i<br>&#x3D; \left( c_k \lambda_i^k + c_{k-1} \lambda_i^{k-1} + \cdots + c_1 \lambda_i + c_0 \right) v_i<br>&#x3D; p(\lambda_i) v_i.$$<br>这表明，如果 $$ v_i $$ 是 $$ A $$ 的特征向量，对应的特征值为 $$ \lambda_i $$，那么 $$ v_i $$ 也是 $$ p(A) $$ 的特征向量，对应的特征值为 $$ p(\lambda_i) $$。</p>
<h4 id="从-A-to-p-A-和-lambda-i-to-p-lambda-i"><a href="#从-A-to-p-A-和-lambda-i-to-p-lambda-i" class="headerlink" title="从 $$ A \to p(A) $$ 和 $$ \lambda_i \to p(\lambda_i) $$"></a><strong>从 $$ A \to p(A) $$ 和 $$ \lambda_i \to p(\lambda_i) $$</strong></h4><ul>
<li>矩阵 $$ A $$ 的特征值 $$ \lambda_1, \lambda_2, \dots, \lambda_n $$ 通过多项式 $$ p $$ 映射为 $$ p(\lambda_1), p(\lambda_2), \dots, p(\lambda_n) $$。</li>
<li>特征向量保持不变，只是特征值被多项式变换。这种映射在谱分析和矩阵函数（如矩阵指数、对数等）中非常重要。</li>
</ul>
<hr>
<h3 id="2-对称矩阵与梯度下降的视角"><a href="#2-对称矩阵与梯度下降的视角" class="headerlink" title="2. 对称矩阵与梯度下降的视角"></a><strong>2. 对称矩阵与梯度下降的视角</strong></h3><h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a><strong>目标函数</strong></h4><p>考虑二次目标函数：<br>$$f(x) &#x3D; \frac{1}{2} x^\top A x - b^\top x,$$<br>其中 $$ A \in \mathbb{R}^{n \times n} $$ 是一个对称矩阵（即 $$ A &#x3D; A^\top $$，这保证了 $$ A $$ 的特征值是实数且特征向量可以构成正交基），$$ x, b \in \mathbb{R}^n $$。</p>
<h4 id="梯度计算"><a href="#梯度计算" class="headerlink" title="梯度计算"></a><strong>梯度计算</strong></h4><p>我们计算目标函数的梯度：<br>$$\nabla f(x) &#x3D; \nabla \left( \frac{1}{2} x^\top A x - b^\top x \right).$$</p>
<ul>
<li>对于第一项 $$ \frac{1}{2} x^\top A x $$：<br>$$\nabla \left( \frac{1}{2} x^\top A x \right) &#x3D; \frac{1}{2} (A + A^\top) x.$$<br>由于 $$ A $$ 是对称的，$$ A^\top &#x3D; A $$，因此：<br>$$\frac{1}{2} (A + A^\top) x &#x3D; \frac{1}{2} (A + A) x &#x3D; \frac{1}{2} \cdot 2A x &#x3D; A x.$$</li>
<li>对于第二项 $$ -b^\top x $$：<br>$$\nabla (-b^\top x) &#x3D; -b.$$<br>因此，梯度为：<br>$$\nabla f(x) &#x3D; A x - b.$$</li>
</ul>
<h4 id="梯度下降方法"><a href="#梯度下降方法" class="headerlink" title="梯度下降方法"></a><strong>梯度下降方法</strong></h4><p>梯度下降的迭代公式为：<br>$$x_{k+1} &#x3D; x_k - \alpha \nabla f(x_k),$$<br>其中 $$ \alpha $$ 是步长。代入梯度：<br>$$\nabla f(x_k) &#x3D; A x_k - b,$$<br>得到：<br>$$x_{k+1} &#x3D; x_k - \alpha (A x_k - b) &#x3D; (I - \alpha A) x_k + \alpha b.$$<br>这是一个线性迭代过程，形式为：<br>$$x_{k+1} &#x3D; T x_k + c,$$<br>其中 $$ T &#x3D; I - \alpha A $$，$$ c &#x3D; \alpha b $$。</p>
<h4 id="梯度下降与矩阵多项式的联系"><a href="#梯度下降与矩阵多项式的联系" class="headerlink" title="梯度下降与矩阵多项式的联系"></a><strong>梯度下降与矩阵多项式的联系</strong></h4><p>梯度下降的迭代可以看作是对初始向量 $$ x_0 $$ 应用一系列矩阵多项式。假设初始点为 $$ x_0 $$，迭代 $$ k $$ 次后：<br>$$x_k &#x3D; (I - \alpha A)^k x_0 + \sum_{j&#x3D;0}^{k-1} (I - \alpha A)^j \alpha b.$$<br>这里，矩阵 $$ I - \alpha A $$ 是一个多项式（一次多项式）的形式，多次迭代形成了高次多项式 $$ (I - \alpha A)^k $$。如果我们考虑误差 $$ e_k &#x3D; x_k - x^* $$，其中 $$ x^* $$ 是目标函数的最优解（满足 $$ A x^* &#x3D; b $$，即 ( x^* &#x3D; A^{-1} b \）），则：<br>$$e_k &#x3D; (I - \alpha A)^k e_0.$$<br>在特征空间中，假设 $$ A $$ 的特征值为 $$ \lambda_i $$，特征向量为 $$ v_i $$，则 $$ I - \alpha A $$ 的特征值为：<br>$$1 - \alpha \lambda_i.$$<br>因此，误差在特征向量 $$ v_i $$ 方向上的分量会按 $$ (1 - \alpha \lambda_i)^k $$ 收敛。收敛速度取决于 $$ |1 - \alpha \lambda_i| &lt; 1 $$，这与矩阵多项式 $$ p(A) &#x3D; (I - \alpha A)^k $$ 的特征值 $$ p(\lambda_i) &#x3D; (1 - \alpha \lambda_i)^k $$ 直接相关。</p>
<hr>
<h3 id="3-两个视角的联系"><a href="#3-两个视角的联系" class="headerlink" title="3. 两个视角的联系"></a><strong>3. 两个视角的联系</strong></h3><h4 id="特征空间与梯度下降"><a href="#特征空间与梯度下降" class="headerlink" title="特征空间与梯度下降"></a><strong>特征空间与梯度下降</strong></h4><ul>
<li><strong>矩阵多项式视角</strong>：矩阵 $$ A $$ 的特征值 $$ \lambda_i $$ 通过多项式 $$ p $$ 映射到 $$ p(\lambda_i) $$。在梯度下降中，矩阵多项式 $$ p(A) &#x3D; (I - \alpha A)^k $$ 将特征值 $$ \lambda_i $$ 映射到 $$ (1 - \alpha \lambda_i)^k $$。这决定了误差在每个特征方向上的收敛速度。</li>
<li><strong>梯度下降视角</strong>：目标函数 $$ f(x) &#x3D; \frac{1}{2} x^\top A x - b^\top x $$ 的优化过程通过迭代 $$ x_{k+1} &#x3D; (I - \alpha A) x_k + \alpha b $$ 逐步逼近最优解 $$ x^* &#x3D; A^{-1} b $$。迭代矩阵 $$ I - \alpha A $$ 的谱性质（即特征值 $$ 1 - \alpha \lambda_i $$）决定了收敛行为。</li>
</ul>
<h4 id="对称矩阵的特殊性"><a href="#对称矩阵的特殊性" class="headerlink" title="对称矩阵的特殊性"></a><strong>对称矩阵的特殊性</strong></h4><p>当 $$ A $$ 是对称矩阵时：</p>
<ul>
<li>$$ A $$ 的特征值是实数，特征向量正交，这简化了特征空间的分析。</li>
<li>目标函数 $$ f(x) $$ 是凸的（若 $$ A $$ 正定，则严格凸），梯度下降保证收敛到全局最优解。</li>
<li>梯度下降的收敛速度由 $$ A $$ 的条件数（最大特征值与最小特征值的比值）决定，因为 $$ |1 - \alpha \lambda_i| $$ 的最大值决定了误差缩小的速度。</li>
</ul>
<h4 id="多项式优化"><a href="#多项式优化" class="headerlink" title="多项式优化"></a><strong>多项式优化</strong></h4><p>在梯度下降中，矩阵多项式 $$ p(A) &#x3D; (I - \alpha A)^k $$ 的作用是将初始误差 $$ e_0 $$ 映射到 $$ e_k &#x3D; p(A) e_0 $$。为了加速收敛，可以选择更复杂的多项式 $$ p(A) $$，例如使用<strong>多项式预条件子</strong>或<strong>共轭梯度法</strong>（Conjugate Gradient, CG）。CG 方法本质上是通过构造一个最优的多项式 $$ p(A) $$，使得误差 $$ | e_k |_A &#x3D; \sqrt{e_k^\top A e_k} $$ 最小化，其中 $$ p(\lambda_i) $$ 在特征值范围内尽可能小。</p>
<hr>
<h3 id="4-补充：梯度公式中的问题"><a href="#4-补充：梯度公式中的问题" class="headerlink" title="4. 补充：梯度公式中的问题"></a><strong>4. 补充：梯度公式中的问题</strong></h3><p>在问题中，梯度计算部分提到：<br>$$\nabla \left( \frac{1}{2} x^\top A x - b^\top x \right) &#x3D; \frac{1}{2} (A + A^\top) x - b &#x3D; A x_k - ?.$$<br>从推导来看：<br>$$\nabla f(x) &#x3D; \frac{1}{2} (A + A^\top) x - b.$$<br>由于 $$ A $$ 是对称的，$$ A &#x3D; A^\top $$，所以：<br>$$\frac{1}{2} (A + A^\top) x &#x3D; \frac{1}{2} (A + A) x &#x3D; A x.$$<br>因此：<br>$$\nabla f(x) &#x3D; A x - b.$$<br>在迭代中，$$ x &#x3D; x_k $$ 时，梯度为：<br>$$\nabla f(x_k) &#x3D; A x_k - b.$$<br>问题中的“$$ A x_k - ? $$” 应该是指：<br>$$\nabla f(x_k) &#x3D; A x_k - b.$$<br>这里的 $$ ? $$ 就是 $$ b $$。如果问题中暗示了其他上下文（例如某种近似或变体），请提供更多细节，我可以进一步分析。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><ul>
<li><strong>矩阵多项式视角</strong>：矩阵 $$ A $$ 的特征值 $$ \lambda_i $$ 通过多项式 $$ p $$ 映射到 $$ p(\lambda_i) $$，特征向量不变。这在分析矩阵函数和迭代方法（如梯度下降）的谱性质时非常有用。</li>
<li><strong>梯度下降视角</strong>：对于对称矩阵 $$ A $$，目标函数 $$ f(x) &#x3D; \frac{1}{2} x^\top A x - b^\top x $$ 的梯度下降迭代可以看作是矩阵多项式 $$ (I - \alpha A)^k $$ 的应用，收敛速度由特征值 $$ 1 - \alpha \lambda_i $$ 决定。</li>
<li><strong>联系</strong>：梯度下降的迭代本质上是通过矩阵多项式操作特征空间中的误差分量，特征值的变换 $$ \lambda_i \to (1 - \alpha \lambda_i)^k $$ 决定了收敛行为。</li>
<li><strong>对称矩阵的优势</strong>：对称性保证了实特征值和正交特征向量，使得分析和优化更简单，梯度下降收敛到全局最优。</li>
</ul>
<p>如果有进一步的问题或需要更深入的推导（例如共轭梯度法、预条件子或谱分析），请告诉我！</p>
<p>这个问题涉及矩阵逆的近似、Richardson迭代的收敛性分析，以及条件数与迭代步数的关系。以下我将详细推导每个部分，帮助你理解问题的核心内容和推导过程。</p>
<hr>
<h3 id="1-矩阵逆的近似：-A-1-approx-p-A"><a href="#1-矩阵逆的近似：-A-1-approx-p-A" class="headerlink" title="1. 矩阵逆的近似：$$ A^{-1} \approx p(A) $$"></a><strong>1. 矩阵逆的近似：$$ A^{-1} \approx p(A) $$</strong></h3><h4 id="目标"><a href="#目标" class="headerlink" title="目标"></a><strong>目标</strong></h4><p>我们希望通过一个多项式 $$ p(A) $$ 来近似矩阵 $$ A $$ 的逆 $$ A^{-1} $$，即：<br>$$A^{-1} \approx p(A),$$<br>其中 $$ p(A) $$ 是矩阵 $$ A $$ 的多项式，形式为：<br>$$p(A) &#x3D; c_k A^k + c_{k-1} A^{k-1} + \cdots + c_1 A + c_0 I.$$<br>理想情况下，$$ p(A) A &#x3D; I $$，但我们通常只能找到一个近似，使得 $$ p(A) A \approx I $$。</p>
<h4 id="等价的多项式-q-x"><a href="#等价的多项式-q-x" class="headerlink" title="等价的多项式 $$ q(x) $$"></a><strong>等价的多项式 $$ q(x) $$</strong></h4><p>为了近似 $$ A^{-1} $$，我们引入一个辅助多项式：<br>$$q(x) &#x3D; 1 - x p(x).$$<br>目标是让 $$ q(A) &#x3D; I - A p(A) \approx 0 $$，因为：<br>$$I - A p(A) &#x3D; 0 \implies A p(A) &#x3D; I \implies p(A) &#x3D; A^{-1}.$$<br>因此，我们希望找到一个多项式 $$ p(x) $$，使得：<br>$$q(x) &#x3D; 1 - x p(x) \approx 0, \quad \forall x \in {\lambda_1, \lambda_2, \dots, \lambda_n},$$<br>其中 $$ \lambda_i $$ 是矩阵 $$ A $$ 的特征值。同时，注意到：<br>$$q(0) &#x3D; 1 - 0 \cdot p(0) &#x3D; 1.$$<br>假设 $$ A $$ 是正定对称矩阵（常见于优化问题），其特征值满足 $$ \lambda_i &gt; 0 $$。我们需要：</p>
<ul>
<li>$$ q(0) &#x3D; 1 $$,</li>
<li>$$ q(x) \approx 0 $$ 对于 $$ x \in [\lambda_1, \lambda_n] $$，其中 $$ \lambda_1 \leq \lambda_i \leq \lambda_n $$ 是 $$ A $$ 的最小和最大特征值。</li>
</ul>
<h4 id="意义"><a href="#意义" class="headerlink" title="意义"></a><strong>意义</strong></h4><p>寻找这样的 $$ p(x) $$ 是一个多项式逼近问题，类似于用多项式逼近函数 $$ 1&#x2F;x $$。在实际中，可以使用切比雪夫多项式或其他优化多项式来构造 $$ p(x) $$，以最小化 $$ |q(x)| $$ 在特征值区间 $$ [\lambda_1, \lambda_n] $$ 上的最大值。</p>
<hr>
<h3 id="2-求解线性系统-Ax-b"><a href="#2-求解线性系统-Ax-b" class="headerlink" title="2. 求解线性系统 $$ Ax &#x3D; b $$"></a><strong>2. 求解线性系统 $$ Ax &#x3D; b $$</strong></h3><h4 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a><strong>目标</strong></h4><p>我们希望解线性方程组：<br>$$Ax &#x3D; b,$$<br>其解为：<br>$$x^* &#x3D; A^{-1} b.$$<br>如果我们用多项式 $$ p(A) $$ 近似 $$ A^{-1} $$，则：<br>$$x^* \approx p(A) b.$$<br>注意到 $$ p(A) b $$ 是 $$ A $$ 的幂次作用在 $$ b $$ 上的线性组合：<br>$$p(A) b &#x3D; \left( c_k A^k + c_{k-1} A^{k-1} + \cdots + c_1 A + c_0 I \right) b &#x3D; c_k A^k b + c_{k-1} A^{k-1} b + \cdots + c_1 A b + c_0 b.$$<br>因此，$$ p(A) b $$ 属于 Krylov 子空间：<br>$$x^* \approx p(A) b \in \text{span}{b, A b, A^2 b, \dots}.$$</p>
<hr>
<h3 id="3-Richardson-迭代"><a href="#3-Richardson-迭代" class="headerlink" title="3. Richardson 迭代"></a><strong>3. Richardson 迭代</strong></h3><h4 id="迭代公式"><a href="#迭代公式" class="headerlink" title="迭代公式"></a><strong>迭代公式</strong></h4><p>Richardson 迭代是一种简单的迭代方法，用于解 $$ Ax &#x3D; b $$。其迭代公式为：<br>$$x_{k+1} &#x3D; (I - \alpha A) x_k + \alpha b,$$<br>初始点设为 $$ x_0 &#x3D; 0 $$。其中，$$ \alpha $$ 是步长（类似梯度下降中的学习率）。</p>
<h4 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a><strong>误差分析</strong></h4><p>令误差 $$ e_k &#x3D; x_k - x^* $$，其中 $$ x^* &#x3D; A^{-1} b $$ 是精确解。则：<br>$$e_{k+1} &#x3D; x_{k+1} - x^* &#x3D; (I - \alpha A) x_k + \alpha b - x^<em>.$$<br>因为 $$ A x^</em> &#x3D; b $$，所以 $$ \alpha b &#x3D; \alpha A x^* $$。代入：<br>$$e_{k+1} &#x3D; (I - \alpha A) x_k + \alpha A x^* - x^* &#x3D; (I - \alpha A) x_k + (\alpha A x^* - x^<em>) &#x3D; (I - \alpha A) x_k - (I - \alpha A) x^</em>.$$<br>因此：<br>$$e_{k+1} &#x3D; (I - \alpha A) (x_k - x^<em>) &#x3D; (I - \alpha A) e_k.$$<br>递归展开：<br>$$e_k &#x3D; (I - \alpha A)^k e_0,$$<br>其中 $$ e_0 &#x3D; x_0 - x^</em> &#x3D; 0 - x^* &#x3D; -x^* $$（因为 $$ x_0 &#x3D; 0 $$）。</p>
<h4 id="收敛性分析"><a href="#收敛性分析" class="headerlink" title="收敛性分析"></a><strong>收敛性分析</strong></h4><p>误差的收敛取决于矩阵 $$ I - \alpha A $$ 的谱半径 $$ \rho(I - \alpha A) $$。假设 $$ A $$ 是对称正定矩阵，特征值为 $$ 0 &lt; \lambda_1 \leq \lambda_2 \leq \cdots \leq \lambda_n $$。则 $$ I - \alpha A $$ 的特征值为：<br>$$1 - \alpha \lambda_i.$$<br>谱半径定义为：<br>$$\rho(I - \alpha A) &#x3D; \max_i |1 - \alpha \lambda_i|.$$<br>为了保证收敛，需要：<br>$$\rho(I - \alpha A) &#x3D; \max_i |1 - \alpha \lambda_i| &lt; 1.$$<br>这意味着对于所有特征值 $$ \lambda_i $$，必须有：<br>$$-1 &lt; 1 - \alpha \lambda_i &lt; 1 \implies 0 &lt; \alpha \lambda_i &lt; 2 \implies 0 &lt; \alpha &lt; \frac{2}{\lambda_i}.$$<br>由于 $$ \lambda_n $$ 是最大特征值，约束条件为：<br>$$0 &lt; \alpha &lt; \frac{2}{\lambda_n}.$$<br>谱半径具体为：<br>$$\rho(I - \alpha A) &#x3D; \max { |1 - \alpha \lambda_1|, |1 - \alpha \lambda_n| },$$<br>因为 $$ \lambda_1 \leq \lambda_i \leq \lambda_n $$，且 $$ 1 - \alpha \lambda_i $$ 在 $$ [1 - \alpha \lambda_n, 1 - \alpha \lambda_1] $$ 之间。</p>
<hr>
<h3 id="4-选择最优步长-alpha"><a href="#4-选择最优步长-alpha" class="headerlink" title="4. 选择最优步长 $$ \alpha $$"></a><strong>4. 选择最优步长 $$ \alpha $$</strong></h3><h4 id="优化-alpha"><a href="#优化-alpha" class="headerlink" title="优化 $$ \alpha $$"></a><strong>优化 $$ \alpha $$</strong></h4><p>为了最小化谱半径 $$ \rho(I - \alpha A) $$，我们希望：<br>$$|1 - \alpha \lambda_1| &#x3D; |1 - \alpha \lambda_n|.$$<br>设：<br>$$1 - \alpha \lambda_1 &#x3D; -(1 - \alpha \lambda_n).$$<br>解这个方程：<br>$$1 - \alpha \lambda_1 &#x3D; -1 + \alpha \lambda_n \implies 1 + 1 &#x3D; \alpha \lambda_n + \alpha \lambda_1 \implies 2 &#x3D; \alpha (\lambda_n + \lambda_1) \implies \alpha &#x3D; \frac{2}{\lambda_1 + \lambda_n}.$$<br>代入 $$ \alpha &#x3D; \frac{2}{\lambda_1 + \lambda_n} $$，计算：<br>$$1 - \alpha \lambda_1 &#x3D; 1 - \frac{2 \lambda_1}{\lambda_1 + \lambda_n} &#x3D; \frac{\lambda_1 + \lambda_n - 2 \lambda_1}{\lambda_1 + \lambda_n} &#x3D; \frac{\lambda_n - \lambda_1}{\lambda_1 + \lambda_n}.$$<br>类似地：<br>$$1 - \alpha \lambda_n &#x3D; 1 - \frac{2 \lambda_n}{\lambda_1 + \lambda_n} &#x3D; \frac{\lambda_1 + \lambda_n - 2 \lambda_n}{\lambda_1 + \lambda_n} &#x3D; \frac{\lambda_1 - \lambda_n}{\lambda_1 + \lambda_n} &#x3D; -\frac{\lambda_n - \lambda_1}{\lambda_1 + \lambda_n}.$$<br>因此：<br>$$|1 - \alpha \lambda_1| &#x3D; \frac{\lambda_n - \lambda_1}{\lambda_1 + \lambda_n}, \quad |1 - \alpha \lambda_n| &#x3D; \frac{\lambda_n - \lambda_1}{\lambda_1 + \lambda_n}.$$<br>谱半径为：<br>$$\rho(I - \alpha A) &#x3D; \frac{\lambda_n - \lambda_1}{\lambda_1 + \lambda_n} &#x3D; \frac{\frac{\lambda_n}{\lambda_1} - 1}{\frac{\lambda_n}{\lambda_1} + 1} &#x3D; \frac{\kappa - 1}{\kappa + 1},$$<br>其中 $$ \kappa &#x3D; \frac{\lambda_n}{\lambda_1} $$ 是 $$ A $$ 的条件数。</p>
<h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a><strong>验证</strong></h4><p>注意到：<br>$$\frac{\kappa - 1}{\kappa + 1} &#x3D; 1 - \frac{2}{\kappa + 1} &#x3D; 1 - \frac{2}{\frac{\lambda_n}{\lambda_1} + 1}.$$<br>这与问题中的表达式一致：<br>$$\rho(I - \alpha A) &#x3D; 1 - \frac{2}{\frac{\lambda_n}{\lambda_1} + 1}.$$</p>
<hr>
<h3 id="5-收敛步数估计"><a href="#5-收敛步数估计" class="headerlink" title="5. 收敛步数估计"></a><strong>5. 收敛步数估计</strong></h3><h4 id="误差收敛"><a href="#误差收敛" class="headerlink" title="误差收敛"></a><strong>误差收敛</strong></h4><p>误差满足：<br>$$e_k &#x3D; (I - \alpha A)^k e_0.$$<br>在范数中：<br>$$|e_k| \leq |(I - \alpha A)^k| |e_0| \leq [\rho(I - \alpha A)]^k |e_0|.$$<br>为了使误差满足 $$ |e_k| \leq \epsilon |e_0| $$，需要：<br>$$[\rho(I - \alpha A)]^k \leq \epsilon.$$<br>取对数：<br>$$k \ln \rho(I - \alpha A) \leq \ln \epsilon \implies k \geq \frac{\ln \epsilon}{\ln \rho(I - \alpha A)}.$$<br>由于 $$ \rho(I - \alpha A) &lt; 1 $$，$$ \ln \rho(I - \alpha A) &lt; 0 $$，所以：<br>$$k \geq \frac{\ln (1&#x2F;\epsilon)}{-\ln \rho(I - \alpha A)}.$$<br>近似地，当 $$ \rho &#x3D; \frac{\kappa - 1}{\kappa + 1} &#x3D; 1 - \frac{2}{\kappa + 1} $$ 接近 1 时（即 $$ \kappa $$ 较大）：<br>$$-\ln \rho \approx -\ln \left( 1 - \frac{2}{\kappa + 1} \right) \approx \frac{2}{\kappa + 1} \quad (\text{因为 } \ln(1 - x) \approx -x \text{ 当 } x \text{ 小时}).$$<br>因此：<br>$$k \gtrsim \frac{\ln (1&#x2F;\epsilon)}{\frac{2}{\kappa + 1}} &#x3D; \frac{\kappa + 1}{2} \ln \frac{1}{\epsilon}.$$<br>考虑到 $$ \kappa &#x3D; \frac{\lambda_n}{\lambda_1} $$，我们得到：<br>$$k \sim O\left( \left( \frac{\lambda_n}{\lambda_1} + 1 \right) \ln \frac{1}{\epsilon} \right) &#x3D; O\left( (\kappa + 1) \ln \frac{1}{\epsilon} \right).$$<br>这表明收敛步数与条件数 $$ \kappa $$ 成正比，条件数越大，收敛越慢。</p>
<hr>
<h3 id="6-条件数的作用"><a href="#6-条件数的作用" class="headerlink" title="6. 条件数的作用"></a><strong>6. 条件数的作用</strong></h3><h4 id="条件数-kappa-frac-lambda-n-lambda-1"><a href="#条件数-kappa-frac-lambda-n-lambda-1" class="headerlink" title="条件数 $$ \kappa &#x3D; \frac{\lambda_n}{\lambda_1} $$"></a><strong>条件数 $$ \kappa &#x3D; \frac{\lambda_n}{\lambda_1} $$</strong></h4><ul>
<li>条件数 $$ \kappa $$ 衡量了矩阵 $$ A $$ 的“病态”程度。较大的 $$ \kappa $$ 表示特征值分布范围广，迭代方法收敛较慢。</li>
<li>在 Richardson 迭代中，谱半径 $$ \rho(I - \alpha A) &#x3D; \frac{\kappa - 1}{\kappa + 1} $$ 接近 1（当 $$ \kappa $$ 很大时），导致收敛缓慢。</li>
<li>条件数直接影响收敛步数，步数与 $$ \kappa $$ 成线性关系。</li>
</ul>
<h4 id="改进方法"><a href="#改进方法" class="headerlink" title="改进方法"></a><strong>改进方法</strong></h4><p>为了克服条件数大的问题，可以使用：</p>
<ul>
<li><strong>预条件子</strong>：引入预条件矩阵 $$ M $$，将系统转化为 $$ M^{-1} A x &#x3D; M^{-1} b $$，减小 $$ M^{-1} A $$ 的条件数。</li>
<li><strong>共轭梯度法</strong>：通过构造 Krylov 子空间中的最优解，收敛步数从 $$ O(\kappa) $$ 降低到 $$ O(\sqrt{\kappa}) $$。</li>
</ul>
<hr>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a><strong>总结</strong></h3><ul>
<li><strong>矩阵逆近似</strong>：通过多项式 $$ p(A) $$ 近似 $$ A^{-1} $$，等价于构造 $$ q(x) &#x3D; 1 - x p(x) \approx 0 $$，满足 $$ q(0) &#x3D; 1 $$。</li>
<li><strong>Richardson 迭代</strong>：迭代 $$ x_{k+1} &#x3D; (I - \alpha A) x_k + \alpha b $$，误差 $$ e_k &#x3D; (I - \alpha A)^k e_0 $$，收敛由谱半径 $$ \rho(I - \alpha A) $$ 决定。</li>
<li><strong>最优步长</strong>：选择 $$ \alpha &#x3D; \frac{2}{\lambda_1 + \lambda_n} $$，使 $$ \rho(I - \alpha A) &#x3D; \frac{\kappa - 1}{\kappa + 1} &#x3D; 1 - \frac{2}{\kappa + 1} $$。</li>
<li><strong>收敛步数</strong>：需要 $$ O((\kappa + 1) \ln (1&#x2F;\epsilon)) $$ 步，条件数 $$ \kappa &#x3D; \frac{\lambda_n}{\lambda_1} $$ 是关键因素。</li>
<li><strong>条件数</strong>：较大的 $$ \kappa $$ 导致收敛缓慢，可通过预条件子或共轭梯度法改进。</li>
</ul>
<p>如果你对某些部分（如切比雪夫多项式逼近、预条件子或共轭梯度法的具体实现）有进一步疑问，请告诉我，我可以更深入地推导或解释！</p>
<p>好的，下面是对上面 Chebyshev 迭代和共轭梯度 (CG) 方法的详细解释和推导的中文翻译，力求流畅准确：</p>
<hr>
<h3 id="1-Chebyshev-迭代"><a href="#1-Chebyshev-迭代" class="headerlink" title="1. Chebyshev 迭代"></a><strong>1. Chebyshev 迭代</strong></h3><h4 id="目标-2"><a href="#目标-2" class="headerlink" title="目标"></a><strong>目标</strong></h4><p>Chebyshev 迭代法的目标是通过求解线性方程组 $$ Ax &#x3D; b $$ 来逼近逆矩阵 $$ A^{-1} $$，其中 $$ A $$ 是一个对称正定 (SPD) 矩阵。该方法将 $$ A^{-1} $$ 近似为一个多项式 $$ p(A) $$，使得 $$ x^* &#x3D; A^{-1}b \approx p(A)b $$。 等价地说，我们希望找到一个多项式 $$ q(x) &#x3D; 1 - x p(x) $$，满足：</p>
<ul>
<li>$$ q(0) &#x3D; 1 $$,</li>
<li>$$ q(x) \approx 0 $$ 对于 $$ x &gt; 0 $$ （特别地，对于 $$ x $$ 在 $$ A $$ 的谱内）。</li>
</ul>
<p>因为 $$ A $$ 是 SPD 矩阵，它的特征值都是正的，假设 $$ \lambda_i \in [\lambda_{\text{min}}, \lambda_{\text{max}}] $$，其中 $$ \lambda_{\text{min}} &gt; 0 $$。</p>
<h4 id="迭代方案"><a href="#迭代方案" class="headerlink" title="迭代方案"></a><strong>迭代方案</strong></h4><p>Chebyshev 迭代法的迭代公式为：<br>$$x_{k+1} &#x3D; (I - \alpha_k A) x_k + \alpha_k b$$<br>其中 $$ \alpha_k $$ 是标量，用于优化收敛速度。 让我们推导误差传播公式来理解这个过程。</p>
<h4 id="误差分析-1"><a href="#误差分析-1" class="headerlink" title="误差分析"></a><strong>误差分析</strong></h4><p>精确解为 $$ x^* &#x3D; A^{-1}b $$。定义第 $$ k $$ 步的误差：<br>$$e_k &#x3D; x_k - x^<em>$$<br>从迭代公式中减去 $$ x^</em> $$ 的迭代公式（$$ A x^* &#x3D; b $$），得到：<br>$$x_{k+1} - x^* &#x3D; (I - \alpha_k A) x_k + \alpha_k b - x^<em>$$<br>因为 $$ b &#x3D; A x^</em> $$，所以：<br>$$\alpha_k b &#x3D; \alpha_k A x^<em>$$<br>因此：<br>$$x_{k+1} - x^</em> &#x3D; (I - \alpha_k A) x_k - (I - \alpha_k A) x^* &#x3D; (I - \alpha_k A) (x_k - x^*)$$<br>所以：<br>$$e_{k+1} &#x3D; (I - \alpha_k A) e_k$$<br>通过归纳法：<br>$$e_k &#x3D; \prod_{i&#x3D;0}^{k-1} (I - \alpha_i A) e_0$$<br>通过应用矩阵多项式 $$ \prod_{i&#x3D;0}^{k-1} (I - \alpha_i A) $$ 来减小误差。 目标是选择 $$ \alpha_i $$ 来最小化这个算子的范数。</p>
<h4 id="与多项式逼近的联系"><a href="#与多项式逼近的联系" class="headerlink" title="与多项式逼近的联系"></a><strong>与多项式逼近的联系</strong></h4><p>因为 $$ e_k &#x3D; \left( \prod_{i&#x3D;0}^{k-1} (I - \alpha_i A) \right) e_0 $$，我们希望：<br>$$\left| \prod_{i&#x3D;0}^{k-1} (I - \alpha_i A) \right|$$<br>尽可能小。 对于 SPD 矩阵 $$ A $$，该范数取决于应用于 $$ A $$ 的多项式的特征值。 设这个多项式为：<br>$$P_k(A) &#x3D; \prod_{i&#x3D;0}^{k-1} (I - \alpha_i A)$$<br>对于 $$ A $$ 的任何特征值 $$ \lambda_i $$，该多项式的值为：<br>$$P_k(\lambda_i) &#x3D; \prod_{i&#x3D;0}^{k-1} (1 - \alpha_i \lambda_i)$$<br>我们需要 $$ P_k(\lambda_i) \approx 0 $$ 对于 $$ \lambda_i \in [\lambda_{\text{min}}, \lambda_{\text{max}}] $$。 这就是 Chebyshev 多项式发挥作用的地方。</p>
<h4 id="Chebyshev-多项式"><a href="#Chebyshev-多项式" class="headerlink" title="Chebyshev 多项式"></a><strong>Chebyshev 多项式</strong></h4><p>第一类 Chebyshev 多项式定义为：<br>$$T_k(x) &#x3D; \cos(k \arccos(x)), \quad x \in [-1, 1]$$<br>它们在 $$[-1, 1]$$ 区间内振荡于 $$-1$$ 和 $$1$$ 之间，并在该区间外迅速增长。为了将它们应用于 $$ A $$ 的谱，我们通过线性变换将区间 $$ [\lambda_{\text{min}}, \lambda_{\text{max}}] $$ 映射到 $$[-1, 1]$$：<br>$$z &#x3D; \frac{2\lambda - (\lambda_{\text{max}} + \lambda_{\text{min}})}{\lambda_{\text{max}} - \lambda_{\text{min}}}$$<br>这个变换将 $$ \lambda &#x3D; \lambda_{\text{min}} $$ 映射到 $$ z &#x3D; -1 $$，将 $$ \lambda &#x3D; \lambda_{\text{max}} $$ 映射到 $$ z &#x3D; 1 $$。Chebyshev 多项式 $$ T_k(z) $$ 用于构造 $$ P_k(\lambda) $$，使其在 $$ [\lambda_{\text{min}}, \lambda_{\text{max}}] $$ 上尽可能小。</p>
<p>参数 $$ \alpha_k $$ 的选择基于 Chebyshev 多项式的根，并调整到区间 $$ [\lambda_{\text{min}}, \lambda_{\text{max}}] $$。 具体来说，$$ T_k $$ 在 $$[-1, 1]$$ 上的根被映射回 $$ [\lambda_{\text{min}}, \lambda_{\text{max}}] $$，且 $$ \alpha_k &#x3D; 1&#x2F;\lambda_k $$，其中 $$ \lambda_k $$ 是这些映射的根。 这确保了多项式 $$ P_k(\lambda) $$ 在特征值范围内的最大范数上被最小化。</p>
<h4 id="Krylov-子空间"><a href="#Krylov-子空间" class="headerlink" title="Krylov 子空间"></a><strong>Krylov 子空间</strong></h4><p>注意：<br>$$x_{k+1} &#x3D; (I - \alpha_k A) x_k + \alpha_k b$$<br>从 $$ x_0 &#x3D; 0 $$ 开始：<br>$$x_1 &#x3D; \alpha_0 b$$<br>$$x_2 &#x3D; (I - \alpha_1 A) (\alpha_0 b) + \alpha_1 b &#x3D; \alpha_1 b + \alpha_0 (I - \alpha_1 A) b$$<br>每次迭代都会添加涉及更高次幂的 $$ A $$ 应用于 $$ b $$ 的项。 因此：<br>$$x_k \in \text{span}{ b, A b, A^2 b, \dots, A^{k-1} b }$$<br>这就是 Krylov 子空间 $$ \mathcal{K}_k &#x3D; \text{span}{ b, A b, \dots, A^{k-1} b } $$。</p>
<h4 id="Chebyshev-迭代的总结"><a href="#Chebyshev-迭代的总结" class="headerlink" title="Chebyshev 迭代的总结"></a><strong>Chebyshev 迭代的总结</strong></h4><ul>
<li>该方法构造 $$ x_k $$ 作为 $$ A $$ 的多项式应用于 $$ b $$。</li>
<li>误差 $$ e_k &#x3D; P_k(A) e_0 $$，其中 $$ P_k(A) $$ 使用 Chebyshev 多项式设计，以最小化 $$ A $$ 的特征值上的谱范数。</li>
<li>需要估计 $$ \lambda_{\text{min}} $$ 和 $$ \lambda_{\text{max}} $$ 来设置 $$ \alpha_k $$。</li>
<li>对于条件良好的矩阵（小的 $$ \kappa &#x3D; \lambda_{\text{max}} &#x2F; \lambda_{\text{min}} $$），收敛速度更快。</li>
</ul>
<hr>
<h3 id="2-共轭梯度-CG"><a href="#2-共轭梯度-CG" class="headerlink" title="2. 共轭梯度 (CG)"></a><strong>2. 共轭梯度 (CG)</strong></h3><h4 id="目标-3"><a href="#目标-3" class="headerlink" title="目标"></a><strong>目标</strong></h4><p>共轭梯度法也用于求解 $$ Ax &#x3D; b $$，其中 $$ A $$ 是一个 SPD 矩阵。它通过利用 $$ A $$ 内积的几何性质，最小化 Krylov 子空间内的 $$ A $$ 范数误差。</p>
<h4 id="A-内积"><a href="#A-内积" class="headerlink" title="A-内积"></a><strong>A-内积</strong></h4><p>定义向量 $$ x, y $$ 的 $$ A $$-内积：<br>$$\langle x, y \rangle_A &#x3D; x^\top A y$$<br>由于 $$ A $$ 是 SPD 矩阵：</p>
<ul>
<li><strong>线性性</strong>: $$ \langle \alpha x + \beta y, z \rangle_A &#x3D; \alpha \langle x, z \rangle_A + \beta \langle y, z \rangle_A $$。</li>
<li><strong>对称性</strong>: $$ \langle x, y \rangle_A &#x3D; \langle y, x \rangle_A $$。</li>
<li><strong>正定性</strong>: $$ \langle x, x \rangle_A &#x3D; x^\top A x &gt; 0 $$ 对于 $$ x \neq 0 $$。</li>
</ul>
<p>相关的 $$ A $$-范数为：<br>$$| x |_A &#x3D; \sqrt{\langle x, x \rangle_A} &#x3D; \sqrt{x^\top A x}$$<br>如果满足以下条件，则向量 $$ x, y $$ 是 $$ A $$-共轭的（或 $$ A $$-正交的）：<br>$$\langle x, y \rangle_A &#x3D; x^\top A y &#x3D; 0$$</p>
<h4 id="优化视角"><a href="#优化视角" class="headerlink" title="优化视角"></a><strong>优化视角</strong></h4><p>考虑二次函数：<br>$$f(x) &#x3D; \frac{1}{2} x^\top A x - b^\top x$$<br>梯度为：<br>$$\nabla f(x) &#x3D; A x - b$$<br>当 $$ \nabla f(x) &#x3D; 0 $$ 时，即 $$ A x &#x3D; b $$ 时，达到最小值。计算：<br>$$f(x) &#x3D; \frac{1}{2} x^\top A x - b^\top x &#x3D; \frac{1}{2} (x - x^<em>)^\top A (x - x^</em>) - \frac{1}{2} x^{<em>\top} A x^</em>$$<br>其中 $$ x^* &#x3D; A^{-1} b $$。 因此：<br>$$f(x) &#x3D; \frac{1}{2} | x - x^* |_A^2 + \text{常量}$$<br>最小化 $$ f(x) $$ 等价于最小化 $$ | x - x^* |_A $$。</p>
<h4 id="CG-算法"><a href="#CG-算法" class="headerlink" title="CG 算法"></a><strong>CG 算法</strong></h4><p>CG 算法生成迭代点 $$ x_k \in \mathcal{K}<em>k &#x3D; \text{span}{ b, A b, \dots, A^{k-1} b } $$，使得：<br>$$x_k &#x3D; \arg\min</em>{x \in \mathcal{K}_k} | x - x^* |_A^2$$<br>定义：</p>
<ul>
<li>$$ v_i &#x3D; x_i - x_{i-1} $$ (搜索方向),</li>
<li>$$ r_i &#x3D; b - A x_i $$ (残差).</li>
</ul>
<p>关键性质是 $$ v_i $$ 是 $$ A $$-共轭的：<br>$$v_i^\top A v_j &#x3D; 0, \quad \forall i \neq j$$</p>
<h4 id="搜索方向的共轭性"><a href="#搜索方向的共轭性" class="headerlink" title="搜索方向的共轭性"></a><strong>搜索方向的共轭性</strong></h4><p><strong>引理</strong>: 向量 $$ { v_i } $$ 是 $$ A $$-共轭的。</p>
<p><strong>证明</strong>:<br>假设 $$ i &lt; j $$。 因为 $$ x_j &#x3D; \arg\min_{x \in \mathcal{K}<em>j} | x - x^* |<em>A^2 $$，所以目标函数在 $$ x_j $$ 处的梯度：<br>$$\nabla \left( \frac{1}{2} | x - x^* |<em>A^2 \right) &#x3D; A x_j - b &#x3D; -r_j$$<br>必须与标准内积中的 $$ \mathcal{K}<em>j $$ 正交（因为 $$ A $$-范数最小化意味着梯度与子空间正交）。因此：<br>$$r_j^\top z &#x3D; 0, \quad \forall z \in \mathcal{K}<em>j$$<br>因为 $$ \mathcal{K}</em>{j-1} \subset \mathcal{K}<em>j $$，我们有：<br>$$r_j^\top z &#x3D; 0, \quad \forall z \in \mathcal{K}</em>{j-1}$$<br>类似地，$$ r</em>{j-1} &#x3D; b - A x</em>{j-1} $$ 与 $$ \mathcal{K}</em>{j-1} $$ 正交。现在：<br>$$A v_j &#x3D; A (x_j - x</em>{j-1}) &#x3D; A x_j - A x_{j-1} &#x3D; (b - r_j) - (b - r_{j-1}) &#x3D; r_{j-1} - r_j$$<br>因为 $$ r_{j-1}, r_j \in \mathcal{K}_j $$ （因为 $$ r_i &#x3D; b - A x_i $$，且 $$ x_i \in \mathcal{K}<em>i $$），所以 $$ A v_j \in \text{span}{ r</em>{j-1}, r_j } $$。我们需要证明 $$ v_i^\top A v_j &#x3D; 0 $$ 对于 $$ i &lt; j $$。</p>
<p>因为 $$ v_i &#x3D; x_i - x_{i-1} \in \mathcal{K}<em>i \subset \mathcal{K}</em>{j-1} $$，且 $$ r_j \perp \mathcal{K}<em>{j-1} $$，我们有：<br>$$r_j^\top v_i &#x3D; 0$$<br>现在计算：<br>$$v_i^\top A v_j &#x3D; v_i^\top (r</em>{j-1} - r_j) &#x3D; v_i^\top r_{j-1} - v_i^\top r_j &#x3D; v_i^\top r_{j-1}$$<br>我们需要 $$ v_i^\top r_{j-1} &#x3D; 0 $$。 注意到 $$ r_{j-1} \perp \mathcal{K}<em>{j-1} $$，并且由于 $$ i \leq j-1 $$，所以 $$ v_i \in \mathcal{K}<em>i \subset \mathcal{K}</em>{j-1} $$。因此：<br>$$v_i^\top r</em>{j-1} &#x3D; 0$$<br>因此：<br>$$v_i^\top A v_j &#x3D; 0, \quad \forall i &lt; j$$<br>向量 $$ { v_i } $$ 是 $$ A $$-共轭的。</p>
<p><strong>推论</strong>: Krylov 子空间是：<br>$$\mathcal{K}<em>i &#x3D; \text{span}{ v_1, v_2, \dots, v_i }$$<br>因为 $$ x_i &#x3D; x</em>{i-1} + v_i &#x3D; x_{i-2} + v_{i-1} + v_i &#x3D; \dots &#x3D; \sum_{j&#x3D;1}^i v_j $$，所以 $$ x_i \in \text{span}{ v_1, \dots, v_i } $$。</p>
<h4 id="共轭向量的线性无关性"><a href="#共轭向量的线性无关性" class="headerlink" title="共轭向量的线性无关性"></a><strong>共轭向量的线性无关性</strong></h4><p><strong>声明</strong>: $$ A $$-共轭向量是线性无关的。</p>
<p><strong>证明</strong>:<br>假设 $$ p_1, p_2, \dots, p_k $$ 是 $$ A $$-共轭的（$$ p_i^\top A p_j &#x3D; 0 $$ 对于 $$ i \neq j $$），并且是线性相关的：<br>$$\alpha_1 p_1 + \dots + \alpha_k p_k &#x3D; 0$$<br>计算：<br>$$\left( \sum_{i&#x3D;1}^k \alpha_i p_i \right)^\top A \left( \sum_{j&#x3D;1}^k \alpha_j p_j \right) &#x3D; \sum_{i,j} \alpha_i \alpha_j p_i^\top A p_j &#x3D; \sum_{i&#x3D;1}^k \alpha_i^2 p_i^\top A p_i$$<br>因为 $$ p_i^\top A p_i &#x3D; | p_i |<em>A^2 &gt; 0 $$ （因为 $$ A $$ 是 SPD 且 $$ p_i \neq 0 $$），并且该总和仅在以下情况下为零：<br>$$\sum</em>{i&#x3D;1}^k \alpha_i^2 | p_i |_A^2 &#x3D; 0 \implies \alpha_i &#x3D; 0, \forall i$$<br>因此，$$ p_i $$ 是线性无关的。</p>
<h4 id="CG-迭代公式"><a href="#CG-迭代公式" class="headerlink" title="CG 迭代公式"></a><strong>CG 迭代公式</strong></h4><p><strong>引理</strong>: 定义 $$ v_i &#x3D; x_i - x_{i-1} $$，$$ r_i &#x3D; b - A x_i $$。 那么：<br>$$v_i &#x3D; \frac{v_i^\top r_{i-1}}{r_{i-1}^\top r_{i-1}} \left( r_{i-1} - \frac{r_{i-1}^\top A v_{i-1}}{v_{i-1}^\top A v_{i-1}} v_{i-1} \right)$$</p>
<p><strong>证明概要</strong>:<br>因为 $$ x_i \in \mathcal{K}<em>i $$，且 $$ \mathcal{K}<em>i &#x3D; \text{span}{ v_1, \dots, v</em>{i-1}, r</em>{i-1} } $$ （因为 $$ r_{i-1} &#x3D; b - A x_{i-1} $$，且 $$ x_{i-1} \in \mathcal{K}<em>{i-1} $$），我们可以写成：<br>$$v_i &#x3D; c_0 r</em>{i-1} + \sum_{j&#x3D;1}^{i-1} c_j v_j$$<br>为了找到 $$ c_0 $$，取与 $$ r_{i-1} $$ 的内积：<br>$$v_i^\top r_{i-1} &#x3D; c_0 r_{i-1}^\top r_{i-1} + \sum_{j&#x3D;1}^{i-1} c_j v_j^\top r_{i-1}$$<br>因为 $$ v_j \in \mathcal{K}<em>j \subset \mathcal{K}</em>{i-1} $$，且 $$ r_{i-1} \perp \mathcal{K}<em>{i-1} $$，所以 $$ v_j^\top r</em>{i-1} &#x3D; 0 $$。因此：<br>$$c_0 &#x3D; \frac{v_i^\top r_{i-1}}{r_{i-1}^\top r_{i-1}}$$<br>对于 $$ c_j $$，强制共轭性 $$ v_i^\top A v_j &#x3D; 0 $$ 对于 $$ j &lt; i $$。 计算：<br>$$v_i^\top A v_j &#x3D; \left( c_0 r_{i-1} + \sum_{l&#x3D;1}^{i-1} c_l v_l \right)^\top A v_j &#x3D; c_0 r_{i-1}^\top A v_j + c_j v_j^\top A v_j$$<br>因为 $$ v_i \perp_A v_j $$，所以我们需要：<br>$$c_0 r_{i-1}^\top A v_j + c_j v_j^\top A v_j &#x3D; 0$$<br>对于 $$ j &lt; i-1 $$，$$ v_j \in \mathcal{K}<em>j \subset \mathcal{K}</em>{i-1} $$，且 $$ r_{i-1} \perp \mathcal{K}<em>{i-1} $$，所以 $$ r</em>{i-1}^\top A v_j &#x3D; v_j^\top A r_{i-1} &#x3D; 0 $$。 因此，$$ c_j &#x3D; 0 $$ 对于 $$ j &lt; i-1 $$。 对于 $$ j &#x3D; i-1 $$：<br>$$c_{i-1} &#x3D; -c_0 \frac{r_{i-1}^\top A v_{i-1}}{v_{i-1}^\top A v_{i-1}}$$<br>所以：<br>$$v_i &#x3D; c_0 \left( r_{i-1} - \frac{r_{i-1}^\top A v_{i-1}}{v_{i-1}^\top A v_{i-1}} v_{i-1} \right)$$<br>在替换 $$ c_0 $$ 后，这与给定的形式匹配。</p>
<h4 id="简化的-CG-算法"><a href="#简化的-CG-算法" class="headerlink" title="简化的 CG 算法"></a><strong>简化的 CG 算法</strong></h4><p>定义：<br>$$d_i &#x3D; \frac{r_{i-1}^\top r_{i-1}}{v_i^\top r_{i-1}} v_i$$<br>那么：<br>$$x_i &#x3D; x_{i-1} + \frac{r_{i-1}^\top r_{i-1}}{d_i^\top A d_i} d_i$$<br>$$d_i &#x3D; r_{i-1} + \frac{r_{i-1}^\top r_{i-1}}{r_{i-2}^\top r_{i-2}} d_{i-1}$$<br>这是标准的 CG 算法，其中 $$ d_i $$ 是共轭方向，使用残差进行更新。</p>
<h4 id="误差界"><a href="#误差界" class="headerlink" title="误差界"></a><strong>误差界</strong></h4><p>CG 中的误差满足：<br>$$| x_k - x^* |<em>A^2 \leq \inf</em>{\substack{q(0)&#x3D;1 \ \deg q \leq k}} \max_i |q(\lambda_i)|^2 \cdot | b |_{A^{-1}}^2$$<br>这是因为 $$ x_k $$ 是 $$ \mathcal{K}_k $$ 中的最佳近似值，并且误差 $$ e_k &#x3D; x_k - x^* $$ 位于多项式空间中。 选择多项式 $$ q(\lambda) $$ 以最小化特征值 $$ \lambda_i $$ 上的最大值，类似于 Chebyshev 迭代，但 CG 会自动适应谱。</p>
<h4 id="收敛性"><a href="#收敛性" class="headerlink" title="收敛性"></a><strong>收敛性</strong></h4><p>CG 最多在 $$ n $$ 次迭代中收敛（在精确算术中），因为 Krylov 子空间 $$ \mathcal{K}_n $$ 跨越 $$ \mathbb{R}^n $$。 在实践中，对于稀疏矩阵或条件良好的 $$ A $$，CG 的收敛速度比高斯消元法等直接方法快得多。</p>
<hr>
<h3 id="比较和联系"><a href="#比较和联系" class="headerlink" title="比较和联系"></a><strong>比较和联系</strong></h3><ul>
<li><strong>Krylov 子空间</strong>: 这两种方法都在 $$ \mathcal{K}_k &#x3D; \text{span}{ b, A b, \dots, A^{k-1} b } $$ 中生成迭代点。</li>
<li><strong>多项式逼近</strong>: 两者都通过多项式 $$ p(A) $$ 逼近 $$ A^{-1} $$。 Chebyshev 迭代显式使用 Chebyshev 多项式，需要特征值估计。 CG 通过最小化 $$ A $$ 范数隐式构造最佳多项式，无需显式特征值信息即可适应谱。</li>
<li><strong>收敛性</strong>: CG 通常对于 SPD 矩阵更有效，因为它直接在 $$ A $$ 范数中优化误差，而 Chebyshev 迭代依赖于特征值范围上的均匀逼近。</li>
<li><strong>实现</strong>: Chebyshev 需要根据 $$ \lambda_{\text{min}}, \lambda_{\text{max}} $$ 调整 $$ \alpha_k $$。 CG 使用内积即时计算步长和方向。</li>
</ul>
<hr>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a><strong>结论</strong></h3><ul>
<li><strong>Chebyshev 迭代</strong>: 一种基于多项式的方法，通过设计一个在 $$ A $$ 的谱上很小的多项式来最小化误差，使用 Chebyshev 多项式。 它很有效，但需要特征值估计。</li>
<li><strong>共轭梯度</strong>: 一种自适应方法，可最小化 Krylov 子空间中的 $$ A $$ 范数误差，使用 $$ A $$ 共轭搜索方向。 它更稳健，并且通常对于 SPD 系统更快。</li>
</ul>
<p>如果你想更深入地探索特定部分（例如，编写 CG 代码、数值示例或更深入的误差分析），请告诉我！</p>
<h1 id="引理的证明推导"><a href="#引理的证明推导" class="headerlink" title="引理的证明推导"></a>引理的证明推导</h1><h3 id="引理重述"><a href="#引理重述" class="headerlink" title="引理重述"></a>引理重述</h3><p>给定对称正定矩阵 $$ A $$ 和向量 $$ b $$，定义 Krylov 子空间：<br>$$\mathcal{K}_i &#x3D; \text{span}{b, Ab, A^2b, \dots, A^{i-1}b}, \quad \mathcal{K}<em>0 &#x3D; {0}.$$<br>设 $$ x_i $$ 是 $$ \mathcal{K}<em>i $$ 中最小化 $$ A $$-范数误差的解：<br>$$x_i &#x3D; \arg\min</em>{x \in \mathcal{K}<em>i} |x - x</em><em>|<em>A^2,$$<br>其中 $$ x</em></em> $$ 是 $$ Ax</em>* &#x3D; b $$ 的解，$$ |x|_A &#x3D; \sqrt{x^T A x} $$。定义：</p>
<ul>
<li>$$ v_i &#x3D; x_i - x_{i-1} $$（解的增量），</li>
<li>$$ r_i &#x3D; b - A x_i $$（残差）。</li>
</ul>
<p>需要证明：<br>$$v_i &#x3D; \frac{v_i^T r_{i-1}}{|r_{i-1}|^2} \left( r_{i-1} - \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1} \right).$$</p>
<h3 id="证明思路"><a href="#证明思路" class="headerlink" title="证明思路"></a>证明思路</h3><ol>
<li><p><strong>最优性条件</strong>：</p>
<ul>
<li>$$ x_i $$ 是 $$ \mathcal{K}<em>i $$ 中最小化 $$ |x - x</em>*|_A $$ 的解，因此残差 $$ r_i $$ 与 $$ \mathcal{K}_i $$ 正交：<br>$$\forall y \in \mathcal{K}_i, \quad y^T r_i &#x3D; 0.$$</li>
<li>类似地，$$ r_{i-1} \perp \mathcal{K}_{i-1} $$。</li>
</ul>
</li>
<li><p><strong>增量方向</strong>：</p>
<ul>
<li>$$ v_i &#x3D; x_i - x_{i-1} \in \mathcal{K}<em>i $$，且 $$ v_i $$ 必须与 $$ \mathcal{K}</em>{i-1} $$ 在 $$ A $$-内积下正交：<br>$$\forall y \in \mathcal{K}_{i-1}, \quad v_i^T A y &#x3D; 0.$$</li>
<li>因此，$$ v_i $$ 可以表示为 $$ r_{i-1} $$ 与 $$ \mathcal{K}_{i-1} $$ 的某种正交化结果。</li>
</ul>
</li>
<li><p><strong>构造 $$ v_i $$</strong>：</p>
<ul>
<li>设 $$ v_i $$ 的方向为 $$ d_i $$，其中 $$ d_i $$ 是 $$ r_{i-1} $$ 减去其在 $$ v_{i-1} $$ 方向上的 $$ A $$-分量：<br>$$d_i &#x3D; r_{i-1} - \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1}.$$</li>
<li>这样构造的 $$ d_i $$ 满足 $$ d_i \perp_A \mathcal{K}_{i-1} $$。</li>
</ul>
</li>
<li><p><strong>步长确定</strong>：</p>
<ul>
<li>令 $$ v_i &#x3D; c_i d_i $$，其中 $$ c_i $$ 是最优步长。</li>
<li>由 $$ x_i &#x3D; x_{i-1} + v_i $$ 是最优解，残差 $$ r_i $$ 应与 $$ \mathcal{K}_i $$ 正交，从而可推导 $$ c_i $$。</li>
</ul>
</li>
<li><p><strong>系数计算</strong>：</p>
<ul>
<li>利用 $$ r_{i-1} \perp \mathcal{K}<em>{i-1} $$ 和 $$ v</em>{i-1} \in \mathcal{K}<em>{i-1} $$，有 $$ v</em>{i-1}^T r_{i-1} &#x3D; 0 $$。</li>
<li>计算 $$ v_i^T r_{i-1} &#x3D; c_i d_i^T r_{i-1} &#x3D; c_i |r_{i-1}|^2 $$，因此：<br>$$c_i &#x3D; \frac{v_i^T r_{i-1}}{|r_{i-1}|^2}.$$</li>
</ul>
</li>
</ol>
<h3 id="详细证明"><a href="#详细证明" class="headerlink" title="详细证明"></a>详细证明</h3><ol>
<li><p><strong>方向构造</strong>：</p>
<ul>
<li>设 $$ v_i &#x3D; c_i d_i $$，其中：<br>$$d_i &#x3D; r_{i-1} - \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1}.$$</li>
<li>验证 $$ d_i \perp_A v_{i-1} $$：<br>$$d_i^T A v_{i-1} &#x3D; r_{i-1}^T A v_{i-1} - \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1}^T A v_{i-1} &#x3D; 0.$$</li>
<li>因此 $$ v_i \perp_A \mathcal{K}_{i-1} $$。</li>
</ul>
</li>
<li><p><strong>步长计算</strong>：</p>
<ul>
<li>由 $$ x_i &#x3D; x_{i-1} + v_i $$ 是最优解，残差 $$ r_i &#x3D; b - A x_i $$ 满足 $$ r_i \perp \mathcal{K}_i $$。</li>
<li>特别地，$$ r_i \perp v_i $$：<br>$$v_i^T r_i &#x3D; v_i^T (b - A x_i) &#x3D; v_i^T r_{i-1} - v_i^T A v_i &#x3D; 0.$$<br>因此：<br>$$v_i^T r_{i-1} &#x3D; v_i^T A v_i.$$</li>
<li>另一方面：<br>$$v_i^T A v_i &#x3D; c_i^2 d_i^T A d_i, \quad v_i^T r_{i-1} &#x3D; c_i d_i^T r_{i-1}.$$<br>由 $$ d_i^T r_{i-1} &#x3D; |r_{i-1}|^2 $$（因为 $$ v_{i-1}^T r_{i-1} &#x3D; 0 $$），有：<br>$$c_i |r_{i-1}|^2 &#x3D; c_i^2 d_i^T A d_i \implies c_i &#x3D; \frac{|r_{i-1}|^2}{d_i^T A d_i}.$$</li>
<li>但由 $$ v_i^T r_{i-1} &#x3D; c_i |r_{i-1}|^2 $$，可得：<br>$$c_i &#x3D; \frac{v_i^T r_{i-1}}{|r_{i-1}|^2}.$$<br>这与步长 $$ \alpha_{i-1} $$ 的计算一致。</li>
</ul>
</li>
<li><p><strong>综合表达式</strong>：</p>
<ul>
<li>将 $$ c_i $$ 和 $$ d_i $$ 代入：<br>$$v_i &#x3D; c_i d_i &#x3D; \frac{v_i^T r_{i-1}}{|r_{i-1}|^2} \left( r_{i-1} - \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1} \right).$$</li>
</ul>
</li>
</ol>
<h3 id="共轭梯度法过程"><a href="#共轭梯度法过程" class="headerlink" title="共轭梯度法过程"></a>共轭梯度法过程</h3><ol>
<li><p><strong>初始化</strong>：</p>
<ul>
<li>$$ x_0 &#x3D; 0 $$, $$ r_0 &#x3D; b $$, $$ p_0 &#x3D; r_0 $$.</li>
</ul>
</li>
<li><p><strong>迭代步骤</strong>（$$ i \geq 1 $$）：</p>
<ul>
<li>计算步长：<br>$$\alpha_{i-1} &#x3D; \frac{r_{i-1}^T r_{i-1}}{p_{i-1}^T A p_{i-1}}.$$</li>
<li>更新解：<br>$$x_i &#x3D; x_{i-1} + \alpha_{i-1} p_{i-1}.$$</li>
<li>更新残差：<br>$$r_i &#x3D; r_{i-1} - \alpha_{i-1} A p_{i-1}.$$</li>
<li>计算系数：<br>$$\beta_i &#x3D; \frac{r_i^T r_i}{r_{i-1}^T r_{i-1}}.$$</li>
<li>更新搜索方向：<br>$$p_i &#x3D; r_i + \beta_i p_{i-1}.$$</li>
</ul>
</li>
<li><p><strong>终止条件</strong>：</p>
<ul>
<li>当 $$ |r_i| $$ 足够小时停止。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="问题背景：我们在解决什么？"><a href="#问题背景：我们在解决什么？" class="headerlink" title="问题背景：我们在解决什么？"></a>问题背景：我们在解决什么？</h3><p>我们需要解决一个线性方程组 $$ Ax &#x3D; b $$，其中：</p>
<ul>
<li>$$ A $$ 是一个对称正定矩阵（就像一个“公平的规则书”，保证方程有唯一解，而且解起来比较“友好”）。</li>
<li>$$ b $$ 是一个已知的向量（可以看作是我们想要达到的目标）。</li>
<li>$$ x $$ 是我们要找的解（我们的“答案”）。</li>
</ul>
<p>直接求解 $$ Ax &#x3D; b $$ 可能很麻烦，尤其是当 $$ A $$ 很大时（比如一个巨大的矩阵）。所以，我们用一种叫<strong>共轭梯度法</strong>的迭代方法，像爬山一样一步步接近答案 $$ x_* $$（真正的解，满足 $$ Ax_* &#x3D; b $$）。</p>
<p>在这个过程中，我们会用到一个叫 <strong>Krylov 子空间</strong> 的东西，还有一些向量，比如残差 $$ r_i $$、方向向量 $$ v_i $$。我们要证明一个关于 $$ v_i $$ 的公式（引理），然后解释共轭梯度法是怎么工作的。</p>
<hr>
<h3 id="什么是-Krylov-子空间？"><a href="#什么是-Krylov-子空间？" class="headerlink" title="什么是 Krylov 子空间？"></a>什么是 Krylov 子空间？</h3><p>想象你在一个迷宫里，起点是向量 $$ b $$。你可以用矩阵 $$ A $$ 像“魔法”一样，把 $$ b $$ 变成新的向量：$$ Ab $$、$$ A^2b $$、$$ A^3b $$，等等。这些向量就像迷宫里的不同路径。<strong>Krylov 子空间</strong> $$ \mathcal{K}_i $$ 就是由这些向量张成的“区域”：<br>$$\mathcal{K}_i &#x3D; \text{span}{b, Ab, A^2b, \dots, A^{i-1}b}.$$</p>
<ul>
<li>当 $$ i &#x3D; 1 $$，$$ \mathcal{K}_1 &#x3D; \text{span}{b} $$，只有 $$ b $$ 这一条路。</li>
<li>当 $$ i &#x3D; 2 $$，$$ \mathcal{K}_2 &#x3D; \text{span}{b, Ab} $$，多了 $$ Ab $$ 这条路。</li>
<li>当 $$ i &#x3D; 0 $$，$$ \mathcal{K}_0 &#x3D; {0} $$，就是“什么也没有”。</li>
</ul>
<p>我们会在这些子空间里找一个“最接近”真解 $$ x_* $$ 的近似解 $$ x_i $$。</p>
<hr>
<h3 id="什么是-A-范数？"><a href="#什么是-A-范数？" class="headerlink" title="什么是 $$ A $$-范数？"></a>什么是 $$ A $$-范数？</h3><p>我们需要一个方法来衡量我们的近似解 $$ x_i $$ 离真解 $$ x_* $$ 有多远。这里的“距离”是用 <strong>$$ A $$-范数</strong> 来定义的：<br>$$|x - x_*|<em>A &#x3D; \sqrt{(x - x</em><em>)^T A (x - x_</em>)}.$$<br>你可以把 $$ A $$-范数想象成一个“加权距离”。普通距离是 $$ \sqrt{x^T x} $$，但这里用 $$ A $$ 来调整方向的重要性（因为 $$ A $$ 是对称正定的，它像一个“放大镜”，让某些方向更重要）。</p>
<p>我们的目标是：<strong>在 $$ \mathcal{K}<em>i $$ 中找到 $$ x_i $$，使得 $$ |x_i - x</em>*|_A $$ 最小</strong>。这就像在迷宫的某块区域里，找到离终点最近的位置。</p>
<hr>
<h3 id="定义一些关键向量"><a href="#定义一些关键向量" class="headerlink" title="定义一些关键向量"></a>定义一些关键向量</h3><ol>
<li><p><strong>残差 $$ r_i $$</strong>：<br>$$r_i &#x3D; b - A x_i.$$<br>残差是“误差向量”，告诉你近似解 $$ x_i $$ 离目标 $$ b $$ 还有多远。如果 $$ x_i &#x3D; x_* $$，那么 $$ A x_i &#x3D; b $$，于是 $$ r_i &#x3D; 0 $$，说明我们到终点了。</p>
</li>
<li><p><strong>增量 $$ v_i $$</strong>：<br>$$v_i &#x3D; x_i - x_{i-1}.$$<br>这是从上一步的近似解 $$ x_{i-1} $$ 到当前解 $$ x_i $$ 的“步伐”。你可以把它看作我们迈出的一步，方向和大小都很重要。</p>
</li>
</ol>
<hr>
<h3 id="引理：我们要证明什么？"><a href="#引理：我们要证明什么？" class="headerlink" title="引理：我们要证明什么？"></a>引理：我们要证明什么？</h3><p>我们需要证明：<br>$$v_i &#x3D; \frac{v_i^T r_{i-1}}{|r_{i-1}|^2} \left( r_{i-1} - \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1} \right).$$<br>这个公式看起来有点吓人，但别慌！我们把它拆开：</p>
<ul>
<li><strong>左边</strong>：$$ v_i $$，是我们从 $$ x_{i-1} $$ 到 $$ x_i $$ 的步伐。</li>
<li><strong>右边</strong>：<ul>
<li>$$ r_{i-1} &#x3D; b - A x_{i-1} $$，是上一步的残差，像一个“指南针”，告诉我们还差多远。</li>
<li>$$ \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1} $$，是从 $$ r_{i-1} $$ 中减去一部分与 $$ v_{i-1} $$ 相关的分量（稍后解释）。</li>
<li>$$ \frac{v_i^T r_{i-1}}{|r_{i-1}|^2} $$，是一个系数，决定步伐的大小（像“步长”）。</li>
</ul>
</li>
</ul>
<p>这个公式在说：<strong>我们的新步伐 $$ v_i $$ 是基于上一步的残差 $$ r_{i-1} $$，但调整了方向，确保它和之前的步伐 $$ v_{i-1} $$ 在某种意义上“垂直”（A-正交）</strong>。</p>
<hr>
<h3 id="共轭梯度法：像爬山一样找答案"><a href="#共轭梯度法：像爬山一样找答案" class="headerlink" title="共轭梯度法：像爬山一样找答案"></a>共轭梯度法：像爬山一样找答案</h3><p>在证明引理之前，我们先了解共轭梯度法的大致思路，方便理解为什么公式长这样。</p>
<p>共轭梯度法就像在山谷里找最低点（真解 $$ x_* $$）。你从一个起点 $$ x_0 $$ 开始，每次迈一步，调整方向，尽量快地到达最低点。关键是：</p>
<ul>
<li><strong>每一步的方向</strong>（叫搜索方向 $$ p_i $$）要很“聪明”，不能重复走过的路。</li>
<li><strong>方向之间要 A-正交</strong>（也叫共轭），意思是 $$ p_i^T A p_j &#x3D; 0 $$（当 ( i \neq j \））。这就像在不同方向上“垂直”，避免浪费精力。</li>
<li><strong>步长</strong>（叫 $$ \alpha_i $$）要选得恰到好处，确保每一步都离目标更近。</li>
</ul>
<p>在我们的引理里，$$ v_i &#x3D; x_i - x_{i-1} $$ 就像是“步长 × 方向”。我们要证明它的具体形式。</p>
<hr>
<h3 id="证明引理：一步步拆解"><a href="#证明引理：一步步拆解" class="headerlink" title="证明引理：一步步拆解"></a>证明引理：一步步拆解</h3><h4 id="1-最优性条件：为什么-x-i-是最好的？"><a href="#1-最优性条件：为什么-x-i-是最好的？" class="headerlink" title="1. 最优性条件：为什么 $$ x_i $$ 是最好的？"></a>1. <strong>最优性条件：为什么 $$ x_i $$ 是最好的？</strong></h4><p>我们知道，$$ x_i $$ 是在 $$ \mathcal{K}<em>i $$ 中使得 $$ |x_i - x</em><em>|<em>A $$ 最小的解。数学上，这意味着：<br>$$|x_i - x</em></em>|<em>A^2 &#x3D; (x_i - x</em><em>)^T A (x_i - x_</em>)$$<br>要最小化。我们把这个看成一个函数：<br>$$f(x) &#x3D; (x - x_*)^T A (x - x_*) &#x3D; x^T A x - 2 x^T A x_* + x_*^T A x_*.$$<br>因为 $$ A x_* &#x3D; b $$，所以 $$ x^T A x_* &#x3D; x^T b $$。于是：<br>$$f(x) &#x3D; x^T A x - 2 x^T b + \text{常数}.$$<br>我们要在 $$ x \in \mathcal{K}_i $$ 中让 $$ f(x) $$ 最小。这就像在一个有限的区域里找最低点。</p>
<p><strong>关键性质</strong>：当 $$ x_i $$ 是最优解时，残差 $$ r_i &#x3D; b - A x_i $$ 会和 $$ \mathcal{K}<em>i $$ 中的所有向量“垂直”（标准内积下）：<br>$$\forall y \in \mathcal{K}<em>i, \quad y^T r_i &#x3D; 0.$$<br>为什么？因为 $$ r_i &#x3D; b - A x_i &#x3D; A (x</em>* - x_i) $$，所以：<br>$$y^T r_i &#x3D; y^T A (x</em>* - x_i).$$<br>如果 $$ x_i $$ 使 $$ f(x) $$ 最小，梯度 $$ \nabla f(x) &#x3D; 2 A x - 2 b $$ 在 $$ \mathcal{K}<em>i $$ 方向上为零，意味着 $$ r_i \perp \mathcal{K}<em>i $$。同样，$$ r</em>{i-1} \perp \mathcal{K}</em>{i-1} $$。</p>
<h4 id="2-增量-v-i-是什么？"><a href="#2-增量-v-i-是什么？" class="headerlink" title="2. 增量 $$ v_i $$ 是什么？"></a>2. <strong>增量 $$ v_i $$ 是什么？</strong></h4><p>因为：<br>$$x_i &#x3D; x_{i-1} + v_i,$$<br>所以：<br>$$v_i &#x3D; x_i - x_{i-1}.$$</p>
<ul>
<li>$$ x_{i-1} \in \mathcal{K}_{i-1} $$，是上一步的最优解。</li>
<li>$$ x_i \in \mathcal{K}_i $$，是当前的最优解。</li>
<li>$$ \mathcal{K}<em>i $$ 比 $$ \mathcal{K}</em>{i-1} $$ 多了一个方向（比如 $$ A^{i-1}b $$）。</li>
</ul>
<p>所以，$$ v_i $$ 必须在 $$ \mathcal{K}<em>i $$ 中，但它得是个“新方向”，不能完全重复 $$ \mathcal{K}</em>{i-1} $$ 里的内容。类比：你在迷宫里，$$ x_{i-1} $$ 是你之前走到的地方，$$ v_i $$ 是你新迈出的一步，指向 $$ \mathcal{K}_i $$ 里的新区域。</p>
<h4 id="3-构造-v-i-的方向"><a href="#3-构造-v-i-的方向" class="headerlink" title="3. 构造 $$ v_i $$ 的方向"></a>3. <strong>构造 $$ v_i $$ 的方向</strong></h4><p>我们假设 $$ v_i $$ 可以写成：<br>$$v_i &#x3D; c_i d_i,$$<br>其中：</p>
<ul>
<li>$$ d_i $$ 是方向（像“指南针”），在 $$ \mathcal{K}_i $$ 中。</li>
<li>$$ c_i $$ 是步长（决定走多远）。</li>
</ul>
<p><strong>方向 $$ d_i $$</strong> 怎么选？在共轭梯度法中，方向要和之前的方向 <strong>A-正交</strong>，即：<br>$$d_i^T A v_{i-1} &#x3D; 0.$$<br>这确保我们不会走“回头路”。我们用上一步的残差 $$ r_{i-1} &#x3D; b - A x_{i-1} $$ 作为起点，因为它指向我们还需要修正的方向。但 $$ r_{i-1} $$ 可能包含一些和 $$ v_{i-1} $$ 相关的成分，我们需要“清理”掉。</p>
<p>所以，构造：<br>$$d_i &#x3D; r_{i-1} - \gamma v_{i-1},$$<br>其中 $$ \gamma $$ 是系数，使得 $$ d_i \perp_A v_{i-1} $$：<br>$$d_i^T A v_{i-1} &#x3D; (r_{i-1} - \gamma v_{i-1})^T A v_{i-1} &#x3D; r_{i-1}^T A v_{i-1} - \gamma v_{i-1}^T A v_{i-1} &#x3D; 0.$$<br>解出：<br>$$\gamma &#x3D; \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}}.$$<br>于是：<br>$$d_i &#x3D; r_{i-1} - \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1}.$$<br>这个 $$ d_i $$ 就像是从 $$ r_{i-1} $$ 中“减去”了它在 $$ v_{i-1} $$ 方向上的投影（用 $$ A $$-内积），确保新方向和旧方向“垂直”。</p>
<h4 id="4-确定步长-c-i"><a href="#4-确定步长-c-i" class="headerlink" title="4. 确定步长 $$ c_i $$"></a>4. <strong>确定步长 $$ c_i $$</strong></h4><p>现在 $$ v_i &#x3D; c_i d_i $$，我们需要找 $$ c_i $$，让 $$ x_i &#x3D; x_{i-1} + v_i $$ 是 $$ \mathcal{K}<em>i $$ 中最优的解。回忆 $$ x_i $$ 使残差 $$ r_i \perp \mathcal{K}<em>i $$。特别地，$$ r_i \perp v_i $$：<br>$$v_i^T r_i &#x3D; 0.$$<br>因为：<br>$$r_i &#x3D; b - A x_i &#x3D; b - A (x</em>{i-1} + v_i) &#x3D; r</em>{i-1} - A v_i,$$<br>所以：<br>$$v_i^T r_i &#x3D; v_i^T (r_{i-1} - A v_i) &#x3D; v_i^T r_{i-1} - v_i^T A v_i &#x3D; 0.$$<br>这推出：<br>$$v_i^T r_{i-1} &#x3D; v_i^T A v_i.$$<br>代入 $$ v_i &#x3D; c_i d_i $$，有：<br>$$v_i^T r_{i-1} &#x3D; c_i d_i^T r_{i-1}, \quad v_i^T A v_i &#x3D; c_i^2 d_i^T A d_i.$$<br>所以：<br>$$c_i d_i^T r_{i-1} &#x3D; c_i^2 d_i^T A d_i \implies c_i &#x3D; \frac{d_i^T r_{i-1}}{d_i^T A d_i}.$$<br>现在计算 $$ d_i^T r_{i-1} $$：<br>$$d_i &#x3D; r_{i-1} - \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1},$$<br>$$d_i^T r_{i-1} &#x3D; r_{i-1}^T r_{i-1} - \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1}^T r_{i-1}.$$<br><strong>重要性质</strong>：因为 $$ x_{i-1} \in \mathcal{K}<em>{i-1} $$ 是最优解，$$ r</em>{i-1} \perp \mathcal{K}<em>{i-1} $$。而 $$ v</em>{i-1} &#x3D; x_{i-1} - x_{i-2} \in \mathcal{K}<em>{i-1} $$，所以：<br>$$v</em>{i-1}^T r_{i-1} &#x3D; 0.$$<br>因此：<br>$$d_i^T r_{i-1} &#x3D; |r_{i-1}|^2.$$<br>于是：<br>$$c_i &#x3D; \frac{|r_{i-1}|^2}{d_i^T A d_i}.$$<br>但引理里给的系数是 $$ \frac{v_i^T r_{i-1}}{|r_{i-1}|^2} $$。我们验证：<br>$$v_i &#x3D; c_i d_i \implies v_i^T r_{i-1} &#x3D; c_i d_i^T r_{i-1} &#x3D; c_i |r_{i-1}|^2.$$<br>所以：<br>$$\frac{v_i^T r_{i-1}}{|r_{i-1}|^2} &#x3D; c_i.$$<br>这正好是我们需要的系数！</p>
<h4 id="5-组合得到引理"><a href="#5-组合得到引理" class="headerlink" title="5. 组合得到引理"></a>5. <strong>组合得到引理</strong></h4><p>把 $$ c_i $$ 和 $$ d_i $$ 代入：<br>$$v_i &#x3D; c_i d_i &#x3D; \frac{v_i^T r_{i-1}}{|r_{i-1}|^2} \left( r_{i-1} - \frac{r_{i-1}^T A v_{i-1}}{v_{i-1}^T A v_{i-1}} v_{i-1} \right).$$<br>这正是我们要证明的公式！虽然公式里 $$ v_i $$ 出现在两边，但 $$ c_i &#x3D; \frac{v_i^T r_{i-1}}{|r_{i-1}|^2} $$ 是通过最优性条件推导出来的，符合共轭梯度法的逻辑。</p>
<hr>
<h3 id="共轭梯度法：完整流程"><a href="#共轭梯度法：完整流程" class="headerlink" title="共轭梯度法：完整流程"></a>共轭梯度法：完整流程</h3><p>现在我们明白了引理，来看共轭梯度法是怎么用这些想法一步步工作的。想象你在玩一个寻宝游戏，每次走一步，调整方向，尽量快地找到宝藏（$$ x_* $$）。</p>
<h4 id="初始化："><a href="#初始化：" class="headerlink" title="初始化："></a>初始化：</h4><ul>
<li>选一个起点 $$ x_0 $$，通常设 $$ x_0 &#x3D; 0 $$。</li>
<li>计算初始残差：$$ r_0 &#x3D; b - A x_0 &#x3D; b $$。</li>
<li>初始方向：$$ p_0 &#x3D; r_0 $$。（第一步直接朝残差方向走）</li>
</ul>
<h4 id="迭代（每一步）："><a href="#迭代（每一步）：" class="headerlink" title="迭代（每一步）："></a>迭代（每一步）：</h4><p>对于 $$ i &#x3D; 1, 2, \dots $$，做以下步骤：</p>
<ol>
<li><p><strong>计算步长 $$ \alpha_{i-1} $$</strong>：<br>$$\alpha_{i-1} &#x3D; \frac{r_{i-1}^T r_{i-1}}{p_{i-1}^T A p_{i-1}}.$$</p>
<ul>
<li>$$ r_{i-1}^T r_{i-1} $$ 是残差的大小（告诉你还差多远）。</li>
<li>$$ p_{i-1}^T A p_{i-1} $$ 是方向的“阻力”（矩阵 $$ A $$ 影响方向的难度）。</li>
<li>$$ \alpha_{i-1} $$ 决定你沿 $$ p_{i-1} $$ 走多远。</li>
</ul>
</li>
<li><p><strong>更新解</strong>：<br>$$x_i &#x3D; x_{i-1} + \alpha_{i-1} p_{i-1}.$$</p>
</li>
<li><p><strong>更新残差</strong>：<br>$$r_i &#x3D; r_{i-1} - \alpha_{i-1} A p_{i-1}.$$</p>
<ul>
<li>这是因为：<br>$$r_i &#x3D; b - A x_i &#x3D; b - A (x_{i-1} + \alpha_{i-1} p_{i-1}) &#x3D; (b - A x_{i-1}) - \alpha_{i-1} A p_{i-1} &#x3D; r_{i-1} - \alpha_{i-1} A p_{i-1}.$$</li>
</ul>
</li>
<li><p><strong>计算新方向的系数 $$ \beta_i $$</strong>：<br>$$\beta_i &#x3D; \frac{r_i^T r_i}{r_{i-1}^T r_{i-1}}.$$</p>
<ul>
<li>这决定了新方向如何结合当前残差和旧方向。</li>
</ul>
</li>
<li><p><strong>更新方向</strong>：<br>$$p_i &#x3D; r_i + \beta_i p_{i-1}.$$</p>
<ul>
<li>新方向是当前残差 $$ r_i $$ 加上一点旧方向 $$ p_{i-1} $$，确保它和之前的方向 A-正交。</li>
</ul>
</li>
<li><p><strong>检查是否到达终点</strong>：</p>
<ul>
<li>如果 $$ |r_i| $$ 很小（比如小于 $$ 10^{-6} $$），说明 $$ x_i $$ 很接近 $$ x_* $$，可以停止。</li>
</ul>
</li>
</ol>
<h4 id="为什么高效？"><a href="#为什么高效？" class="headerlink" title="为什么高效？"></a>为什么高效？</h4><ul>
<li><strong>残差正交</strong>：$$ r_i^T r_j &#x3D; 0 $$（当 ( i \neq j \）），残差不会重复。</li>
<li><strong>方向 A-正交</strong>：$$ p_i^T A p_j &#x3D; 0 $$（当 ( i \neq j \）），每一步都在新方向上前进。</li>
<li><strong>最多 n 步</strong>：理论上，n 次迭代（n 是矩阵维度）就能找到精确解。</li>
</ul>
<hr>
<h3 id="例子：手动算一步"><a href="#例子：手动算一步" class="headerlink" title="例子：手动算一步"></a>例子：手动算一步</h3><p>假设：</p>
<ul>
<li>$$ A &#x3D; \begin{bmatrix} 4 &amp; 1 \ 1 &amp; 3 \end{bmatrix} $$，$$ b &#x3D; \begin{bmatrix} 1 \ 2 \end{bmatrix} $$。</li>
<li>初始：$$ x_0 &#x3D; \begin{bmatrix} 0 \ 0 \end{bmatrix} $$，$$ r_0 &#x3D; b &#x3D; \begin{bmatrix} 1 \ 2 \end{bmatrix} $$，$$ p_0 &#x3D; r_0 $$.</li>
</ul>
<p><strong>第一步</strong>：</p>
<ul>
<li>步长：<br>$$r_0^T r_0 &#x3D; 1^2 + 2^2 &#x3D; 5,$$<br>$$p_0^T A p_0 &#x3D; \begin{bmatrix} 1 &amp; 2 \end{bmatrix} \begin{bmatrix} 4 &amp; 1 \ 1 &amp; 3 \end{bmatrix} \begin{bmatrix} 1 \ 2 \end{bmatrix} &#x3D; \begin{bmatrix} 1 &amp; 2 \end{bmatrix} \begin{bmatrix} 6 \ 7 \end{bmatrix} &#x3D; 6 + 14 &#x3D; 20,$$<br>$$\alpha_0 &#x3D; \frac{5}{20} &#x3D; 0.25.$$</li>
<li>更新解：<br>$$x_1 &#x3D; x_0 + \alpha_0 p_0 &#x3D; \begin{bmatrix} 0 \ 0 \end{bmatrix} + 0.25 \begin{bmatrix} 1 \ 2 \end{bmatrix} &#x3D; \begin{bmatrix} 0.25 \ 0.5 \end{bmatrix}.$$</li>
<li>更新残差：<br>$$r_1 &#x3D; r_0 - \alpha_0 A p_0 &#x3D; \begin{bmatrix} 1 \ 2 \end{bmatrix} - 0.25 \begin{bmatrix} 4 &amp; 1 \ 1 &amp; 3 \end{bmatrix} \begin{bmatrix} 1 \ 2 \end{bmatrix} &#x3D; \begin{bmatrix} 1 \ 2 \end{bmatrix} - 0.25 \begin{bmatrix} 6 \ 7 \end{bmatrix} &#x3D; \begin{bmatrix} -0.5 \ 0.25 \end{bmatrix}.$$</li>
<li>新方向系数：<br>$$r_1^T r_1 &#x3D; (-0.5)^2 + (0.25)^2 &#x3D; 0.25 + 0.0625 &#x3D; 0.3125,$$<br>$$\beta_1 &#x3D; \frac{0.3125}{5} &#x3D; 0.0625.$$</li>
<li>新方向：<br>$$p_1 &#x3D; r_1 + \beta_1 p_0 &#x3D; \begin{bmatrix} -0.5 \ 0.25 \end{bmatrix} + 0.0625 \begin{bmatrix} 1 \ 2 \end{bmatrix} &#x3D; \begin{bmatrix} -0.4375 \ 0.375 \end{bmatrix}.$$</li>
</ul>
<p>继续迭代，直到 $$ r_i $$ 很小。</p>
<hr>
<h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><p><strong>引理</strong>：我们证明了 $$ v_i $$ 是通过残差 $$ r_{i-1} $$ 减去与 $$ v_{i-1} $$ 的 A-投影，再乘以一个步长系数得到的。这确保了每一步的方向都是“新”的（A-正交），而且步伐大小是最优的。</p>
<p><strong>共轭梯度法</strong>：像一个聪明的导航系统，每次选一个新方向（A-正交），走恰当的距离（步长），在 Krylov 子空间里快速接近真解。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenzhan20050128.github.io/notes.github.io/2025/06/23/%E7%AE%97%E5%AD%90%E8%8C%83%E6%95%B0note/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/notes.github.io/images/woshicaigou.jpg">
      <meta itemprop="name" content="Chen Zhan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cz Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/notes.github.io/2025/06/23/%E7%AE%97%E5%AD%90%E8%8C%83%E6%95%B0note/" class="post-title-link" itemprop="url">算子范数note</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-23 18:56:58" itemprop="dateCreated datePublished" datetime="2025-06-23T18:56:58+08:00">2025-06-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Euclid范数的酉不变性："><a href="#Euclid范数的酉不变性：" class="headerlink" title="Euclid范数的酉不变性："></a>Euclid范数的酉不变性：</h2><p>对于向量 $X$ 和酉矩阵 $U$，有：</p>
<p>$|UX|_2 &#x3D; \sqrt{(UX)^H UX} &#x3D; \sqrt{X^H U^H UX} &#x3D; \sqrt{X^H X} &#x3D; |X|_2$</p>
<p>即：</p>
<p>$|UX|_2 &#x3D; |X|_2$</p>
<h2 id="无穷范数是最大值的证明"><a href="#无穷范数是最大值的证明" class="headerlink" title="无穷范数是最大值的证明"></a>无穷范数是最大值的证明</h2><p>要证明对于复数 $$ x_1, x_2, \ldots, x_n $$，有</p>
<p>$$\lim_{p \to \infty} \left( |x_1|^p + |x_2|^p + \cdots + |x_n|^p \right)^{1&#x2F;p} &#x3D; \max { |x_1|, |x_2|, \ldots, |x_n| },$$</p>
<p>其中 $$ |x_i| $$ 表示复数 $$ x_i $$ 的模长。</p>
<p><strong>证明过程如下：</strong></p>
<p>设 $$ M &#x3D; \max { |x_1|, |x_2|, \ldots, |x_n| } $$，并假设 $$ |x_k| &#x3D; M $$ 对于某个 $$ k $$。对于任意 $$ p &gt; 0 $$，有</p>
<p>$$|x_k|^p \leq |x_1|^p + |x_2|^p + \cdots + |x_n|^p \leq n \cdot M^p.$$</p>
<p>取 $$ p $$-th 根，得到</p>
<p>$$M \leq \left( \sum_{i&#x3D;1}^n |x_i|^p \right)^{1&#x2F;p} \leq n^{1&#x2F;p} \cdot M.$$</p>
<p>当 $$ p \to \infty $$，$$ n^{1&#x2F;p} \to 1 $$，因此由夹逼定理，</p>
<p>$$\lim_{p \to \infty} \left( \sum_{i&#x3D;1}^n |x_i|^p \right)^{1&#x2F;p} &#x3D; M.$$</p>
<p>即</p>
<p>$$\lim_{p \to \infty} \left( |x_1|^p + |x_2|^p + \cdots + |x_n|^p \right)^{1&#x2F;p} &#x3D; \max { |x_1|, |x_2|, \ldots, |x_n| }.$$</p>
<p><strong>证毕。</strong></p>
<h3 id="Frobenius-范数的详细解释"><a href="#Frobenius-范数的详细解释" class="headerlink" title="Frobenius 范数的详细解释"></a><strong>Frobenius 范数的详细解释</strong></h3><p>对于一个 $$ m \times n $$ 的实（或复）矩阵 $$ A $$，其 Frobenius 范数定义为：</p>
<p>$$| A |<em>F &#x3D; \sqrt{ \sum</em>{i&#x3D;1}^m \sum_{j&#x3D;1}^n |a_{ij}|^2 }$$</p>
<h3 id="用矩阵的迹表示"><a href="#用矩阵的迹表示" class="headerlink" title="用矩阵的迹表示"></a><strong>用矩阵的迹表示</strong></h3><p>$$| A |_F &#x3D; \sqrt{ \text{tr}(A^T A) } &#x3D; \sqrt{ \text{tr}(A A^T) }$$</p>
<h3 id="乘法不等式（次可乘性）"><a href="#乘法不等式（次可乘性）" class="headerlink" title="乘法不等式（次可乘性）"></a><strong>乘法不等式（次可乘性）</strong></h3><p>如果 $$ A $$ 是 $$ m \times n $$ 矩阵，$$ B $$ 是 $$ n \times p $$ 矩阵，则：<br>$$| AB |_F \leq | A |_F \cdot | B |_F$$</p>
<h3 id="与谱范数的关系"><a href="#与谱范数的关系" class="headerlink" title="与谱范数的关系"></a><strong>与谱范数的关系</strong></h3><p>Frobenius 范数与 <strong>谱范数（spectral norm, $$ | A |_2 $$)</strong> 满足：<br>$$| A |_2 \leq | A |_F \leq \sqrt{r} | A |_2$$<br>其中 $$ r &#x3D; \text{rank}(A) $$。</p>
<h3 id="与奇异值的关系"><a href="#与奇异值的关系" class="headerlink" title="与奇异值的关系"></a><strong>与奇异值的关系</strong></h3><p>设 $$ \sigma_1, \sigma_2, \ldots, \sigma_r $$ 是 $$ A $$ 的非零奇异值，则：<br>$$| A |_F &#x3D; \sqrt{ \sigma_1^2 + \sigma_2^2 + \cdots + \sigma_r^2 }$$</p>
<h2 id="算子范数"><a href="#算子范数" class="headerlink" title="算子范数"></a>算子范数</h2><p>| 范数表示 ( |     | A   |  | )                         | 定义                                 | 说明                                                                                                      |<br>| ———- | — | — |<br>| $          |     | A   |  | <em>{\infty}$ (最大行和范数) | $\max</em>{1 \le i \le m} \sum_{j&#x3D;1}^{n} | a_{ij}                                                                                                    | $    | 将矩阵的每一行元素的绝对值加起来，取最大值。                                            |<br>| $          |     | A   |  | <em>1$ (最大列和范数)        | $\max</em>{1 \le j \le n} \sum_{i&#x3D;1}^{m} | a_{ij}                                                                                                    | $    | 将矩阵的每一列元素的绝对值加起来，取最大值。                                            |<br>| $          |     | A   |  | <em>2$ (谱范数&#x2F;算子范数)     | $\sqrt{\lambda</em>{\max}(A^H A)}$       | $A^H$ 是 $A$ 的共轭转置。 $\lambda_{\max}(A^H A)$ 是矩阵 $A^H A$ 的最大特征值。 也是矩阵$A$的最大奇异值。 |<br>| $          |     | A   |  | <em>F$ (Frobenius范数)       | $\sqrt{\sum</em>{i&#x3D;1}^{m} \sum_{j&#x3D;1}^{n} | a_{ij}                                                                                                    | ^2}$ | 将矩阵所有元素平方后加起来，再开根号。 相当于将矩阵看作一个向量，然后取其欧几里得范数。 |<br>| $          |     | A   |  | <em>{\max}$ (最大模范数)     | $\max</em>{i,j}                          | a_{ij}                                                                                                    | $    | 矩阵中绝对值最大的元素。                                                                |</p>
<h3 id="Euclid空间是一个定义了一个二元实函数“内积”（即是向量）的线性空间。"><a href="#Euclid空间是一个定义了一个二元实函数“内积”（即是向量）的线性空间。" class="headerlink" title="Euclid空间是一个定义了一个二元实函数“内积”（即是向量）的线性空间。"></a>Euclid空间是一个定义了一个二元实函数“内积”（即是向量）的线性空间。</h3><h2 id="课上内容"><a href="#课上内容" class="headerlink" title="课上内容"></a>课上内容</h2><p>给定矩阵 $A \in \mathbb{R}^{m \times n}$，向量 $b \in \mathbb{R}^m$，求 $x \in \mathbb{R}^n$ 使得 $Ax &#x3D; b$.</p>
<ul>
<li><p>假设向量 $b$ 有误差，变成 $b + e$， $x$ 会怎么变化？</p>
</li>
<li><p>$x &#x3D; A^{-1}b \rightarrow x &#x3D; A^{-1}(b+e)$</p>
</li>
<li><p>该线性方程组的条件数 $\text{cond}(A) &#x3D; \frac{x \text{的相对误差}}{b \text{的相对误差}}$.</p>
</li>
</ul>
<p>记 $e$ 为 $b$ 的误差，则 $x$ 的误差为 $A^{-1}e$。任取一种向量范数，</p>
<p>$\text{cond}(A) &#x3D; \max_{e, b \neq 0} \frac{\frac{|A^{-1}e|}{|A^{-1}b|}}{\frac{|e|}{|b|}} &#x3D; \max_{e, b \neq 0} \frac{|A^{-1}e|}{|e|} \frac{|b|}{|A^{-1}b|} &#x3D; \max_{e \neq 0} \frac{|A^{-1}e|}{|e|} \max_{x \neq 0} \frac{|Ax|}{|x|}$</p>
<ul>
<li><p>矩阵的算子范数 $|A| :&#x3D; \max_{x \neq 0} \frac{|Ax|}{|x|}$</p>
</li>
<li><p>因此条件数 $\text{cond}(A) &#x3D; |A| \cdot |A^{-1}|$</p>
</li>
</ul>
<p>条件数越大，表示问题越敏感，输入数据的微小扰动可能会导致解的巨大变化。 条件数越接近于1，表示问题越稳定。</p>
<h2 id="严格对角占优矩阵-Strictly-Diagonally-Dominant-Matrix"><a href="#严格对角占优矩阵-Strictly-Diagonally-Dominant-Matrix" class="headerlink" title="严格对角占优矩阵 (Strictly Diagonally Dominant Matrix)"></a><strong>严格对角占优矩阵 (Strictly Diagonally Dominant Matrix)</strong></h2><p>定义：我们称矩阵 $A \in \mathbb{R}^{n \times n}$ 为严格对角占优，如果它满足以下条件：</p>
<p>$\forall i \in {1, 2, …, n},  |a_{ii}| &gt; \sum_{j&#x3D;1, j \neq i}^{n} |a_{ij}|$</p>
<p>换句话说，对于矩阵的每一行，对角线元素的绝对值必须大于该行所有其他元素绝对值之和。</p>
<p><strong>定理：</strong></p>
<p>如果方阵 $A$ 是严格对角占优的，则 $A$ 是可逆的，而且对于所有向量 $b$ 和初始猜测 $x^{(0)}$，对线性方程组 $Ax &#x3D; b$ 使用 Jacobi 迭代都会收敛到唯一解。</p>
<ol>
<li><p><strong>Jacobi 迭代：</strong> Jacobi 迭代是一种求解线性方程组的迭代方法。它通过不断迭代更新解向量 $x$ 的每个分量，直到收敛到一个稳定值。 对于方程 $Ax &#x3D; b$, Jacobi 迭代的公式可以写成如下形式：</p>
<p>$x_i^{(k+1)} &#x3D; \frac{1}{a_{ii}} \left(b_i - \sum_{j&#x3D;1, j \neq i}^{n} a_{ij} x_j^{(k)} \right)$， 其中 $x_i^{(k)}$ 表示第 $i$ 个分量在第 $k$ 次迭代的值。</p>
</li>
<li><p><strong>收敛性：</strong> 严格对角占优性保证了 Jacobi 迭代的收敛性。这意味着，无论我们选择什么样的初始猜测 $x^{(0)}$，Jacobi 迭代最终都会收敛到线性方程组 $Ax&#x3D;b$ 的唯一解。</p>
</li>
<li><p><strong>重要性：</strong> 严格对角占优矩阵在数值线性代数中很重要，因为它们保证了某些迭代方法（如 Jacobi 迭代和 Gauss-Seidel 迭代）的收敛性。这在求解大型稀疏线性方程组时非常有用。</p>
</li>
</ol>
<h2 id="ρ-A-的定义"><a href="#ρ-A-的定义" class="headerlink" title="ρ(A) 的定义"></a>ρ(A) 的定义</h2><p>ρ(A) (读作 “rho of A”) 是矩阵 A 的所有特征值的绝对值的最大值。 更正式地：</p>
<p>$$ ρ(A) &#x3D; max{|λ_1|, |λ_2|, …, |λ_n|}$$</p>
<p>其中 $$λ_1, λ_2, …, λ_n$$ 是矩阵 A 的所有特征值（包括复数特征值）</p>
<h3 id="命题：-rho-A-1-当且仅当-lim-k-to-infty-A-k-0-即-A-k-收敛到零矩阵-。"><a href="#命题：-rho-A-1-当且仅当-lim-k-to-infty-A-k-0-即-A-k-收敛到零矩阵-。" class="headerlink" title="命题： $\rho(A) &lt; 1$  当且仅当 $\lim_{k\to\infty} A^k &#x3D; 0$ (即 $A^k$ 收敛到零矩阵)。"></a><strong>命题：</strong> $\rho(A) &lt; 1$  当且仅当 $\lim_{k\to\infty} A^k &#x3D; 0$ (即 $A^k$ 收敛到零矩阵)。</h3><p><strong>证明 $\lim_{k\to\infty} A^k &#x3D; 0 \Rightarrow \rho(A) &lt; 1$：</strong></p>
<p>设 $\lambda$ 是 $A$ 的一个特征值， $v$ 是对应的特征向量。 那么 $Av &#x3D; \lambda v$。 因此，$A^k v &#x3D; \lambda^k v$。</p>
<p>假设 $\lim_{k\to\infty} A^k &#x3D; 0$。 这意味着对于任何向量 $x$， $\lim_{k\to\infty} A^k x &#x3D; 0$。  特别地，$\lim_{k\to\infty} A^k v &#x3D; 0$。</p>
<p>所以，$\lim_{k\to\infty} \lambda^k v &#x3D; 0$。  因为 $v$ 是一个非零向量（特征向量的定义），所以必须有 $\lim_{k\to\infty} \lambda^k &#x3D; 0$。</p>
<p>这意味着 $|\lambda| &lt; 1$。  因为 $\lambda$ 是 $A$ 的任意特征值，所以 $A$ 的所有特征值的绝对值都小于 1。  因此，$\rho(A) &#x3D; \max{|\lambda_i|} &lt; 1$。</p>
<p><strong>结论：</strong></p>
<p>$\rho(A) &lt; 1$  是 $\lim_{k\to\infty} A^k &#x3D; 0$ 的一个充分必要条件。 也就是说，这两个命题是等价的。  如果一个成立，另一个也一定成立。<br>当 $A^k \to 0$ (即 $\rho(A) &lt; 1$) 的时候，对任意初始值都收敛的原因如下：</p>
<p>考虑迭代过程 $x_{k+1} &#x3D; Ax_k + b$。  固定点 $x^<em>$ 满足 $x^</em> &#x3D; Ax^* + b$。</p>
<p><strong>方法一：误差分析</strong></p>
<p>定义误差 $e_k &#x3D; x_k - x^*$。  那么：</p>
<p>$e_{k+1} &#x3D; x_{k+1} - x^* &#x3D; (Ax_k + b) - (Ax^* + b) &#x3D; A(x_k - x^*) &#x3D; Ae_k$</p>
<p>因此， $e_k &#x3D; A^k e_0 &#x3D; A^k (x_0 - x^*)$。</p>
<p>如果 $\rho(A) &lt; 1$，那么 $\lim_{k\to\infty} A^k &#x3D; 0$。</p>
<p>所以，$\lim_{k\to\infty} e_k &#x3D; \lim_{k\to\infty} A^k (x_0 - x^*) &#x3D; 0$。</p>
<p>这意味着 $\lim_{k\to\infty} x_k &#x3D; x^<em>$，即迭代收敛到固定点，且收敛性与初值$x_0$ 无关。 $|e_k| &#x3D; |A^k(x_0-x^</em>)| \le |A^k| |x_0 - x^*| \to 0$</p>
<p><strong>方法二：迭代展开</strong></p>
<p>$x_k &#x3D; Ax_{k-1} + b &#x3D; A(Ax_{k-2} + b) + b &#x3D; A^2 x_{k-2} + Ab + b &#x3D; \dots &#x3D; A^k x_0 + A^{k-1}b + A^{k-2}b + \dots + Ab + b$</p>
<p>可以写成：<br>$x_k &#x3D; A^k x_0 + \sum_{i&#x3D;0}^{k-1} A^i b &#x3D; A^k x_0 + (A^{k-1} + A^{k-2} + \dots + A + I)b$</p>
<p>因为 $\rho(A) &lt; 1$，所以 $\lim_{k\to\infty} A^k &#x3D; 0$。 并且 $\sum_{i&#x3D;0}^{\infty} A^i &#x3D; (I - A)^{-1}$ （这是一个矩阵几何级数）。</p>
<p>因此：</p>
<p>$\lim_{k\to\infty} x_k &#x3D; \lim_{k\to\infty} A^k x_0 + \lim_{k\to\infty}  \sum_{i&#x3D;0}^{k-1} A^i b &#x3D; 0 + (I - A)^{-1} b &#x3D; (I - A)^{-1} b$</p>
<p>固定点 $x^<em>$ 满足 $x^</em> &#x3D; Ax^* + b$，因此 $x^* &#x3D; (I - A)^{-1} b$。</p>
<p>所以， $\lim_{k\to\infty} x_k &#x3D; x^* &#x3D; (I - A)^{-1} b$。</p>
<p>同样，迭代收敛到固定点，与初值 $x_0$ 无关。</p>
<p><strong>总结</strong></p>
<p>当 $\rho(A) &lt; 1$ 时，误差会随着迭代次数的增加而减小（趋向于0），或者说迭代值会逐渐逼近固定点，与初始值无关。 这两种方法都展示了收敛性，并说明了为什么初值不影响最终的收敛结果。</p>
<h2 id="Jacobi-迭代和-Gauss-Seidel-迭代"><a href="#Jacobi-迭代和-Gauss-Seidel-迭代" class="headerlink" title="Jacobi 迭代和 Gauss-Seidel 迭代"></a>Jacobi 迭代和 Gauss-Seidel 迭代</h2><p><strong>1. Jacobi 迭代</strong></p>
<ul>
<li><strong>原理：</strong> Jacobi 迭代是一种求解线性方程组 $Ax &#x3D; b$ 的迭代方法。它的基本思想是将系数矩阵 $A$ 分解为对角矩阵 $D$，下三角矩阵 $L$ 和上三角矩阵 $U$，即 $A &#x3D; D - L - U$，然后将方程组转化为 $x &#x3D; D^{-1}(L + U)x + D^{-1}b$ 的形式，并进行迭代求解。</li>
<li><strong>公式：</strong> 将 $A &#x3D; D - L - U$ 代入 $Ax &#x3D; b$，得到：<br>$(D - L - U)x &#x3D; b$<br>$Dx &#x3D; (L + U)x + b$<br>$x &#x3D; D^{-1}(L + U)x + D^{-1}b$<br>因此，Jacobi 迭代的迭代公式为：<br>$x^{(k+1)} &#x3D; D^{-1}(L + U)x^{(k)} + D^{-1}b$<br>或者写成逐个分量的形式：<br>$x_i^{(k+1)} &#x3D; \frac{1}{a_{ii}} \left(b_i - \sum_{j&#x3D;1, j \neq i}^{n} a_{ij} x_j^{(k)}\right)$,  $i &#x3D; 1, 2, \dots, n$<br>其中，$x^{(k)}$ 表示第 $k$ 次迭代的解向量，$a_{ij}$ 是矩阵 $A$ 的元素，$b_i$ 是向量 $b$ 的元素。</li>
<li><strong>收敛性条件：</strong> Jacobi 迭代的收敛性取决于迭代矩阵 $B_J &#x3D; D^{-1}(L + U)$ 的谱半径 $\rho(B_J)$。<ul>
<li>如果 $\rho(B_J) &lt; 1$，则 Jacobi 迭代收敛。</li>
<li>充分条件：<ul>
<li>矩阵 $A$ 是严格对角占优矩阵（Strictly Diagonally Dominant）：对于所有 $i$，满足 $|a_{ii}| &gt; \sum_{j&#x3D;1, j \neq i}^{n} |a_{ij}|$。</li>
<li>矩阵 $A$ 是不可约的对角占优矩阵。</li>
</ul>
</li>
</ul>
</li>
<li><strong>算法步骤：</strong><ol>
<li>将矩阵 $A$ 分解为 $D - L - U$。</li>
<li>计算迭代矩阵 $B_J &#x3D; D^{-1}(L + U)$ 和向量 $f &#x3D; D^{-1}b$。</li>
<li>选择初始向量 $x^{(0)}$。</li>
<li>迭代计算 $x^{(k+1)} &#x3D; B_J x^{(k)} + f$，直到满足收敛条件（例如，$|x^{(k+1)} - x^{(k)}| &lt; \epsilon$，其中 $\epsilon$ 是一个很小的正数）。</li>
</ol>
</li>
<li><strong>优点：</strong><ul>
<li>每次迭代的计算量较小。</li>
<li>算法简单，容易实现。</li>
</ul>
</li>
<li><strong>缺点：</strong><ul>
<li>收敛速度可能较慢。</li>
<li>收敛条件较为苛刻，可能不收敛。</li>
<li>需要存储多个向量，占用内存空间较大。</li>
</ul>
</li>
</ul>
<p><strong>2. Gauss-Seidel 迭代</strong></p>
<ul>
<li><strong>原理：</strong> Gauss-Seidel 迭代也是一种求解线性方程组 $Ax &#x3D; b$ 的迭代方法。与 Jacobi 迭代类似，它也将系数矩阵 $A$ 分解为 $A &#x3D; D - L - U$。不同之处在于，Gauss-Seidel 迭代在计算 $x_i^{(k+1)}$ 时，会立即使用已经计算出的 $x_1^{(k+1)}, x_2^{(k+1)}, \dots, x_{i-1}^{(k+1)}$，而不是像 Jacobi 迭代那样使用上一轮迭代的值。</li>
<li><strong>公式：</strong> 将 $A &#x3D; D - L - U$ 代入 $Ax &#x3D; b$，得到：<br>$(D - L - U)x &#x3D; b$<br>$(D - L)x &#x3D; Ux + b$<br>$x &#x3D; (D - L)^{-1}Ux + (D - L)^{-1}b$<br>因此，Gauss-Seidel 迭代的迭代公式为：<br>$x^{(k+1)} &#x3D; (D - L)^{-1}Ux^{(k)} + (D - L)^{-1}b$<br>或者写成逐个分量的形式：<br>$x_i^{(k+1)} &#x3D; \frac{1}{a_{ii}} \left(b_i - \sum_{j&#x3D;1}^{i-1} a_{ij} x_j^{(k+1)} - \sum_{j&#x3D;i+1}^{n} a_{ij} x_j^{(k)}\right)$,  $i &#x3D; 1, 2, \dots, n$</li>
<li><strong>收敛性条件：</strong> Gauss-Seidel 迭代的收敛性取决于迭代矩阵 $B_{GS} &#x3D; (D - L)^{-1}U$ 的谱半径 $\rho(B_{GS})$。<ul>
<li>如果 $\rho(B_{GS}) &lt; 1$，则 Gauss-Seidel 迭代收敛。</li>
<li>充分条件：<ul>
<li>矩阵 $A$ 是严格对角占优矩阵。</li>
<li>矩阵 $A$ 是对称正定矩阵。</li>
</ul>
</li>
</ul>
</li>
<li><strong>算法步骤：</strong><ol>
<li>将矩阵 $A$ 分解为 $D - L - U$。</li>
<li>选择初始向量 $x^{(0)}$。</li>
<li>对于 $i &#x3D; 1, 2, \dots, n$，依次计算 $x_i^{(k+1)} &#x3D; \frac{1}{a_{ii}} \left(b_i - \sum_{j&#x3D;1}^{i-1} a_{ij} x_j^{(k+1)} - \sum_{j&#x3D;i+1}^{n} a_{ij} x_j^{(k)}\right)$。</li>
<li>重复步骤 3，直到满足收敛条件。</li>
</ol>
</li>
<li><strong>优点：</strong><ul>
<li>通常比 Jacobi 迭代收敛速度更快。</li>
<li>只需要存储一个向量，占用内存空间较小。</li>
</ul>
</li>
<li><strong>缺点：</strong><ul>
<li>每次迭代的计算量比 Jacobi 迭代略大。</li>
<li>收敛性分析比 Jacobi 迭代更复杂。</li>
<li>不适合并行计算，因为计算依赖于之前的结果。</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/notes.github.io/page/2/">2</a><a class="page-number" href="/notes.github.io/page/3/">3</a><a class="extend next" rel="next" href="/notes.github.io/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Chen Zhan"
      src="/notes.github.io/images/woshicaigou.jpg">
  <p class="site-author-name" itemprop="name">Chen Zhan</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/notes.github.io/archives/">
        
          <span class="site-state-item-count">23</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chen Zhan</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/notes.github.io/lib/anime.min.js"></script>
  <script src="/notes.github.io/lib/velocity/velocity.min.js"></script>
  <script src="/notes.github.io/lib/velocity/velocity.ui.min.js"></script>

<script src="/notes.github.io/js/utils.js"></script>

<script src="/notes.github.io/js/motion.js"></script>


<script src="/notes.github.io/js/schemes/pisces.js"></script>


<script src="/notes.github.io/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
